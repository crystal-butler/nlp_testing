{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alabaster==0.7.10 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.7.10)\n",
      "Requirement already satisfied: anaconda-client==1.6.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: anaconda-navigator==1.6.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.6.2)\n",
      "Requirement already satisfied: anaconda-project==0.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.6.0)\n",
      "Requirement already satisfied: appnope==0.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.1.0)\n",
      "Requirement already satisfied: asn1crypto==0.22.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.22.0)\n",
      "Requirement already satisfied: astroid==1.4.9 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.4.9)\n",
      "Requirement already satisfied: astropy==2.0.9 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.0.9)\n",
      "Requirement already satisfied: attrs==19.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (19.3.0)\n",
      "Requirement already satisfied: Babel==2.4.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.4.0)\n",
      "Requirement already satisfied: backcall==0.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: backports.shutil-get-terminal-size==1.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (4.6.0)\n",
      "Requirement already satisfied: bitarray==0.8.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (0.8.1)\n",
      "Requirement already satisfied: blaze==0.10.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (0.10.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (1.5.0)\n",
      "Requirement already satisfied: bokeh==0.12.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (0.12.5)\n",
      "Requirement already satisfied: boto==2.46.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (2.46.1)\n",
      "Requirement already satisfied: boto3==1.12.26 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (1.12.26)\n",
      "Requirement already satisfied: botocore==1.15.26 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 20)) (1.15.26)\n",
      "Requirement already satisfied: Bottleneck==1.2.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 21)) (1.2.1)\n",
      "Requirement already satisfied: brewer2mpl==1.4.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (1.4.1)\n",
      "Requirement already satisfied: cec2005real==0.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages/cec2005real-0.1-py3.6-linux-x86_64.egg (from -r requirements.txt (line 23)) (0.1)\n",
      "Requirement already satisfied: cec2013lsgo==2.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (2.2)\n",
      "Requirement already satisfied: certifi==2019.9.11 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (2019.9.11)\n",
      "Requirement already satisfied: cffi==1.10.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 26)) (1.10.0)\n",
      "Requirement already satisfied: chardet==3.0.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 27)) (3.0.3)\n",
      "Requirement already satisfied: click==6.7 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 28)) (6.7)\n",
      "Requirement already satisfied: cloudpickle==0.2.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 29)) (0.2.2)\n",
      "Requirement already satisfied: clyent==1.2.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 30)) (1.2.2)\n",
      "Requirement already satisfied: colorama==0.3.9 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 31)) (0.3.9)\n",
      "Requirement already satisfied: conda==4.7.12 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 32)) (4.7.12)\n",
      "Requirement already satisfied: conda-package-handling==1.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 33)) (1.6.0)\n",
      "Requirement already satisfied: contextlib2==0.5.5 in /home/jupyter/.local/lib/python3.6/site-packages (from -r requirements.txt (line 34)) (0.5.5)\n",
      "Requirement already satisfied: cryptography==2.8 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 35)) (2.8)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 36)) (0.10.0)\n",
      "Requirement already satisfied: Cython==0.27.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 37)) (0.27.3)\n",
      "Requirement already satisfied: cytoolz==0.8.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 38)) (0.8.2)\n",
      "Requirement already satisfied: dask==2.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 39)) (2.6.0)\n",
      "Requirement already satisfied: datashape==0.5.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 40)) (0.5.4)\n",
      "Requirement already satisfied: decorator==4.0.11 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 41)) (4.0.11)\n",
      "Requirement already satisfied: distributed==1.16.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 42)) (1.16.3)\n",
      "Requirement already satisfied: docutils==0.13.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 43)) (0.13.1)\n",
      "Requirement already satisfied: entrypoints==0.2.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 44)) (0.2.2)\n",
      "Requirement already satisfied: environment-kernels==1.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 45)) (1.1)\n",
      "Requirement already satisfied: et-xmlfile==1.0.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 46)) (1.0.1)\n",
      "Requirement already satisfied: fastcache==1.0.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 47)) (1.0.2)\n",
      "Requirement already satisfied: Flask==0.12.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 48)) (0.12.2)\n",
      "Requirement already satisfied: Flask-Cors==3.0.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 49)) (3.0.2)\n",
      "Requirement already satisfied: future==0.16.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 50)) (0.16.0)\n",
      "Requirement already satisfied: gevent==1.2.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 51)) (1.2.1)\n",
      "Requirement already satisfied: glfw==1.5.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 52)) (1.5.1)\n",
      "Requirement already satisfied: greenlet==0.4.12 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 53)) (0.4.12)\n",
      "Requirement already satisfied: gym==0.10.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 54)) (0.10.5)\n",
      "Requirement already satisfied: h5py==2.9.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 55)) (2.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: HeapDict==1.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 56)) (1.0.0)\n",
      "Requirement already satisfied: html5lib==0.999 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 57)) (0.999)\n",
      "Requirement already satisfied: idna==2.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 58)) (2.5)\n",
      "Requirement already satisfied: ImageHash==4.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 59)) (4.0)\n",
      "Requirement already satisfied: imageio==2.6.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 60)) (2.6.1)\n",
      "Requirement already satisfied: imagesize==0.7.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 61)) (0.7.1)\n",
      "Requirement already satisfied: import-ipynb==0.1.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 62)) (0.1.3)\n",
      "Requirement already satisfied: imutils==0.5.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 63)) (0.5.2)\n",
      "Requirement already satisfied: inflection==0.3.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 64)) (0.3.1)\n",
      "Requirement already satisfied: ipdb==0.11 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 65)) (0.11)\n",
      "Requirement already satisfied: ipykernel==4.6.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 66)) (4.6.1)\n",
      "Requirement already satisfied: ipython==5.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 67)) (5.3.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 68)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==7.0.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 69)) (7.0.1)\n",
      "Requirement already satisfied: isort==4.2.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 70)) (4.2.5)\n",
      "Requirement already satisfied: itsdangerous==0.24 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 71)) (0.24)\n",
      "Requirement already satisfied: jdcal==1.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 72)) (1.3)\n",
      "Requirement already satisfied: jedi==0.10.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 73)) (0.10.2)\n",
      "Requirement already satisfied: Jinja2==2.9.6 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 74)) (2.9.6)\n",
      "Requirement already satisfied: jmespath==0.9.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 75)) (0.9.5)\n",
      "Requirement already satisfied: joblib==0.13.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 76)) (0.13.2)\n",
      "Requirement already satisfied: jsonschema==2.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 77)) (2.6.0)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 78)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client==5.0.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 79)) (5.0.1)\n",
      "Requirement already satisfied: jupyter-console==5.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 80)) (5.1.0)\n",
      "Requirement already satisfied: jupyter-core==4.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 81)) (4.3.0)\n",
      "Requirement already satisfied: jupyterlab==0.35.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 82)) (0.35.4)\n",
      "Requirement already satisfied: jupyterlab-server==0.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 83)) (0.2.0)\n",
      "Requirement already satisfied: kiwisolver==1.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 84)) (1.1.0)\n",
      "Requirement already satisfied: lazy-object-proxy==1.2.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 85)) (1.2.2)\n",
      "Requirement already satisfied: llvmlite==0.30.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 86)) (0.30.0)\n",
      "Requirement already satisfied: locket==0.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 87)) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe==0.23 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 88)) (0.23)\n",
      "Requirement already satisfied: matplotlib==3.1.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 89)) (3.1.1)\n",
      "Requirement already satisfied: mistune==0.7.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 90)) (0.7.4)\n",
      "Requirement already satisfied: mkl-fft==1.0.12 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 91)) (1.0.12)\n",
      "Requirement already satisfied: mkl-random==1.0.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 92)) (1.0.2)\n",
      "Requirement already satisfied: mkl-service==2.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 93)) (2.3.0)\n",
      "Requirement already satisfied: mock==3.0.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 94)) (3.0.5)\n",
      "Requirement already satisfied: mpmath==0.19 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 95)) (0.19)\n",
      "Requirement already satisfied: msgpack-python==0.4.8 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 96)) (0.4.8)\n",
      "Requirement already satisfied: multipledispatch==0.4.9 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 97)) (0.4.9)\n",
      "Requirement already satisfied: navigator-updater==0.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 98)) (0.1.0)\n",
      "Requirement already satisfied: nbconvert==5.1.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 99)) (5.1.1)\n",
      "Requirement already satisfied: nbformat==4.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 100)) (4.3.0)\n",
      "Requirement already satisfied: networkx==1.11 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 101)) (1.11)\n",
      "Requirement already satisfied: nltk==3.2.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 102)) (3.2.3)\n",
      "Requirement already satisfied: nose==1.3.7 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 103)) (1.3.7)\n",
      "Requirement already satisfied: notebook==5.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 104)) (5.0.0)\n",
      "Requirement already satisfied: numba==0.46.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 105)) (0.46.0)\n",
      "Requirement already satisfied: numexpr==2.7.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 106)) (2.7.0)\n",
      "Requirement already satisfied: numpy==1.17.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 107)) (1.17.3)\n",
      "Requirement already satisfied: numpydoc==0.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 108)) (0.6.0)\n",
      "Requirement already satisfied: nvidia-ml-py==3.295.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 109)) (3.295.0)\n",
      "Requirement already satisfied: odo==0.5.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 110)) (0.5.0)\n",
      "Requirement already satisfied: olefile==0.44 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 111)) (0.44)\n",
      "Requirement already satisfied: openpyxl==2.4.7 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 112)) (2.4.7)\n",
      "Requirement already satisfied: packaging==16.8 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 113)) (16.8)\n",
      "Requirement already satisfied: pandas==0.24.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 114)) (0.24.2)\n",
      "Requirement already satisfied: pandocfilters==1.4.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 115)) (1.4.1)\n",
      "Requirement already satisfied: partd==0.3.8 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 116)) (0.3.8)\n",
      "Requirement already satisfied: pathlib2==2.2.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 117)) (2.2.1)\n",
      "Requirement already satisfied: patsy==0.4.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 118)) (0.4.1)\n",
      "Requirement already satisfied: pep8==1.7.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 119)) (1.7.0)\n",
      "Requirement already satisfied: pexpect==4.2.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 120)) (4.2.1)\n",
      "Requirement already satisfied: pickleshare==0.7.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 121)) (0.7.4)\n",
      "Requirement already satisfied: Pillow==6.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 122)) (6.2.0)\n",
      "Requirement already satisfied: ply==3.10 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 123)) (3.10)\n",
      "Requirement already satisfied: profanityfilter==2.0.6 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 124)) (2.0.6)\n",
      "Requirement already satisfied: prompt-toolkit==1.0.14 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 125)) (1.0.14)\n",
      "Requirement already satisfied: psutil==5.2.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 126)) (5.2.2)\n",
      "Requirement already satisfied: ptyprocess==0.5.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 127)) (0.5.1)\n",
      "Requirement already satisfied: py==1.4.33 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 128)) (1.4.33)\n",
      "Requirement already satisfied: pycosat==0.6.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 129)) (0.6.3)\n",
      "Requirement already satisfied: pycparser==2.17 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 130)) (2.17)\n",
      "Requirement already satisfied: pycrypto==2.6.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 131)) (2.6.1)\n",
      "Requirement already satisfied: pycurl==7.43.0.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 132)) (7.43.0.3)\n",
      "Requirement already satisfied: pyflakes==1.5.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 133)) (1.5.0)\n",
      "Requirement already satisfied: pyglet==1.3.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 134)) (1.3.2)\n",
      "Requirement already satisfied: Pygments==2.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 135)) (2.2.0)\n",
      "Requirement already satisfied: pylint==1.6.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 136)) (1.6.4)\n",
      "Requirement already satisfied: pyodbc==4.0.16 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 137)) (4.0.16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyOpenSSL==17.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 138)) (17.0.0)\n",
      "Requirement already satisfied: pyparsing==2.1.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 139)) (2.1.4)\n",
      "Requirement already satisfied: PySocks==1.6.8 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 140)) (1.6.8)\n",
      "Requirement already satisfied: pytest==3.0.7 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 141)) (3.0.7)\n",
      "Requirement already satisfied: pytest-instafail==0.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 142)) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil==2.6.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 143)) (2.6.0)\n",
      "Requirement already satisfied: pytorch-pretrained-bert==0.6.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 144)) (0.6.2)\n",
      "Requirement already satisfied: pytz==2017.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 145)) (2017.2)\n",
      "Requirement already satisfied: PyWavelets==1.1.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 146)) (1.1.1)\n",
      "Requirement already satisfied: PyYAML==3.12 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 147)) (3.12)\n",
      "Requirement already satisfied: pyzmq==16.0.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 148)) (16.0.2)\n",
      "Requirement already satisfied: QtAwesome==0.4.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 149)) (0.4.4)\n",
      "Requirement already satisfied: qtconsole==4.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 150)) (4.3.0)\n",
      "Requirement already satisfied: QtPy==1.2.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 151)) (1.2.1)\n",
      "Requirement already satisfied: regex==2020.2.20 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 152)) (2020.2.20)\n",
      "Requirement already satisfied: requests==2.21.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 153)) (2.21.0)\n",
      "Requirement already satisfied: rope-py3k==0.9.4.post1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 154)) (0.9.4.post1)\n",
      "Requirement already satisfied: ruamel.yaml==0.16.10 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 155)) (0.16.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib==0.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 156)) (0.2.0)\n",
      "Requirement already satisfied: s3transfer==0.3.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 157)) (0.3.3)\n",
      "Requirement already satisfied: scikit-image==0.15.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 158)) (0.15.0)\n",
      "Requirement already satisfied: scikit-learn==0.21.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 159)) (0.21.3)\n",
      "Requirement already satisfied: scipy==1.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 160)) (1.1.0)\n",
      "Requirement already satisfied: seaborn==0.7.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 161)) (0.7.1)\n",
      "Requirement already satisfied: simplegeneric==0.8.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 162)) (0.8.1)\n",
      "Requirement already satisfied: singledispatch==3.4.0.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 163)) (3.4.0.3)\n",
      "Requirement already satisfied: six==1.10.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 164)) (1.10.0)\n",
      "Requirement already satisfied: snowballstemmer==1.2.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 165)) (1.2.1)\n",
      "Requirement already satisfied: sortedcollections==0.5.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 166)) (0.5.3)\n",
      "Requirement already satisfied: sortedcontainers==1.5.7 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 167)) (1.5.7)\n",
      "Requirement already satisfied: Sphinx==1.5.6 in /home/jupyter/anaconda3/lib/python3.6/site-packages/Sphinx-1.5.6-py3.6.egg (from -r requirements.txt (line 168)) (1.5.6)\n",
      "Requirement already satisfied: sphinx-rtd-theme==0.2.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 169)) (0.2.4)\n",
      "Requirement already satisfied: spyder==3.1.4 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 170)) (3.1.4)\n",
      "Requirement already satisfied: SQLAlchemy==1.1.9 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 171)) (1.1.9)\n",
      "Requirement already satisfied: statsmodels==0.10.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 172)) (0.10.1)\n",
      "Requirement already satisfied: sympy==1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 173)) (1.0)\n",
      "Requirement already satisfied: tables==3.5.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 174)) (3.5.2)\n",
      "Requirement already satisfied: tblib==1.3.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 175)) (1.3.2)\n",
      "Requirement already satisfied: terminado==0.6 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 176)) (0.6)\n",
      "Requirement already satisfied: testpath==0.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 177)) (0.3)\n",
      "Requirement already satisfied: toolz==0.8.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 178)) (0.8.2)\n",
      "Requirement already satisfied: torch==1.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 179)) (1.3.0)\n",
      "Requirement already satisfied: torchvision==0.4.1a0+d94043a in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 180)) (0.4.1a0+d94043a)\n",
      "Requirement already satisfied: tornado==4.5.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 181)) (4.5.1)\n",
      "Requirement already satisfied: tqdm==4.36.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 182)) (4.36.1)\n",
      "Requirement already satisfied: traitlets==4.3.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 183)) (4.3.2)\n",
      "Requirement already satisfied: unicodecsv==0.14.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 184)) (0.14.1)\n",
      "Requirement already satisfied: urllib3==1.24.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 185)) (1.24.1)\n",
      "Requirement already satisfied: wcwidth==0.1.7 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 186)) (0.1.7)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 187)) (0.5.1)\n",
      "Requirement already satisfied: Werkzeug==0.12.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 188)) (0.12.2)\n",
      "Requirement already satisfied: widgetsnbextension==3.0.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 189)) (3.0.2)\n",
      "Requirement already satisfied: wrapt==1.10.10 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 190)) (1.10.10)\n",
      "Requirement already satisfied: xlrd==1.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 191)) (1.0.0)\n",
      "Requirement already satisfied: XlsxWriter==0.9.6 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 192)) (0.9.6)\n",
      "Requirement already satisfied: xlwt==1.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 193)) (1.2.0)\n",
      "Requirement already satisfied: yapf==0.29.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 194)) (0.29.0)\n",
      "Requirement already satisfied: zict==0.1.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 195)) (0.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /home/jupyter/anaconda3/lib/python3.6/site-packages (from ipdb==0.11->-r requirements.txt (line 65)) (40.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_pretrained_bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c89744dba048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_pretrained_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_pretrained_bert'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgusted'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]\n",
    "list(tokenizer.vocab.keys())[17733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-76e0f8f130a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Split the sentence into tokens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# tokenized_text = tokenizer.tokenize(marked_text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "# text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "#        \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# text = \"[CLS] Why the disgusted face [SEP] Did you smell some disgustingly ripe cheese [SEP]\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Add the special tokens.\n",
    "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "# tokenized_text = tokenizer.tokenize(marked_text)\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "# text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "#        \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# text = \"[CLS] Why the disgusted face [SEP] Did you smell some disgustingly ripe cheese [SEP]\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Add the special tokens.\n",
    "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "# tokenized_text = tokenizer.tokenize(marked_text)\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[101, 2016, 2081, 1037, 17733, 13433, 4904, 102, 2014, 17733, 3670, 2001, 9530, 15900, 6313, 102]\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the tokens as belonging to sentence \"0\" or \"1\".\n",
    "# segments_ids = [1] * len(tokenized_text)\n",
    "segments_ids = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]\n",
    "# segments_ids = [0,0,0,1,1]\n",
    "print (segments_ids)\n",
    "print(indexed_tokens)\n",
    "print(tokenized_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 16\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 3\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAI/CAYAAAC4QOfKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVq0lEQVR4nO3df4ytCX3X8c9XBtRIK5CdrhvgemqlNfiDxdyuNGgs0Na1NxGaNI38QdYUvWiKAUNipjRRGk2c/oKYaJpss5vuH9iWSCmkg21XQiRNZHXBLSxsK5RMLduFhdQWTGObpV//uGfXW3rvznzn13PundcrmcxznvOcOd99ZnLnvc9z5jzV3QEA4PD+xNIDAADcaAQUAMCQgAIAGBJQAABDAgoAYEhAAQAMbZ3lk91yyy29Wq3O8ikBAI7kIx/5yBe7e/ta951pQK1Wqzz44INn+ZQAAEdSVb9xvfucwgMAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMDQ1tIDAMDEamfvqeX93UsLTsJ55ggUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGDowICqqj9VVf+tqn6lqj5RVT+4Xv/1VfVAVX26qn6mqp51+uMCACzvMEegfj/JK7v7JUluT3JnVb0syQ8leUd3/8Uk/zvJ609vTACAzXFgQPUV/2d985nrj07yyiT/cb3+viSvOZUJAQA2zKFeA1VVz6iqh5I8nuT+JL+e5He6+4n1Jp9N8vzTGREAYLNsHWaj7v5Kktur6jlJ3pPkLx32CarqcpLLSXLhwoWjzAgAWe3sLT0CPGX0V3jd/TtJPpjkW5I8p6qeDLAXJHn0Oo+5u7svdvfF7e3tYw0LALAJDvNXeNvrI0+pqj+d5NuTPJIrIfXd683uSvLe0xoSAGCTHOYU3m1J7quqZ+RKcL2ru3++qj6Z5Ker6l8n+R9J7jnFOQEANsaBAdXdH0vy0mus/0ySO05jKACATeadyAEAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDW0sPAABnZbWz99Ty/u6lBSfhRucIFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUABtntbOX1c7e0mPAdQkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMbS09AADn22pnL0myv3vp1J8DToojUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwdGFBV9cKq+mBVfbKqPlFVb1qvf1tVPVpVD60/vvP0xwUAWN5hLib8RJK3dPdHq+prknykqu5f3/eO7v7R0xsPAGDzHBhQ3f1YksfWy1+uqkeSPP+0BwMA2FSj10BV1SrJS5M8sF71xqr6WFXdW1XPPeHZAAA20qEDqqqeneTdSd7c3V9K8uNJviHJ7blyhOrHrvO4y1X1YFU9+IUvfOEERgYAWNahAqqqnpkr8fTO7v7ZJOnuz3f3V7r7D5P8RJI7rvXY7r67uy9298Xt7e2TmhsAYDGH+Su8SnJPkke6++1Xrb/tqs2+K8nDJz8eAMDmOcxf4b08yeuSfLyqHlqve2uS11bV7Uk6yX6SN5zKhAAAG+Ywf4X3y0nqGne9/+THAQDYfN6JHABgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAA4BpWO3tZ7ewtPQYbSkABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAXDDWu3sZbWzd+A6OGkCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhg4MqKp6YVV9sKo+WVWfqKo3rdc/r6rur6pPrT8/9/THBQBY3mGOQD2R5C3d/eIkL0vyfVX14iQ7ST7Q3S9K8oH1bQCAm96BAdXdj3X3R9fLX07ySJLnJ3l1kvvWm92X5DWnNSQAwCYZvQaqqlZJXprkgSS3dvdj67s+l+TWE50MAGBDbR12w6p6dpJ3J3lzd3+pqp66r7u7qvo6j7uc5HKSXLhw4XjTAnDDWe3sJUn2dy/9sXWHfSxsmkMdgaqqZ+ZKPL2zu392vfrzVXXb+v7bkjx+rcd2993dfbG7L25vb5/EzAAAizrMX+FVknuSPNLdb7/qrvcluWu9fFeS9578eAAAm+cwp/BenuR1ST5eVQ+t1701yW6Sd1XV65P8RpLvOZ0RAQA2y4EB1d2/nKSuc/erTnYcAIDN553IAQCGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGDrMxYQB4NStdvaWHuFAT864v3tp4UlYmiNQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAY2lp6AAA4rtXO3tIjcM44AgUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBXCOrXb2strZ29ivB5tKQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYGhr6QEAuHGsdvaeWt7fvbTgJAe7elY4aY5AAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMHRgQFXVvVX1eFU9fNW6t1XVo1X10PrjO093TACAzXGYI1A/meTOa6x/R3ffvv54/8mOBQCwuQ4MqO7+UJLfPoNZAABuCMd5DdQbq+pj61N8zz2xiQAANtzWER/340n+VZJef/6xJN97rQ2r6nKSy0ly4cKFIz4dAJtqtbO39AhHcq2593cvHWo7ONIRqO7+fHd/pbv/MMlPJLnjaba9u7svdvfF7e3to84JALAxjhRQVXXbVTe/K8nD19sWAOBmc+ApvKr6qSTfmuSWqvpskn+Z5Fur6vZcOYW3n+QNpzgjAMBGOTCguvu111h9zynMAgBwQ/BO5AAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAoQMvJgwAJ2G1s7f0CHBiHIECABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMDQ1tIDAHBjWu3sLT3CibsZ/5s4HY5AAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAENbSw8AwPJWO3tPLe/vXrruuqN8vZvRcfYNNwdHoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMLS19AAAnI3Vzl6SZH/30qG243CutV+fbl9fvX8P+l6wuRyBAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMHRhQVXVvVT1eVQ9fte55VXV/VX1q/fm5pzsmAMDmOMwRqJ9McudXrdtJ8oHuflGSD6xvAwCcCwcGVHd/KMlvf9XqVye5b718X5LXnPBcAAAb66ivgbq1ux9bL38uya0nNA8AwMbbOu4X6O6uqr7e/VV1OcnlJLlw4cJxnw6ABax29pYeATbKUY9Afb6qbkuS9efHr7dhd9/d3Re7++L29vYRnw4AYHMcNaDel+Su9fJdSd57MuMAAGy+w7yNwU8l+a9JvqmqPltVr0+ym+Tbq+pTSb5tfRsA4Fw48DVQ3f3a69z1qhOeBQDghuCdyAEAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABg68Fp4AMDpWu3sPbW8v3tpwUk4LEegAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwtLX0AACcrNXO3lPL+7uXFpzkfLl6v19rne/FzcURKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADG0tPQAAR7fa2XtqeX/30oKTcBRXf/+4sTgCBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAoa2lBwDgZKx29pYegadx2O/P1dvt71667v3Xuo+z4wgUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQ8e6Fl5V7Sf5cpKvJHmiuy+exFAAAJvsJC4m/Iru/uIJfB0AgBuCU3gAAEPHDahO8ktV9ZGqunwSAwEAbLrjnsL7m939aFV9XZL7q+pXu/tDV2+wDqvLSXLhwoVjPh0AnD+rnb1DrdvfvXQW45BjHoHq7kfXnx9P8p4kd1xjm7u7+2J3X9ze3j7O0wEAbIQjB1RV/Zmq+ponl5N8R5KHT2owAIBNdZxTeLcmeU9VPfl1/kN3/8KJTAUAsMGOHFDd/ZkkLznBWQAAbgjexgAAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMHTkiwkDcDZWO3t/bN3+7qUjP/Za69hMvlebyxEoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMbS09AABzq529pUdgwz35M7K/e2nhSW5OjkABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQ1tLDwDA/7fa2UuS7O9eWngSbkRP/vxcb92TP1fXWnfQY/ijHIECABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMDQ1tIDnLTVzt5Ty/u7lxacBLgRXP1vxtO51r8nBz326sc8ue1hv85h54KJp/tZO8rvzLP+nbtJv+MdgQIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADB0roKrqzqr6tar6dFXtnNRQAACb7MgBVVXPSPLvk/zdJC9O8tqqevFJDQYAsKmOcwTqjiSf7u7PdPcfJPnpJK8+mbEAADbXcQLq+Ul+86rbn12vAwC4qVV3H+2BVd+d5M7u/ofr269L8je6+41ftd3lJJfXN78pya8dfdwjuyXJFxd43vPOfl+G/X727PNl2O/LOE/7/c939/a17tg6xhd9NMkLr7r9gvW6P6K7705y9zGe59iq6sHuvrjkDOeR/b4M+/3s2efLsN+XYb9fcZxTeP89yYuq6uur6llJ/n6S953MWAAAm+vIR6C6+4mqemOSX0zyjCT3dvcnTmwyAIANdZxTeOnu9yd5/wnNcpoWPYV4jtnvy7Dfz559vgz7fRn2e47xInIAgPPKpVwAAIbOTUBV1e1V9eGqeqiqHqyqO5ae6byoqn9aVb9aVZ+oqh9eep7zoqreUlVdVbcsPct5UFU/sv45/1hVvaeqnrP0TDczlxI7e1X1wqr6YFV9cv3v+ZuWnmlJ5yagkvxwkh/s7tuT/Iv1bU5ZVb0iV96h/iXd/ZeT/OjCI50LVfXCJN+R5H8tPcs5cn+Sv9Ldfy3J/0zy/QvPc9NyKbHFPJHkLd394iQvS/J953m/n6eA6iRfu17+s0l+a8FZzpN/kmS3u38/Sbr78YXnOS/ekeSf58rPPWegu3+pu59Y3/xwrrw3HqfDpcQW0N2PdfdH18tfTvJIzvEVSM5TQL05yY9U1W/mylEQ/3d4Nr4xyd+qqgeq6r9U1TcvPdDNrqpeneTR7v6VpWc5x743yX9aeoibmEuJLayqVklemuSBZSdZzrHexmDTVNV/TvLnrnHXDyR5VZJ/1t3vrqrvSXJPkm87y/luVgfs960kz8uVw73fnORdVfUX2p9/HssB+/ytuXL6jhP2dPu9u9+73uYHcuVUxzvPcjY4K1X17CTvTvLm7v7S0vMs5dy8jUFV/W6S53R3V1Ul+d3u/tqDHsfxVNUvJPmh7v7g+vavJ3lZd39h2cluTlX1V5N8IMnvrVe9IFdOV9/R3Z9bbLBzoqr+QZI3JHlVd//eAZtzRFX1LUne1t1/Z337+5Oku//NooOdA1X1zCQ/n+QXu/vtS8+zpPN0Cu+3kvzt9fIrk3xqwVnOk59L8ookqapvTPKsnJ+LUJ657v54d39dd6+6e5Urpzb+ung6fVV1Z6687uzviadT51JiC1gffLgnySPnPZ6Sm+wU3gH+UZJ/W1VbSf5vkssLz3Ne3Jvk3qp6OMkfJLnL6TtuUv8uyZ9Mcv+V3zP5cHf/42VHujm5lNhiXp7kdUk+XlUPrde9dX1VknPn3JzCAwA4KefpFB4AwIkQUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwND/Aw1CmUpE/A0fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 4\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# print(vec)\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type of encoded_layers:  <class 'list'>\n",
      "Tensor shape for each layer:  torch.Size([1, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 16, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 16 x 3072\n",
      "tensor([ 0.1730,  0.5220, -0.6051,  ..., -0.4742,  0.0104,  0.4212])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 16 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 16 x 3072\n",
      "tensor([ 0.1730,  0.5220, -0.6051,  ..., -0.4742,  0.0104,  0.4212])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:4], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_first.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_first), len(token_vecs_sum_first[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 3072\n",
      "tensor([ 0.1730,  0.5220, -0.6051,  ..., -0.4742,  0.0104,  0.4212])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[4:8], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle1.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle1), len(token_vecs_sum_middle1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 3072\n",
      "tensor([ 0.1730,  0.5220, -0.6051,  ..., -0.4742,  0.0104,  0.4212])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[8:12], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle2.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle2), len(token_vecs_sum_middle2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_all\n",
    ".333333333333333= []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n",
      "tensor(0.0927)\n",
      "tensor(0.0927)\n",
      "Shape of sentences vector is: 768\n",
      "tensor(0.0927)\n"
     ]
    }
   ],
   "source": [
    "# Make a single vector to represent the pair of sentences by averaging across tokens.\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "sentences_vec = []\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "for s in sentence_embedding:\n",
    "    sentences_vec.append(s)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "print(sentence_embedding[767])\n",
    "print(sentence_embedding[-1])\n",
    "print(f'Shape of sentences vector is: {len(sentences_vec)}')\n",
    "print(sentences_vec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 she\n",
      "2 made\n",
      "3 a\n",
      "4 disgusted\n",
      "5 po\n",
      "6 ##ut\n",
      "7 [SEP]\n",
      "8 her\n",
      "9 disgusted\n",
      "10 expression\n",
      "11 was\n",
      "12 con\n",
      "13 ##tag\n",
      "14 ##ious\n",
      "15 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_string in enumerate(tokenized_text):\n",
    "    print(i, token_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of disgusted and disgusted in token_vecs_cat is: 0.7731837630271912\n",
      "Similarity of disgusted and disgusted in token_vecs_sum is: 0.7783510684967041\n",
      "Similarity of disgusted and disgusted in token_vecs_cat_first is: 0.8062489628791809\n",
      "Similarity of disgusted and disgusted in token_vecs_sum_first is: 0.6329748630523682\n",
      "Similarity of disgusted and disgusted in token_vecs_cat_middle1 is: 0.6662847995758057\n",
      "Similarity of disgusted and disgusted in token_vecs_sum_middle1 is: 0.6929298043251038\n",
      "Similarity of disgusted and disgusted in token_vecs_cat_middle2 is: 0.6831039786338806\n",
      "Similarity of disgusted and disgusted in token_vecs_sum_middle2 is: 0.7416453957557678\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "similarity = 1 - cosine(token_vecs_cat[4], token_vecs_cat[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum[4], token_vecs_sum[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_first[4], token_vecs_cat_first[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_first is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_first[4], token_vecs_sum_first[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_first is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_middle1[4], token_vecs_cat_middle1[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle1 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_middle1[4], token_vecs_sum_middle1[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle1 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_middle2[4], token_vecs_cat_middle2[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle2 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_middle2[4], token_vecs_sum_middle2[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle2 is: {similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
