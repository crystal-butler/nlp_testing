{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Notebooks/crystal/NLP/nlp_testing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgusted'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]\n",
    "list(tokenizer.vocab.keys())[17733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"disgusted\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreate vocabulary words from their tokenized representations.\n",
    "for t in tokenized_text:\n",
    "    this_word = ''\n",
    "    for token in t:\n",
    "        this_word += token.strip('#')\n",
    "#     print(this_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mark each of the tokens as belonging to sentence \"0\" or \"1\".\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text[3])\n",
    "# segments_ids = [0,0,0]\n",
    "print (segments_ids)\n",
    "print(indexed_tokens)\n",
    "print(tokenized_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens[3]])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 1\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For our token, select its feature values from layer 5.\n",
    "token_i = 1\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# print(vec)\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 1 x 3072\n",
      "tensor([-0.2373,  0.8259, -0.6190,  ..., -0.3836, -0.5039,  0.6153])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_last = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "print(token_vecs_cat_last[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 1 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_last = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_last.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_last), len(token_vecs_sum_last[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the first 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the first 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:4], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_first.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_first), len(token_vecs_sum_first[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[4:8], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle1.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle1), len(token_vecs_sum_middle1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[8:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle2.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle2), len(token_vecs_sum_middle2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate all hidden layers to create word embeddings.\n",
    "token_vecs_cat_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3], token[4], token[5], token[6], token[7], token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_all.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_all), len(token_vecs_cat_all[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum all hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_all.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_all), len(token_vecs_sum_all[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a single vector to represent the pair of sentences by averaging across tokens.\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "sentences_vec = []\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "for s in sentence_embedding:\n",
    "    sentences_vec.append(s)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "print(sentence_embedding[767])\n",
    "print(sentence_embedding[-1])\n",
    "print(f'Shape of sentences vector is: {len(sentences_vec)}')\n",
    "print(sentences_vec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# Test the similarity of a word with itself.\n",
    "# For words trained contextually, self-synonymy is less than 1.\n",
    "similarity = 1 - cosine(token_vecs_cat[0], token_vecs_cat[0])\n",
    "print(f'Similarity of {tokenized_text[8]} and {tokenized_text[8]} in token_vecs_cat is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum[4], token_vecs_sum[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_first[4], token_vecs_cat_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_first[4], token_vecs_sum_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle1[4], token_vecs_cat_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle1[4], token_vecs_sum_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle2[4], token_vecs_cat_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle2[4], token_vecs_sum_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_all[4], token_vecs_cat_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_all is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_all[4], token_vecs_sum_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_all is: {similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "############## BEGIN TESTING STATIC CONTEXTUAL EMBEDDING CREATION ####################\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(vocab_file):\n",
    "    # start = timer()\n",
    "    vocab = []\n",
    "    # vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "    with open(vocab_file, 'r') as v:\n",
    "        vocab = v.read().splitlines()\n",
    "    # end = timer()\n",
    "    # run_time = end - start\n",
    "#     print(f'There are {len(vocab)} words in the vocabulary.\\n')\n",
    "#     print(f'It took {run_time} seconds to read the vocabulary file into memory.')\n",
    "#     print(f'Test word is {vocab[2]}.')\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(vocab):\n",
    "    tokenized_text = []\n",
    "    indexed_tokens = []\n",
    "    for word in vocab:\n",
    "        # Add the special tokens.\n",
    "    #     marked_text = \"[CLS] \" + word + \" [SEP]\"\n",
    "        marked_text = word\n",
    "\n",
    "        # Split the sentence into tokens.\n",
    "        # tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        tokenized_text.append(tokenizer.tokenize(marked_text))\n",
    "#         print(f'Added {tokenized_text[-1]} to the tokenized_text array.')\n",
    "\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens.append(tokenizer.convert_tokens_to_ids(tokenized_text[-1]))\n",
    "\n",
    "        # Display the words with their indeces.\n",
    "    #     print(f'The word {tokenized_text[-1][1]} is at index {indexed_tokens[-1]}.')\n",
    "#         for tup in zip(tokenized_text[-1], indexed_tokens[-1]):\n",
    "#             print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "    return tokenized_text, indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_segments_IDs(tokenized_text):\n",
    "    # Create segment IDs for sentence 1 (there can be a sentence 0 to compare to\n",
    "    # sentence 1, but we're not doing that).\n",
    "    # Check that indices and token indices look correct.\n",
    "    segments_IDs = []\n",
    "    for i in range(len(tokenized_text)):\n",
    "        segments_IDs.append([1] * len(tokenized_text[i]))\n",
    "#     for i in range(len(segments_IDs)):\n",
    "#         print (segments_IDs[i])\n",
    "#         print(tokenized_text[i])\n",
    "    return segments_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(indexed_tokens, segments_IDs):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_IDs])\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "#         print('Type of encoded_layers: ', type(encoded_layers))\n",
    "        # Each layer in the list is a torch tensor.\n",
    "#         print('Tensor shape for each layer: ', encoded_layers[0].size())\n",
    "\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "#     print(token_embeddings.size())\n",
    "    \n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_last_four(token_embeddings): \n",
    "    # Concatenate the last 4 hidden layers to create contextual embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_last = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "    print(token_vecs_cat_last[0])\n",
    "    \n",
    "    return token_vecs_cat_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_middle_four1(token_embeddings):\n",
    "    # Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_middle1 = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "    print(token_vecs_cat_middle1[0])\n",
    "    \n",
    "    return token_vecs_cat_middle1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_first_four(token_embeddings):\n",
    "    token_vecs_cat_first = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "    print(token_vecs_cat_first[0])\n",
    "    \n",
    "    return token_vecs_cat_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_embedding(token_embeddings):\n",
    "    mean_embedding = sum(token_embeddings) / len(token_embeddings)\n",
    "    print(mean_embedding)\n",
    "    \n",
    "    return mean_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_tokens(tokenized_text):\n",
    "    vocab_word = ''\n",
    "    for i in tokenized_text:\n",
    "        vocab_word += i.strip('#')\n",
    "    print(vocab_word)\n",
    "\n",
    "    return vocab_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_embedding(embeddings_file, vocab_word, contextual_embedding):\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(vocab_word)\n",
    "            for value in contextual_embedding[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {vocab_word}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aback'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3298,  0.4090, -0.5590,  ..., -0.3376, -0.3176,  0.0872])\n",
      "aback\n",
      "Saved the embedding for aback.\n",
      "['aba', '##shed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1815,  0.2656, -0.7644,  ..., -1.2575, -1.1458,  0.3598])\n",
      "abashed\n",
      "Saved the embedding for abashed.\n",
      "['ab', '##hor'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0624, -0.0087,  0.2358,  ..., -0.8970, -0.5811,  0.3655])\n",
      "abhor\n",
      "Saved the embedding for abhor.\n",
      "['ab', '##hor', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1223, -0.0474, -0.1086,  ..., -0.7768, -0.3913,  0.2025])\n",
      "abhorred\n",
      "Saved the embedding for abhorred.\n",
      "['ab', '##hor', '##rence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2506,  0.1359, -0.1205,  ..., -1.0102, -0.0365,  0.6184])\n",
      "abhorrence\n",
      "Saved the embedding for abhorrence.\n",
      "['ab', '##hor', '##rent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0179,  0.1897, -0.2314,  ..., -0.5544, -0.2888,  0.3617])\n",
      "abhorrent\n",
      "Saved the embedding for abhorrent.\n",
      "['ab', '##omi', '##nable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1578,  0.8979,  0.0952,  ..., -0.3193,  0.1398,  0.4150])\n",
      "abominable\n",
      "Saved the embedding for abominable.\n",
      "['ab', '##ound'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1426,  0.2680, -0.3646,  ..., -0.4423, -0.1434,  0.5130])\n",
      "abound\n",
      "Saved the embedding for abound.\n",
      "['absent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0866, -0.0855, -0.1088,  ..., -0.3575, -0.2566, -0.3931])\n",
      "absent\n",
      "Saved the embedding for absent.\n",
      "['absorbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4095,  0.1128,  0.1645,  ..., -0.3897, -0.4331,  0.0083])\n",
      "absorbed\n",
      "Saved the embedding for absorbed.\n",
      "['acceptance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3865,  0.6119,  0.0401,  ..., -1.1459, -0.9382, -0.1727])\n",
      "acceptance\n",
      "Saved the embedding for acceptance.\n",
      "['accepted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1543,  0.8703, -0.4369,  ...,  0.4525, -1.0517, -0.1511])\n",
      "accepted\n",
      "Saved the embedding for accepted.\n",
      "['accepting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0545,  0.1381,  0.8028,  ...,  0.5194, -1.0171, -0.8063])\n",
      "accepting\n",
      "Saved the embedding for accepting.\n",
      "['acc', '##om', '##mo', '##dating'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6630,  0.6453, -0.2709,  ...,  0.1819, -0.2401,  0.4228])\n",
      "accommodating\n",
      "Saved the embedding for accommodating.\n",
      "['accomplished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3669, -0.0713,  0.7407,  ..., -0.9444, -0.1553, -0.6420])\n",
      "accomplished\n",
      "Saved the embedding for accomplished.\n",
      "['accord', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3218,  0.1479, -0.2170,  ..., -0.9971, -0.3591,  0.0091])\n",
      "accordant\n",
      "Saved the embedding for accordant.\n",
      "['acc', '##urse', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9624,  0.3019, -0.1947,  ..., -0.5293, -0.5578,  0.3455])\n",
      "accursed\n",
      "Saved the embedding for accursed.\n",
      "['acc', '##usa', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0799, -0.1087,  0.0370,  ..., -0.1136, -0.4137, -0.0186])\n",
      "accusatory\n",
      "Saved the embedding for accusatory.\n",
      "['accused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2786, -0.2788, -0.3812,  ..., -0.3873,  0.3006, -0.5045])\n",
      "accused\n",
      "Saved the embedding for accused.\n",
      "['accusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0250, -0.1786, -0.0563,  ..., -0.5391, -0.9917, -0.2026])\n",
      "accusing\n",
      "Saved the embedding for accusing.\n",
      "['ace', '##rb', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2449,  0.2530,  1.0058,  ..., -0.6647, -1.1780, -0.0592])\n",
      "acerbic\n",
      "Saved the embedding for acerbic.\n",
      "['acidic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2684,  0.2573,  1.1717,  ...,  0.6794, -1.0125,  0.0324])\n",
      "acidic\n",
      "Saved the embedding for acidic.\n",
      "['active'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2208,  1.5184,  0.6717,  ...,  0.1169, -1.1806, -1.0678])\n",
      "active\n",
      "Saved the embedding for active.\n",
      "['acute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2673, -0.0288,  0.8989,  ...,  0.1480,  0.1528, -0.1960])\n",
      "acute\n",
      "Saved the embedding for acute.\n",
      "['adamant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2781,  0.0886, -0.2748,  ..., -0.4949, -0.3564,  0.3648])\n",
      "adamant\n",
      "Saved the embedding for adamant.\n",
      "['add', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.1486, -0.4951,  0.3470,  ..., -0.9472, -0.4187,  0.8946])\n",
      "addled\n",
      "Saved the embedding for addled.\n",
      "['admiration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1769,  0.5211,  0.0820,  ...,  0.0536, -0.7707,  0.2686])\n",
      "admiration\n",
      "Saved the embedding for admiration.\n",
      "['admit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0577,  0.3112, -0.3257,  ...,  0.4639,  0.2410,  0.8760])\n",
      "admit\n",
      "Saved the embedding for admit.\n",
      "['ad', '##oration'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9220,  0.2051,  0.8889,  ..., -0.8897, -0.2199,  0.8744])\n",
      "adoration\n",
      "Saved the embedding for adoration.\n",
      "['ad', '##orin', '##g'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.0127,  0.0573,  0.0698,  ..., -1.7831, -0.5429, -0.0946])\n",
      "adoring\n",
      "Saved the embedding for adoring.\n",
      "['ad', '##rift'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4195, -0.1363,  0.1555,  ..., -0.9262,  0.1523,  0.9967])\n",
      "adrift\n",
      "Saved the embedding for adrift.\n",
      "['ad', '##vers', '##aria', '##l'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1707,  0.6583,  0.0323,  ..., -0.4385, -0.6767,  0.8419])\n",
      "adversarial\n",
      "Saved the embedding for adversarial.\n",
      "['af', '##fa', '##bility'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2451, -0.4903, -0.6764,  ..., -1.1656, -1.5046,  0.4109])\n",
      "affability\n",
      "Saved the embedding for affability.\n",
      "['affected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1224, -0.1033, -0.1833,  ..., -0.0542,  0.0535, -0.8947])\n",
      "affected\n",
      "Saved the embedding for affected.\n",
      "['affection', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1477,  0.6990,  0.3839,  ...,  0.0793, -1.1106,  0.0712])\n",
      "affectionate\n",
      "Saved the embedding for affectionate.\n",
      "['af', '##flict', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1363, -0.5851, -0.5500,  ..., -1.5200,  0.0285,  0.2404])\n",
      "afflicted\n",
      "Saved the embedding for afflicted.\n",
      "['af', '##front', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2232, -0.6481, -0.7687,  ..., -0.9370, -0.2901,  0.3885])\n",
      "affronted\n",
      "Saved the embedding for affronted.\n",
      "['afl', '##utter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5645,  0.7156, -0.5200,  ..., -0.5875, -0.4523,  0.9127])\n",
      "aflutter\n",
      "Saved the embedding for aflutter.\n",
      "['afraid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2894,  0.4130, -0.3747,  ..., -0.3599, -1.2701,  0.4492])\n",
      "afraid\n",
      "Saved the embedding for afraid.\n",
      "['ag', '##ape'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1513,  0.6968,  0.0687,  ..., -0.3779, -0.0521,  0.1788])\n",
      "agape\n",
      "Saved the embedding for agape.\n",
      "['aggravated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2207, -0.0013,  0.0618,  ..., -0.8973, -1.1103, -0.6496])\n",
      "aggravated\n",
      "Saved the embedding for aggravated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ag', '##gra', '##vation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1651,  0.7620,  0.1863,  ...,  0.1485,  0.2556, -0.3368])\n",
      "aggravation\n",
      "Saved the embedding for aggravation.\n",
      "['aggression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5449,  0.5502,  0.2965,  ..., -0.6756, -0.8149, -0.6476])\n",
      "aggression\n",
      "Saved the embedding for aggression.\n",
      "['aggressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2159,  0.4010,  0.4523,  ..., -0.0068, -0.6904, -0.1985])\n",
      "aggressive\n",
      "Saved the embedding for aggressive.\n",
      "['ag', '##gr', '##ie', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2395,  0.8428,  0.0794,  ..., -0.5343,  0.2387,  0.1088])\n",
      "aggrieve\n",
      "Saved the embedding for aggrieve.\n",
      "['ag', '##gr', '##ie', '##ved'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1582,  0.8501,  0.0612,  ..., -1.1264,  0.3188, -0.2810])\n",
      "aggrieved\n",
      "Saved the embedding for aggrieved.\n",
      "['ag', '##has', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1422,  0.7136,  0.1293,  ..., -0.9572,  0.2532,  0.1865])\n",
      "aghast\n",
      "Saved the embedding for aghast.\n",
      "['agitated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1319,  0.0895,  0.3601,  ..., -0.2240, -0.4893, -0.6041])\n",
      "agitated\n",
      "Saved the embedding for agitated.\n",
      "['ago', '##g'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.4859, -0.2868, -0.5654,  ..., -0.0787, -0.4343,  0.1052])\n",
      "agog\n",
      "Saved the embedding for agog.\n",
      "['ago', '##ni', '##zed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.2074, -0.5891,  0.0343,  ..., -0.5554, -0.5876,  0.1460])\n",
      "agonized\n",
      "Saved the embedding for agonized.\n",
      "['agree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1167,  0.2260,  0.5425,  ...,  0.1216, -0.9855, -0.4921])\n",
      "agreeable\n",
      "Saved the embedding for agreeable.\n",
      "['ag', '##ress', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3178, 0.6522, 0.2430,  ..., 0.0578, 0.3720, 0.0325])\n",
      "agressive\n",
      "Saved the embedding for agressive.\n",
      "['air', '##head'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0326,  0.8785,  0.4158,  ..., -0.4783, -0.4456, -0.0848])\n",
      "airhead\n",
      "Saved the embedding for airhead.\n",
      "['alarm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-2.0000e-04,  1.0446e+00, -3.7123e-01,  ..., -6.8210e-01,\n",
      "        -4.3341e-01,  8.5118e-02])\n",
      "alarm\n",
      "Saved the embedding for alarm.\n",
      "['alarmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1472,  0.0068,  0.5304,  ..., -0.5558, -0.4776, -0.4694])\n",
      "alarmed\n",
      "Saved the embedding for alarmed.\n",
      "['alarm', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0048,  1.1250,  0.1959,  ..., -0.9028, -0.6554,  0.4478])\n",
      "alarming\n",
      "Saved the embedding for alarming.\n",
      "['alert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0876,  0.9605,  0.1765,  ..., -1.2592, -0.1964,  0.1506])\n",
      "alert\n",
      "Saved the embedding for alert.\n",
      "['alerted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1011,  0.1846, -0.0333,  ...,  0.7862, -0.2831, -0.0929])\n",
      "alerted\n",
      "Saved the embedding for alerted.\n",
      "['alien', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7212, -0.0710,  0.0993,  ...,  0.1081, -0.0771,  0.0746])\n",
      "alienated\n",
      "Saved the embedding for alienated.\n",
      "['allergic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2145, -0.0274,  0.7127,  ..., -0.2574, -0.1961,  0.6006])\n",
      "allergic\n",
      "Saved the embedding for allergic.\n",
      "['alleviate', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8624,  0.4422,  0.4347,  ..., -0.6295, -0.9478,  0.1664])\n",
      "alleviated\n",
      "Saved the embedding for alleviated.\n",
      "['all', '##uring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1935, -0.3515, -0.2452,  ..., -0.6634, -0.7882, -0.2297])\n",
      "alluring\n",
      "Saved the embedding for alluring.\n",
      "['al', '##oof'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2478, -0.0728, -0.3324,  ..., -0.2632,  0.0181,  1.0516])\n",
      "aloof\n",
      "Saved the embedding for aloof.\n",
      "['ama', '##tory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1816, -0.2407, -0.6397,  ..., -1.7947, -1.8796,  0.3397])\n",
      "amatory\n",
      "Saved the embedding for amatory.\n",
      "['amazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5699,  0.0453, -0.5264,  ..., -0.3304, -0.8983,  0.4490])\n",
      "amazed\n",
      "Saved the embedding for amazed.\n",
      "['amazement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8924,  0.3167, -0.4070,  ..., -0.2363, -0.4358,  0.4594])\n",
      "amazement\n",
      "Saved the embedding for amazement.\n",
      "['amazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3700,  0.0059,  0.4761,  ..., -1.4215, -1.0325,  0.2796])\n",
      "amazing\n",
      "Saved the embedding for amazing.\n",
      "['ambition'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4795,  0.0343,  0.8158,  ..., -0.7056, -0.6354, -0.3309])\n",
      "ambition\n",
      "Saved the embedding for ambition.\n",
      "['ambitious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1085, -0.2555,  1.0089,  ..., -0.7625, -0.2812, -0.7105])\n",
      "ambitious\n",
      "Saved the embedding for ambitious.\n",
      "['am', '##bi', '##vale', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2591, -0.1765,  0.0799,  ..., -0.0186, -0.0697,  0.1033])\n",
      "ambivalence\n",
      "Saved the embedding for ambivalence.\n",
      "['am', '##bi', '##valent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2814, -0.2743,  0.1729,  ..., -0.5860, -0.3975, -0.2030])\n",
      "ambivalent\n",
      "Saved the embedding for ambivalent.\n",
      "['am', '##ena', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0727, -0.3635, -0.1887,  ..., -1.1703, -0.3706,  0.0299])\n",
      "amenable\n",
      "Saved the embedding for amenable.\n",
      "['ami', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0458,  0.4617, -0.0579,  ..., -1.0200, -1.2806, -0.1478])\n",
      "amiable\n",
      "Saved the embedding for amiable.\n",
      "['ami', '##cable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0713,  0.2103, -0.0546,  ..., -0.6855, -1.4921, -0.0293])\n",
      "amicable\n",
      "Saved the embedding for amicable.\n",
      "['amused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2192,  0.6699, -0.0739,  ..., -0.4939,  0.2006,  0.6143])\n",
      "amused\n",
      "Saved the embedding for amused.\n",
      "['amusement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0261,  0.8996, -0.1932,  ..., -0.1259, -1.4769, -0.1215])\n",
      "amusement\n",
      "Saved the embedding for amusement.\n",
      "['analytical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4642,  0.6915,  0.3922,  ..., -0.0685, -0.5626, -0.0926])\n",
      "analytical\n",
      "Saved the embedding for analytical.\n",
      "['analyzing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9731,  0.3472,  0.5582,  ..., -0.7235, -1.3145, -0.3990])\n",
      "analyzing\n",
      "Saved the embedding for analyzing.\n",
      "['anger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1335,  0.8163, -0.3551,  ...,  0.0553, -0.3414,  0.0762])\n",
      "anger\n",
      "Saved the embedding for anger.\n",
      "['angered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1749,  0.4152,  0.1984,  ..., -0.2645, -0.6329,  0.9541])\n",
      "angered\n",
      "Saved the embedding for angered.\n",
      "['angrily'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0302,  0.4498, -0.2607,  ..., -0.2994, -0.5607,  0.6085])\n",
      "angrily\n",
      "Saved the embedding for angrily.\n",
      "['angry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2513,  0.6504,  0.5910,  ..., -0.0612, -0.5430, -0.1512])\n",
      "angry\n",
      "Saved the embedding for angry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ang', '##st'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0919, -0.0538,  0.7924,  ..., -0.5212, -0.3995,  0.1277])\n",
      "angst\n",
      "Saved the embedding for angst.\n",
      "['anguish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1329, -0.1217, -0.2044,  ..., -0.4078,  0.4993, -0.6908])\n",
      "anguish\n",
      "Saved the embedding for anguish.\n",
      "['anguish', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1667, -0.0780,  0.1563,  ..., -0.0180,  0.2595, -0.5629])\n",
      "anguished\n",
      "Saved the embedding for anguished.\n",
      "['animated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1417, -0.8973, -0.4974,  ..., -0.0671, -0.4695,  0.0209])\n",
      "animated\n",
      "Saved the embedding for animated.\n",
      "['an', '##imo', '##sity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1243,  0.7214,  0.0455,  ..., -0.5057, -0.8948,  1.1199])\n",
      "animosity\n",
      "Saved the embedding for animosity.\n",
      "['annoyance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2489,  0.6740,  0.0616,  ...,  0.4201, -0.5377, -0.2970])\n",
      "annoyance\n",
      "Saved the embedding for annoyance.\n",
      "['annoyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1870,  0.6861,  0.8616,  ..., -0.0607, -0.7676,  0.0315])\n",
      "annoyed\n",
      "Saved the embedding for annoyed.\n",
      "['annoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2983,  0.5701, -0.3669,  ..., -0.0467, -0.5475,  0.3272])\n",
      "annoying\n",
      "Saved the embedding for annoying.\n",
      "['antagonist', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1199,  0.5142,  0.4415,  ..., -0.7129, -0.6177, -0.2795])\n",
      "antagonistic\n",
      "Saved the embedding for antagonistic.\n",
      "['ant', '##ago', '##ni', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.8824,  0.0910,  0.1550,  ...,  0.0320, -0.4201, -0.3309])\n",
      "antagonized\n",
      "Saved the embedding for antagonized.\n",
      "['anticipated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0565,  0.4886,  1.5072,  ...,  0.2687, -1.1396, -0.6958])\n",
      "anticipated\n",
      "Saved the embedding for anticipated.\n",
      "['anticipating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3711, -0.0288,  1.1473,  ..., -0.3070, -0.7635, -0.1346])\n",
      "anticipating\n",
      "Saved the embedding for anticipating.\n",
      "['anticipation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0406,  0.7904,  0.4513,  ..., -0.5572, -0.2085, -0.1260])\n",
      "anticipation\n",
      "Saved the embedding for anticipation.\n",
      "['anti', '##ci', '##pati', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5756,  0.7646,  0.4797,  ..., -0.5256,  0.3420, -0.8276])\n",
      "anticipative\n",
      "Saved the embedding for anticipative.\n",
      "['anti', '##ci', '##pa', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2756,  0.3076,  0.3998,  ..., -0.3698,  0.0145, -0.2758])\n",
      "anticipatory\n",
      "Saved the embedding for anticipatory.\n",
      "['anti', '##pathy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5569,  0.7648,  0.7559,  ..., -0.8725, -0.9962,  0.1597])\n",
      "antipathy\n",
      "Saved the embedding for antipathy.\n",
      "['ants', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2180,  0.9003, -0.7838,  ..., -0.4300, -0.5975,  0.2304])\n",
      "antsy\n",
      "Saved the embedding for antsy.\n",
      "['anxiety'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 2.0473e-01,  7.1302e-01,  7.5124e-02,  ...,  7.4404e-01,\n",
      "        -1.2362e+00, -7.7375e-04])\n",
      "anxiety\n",
      "Saved the embedding for anxiety.\n",
      "['anxious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5297,  0.3551,  1.2918,  ...,  0.5237, -0.9209, -0.9081])\n",
      "anxious\n",
      "Saved the embedding for anxious.\n",
      "['anxiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0786, -0.0416,  0.4540,  ...,  0.1452, -0.0066, -0.5792])\n",
      "anxiously\n",
      "Saved the embedding for anxiously.\n",
      "['ap', '##ath', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3838,  0.0814,  0.0071,  ..., -0.3076,  0.0439,  0.6013])\n",
      "apathetic\n",
      "Saved the embedding for apathetic.\n",
      "['ap', '##athy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2314,  0.4913, -0.2267,  ..., -1.3674, -0.5577,  0.5015])\n",
      "apathy\n",
      "Saved the embedding for apathy.\n",
      "['apologetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6289,  0.4648,  0.3493,  ..., -0.1849, -0.4988,  0.0811])\n",
      "apologetic\n",
      "Saved the embedding for apologetic.\n",
      "['appalled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5788,  0.1666,  1.1016,  ..., -0.0690,  0.0246, -0.5131])\n",
      "appalled\n",
      "Saved the embedding for appalled.\n",
      "['app', '##all', '##ingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3556, -0.4638,  0.3884,  ..., -0.3724, -0.0335,  0.0500])\n",
      "appallingly\n",
      "Saved the embedding for appallingly.\n",
      "['app', '##eased'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2759, -0.6159,  1.1013,  ..., -0.3501,  0.4218, -0.1749])\n",
      "appeased\n",
      "Saved the embedding for appeased.\n",
      "['app', '##ea', '##sing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0654, -0.5129,  0.9344,  ..., -0.4755,  0.5503,  0.1787])\n",
      "appeasing\n",
      "Saved the embedding for appeasing.\n",
      "['app', '##re', '##cia', '##tive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0381, -0.4792,  0.6446,  ...,  0.2827,  0.1473,  0.2727])\n",
      "appreciative\n",
      "Saved the embedding for appreciative.\n",
      "['apprehension'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6004,  0.7562, -0.1838,  ..., -0.3253, -0.6849,  0.3080])\n",
      "apprehension\n",
      "Saved the embedding for apprehension.\n",
      "['app', '##re', '##hen', '##sive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3170, -0.3710,  0.7593,  ..., -0.3143,  0.3218,  0.0269])\n",
      "apprehensive\n",
      "Saved the embedding for apprehensive.\n",
      "['approve'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2294, -0.4731,  0.1284,  ..., -0.8913, -0.0361, -0.1987])\n",
      "approve\n",
      "Saved the embedding for approve.\n",
      "['approved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0154, -0.3930, -0.1836,  ..., -0.7466,  0.0971, -0.3229])\n",
      "approved\n",
      "Saved the embedding for approved.\n",
      "['app', '##roving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2826, -0.4281,  0.7462,  ..., -1.1386,  0.1752,  0.3578])\n",
      "approving\n",
      "Saved the embedding for approving.\n",
      "['argue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2247, -0.1445, -0.2174,  ..., -0.0168,  0.5015, -0.0654])\n",
      "argue\n",
      "Saved the embedding for argue.\n",
      "['argument', '##ative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1049,  0.1499,  0.3188,  ..., -0.4733, -0.0504,  0.1775])\n",
      "argumentative\n",
      "Saved the embedding for argumentative.\n",
      "['aroused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0482,  0.3631, -0.2728,  ..., -1.1261, -0.1854, -0.2143])\n",
      "aroused\n",
      "Saved the embedding for aroused.\n",
      "['arrogance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0788,  0.8214,  0.7882,  ..., -0.1165, -1.4851,  0.1613])\n",
      "arrogance\n",
      "Saved the embedding for arrogance.\n",
      "['arrogant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0155,  0.6839,  0.9799,  ..., -0.0968, -0.8768, -0.6018])\n",
      "arrogant\n",
      "Saved the embedding for arrogant.\n",
      "['arrogant', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0707,  0.4968,  1.1778,  ...,  0.4950, -0.6847, -0.4102])\n",
      "arrogantly\n",
      "Saved the embedding for arrogantly.\n",
      "['artificial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1996,  0.3228, -0.4798,  ..., -0.5926, -0.3222, -0.1363])\n",
      "artificial\n",
      "Saved the embedding for artificial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ashamed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2217, -0.0502,  0.2985,  ..., -0.5433, -0.9641, -0.2594])\n",
      "ashamed\n",
      "Saved the embedding for ashamed.\n",
      "['aspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1903,  0.1534,  0.5512,  ..., -0.1296, -1.0976, -0.0734])\n",
      "aspiring\n",
      "Saved the embedding for aspiring.\n",
      "['assert', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0207,  0.3628,  0.3114,  ..., -0.4476, -1.1078, -0.6858])\n",
      "assertive\n",
      "Saved the embedding for assertive.\n",
      "['assert', '##ively'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1240,  0.4932,  0.0686,  ..., -0.3355, -0.7104, -1.1085])\n",
      "assertively\n",
      "Saved the embedding for assertively.\n",
      "['assessing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1840,  0.0447, -0.1364,  ..., -0.6361, -0.2406,  0.4616])\n",
      "assessing\n",
      "Saved the embedding for assessing.\n",
      "['assured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6196, -0.0093,  0.7322,  ..., -0.6241,  0.7078, -0.6553])\n",
      "assured\n",
      "Saved the embedding for assured.\n",
      "['astonished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2766, -0.0689,  0.0910,  ...,  0.6161, -0.2036,  0.0624])\n",
      "astonished\n",
      "Saved the embedding for astonished.\n",
      "['astonishment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1411,  0.4104,  0.0599,  ..., -0.0911,  0.3794, -0.2453])\n",
      "astonishment\n",
      "Saved the embedding for astonishment.\n",
      "['as', '##tou', '##nded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3429,  0.0706,  1.2344,  ..., -1.2333, -0.3843,  0.4051])\n",
      "astounded\n",
      "Saved the embedding for astounded.\n",
      "['attempting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0820,  0.3117,  0.1025,  ...,  0.0239, -0.6220,  0.3467])\n",
      "attempting\n",
      "Saved the embedding for attempting.\n",
      "['at', '##ten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2926, -0.5008, -0.3635,  ..., -0.0532, -0.0597,  0.2091])\n",
      "attentive\n",
      "Saved the embedding for attentive.\n",
      "['at', '##ten', '##tive', '##ness'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4989, -0.3482, -0.6118,  ..., -0.0321, -0.0406,  0.4491])\n",
      "attentiveness\n",
      "Saved the embedding for attentiveness.\n",
      "['attracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3959,  0.7180,  1.0058,  ...,  0.1678, -0.5034, -0.0167])\n",
      "attracted\n",
      "Saved the embedding for attracted.\n",
      "['ave', '##nging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1395, -0.0764, -1.1620,  ..., -0.2847,  0.1406, -0.1575])\n",
      "avenging\n",
      "Saved the embedding for avenging.\n",
      "['ave', '##rse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4888, -0.1805, -1.1613,  ..., -0.4407, -0.1940, -0.2789])\n",
      "averse\n",
      "Saved the embedding for averse.\n",
      "['ave', '##rs', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1800, -0.0989, -0.8761,  ..., -0.6483, -0.4255,  0.0150])\n",
      "aversion\n",
      "Saved the embedding for aversion.\n",
      "['ave', '##rs', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2325, -0.2503, -0.5568,  ..., -0.4451, -0.3371,  0.0140])\n",
      "aversive\n",
      "Saved the embedding for aversive.\n",
      "['avid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0136,  0.0722,  0.4017,  ..., -0.1736, -0.9516, -0.1750])\n",
      "avid\n",
      "Saved the embedding for avid.\n",
      "['avoiding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2820,  0.0570, -0.0222,  ..., -0.2702,  0.0978,  0.0803])\n",
      "avoiding\n",
      "Saved the embedding for avoiding.\n",
      "['awaiting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6452,  0.6993,  0.5665,  ..., -0.6212,  0.1096, -0.6529])\n",
      "awaiting\n",
      "Saved the embedding for awaiting.\n",
      "['awakened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0141,  0.1569,  0.2102,  ...,  0.4400,  0.6496, -0.2292])\n",
      "awakened\n",
      "Saved the embedding for awakened.\n",
      "['aware'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6456,  0.3538, -0.0781,  ...,  1.1750, -0.2179, -0.0431])\n",
      "aware\n",
      "Saved the embedding for aware.\n",
      "['awareness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1296,  0.7537,  0.3361,  ..., -0.2715,  0.3407,  0.0398])\n",
      "awareness\n",
      "Saved the embedding for awareness.\n",
      "['awe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3471,  0.2743, -0.1215,  ..., -0.6083, -0.6923,  0.1481])\n",
      "awe\n",
      "Saved the embedding for awe.\n",
      "['awe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3368,  0.3446, -0.2270,  ..., -0.9504, -0.6195, -0.2210])\n",
      "awed\n",
      "Saved the embedding for awed.\n",
      "['awe', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7429,  0.1910,  0.1532,  ..., -0.3360, -0.1702, -0.0870])\n",
      "awestruck\n",
      "Saved the embedding for awestruck.\n",
      "['awful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0206, -0.3591,  0.1443,  ..., -0.1536,  0.3003, -0.5401])\n",
      "awful\n",
      "Saved the embedding for awful.\n",
      "['awkward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4088,  0.2980, -0.3250,  ...,  0.1359, -1.0959,  0.3899])\n",
      "awkward\n",
      "Saved the embedding for awkward.\n",
      "['awkward', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0812,  0.5627, -0.1388,  ..., -1.7572, -1.5313,  0.6102])\n",
      "awkwardness\n",
      "Saved the embedding for awkwardness.\n",
      "['axe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1102,  0.0887, -0.0033,  ...,  0.2081, -0.8234, -1.0199])\n",
      "axed\n",
      "Saved the embedding for axed.\n",
      "['back', '##hand', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5895, -0.5050, -0.7059,  ..., -0.1918,  0.0321, -0.9085])\n",
      "backhanded\n",
      "Saved the embedding for backhanded.\n",
      "['badly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5393, -0.4111, -0.2105,  ...,  0.1590, -0.3157,  0.4805])\n",
      "badly\n",
      "Saved the embedding for badly.\n",
      "['ba', '##ffle'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2575, -0.2699, -0.5013,  ..., -0.7701, -1.0268,  0.7359])\n",
      "baffle\n",
      "Saved the embedding for baffle.\n",
      "['baffled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5382,  0.4103, -0.1621,  ..., -0.0808, -0.8299,  0.4093])\n",
      "baffled\n",
      "Saved the embedding for baffled.\n",
      "['ba', '##ff', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0804,  0.0686, -0.3453,  ..., -0.4378, -0.3599,  0.4915])\n",
      "baffling\n",
      "Saved the embedding for baffling.\n",
      "['baked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1549, -0.1003,  0.2386,  ..., -0.2398, -0.7266,  0.3128])\n",
      "baked\n",
      "Saved the embedding for baked.\n",
      "['ban', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4332, -0.3227, -0.8729,  ..., -0.6347, -0.2401, -0.7747])\n",
      "banal\n",
      "Saved the embedding for banal.\n",
      "['barking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0780,  0.2264,  0.1319,  ..., -0.6112, -0.5452, -0.0413])\n",
      "barking\n",
      "Saved the embedding for barking.\n",
      "['bash', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5086,  0.4906, -0.3140,  ..., -0.7660, -0.0669,  0.5059])\n",
      "bashful\n",
      "Saved the embedding for bashful.\n",
      "['beaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1304,  0.0182, -0.3203,  ..., -0.8350, -0.1929, -0.1481])\n",
      "beaming\n",
      "Saved the embedding for beaming.\n",
      "['bear', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7274, -0.1783,  0.6754,  ..., -0.4556, -0.9946, -0.0544])\n",
      "bearish\n",
      "Saved the embedding for bearish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3468,  0.3886,  0.4718,  ...,  0.2080,  0.0875, -0.1007])\n",
      "beat\n",
      "Saved the embedding for beat.\n",
      "['beaten'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0346,  0.1107, -0.1936,  ...,  0.3533, -0.3622,  0.0366])\n",
      "beaten\n",
      "Saved the embedding for beaten.\n",
      "['bed', '##ev', '##iled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2118,  0.1441,  0.0653,  ..., -0.0241, -0.5221, -0.1654])\n",
      "bedeviled\n",
      "Saved the embedding for bedeviled.\n",
      "['be', '##fu', '##ddled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3803, -0.2611, -0.2467,  ..., -0.4744, -0.3737,  0.0625])\n",
      "befuddled\n",
      "Saved the embedding for befuddled.\n",
      "['begging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3503,  0.8269,  0.5973,  ...,  0.5078, -0.0924, -0.7290])\n",
      "begging\n",
      "Saved the embedding for begging.\n",
      "['beg', '##rud', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1836,  0.3242, -0.4813,  ..., -0.3638, -0.3881,  0.3686])\n",
      "begrudge\n",
      "Saved the embedding for begrudge.\n",
      "['beg', '##rud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1705,  0.6150, -0.1261,  ..., -0.5041, -0.6678,  0.3519])\n",
      "begrudging\n",
      "Saved the embedding for begrudging.\n",
      "['beg', '##rud', '##gingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-2.3148e-01,  6.8930e-01,  2.4000e-01,  ..., -4.1654e-01,\n",
      "        -5.7393e-01,  3.6581e-04])\n",
      "begrudgingly\n",
      "Saved the embedding for begrudgingly.\n",
      "['beg', '##uil', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3839,  0.1570, -0.3722,  ..., -0.7327, -0.5966, -0.2232])\n",
      "beguiled\n",
      "Saved the embedding for beguiled.\n",
      "['bela', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5633,  0.0710, -0.7529,  ..., -0.7776, -0.2318, -0.4321])\n",
      "belated\n",
      "Saved the embedding for belated.\n",
      "['bel', '##itt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4603,  0.6594, -0.9073,  ..., -0.1399,  0.0360,  0.6368])\n",
      "belittling\n",
      "Saved the embedding for belittling.\n",
      "['bell', '##iger', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6872,  0.6801, -0.7873,  ..., -0.3525, -0.6360,  0.2028])\n",
      "belligerence\n",
      "Saved the embedding for belligerence.\n",
      "['bell', '##iger', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4818,  0.3621, -0.3687,  ..., -0.2966, -0.7566, -0.5819])\n",
      "belligerent\n",
      "Saved the embedding for belligerent.\n",
      "['belonging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1086,  0.0638, -0.0611,  ..., -0.1820, -1.2727,  0.2048])\n",
      "belonging\n",
      "Saved the embedding for belonging.\n",
      "['be', '##mus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4326, -0.4318, -0.2885,  ..., -0.2819,  0.1635,  0.2498])\n",
      "bemused\n",
      "Saved the embedding for bemused.\n",
      "['be', '##mus', '##ement'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6689, -0.2417, -0.0163,  ..., -0.5810, -0.3052,  1.5347])\n",
      "bemusement\n",
      "Saved the embedding for bemusement.\n",
      "['ben', '##ev', '##ole', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2255,  0.5262, -0.5815,  ..., -0.7365, -0.3510,  0.5633])\n",
      "benevolence\n",
      "Saved the embedding for benevolence.\n",
      "['benevolent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2377,  0.8772, -0.0536,  ..., -0.8764, -1.0031,  0.2400])\n",
      "benevolent\n",
      "Saved the embedding for benevolent.\n",
      "['ben', '##umb', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3656,  0.2355, -0.8250,  ..., -0.8689, -0.1513,  0.9875])\n",
      "benumbed\n",
      "Saved the embedding for benumbed.\n",
      "['be', '##rate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6293, -0.1775, -0.1311,  ..., -0.5100, -0.1954,  0.6631])\n",
      "berate\n",
      "Saved the embedding for berate.\n",
      "['be', '##rating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7481, -0.2528, -0.0719,  ..., -0.9649,  0.1362,  0.2619])\n",
      "berating\n",
      "Saved the embedding for berating.\n",
      "['be', '##rea', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2268, -0.0181, -0.0425,  ..., -1.0147, -0.0382,  0.2187])\n",
      "bereaved\n",
      "Saved the embedding for bereaved.\n",
      "['be', '##re', '##ft'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3103, -0.4566, -0.4701,  ..., -0.4272,  0.3571,  1.0231])\n",
      "bereft\n",
      "Saved the embedding for bereft.\n",
      "['be', '##see', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3023,  0.0213,  0.0620,  ..., -0.7753, -0.1972,  0.1534])\n",
      "beseeching\n",
      "Saved the embedding for beseeching.\n",
      "['best', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7570, -0.1100,  0.5166,  ..., -0.7366, -0.3058,  0.4624])\n",
      "bested\n",
      "Saved the embedding for bested.\n",
      "['betrayal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5020, -0.0590, -0.3124,  ..., -0.1036, -0.9724, -0.5593])\n",
      "betrayal\n",
      "Saved the embedding for betrayal.\n",
      "['betrayed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0372,  0.2687,  0.5127,  ..., -0.5688, -1.1415, -0.1935])\n",
      "betrayed\n",
      "Saved the embedding for betrayed.\n",
      "['bewildered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1025, -0.0179,  0.1565,  ...,  0.3724, -0.7655, -0.2684])\n",
      "bewildered\n",
      "Saved the embedding for bewildered.\n",
      "['be', '##wil', '##der', '##ment'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 2.0630e-01,  7.9155e-02, -1.2100e-01,  ..., -9.1495e-01,\n",
      "        -6.9870e-04,  6.3011e-01])\n",
      "bewilderment\n",
      "Saved the embedding for bewilderment.\n",
      "['bi'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4425, -0.3026, -0.2158,  ..., -0.1574, -0.1125,  0.0053])\n",
      "bi\n",
      "Saved the embedding for bi.\n",
      "['bi', '##lio', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3157, -0.5889, -0.3025,  ...,  0.2651,  0.3683,  0.4720])\n",
      "bilious\n",
      "Saved the embedding for bilious.\n",
      "['bit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0041, -0.0456, -0.0084,  ..., -0.4535, -0.3531,  0.0526])\n",
      "bit\n",
      "Saved the embedding for bit.\n",
      "['biting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1126,  0.1298, -0.4530,  ..., -0.2179, -0.6705,  0.1194])\n",
      "biting\n",
      "Saved the embedding for biting.\n",
      "['bitter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2038,  0.2621, -0.5047,  ...,  0.2623, -0.3728, -0.0697])\n",
      "bitter\n",
      "Saved the embedding for bitter.\n",
      "['bitter', '##sw', '##eet'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1236, -0.1192, -0.9221,  ..., -0.0387,  0.1410,  0.3603])\n",
      "bittersweet\n",
      "Saved the embedding for bittersweet.\n",
      "['blaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4852,  0.0375,  0.5473,  ..., -1.5953, -0.8409, -0.3374])\n",
      "blaming\n",
      "Saved the embedding for blaming.\n",
      "['bland'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3297, -0.3812, -0.5290,  ..., -0.5811, -0.0490,  0.7239])\n",
      "bland\n",
      "Saved the embedding for bland.\n",
      "['blank'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6831,  0.2908, -0.0547,  ...,  0.1513,  0.0978, -0.1527])\n",
      "blank\n",
      "Saved the embedding for blank.\n",
      "['b', '##lase'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0355, -0.3481,  0.0162,  ..., -0.5801, -0.1666,  0.0534])\n",
      "blase\n",
      "Saved the embedding for blase.\n",
      "['blazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3211, -0.0926,  0.6225,  ..., -0.0419,  0.1010, -0.3678])\n",
      "blazed\n",
      "Saved the embedding for blazed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bleak'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4399, -0.3844, -0.1213,  ..., -1.1919, -0.0960,  0.2951])\n",
      "bleak\n",
      "Saved the embedding for bleak.\n",
      "['b', '##lea', '##ry'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2619, -0.0184,  0.2907,  ..., -0.8140, -0.9146, -0.0279])\n",
      "bleary\n",
      "Saved the embedding for bleary.\n",
      "['blessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1679,  1.3999,  0.3925,  ..., -0.3641,  0.0469,  0.1279])\n",
      "blessed\n",
      "Saved the embedding for blessed.\n",
      "['blew'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3698, -0.2978, -0.9332,  ..., -0.1053, -0.4458, -0.1950])\n",
      "blew\n",
      "Saved the embedding for blew.\n",
      "['blinded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0269,  0.3349, -0.3795,  ...,  0.6970,  0.0298,  0.0093])\n",
      "blinded\n",
      "Saved the embedding for blinded.\n",
      "['blinds', '##ided'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0825,  0.2399, -0.6364,  ...,  0.4127, -0.2866,  0.2593])\n",
      "blindsided\n",
      "Saved the embedding for blindsided.\n",
      "['bliss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7469,  0.3454,  0.2697,  ..., -1.3096, -0.1816,  0.6486])\n",
      "bliss\n",
      "Saved the embedding for bliss.\n",
      "['bliss', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4270,  0.2225,  0.0672,  ..., -0.9610,  0.1186,  0.6628])\n",
      "blissful\n",
      "Saved the embedding for blissful.\n",
      "['bliss', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4713,  0.0467,  0.0876,  ..., -1.2651,  0.2520,  0.4185])\n",
      "blissfully\n",
      "Saved the embedding for blissfully.\n",
      "['b', '##lit', '##he'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1022, -0.0837,  0.2460,  ..., -0.4034, -0.8630,  0.5538])\n",
      "blithe\n",
      "Saved the embedding for blithe.\n",
      "['blown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1460,  0.4489, -0.1927,  ..., -0.2844, -0.7935, -0.0041])\n",
      "blown\n",
      "Saved the embedding for blown.\n",
      "['blue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2319, -0.5447, -0.3884,  ...,  0.3543, -0.1851, -0.1053])\n",
      "blue\n",
      "Saved the embedding for blue.\n",
      "['blues'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0722, -0.0075, -0.3383,  ..., -0.2483,  0.1304, -0.5276])\n",
      "blues\n",
      "Saved the embedding for blues.\n",
      "['bluff', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3425,  0.6279, -0.1705,  ..., -0.3522, -0.6123,  0.1372])\n",
      "bluffing\n",
      "Saved the embedding for bluffing.\n",
      "['blunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3301, -0.0168,  0.6656,  ..., -0.2214, -0.8773, -0.4511])\n",
      "blunt\n",
      "Saved the embedding for blunt.\n",
      "['blushing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5888,  0.8076,  1.2826,  ...,  0.4618,  0.4636, -0.6344])\n",
      "blushing\n",
      "Saved the embedding for blushing.\n",
      "['blu', '##ster', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0702, -0.1026,  0.0786,  ..., -0.4142, -0.2605, -0.1418])\n",
      "blustering\n",
      "Saved the embedding for blustering.\n",
      "['bo', '##ast', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0768,  0.2199, -0.4464,  ..., -0.5054,  0.1123,  0.3991])\n",
      "boastful\n",
      "Saved the embedding for boastful.\n",
      "['bog', '##gled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2909, -0.4422, -0.4847,  ..., -1.0548, -0.9462, -0.8280])\n",
      "boggled\n",
      "Saved the embedding for boggled.\n",
      "['boiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1306,  0.1922, -0.6237,  ...,  0.2190, -0.8726,  0.4913])\n",
      "boiling\n",
      "Saved the embedding for boiling.\n",
      "['bois', '##ter', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3789, -0.1679,  0.4133,  ...,  0.2109,  0.0062,  0.4291])\n",
      "boisterous\n",
      "Saved the embedding for boisterous.\n",
      "['bold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3764,  0.5867, -0.2133,  ..., -0.0449, -0.8211, -0.4831])\n",
      "bold\n",
      "Saved the embedding for bold.\n",
      "['bored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1098,  0.3185, -0.1843,  ..., -0.1979, -0.2647,  0.7985])\n",
      "bored\n",
      "Saved the embedding for bored.\n",
      "['boredom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5929,  0.6451,  0.0333,  ..., -0.5453, -0.9463, -0.3747])\n",
      "boredom\n",
      "Saved the embedding for boredom.\n",
      "['boring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1954,  0.3655, -0.5319,  ..., -0.2388, -0.9744,  0.3137])\n",
      "boring\n",
      "Saved the embedding for boring.\n",
      "['bothered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4006,  0.6626, -0.2633,  ..., -0.0519, -0.9564, -0.3816])\n",
      "bothered\n",
      "Saved the embedding for bothered.\n",
      "['bound', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1886,  0.0953,  0.2011,  ..., -0.3823,  0.6331,  0.1321])\n",
      "bounder\n",
      "Saved the embedding for bounder.\n",
      "['bra', '##sh', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1972,  0.2319, -0.1615,  ..., -0.0764, -0.4637, -0.6458])\n",
      "brashness\n",
      "Saved the embedding for brashness.\n",
      "['brat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3998,  0.6924, -0.2266,  ..., -0.0452, -1.1231, -0.3253])\n",
      "bratty\n",
      "Saved the embedding for bratty.\n",
      "['brave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3584,  0.4515,  0.7034,  ...,  0.1530,  0.0565,  0.1417])\n",
      "brave\n",
      "Saved the embedding for brave.\n",
      "['bright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5701,  0.5470, -0.0848,  ..., -0.6190, -0.7232,  0.6994])\n",
      "bright\n",
      "Saved the embedding for bright.\n",
      "['br', '##ist', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2137,  0.6703, -0.9046,  ..., -0.4316, -0.1590,  0.5829])\n",
      "bristling\n",
      "Saved the embedding for bristling.\n",
      "['broken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2088,  0.1583, -0.6576,  ..., -0.7573, -0.4625,  0.0745])\n",
      "broken\n",
      "Saved the embedding for broken.\n",
      "['broken', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1127, -0.0785, -0.2448,  ..., -1.3083, -0.3184,  0.1432])\n",
      "brokenhearted\n",
      "Saved the embedding for brokenhearted.\n",
      "['broken', '##hearted', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2469,  0.2697, -0.4063,  ..., -0.6244,  0.2065, -0.3382])\n",
      "brokenheartedly\n",
      "Saved the embedding for brokenheartedly.\n",
      "['brooding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8343,  0.2459,  0.0172,  ..., -0.2822,  0.0244, -0.6676])\n",
      "brooding\n",
      "Saved the embedding for brooding.\n",
      "['brood', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1663, 0.5947, 0.0187,  ..., 0.2229, 0.3465, 0.2718])\n",
      "broody\n",
      "Saved the embedding for broody.\n",
      "['bruised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2851,  0.3237, -0.8803,  ..., -0.3194, -0.9321,  0.2884])\n",
      "bruised\n",
      "Saved the embedding for bruised.\n",
      "['br', '##us', '##que'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8087,  0.4641, -0.7094,  ...,  0.2994, -0.3167,  1.3406])\n",
      "brusque\n",
      "Saved the embedding for brusque.\n",
      "['bug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2807, -0.0179,  0.2340,  ..., -1.1620, -0.6044,  0.1880])\n",
      "bug\n",
      "Saved the embedding for bug.\n",
      "['bulging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3469,  0.3347,  0.3317,  ..., -0.6858, -0.7503,  0.0698])\n",
      "bulging\n",
      "Saved the embedding for bulging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5327,  0.7858,  0.1503,  ...,  0.8557, -0.9734, -0.7696])\n",
      "bully\n",
      "Saved the embedding for bully.\n",
      "['bullying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8483,  0.2726,  0.2430,  ...,  0.2717, -1.3924, -1.2614])\n",
      "bullying\n",
      "Saved the embedding for bullying.\n",
      "['bum', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6281,  0.2373, -0.2239,  ..., -0.2081, -0.4644,  0.3086])\n",
      "bummed\n",
      "Saved the embedding for bummed.\n",
      "['bu', '##oya', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0402,  0.0630,  0.7273,  ..., -1.2395, -0.0301,  0.9115])\n",
      "buoyant\n",
      "Saved the embedding for buoyant.\n",
      "['burden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3478, -0.4301,  0.1586,  ..., -0.5697, -0.3919, -0.0998])\n",
      "burdened\n",
      "Saved the embedding for burdened.\n",
      "['burn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1772, -0.3661, -0.1363,  ..., -0.4211, -1.2821,  0.9571])\n",
      "burn\n",
      "Saved the embedding for burn.\n",
      "['bursting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2474, -0.0461, -0.0557,  ..., -1.0255, -0.3552, -0.0184])\n",
      "bursting\n",
      "Saved the embedding for bursting.\n",
      "['bush', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0111,  0.0716,  0.1236,  ..., -0.0734, -0.7798, -0.3345])\n",
      "bushed\n",
      "Saved the embedding for bushed.\n",
      "['cage', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7151,  1.0505, -0.0960,  ..., -0.3192, -1.5118, -0.1719])\n",
      "cagey\n",
      "Saved the embedding for cagey.\n",
      "['ca', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5494, -0.5669, -0.0595,  ..., -0.6264, -0.3007,  0.2079])\n",
      "cagy\n",
      "Saved the embedding for cagy.\n",
      "['calculating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8333,  0.4044,  0.1873,  ...,  0.1469, -0.0724,  0.5223])\n",
      "calculating\n",
      "Saved the embedding for calculating.\n",
      "['call', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0825, -0.5908,  0.7959,  ..., -0.3327,  0.1514,  0.5342])\n",
      "callous\n",
      "Saved the embedding for callous.\n",
      "['call', '##used'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1562, -0.2598,  0.7016,  ..., -0.1181,  0.1573,  0.5485])\n",
      "callused\n",
      "Saved the embedding for callused.\n",
      "['calm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4163,  0.1166,  0.4450,  ..., -0.3292, -0.4511, -0.8004])\n",
      "calm\n",
      "Saved the embedding for calm.\n",
      "['calming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5682,  0.6759,  0.5094,  ..., -0.1157, -1.4636,  0.2237])\n",
      "calming\n",
      "Saved the embedding for calming.\n",
      "['calm', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1086, -0.1553,  0.2109,  ..., -1.4806, -1.4092,  0.7188])\n",
      "calmness\n",
      "Saved the embedding for calmness.\n",
      "['can', '##ny'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6858, -0.3285,  0.3532,  ...,  0.1275, -0.3903,  0.5766])\n",
      "canny\n",
      "Saved the embedding for canny.\n",
      "['can', '##tan', '##ker', '##ous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.8833, -0.0661,  0.4470,  ..., -0.5985, -0.3003,  0.2458])\n",
      "cantankerous\n",
      "Saved the embedding for cantankerous.\n",
      "['capable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0353, -0.0666,  0.0276,  ..., -0.3088, -0.1754, -0.2164])\n",
      "capable\n",
      "Saved the embedding for capable.\n",
      "['cap', '##ric', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4815, -0.1566, -0.4285,  ..., -0.4932, -0.3505, -0.6840])\n",
      "capricious\n",
      "Saved the embedding for capricious.\n",
      "['capt', '##ivated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3996,  0.2169,  0.2545,  ..., -0.3300, -0.1732,  0.4767])\n",
      "captivated\n",
      "Saved the embedding for captivated.\n",
      "['captive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4038, -0.1472, -0.0544,  ..., -0.6171, -0.1541, -0.8677])\n",
      "captive\n",
      "Saved the embedding for captive.\n",
      "['care', '##free'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7656,  0.1579, -0.1607,  ..., -0.9369, -0.8902,  0.1463])\n",
      "carefree\n",
      "Saved the embedding for carefree.\n",
      "['careful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5059,  0.0402,  0.0997,  ..., -0.3412, -0.6915,  0.4313])\n",
      "careful\n",
      "Saved the embedding for careful.\n",
      "['careless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1432,  0.7154,  0.2646,  ..., -0.2529, -1.1498,  0.1928])\n",
      "careless\n",
      "Saved the embedding for careless.\n",
      "['caring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4677,  0.1472,  0.9958,  ..., -0.2868, -1.4770, -0.2979])\n",
      "caring\n",
      "Saved the embedding for caring.\n",
      "['cat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8081, -0.1680,  0.5616,  ..., -1.1432, -0.7343,  0.1854])\n",
      "catty\n",
      "Saved the embedding for catty.\n",
      "['ca', '##ust', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3650, -0.2586,  0.0542,  ..., -1.0767, -0.4288,  0.7523])\n",
      "caustic\n",
      "Saved the embedding for caustic.\n",
      "['caution', '##ary'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-2.1633e-01, -2.5297e-01, -8.6528e-04,  ..., -1.1180e+00,\n",
      "        -4.3767e-01,  2.2884e-01])\n",
      "cautionary\n",
      "Saved the embedding for cautionary.\n",
      "['cautious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5772,  0.4758,  0.1377,  ..., -0.3594,  0.4259, -0.4349])\n",
      "cautious\n",
      "Saved the embedding for cautious.\n",
      "['cavalier'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7781,  0.6033, -0.1872,  ..., -0.9413, -0.6237, -0.4932])\n",
      "cavalier\n",
      "Saved the embedding for cavalier.\n",
      "['celebrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0771,  0.7744,  0.3980,  ..., -0.6016, -0.5738,  0.8251])\n",
      "celebrating\n",
      "Saved the embedding for celebrating.\n",
      "['celebration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0311,  0.7857,  0.6150,  ...,  0.0092, -0.7219,  0.2288])\n",
      "celebration\n",
      "Saved the embedding for celebration.\n",
      "['ce', '##ns', '##ure'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4265,  0.1699,  0.3018,  ..., -0.9398, -1.0957, -0.1108])\n",
      "censure\n",
      "Saved the embedding for censure.\n",
      "['centered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4382,  0.3064,  0.4261,  ...,  0.1798, -0.4310, -0.4517])\n",
      "centered\n",
      "Saved the embedding for centered.\n",
      "['certain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4289,  0.3469, -0.7162,  ..., -0.4030, -0.9535,  0.1753])\n",
      "certain\n",
      "Saved the embedding for certain.\n",
      "['cha', '##fed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4204, -0.7631, -0.8147,  ..., -0.8620, -0.7609, -0.4206])\n",
      "chafed\n",
      "Saved the embedding for chafed.\n",
      "['cha', '##grin'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2045, -0.3738, -0.5447,  ..., -1.5907, -0.6338,  0.1742])\n",
      "chagrin\n",
      "Saved the embedding for chagrin.\n",
      "['cha', '##grin', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2344, -0.1239, -0.7737,  ..., -0.8614,  0.0763,  0.4220])\n",
      "chagrined\n",
      "Saved the embedding for chagrined.\n",
      "['cha', '##grin', '##ned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1393, -0.1854, -0.7383,  ..., -0.4501, -0.0508,  0.2229])\n",
      "chagrinned\n",
      "Saved the embedding for chagrinned.\n",
      "['challenge'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5009, -0.2965,  0.6787,  ..., -0.3635, -0.3105,  0.3671])\n",
      "challenge\n",
      "Saved the embedding for challenge.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['challenged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2603,  0.0813,  0.7254,  ..., -0.8205, -1.4512,  0.2784])\n",
      "challenged\n",
      "Saved the embedding for challenged.\n",
      "['challenging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0730,  0.3807,  1.2924,  ..., -0.1164, -0.8546, -0.0895])\n",
      "challenging\n",
      "Saved the embedding for challenging.\n",
      "['chaotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8538,  0.3801,  0.0631,  ..., -0.9652, -0.3289, -0.0336])\n",
      "chaotic\n",
      "Saved the embedding for chaotic.\n",
      "['charged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7537,  0.3778, -0.0160,  ...,  0.5611,  0.8080,  0.5534])\n",
      "charged\n",
      "Saved the embedding for charged.\n",
      "['charm', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8889, -0.3732, -0.3213,  ..., -0.7489, -0.2160, -0.4076])\n",
      "charmed\n",
      "Saved the embedding for charmed.\n",
      "['charming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1880,  0.3383,  0.4908,  ...,  0.1415, -0.2582,  0.6851])\n",
      "charming\n",
      "Saved the embedding for charming.\n",
      "['char', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7029, -0.0240, -0.7497,  ..., -1.6957, -0.9118,  0.4883])\n",
      "chary\n",
      "Saved the embedding for chary.\n",
      "['cheated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6450,  0.1566,  0.2871,  ...,  1.3193, -0.4561, -0.5921])\n",
      "cheated\n",
      "Saved the embedding for cheated.\n",
      "['cheek', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2499,  0.6101, -0.2374,  ..., -0.4540, -0.5290,  0.5626])\n",
      "cheeky\n",
      "Saved the embedding for cheeky.\n",
      "['cheered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0993, -0.2819, -0.1126,  ..., -1.4843, -1.1269, -0.4625])\n",
      "cheered\n",
      "Saved the embedding for cheered.\n",
      "['cheerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7942,  0.3733,  0.5577,  ..., -0.4683, -0.3636, -0.4989])\n",
      "cheerful\n",
      "Saved the embedding for cheerful.\n",
      "['cheering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0901,  0.3823,  0.1056,  ..., -0.8069, -0.5548,  0.3337])\n",
      "cheering\n",
      "Saved the embedding for cheering.\n",
      "['cheer', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4850,  0.3352, -0.4943,  ..., -0.7532, -0.1871,  0.4220])\n",
      "cheerless\n",
      "Saved the embedding for cheerless.\n",
      "['cheer', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3003,  0.4409, -0.5407,  ..., -0.7067,  0.0785,  0.3722])\n",
      "cheery\n",
      "Saved the embedding for cheery.\n",
      "['che', '##es', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5790,  0.4363, -0.5431,  ..., -0.6844, -1.0445,  0.4283])\n",
      "cheesy\n",
      "Saved the embedding for cheesy.\n",
      "['chest', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2201,  0.3367, -0.5972,  ..., -1.2346, -0.7693,  0.2230])\n",
      "chesty\n",
      "Saved the embedding for chesty.\n",
      "['chi', '##de'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2052,  0.0585, -0.6113,  ..., -0.9224, -1.1031, -0.0887])\n",
      "chide\n",
      "Saved the embedding for chide.\n",
      "['chi', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4119,  0.1442, -0.5191,  ..., -1.1131, -1.3947, -0.3052])\n",
      "chiding\n",
      "Saved the embedding for chiding.\n",
      "['childish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0662,  0.5155, -0.2485,  ..., -0.5861, -1.1641,  0.2559])\n",
      "childish\n",
      "Saved the embedding for childish.\n",
      "['childish', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3641,  0.4968, -0.0362,  ..., -1.0143, -1.0590,  0.0118])\n",
      "childishly\n",
      "Saved the embedding for childishly.\n",
      "['child', '##like'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2840, -0.1691, -0.2120,  ..., -0.1276, -0.5670, -0.0325])\n",
      "childlike\n",
      "Saved the embedding for childlike.\n",
      "['chill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0403, -0.2704,  0.2453,  ..., -0.4666, -1.1365, -0.1113])\n",
      "chill\n",
      "Saved the embedding for chill.\n",
      "['chilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1678, -0.1671, -0.7879,  ..., -0.1944,  0.7467, -0.4478])\n",
      "chilled\n",
      "Saved the embedding for chilled.\n",
      "['chilling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3692, -0.6944,  0.4462,  ..., -1.1293, -0.2375, -0.4002])\n",
      "chilling\n",
      "Saved the embedding for chilling.\n",
      "['chip', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0219, -0.4293, -0.5623,  ..., -0.2903, -0.1556, -0.0801])\n",
      "chipper\n",
      "Saved the embedding for chipper.\n",
      "['chi', '##rp', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1544,  0.3537, -0.3107,  ..., -0.7113, -0.7929,  0.2952])\n",
      "chirpy\n",
      "Saved the embedding for chirpy.\n",
      "['cho', '##ler', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0130, -0.6034, -0.5891,  ..., -0.3972,  0.0193,  1.4128])\n",
      "choleric\n",
      "Saved the embedding for choleric.\n",
      "['cho', '##rt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0156, -0.5186, -1.2747,  ..., -0.4418,  0.6938,  0.2977])\n",
      "chortling\n",
      "Saved the embedding for chortling.\n",
      "['chuckle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2062,  0.1194, -0.6285,  ..., -0.1225, -1.0451,  0.1653])\n",
      "chuckle\n",
      "Saved the embedding for chuckle.\n",
      "['chuck', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2299,  0.4156, -0.1354,  ..., -0.5134, -0.9876,  0.1236])\n",
      "chuckling\n",
      "Saved the embedding for chuckling.\n",
      "['chu', '##rl', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2121, -0.1660, -1.0369,  ..., -0.3741, -0.4520,  0.8618])\n",
      "churlish\n",
      "Saved the embedding for churlish.\n",
      "['ci', '##rc', '##ums', '##pe', '##ct'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.6492, -0.9289, -0.3407,  ...,  0.0864,  0.2768, -0.0816])\n",
      "circumspect\n",
      "Saved the embedding for circumspect.\n",
      "['cl', '##amo', '##rous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4925, -0.0982,  0.6221,  ..., -1.8885, -0.3132, -0.2208])\n",
      "clamorous\n",
      "Saved the embedding for clamorous.\n",
      "['clash'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8546,  0.7288,  0.0711,  ..., -0.3989, -0.6487, -1.6361])\n",
      "clash\n",
      "Saved the embedding for clash.\n",
      "['clear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4825,  0.3684, -0.0196,  ..., -0.3930, -0.3625, -0.3927])\n",
      "clear\n",
      "Saved the embedding for clear.\n",
      "['clenched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1460,  0.0058, -0.3379,  ...,  0.1068, -0.2166,  0.1535])\n",
      "clenched\n",
      "Saved the embedding for clenched.\n",
      "['clever'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6389,  0.7868,  0.1976,  ..., -0.1601, -0.2519,  0.2220])\n",
      "clever\n",
      "Saved the embedding for clever.\n",
      "['close'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0038,  0.3392, -0.2351,  ...,  0.2502, -1.2080,  0.1591])\n",
      "close\n",
      "Saved the embedding for close.\n",
      "['closed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2893,  0.2045, -0.6885,  ..., -0.4445, -0.6358, -0.1355])\n",
      "closed\n",
      "Saved the embedding for closed.\n",
      "['close', '##mouth', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2740, -0.3504, -0.2419,  ...,  0.1332, -0.3154,  0.1209])\n",
      "closemouthed\n",
      "Saved the embedding for closemouthed.\n",
      "['cl', '##oy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4021, -0.1943,  0.3741,  ..., -0.8915, -1.2738, -0.1255])\n",
      "cloy\n",
      "Saved the embedding for cloy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clue', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3378,  0.1192,  0.3622,  ..., -0.5830, -0.9037,  0.3990])\n",
      "clueless\n",
      "Saved the embedding for clueless.\n",
      "['clutched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5151,  0.0657, -0.4591,  ..., -0.1292, -0.8105,  0.0264])\n",
      "clutched\n",
      "Saved the embedding for clutched.\n",
      "['cl', '##uttered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3183, -0.4592,  0.3346,  ..., -0.8507, -0.7320, -0.6789])\n",
      "cluttered\n",
      "Saved the embedding for cluttered.\n",
      "['cock', '##eye', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5425,  0.3553,  0.2213,  ...,  0.2495, -0.2981, -0.3728])\n",
      "cockeyed\n",
      "Saved the embedding for cockeyed.\n",
      "['cock', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0731,  0.5986,  0.9266,  ..., -0.0702, -1.2590,  0.7583])\n",
      "cockiness\n",
      "Saved the embedding for cockiness.\n",
      "['cock', '##sure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4063,  0.0244,  0.1837,  ...,  0.2781, -1.0330, -0.0542])\n",
      "cocksure\n",
      "Saved the embedding for cocksure.\n",
      "['cocky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4010,  0.4328,  0.9910,  ...,  0.6639, -1.0834, -0.8523])\n",
      "cocky\n",
      "Saved the embedding for cocky.\n",
      "['co', '##gni', '##zan', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0790, -0.3379,  0.1927,  ..., -0.6761,  0.0889,  0.2480])\n",
      "cognizant\n",
      "Saved the embedding for cognizant.\n",
      "['cold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0347,  0.3480,  0.0173,  ...,  0.4306, -0.8514, -0.6890])\n",
      "cold\n",
      "Saved the embedding for cold.\n",
      "['collected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0795, -0.0342,  0.7599,  ...,  0.5598, -1.0926,  0.0044])\n",
      "collected\n",
      "Saved the embedding for collected.\n",
      "['col', '##lus', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1777, -0.2486,  0.2397,  ..., -0.1466,  0.0627,  0.5285])\n",
      "collusive\n",
      "Saved the embedding for collusive.\n",
      "['colon', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2293,  0.7017, -0.7014,  ..., -0.5284, -0.4475,  1.0308])\n",
      "colonized\n",
      "Saved the embedding for colonized.\n",
      "['combat', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0560,  0.7695, -0.6521,  ..., -0.3731,  0.1530,  0.5618])\n",
      "combative\n",
      "Saved the embedding for combative.\n",
      "['comedic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3001, -0.4853,  1.0150,  ..., -0.1516,  0.1922, -1.5022])\n",
      "comedic\n",
      "Saved the embedding for comedic.\n",
      "['comfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5721,  0.5729,  0.0971,  ...,  0.1089, -0.8072,  0.4657])\n",
      "comfort\n",
      "Saved the embedding for comfort.\n",
      "['comfortable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3060, -0.1211,  0.2546,  ..., -0.6333, -0.7113, -0.0338])\n",
      "comfortable\n",
      "Saved the embedding for comfortable.\n",
      "['comfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8321,  0.3792, -0.0499,  ...,  0.1663, -0.9972,  0.2627])\n",
      "comforted\n",
      "Saved the embedding for comforted.\n",
      "['comical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1512,  0.2926,  0.2452,  ..., -0.5126, -0.7387, -0.0201])\n",
      "comical\n",
      "Saved the embedding for comical.\n",
      "['commanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4397,  1.6036, -0.1171,  ..., -0.1293, -0.6575, -0.1878])\n",
      "commanding\n",
      "Saved the embedding for commanding.\n",
      "['com', '##mise', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2465,  0.2738,  0.3530,  ..., -0.8894,  0.0459,  0.0581])\n",
      "commiserating\n",
      "Saved the embedding for commiserating.\n",
      "['com', '##mise', '##rative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0619,  0.1693,  0.0526,  ..., -0.3344,  0.0720, -0.2765])\n",
      "commiserative\n",
      "Saved the embedding for commiserative.\n",
      "['com', '##mun', '##icative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0813, -0.0364, -0.2613,  ..., -0.5420, -0.1953,  0.6390])\n",
      "communicative\n",
      "Saved the embedding for communicative.\n",
      "['compassion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4315,  0.3030,  0.2390,  ..., -0.6774, -1.4938, -0.0824])\n",
      "compassion\n",
      "Saved the embedding for compassion.\n",
      "['compassionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3031,  0.0250,  0.7241,  ..., -0.0700, -0.4206,  0.0761])\n",
      "compassionate\n",
      "Saved the embedding for compassionate.\n",
      "['competent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4853,  0.0785,  0.4633,  ..., -0.9621, -0.5486,  1.0780])\n",
      "competent\n",
      "Saved the embedding for competent.\n",
      "['competitive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2499,  0.0443,  0.3294,  ..., -0.0873, -0.6454, -0.3596])\n",
      "competitive\n",
      "Saved the embedding for competitive.\n",
      "['com', '##pl', '##ace', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4134,  0.4237, -0.1493,  ..., -0.1027,  0.2041,  0.2372])\n",
      "complacence\n",
      "Saved the embedding for complacence.\n",
      "['com', '##pl', '##ace', '##ncy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.7750,  0.3281, -0.3965,  ...,  0.0844,  0.2376, -0.2872])\n",
      "complacency\n",
      "Saved the embedding for complacency.\n",
      "['com', '##pl', '##ace', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5229,  0.4898, -0.1479,  ..., -0.1167,  0.0587,  0.0155])\n",
      "complacent\n",
      "Saved the embedding for complacent.\n",
      "['com', '##pl', '##ace', '##ntly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6933,  0.5777,  0.2457,  ..., -0.5549,  0.4501, -0.1999])\n",
      "complacently\n",
      "Saved the embedding for complacently.\n",
      "['complain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3436,  0.3659,  0.6229,  ..., -0.4143, -0.2977,  0.5440])\n",
      "complain\n",
      "Saved the embedding for complain.\n",
      "['complaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1542,  0.1409,  0.4826,  ...,  0.0782, -0.8256,  0.7007])\n",
      "complaining\n",
      "Saved the embedding for complaining.\n",
      "['composed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1678,  0.3042,  0.0598,  ...,  0.0178, -0.8375, -0.1052])\n",
      "composed\n",
      "Saved the embedding for composed.\n",
      "['comprehend', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6699,  0.1423, -0.6117,  ..., -0.8672, -0.1239,  0.2428])\n",
      "comprehending\n",
      "Saved the embedding for comprehending.\n",
      "['com', '##pu', '##ls', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1852,  0.0889, -0.1629,  ..., -0.1958,  0.0331,  0.1466])\n",
      "compulsive\n",
      "Saved the embedding for compulsive.\n",
      "['concealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1813, -0.4626, -0.4031,  ..., -0.8089, -1.0783,  0.1531])\n",
      "concealed\n",
      "Saved the embedding for concealed.\n",
      "['con', '##ced', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1160,  0.4367,  0.7224,  ...,  0.1026, -1.4764,  1.1809])\n",
      "conceding\n",
      "Saved the embedding for conceding.\n",
      "['con', '##ce', '##ited'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0228, -0.2041,  0.1340,  ...,  0.1492, -1.1368,  1.0714])\n",
      "conceited\n",
      "Saved the embedding for conceited.\n",
      "['concentrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0734,  0.2370, -0.4650,  ..., -0.2323, -0.3960,  0.0572])\n",
      "concentrated\n",
      "Saved the embedding for concentrated.\n",
      "['concentrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0682,  0.1291, -0.5169,  ...,  0.0387, -1.0415,  0.3358])\n",
      "concentrating\n",
      "Saved the embedding for concentrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concentration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.0188,  1.6752, -0.1792,  ..., -0.0436, -0.0198,  0.1528])\n",
      "concentration\n",
      "Saved the embedding for concentration.\n",
      "['concern'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1071,  0.9430,  0.2099,  ...,  0.1873, -0.7079,  0.0045])\n",
      "concern\n",
      "Saved the embedding for concern.\n",
      "['concerned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4832,  1.3301,  0.2816,  ...,  0.6450, -0.2615, -0.3618])\n",
      "concerned\n",
      "Saved the embedding for concerned.\n",
      "['con', '##ci', '##lia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1205, -0.2932, -0.0601,  ..., -0.1939, -0.5387,  0.9987])\n",
      "conciliatory\n",
      "Saved the embedding for conciliatory.\n",
      "['con', '##clusive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4019,  0.3343,  0.2059,  ...,  0.3427, -1.2563,  0.7199])\n",
      "conclusive\n",
      "Saved the embedding for conclusive.\n",
      "['condemning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0495, -0.0627,  0.0604,  ..., -0.1051, -0.3507, -0.4409])\n",
      "condemning\n",
      "Saved the embedding for condemning.\n",
      "['conde', '##sc', '##ending'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3343,  0.3054, -0.2560,  ..., -0.9746, -0.3418,  0.2145])\n",
      "condescending\n",
      "Saved the embedding for condescending.\n",
      "['condo', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4384,  0.6682, -0.1462,  ...,  0.6179, -1.1830, -0.5509])\n",
      "condoling\n",
      "Saved the embedding for condoling.\n",
      "['confidence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8082, -0.1200,  0.1415,  ..., -1.2227, -1.0061,  0.0525])\n",
      "confidence\n",
      "Saved the embedding for confidence.\n",
      "['confident'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1607,  0.0709,  0.8221,  ..., -0.5247, -0.2428, -0.6388])\n",
      "confident\n",
      "Saved the embedding for confident.\n",
      "['confidently'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0677, -0.2021,  0.4483,  ..., -0.3762, -0.9539, -0.2371])\n",
      "confidently\n",
      "Saved the embedding for confidently.\n",
      "['conflict', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1082,  0.7849,  0.7460,  ..., -1.2722, -1.4454, -0.1127])\n",
      "conflicted\n",
      "Saved the embedding for conflicted.\n",
      "['con', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1525,  0.4606,  0.2705,  ...,  0.4457, -1.4881,  1.3690])\n",
      "confound\n",
      "Saved the embedding for confound.\n",
      "['con', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6770,  0.3397,  0.6436,  ...,  0.3228, -1.1699,  0.2634])\n",
      "confounded\n",
      "Saved the embedding for confounded.\n",
      "['confrontation', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0509,  0.4477, -0.4777,  ..., -0.5587, -1.0834,  0.0509])\n",
      "confrontational\n",
      "Saved the embedding for confrontational.\n",
      "['confused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5469,  0.5177,  0.5516,  ..., -0.1567,  1.0062, -0.2658])\n",
      "confused\n",
      "Saved the embedding for confused.\n",
      "['confusion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5998,  0.8039,  0.1686,  ..., -0.3502, -0.0453, -0.4031])\n",
      "confusion\n",
      "Saved the embedding for confusion.\n",
      "['cong', '##enia', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0506, -0.0855, -0.2523,  ..., -0.5467,  0.3691,  0.3300])\n",
      "congenial\n",
      "Saved the embedding for congenial.\n",
      "['cong', '##rat', '##ulator', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3329, -0.3508,  0.0699,  ..., -0.7495, -0.2948,  0.0280])\n",
      "congratulatory\n",
      "Saved the embedding for congratulatory.\n",
      "['con', '##ni', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0795,  0.7881,  0.5177,  ...,  0.5606, -0.5862,  0.6385])\n",
      "conniving\n",
      "Saved the embedding for conniving.\n",
      "['conscious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2788, -0.2019, -0.1664,  ..., -0.6511, -0.2988, -1.0589])\n",
      "conscious\n",
      "Saved the embedding for conscious.\n",
      "['conservative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6058,  0.2356,  0.6427,  ...,  0.7278, -0.2503, -0.0676])\n",
      "conservative\n",
      "Saved the embedding for conservative.\n",
      "['consider', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0277,  0.7816,  0.0516,  ..., -0.2534, -0.8801, -0.1528])\n",
      "considerate\n",
      "Saved the embedding for considerate.\n",
      "['considering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0108,  0.7418,  0.0163,  ..., -0.3489, -0.8393,  0.5271])\n",
      "considering\n",
      "Saved the embedding for considering.\n",
      "['con', '##sol', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2867,  0.5894,  0.6539,  ...,  0.4450, -1.2322,  0.5593])\n",
      "consoling\n",
      "Saved the embedding for consoling.\n",
      "['con', '##sp', '##ira', '##tori', '##al'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0102, -0.1169, -0.0980,  ..., -0.2968, -0.4430,  0.7701])\n",
      "conspiratorial\n",
      "Saved the embedding for conspiratorial.\n",
      "['con', '##sp', '##iring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2211,  0.6232, -0.1525,  ..., -0.3920, -0.6973,  0.1901])\n",
      "conspiring\n",
      "Saved the embedding for conspiring.\n",
      "['con', '##ster', '##nation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4423,  0.7064, -0.0310,  ...,  1.4097, -0.1015,  0.5798])\n",
      "consternation\n",
      "Saved the embedding for consternation.\n",
      "['con', '##sti', '##pate', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3803,  0.3831,  0.5078,  ..., -0.5893, -0.7007,  0.9629])\n",
      "constipated\n",
      "Saved the embedding for constipated.\n",
      "['constrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1393,  0.2281, -0.2860,  ..., -0.0474,  0.3162, -0.1981])\n",
      "constrained\n",
      "Saved the embedding for constrained.\n",
      "['consumed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5597,  0.1514, -0.1904,  ..., -0.5893,  0.3387, -0.5037])\n",
      "consumed\n",
      "Saved the embedding for consumed.\n",
      "['consuming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5652, -0.1995,  0.7434,  ..., -0.7436, -0.7321, -0.3172])\n",
      "consuming\n",
      "Saved the embedding for consuming.\n",
      "['contained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0443, -0.1199, -0.6433,  ...,  0.0455, -0.9430,  0.1491])\n",
      "contained\n",
      "Saved the embedding for contained.\n",
      "['con', '##tem', '##plate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2878,  0.4713,  0.2695,  ...,  0.8912, -0.9289,  0.6743])\n",
      "contemplate\n",
      "Saved the embedding for contemplate.\n",
      "['contemplating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1164,  0.6731,  0.1213,  ...,  0.4106, -1.0679, -0.2863])\n",
      "contemplating\n",
      "Saved the embedding for contemplating.\n",
      "['con', '##tem', '##pl', '##ation'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5010, -0.0611, -0.0818,  ..., -0.3768, -1.3420,  0.2767])\n",
      "contemplation\n",
      "Saved the embedding for contemplation.\n",
      "['con', '##tem', '##pl', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4426, -0.0673, -0.0703,  ..., -0.4925, -0.9203,  0.2606])\n",
      "contemplative\n",
      "Saved the embedding for contemplative.\n",
      "['contempt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3973,  1.4379,  0.0882,  ...,  0.2653, -0.5565,  0.5766])\n",
      "contempt\n",
      "Saved the embedding for contempt.\n",
      "['contempt', '##uous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6333,  1.3667,  0.5837,  ..., -0.1341, -0.8987,  0.6326])\n",
      "contemptuous\n",
      "Saved the embedding for contemptuous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1413,  0.7672,  0.3045,  ..., -0.0193,  0.0350,  0.3606])\n",
      "content\n",
      "Saved the embedding for content.\n",
      "['content', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8337,  0.5967,  0.1751,  ..., -0.1295, -0.0537,  0.3823])\n",
      "contented\n",
      "Saved the embedding for contented.\n",
      "['contentious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2194,  0.4908, -0.1427,  ..., -0.7064, -1.1856, -0.8028])\n",
      "contentious\n",
      "Saved the embedding for contentious.\n",
      "['content', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8588,  0.9086,  0.7389,  ..., -0.9285, -0.7225,  0.2137])\n",
      "contently\n",
      "Saved the embedding for contently.\n",
      "['content', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8610,  0.6848,  0.5005,  ..., -0.0501,  0.0319,  0.4384])\n",
      "contentment\n",
      "Saved the embedding for contentment.\n",
      "['contradictory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2045, -0.6536,  0.5005,  ...,  0.0450, -0.2861, -0.8446])\n",
      "contradictory\n",
      "Saved the embedding for contradictory.\n",
      "['contrary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3016, -0.3526,  0.4557,  ...,  0.1388, -0.7453,  0.1287])\n",
      "contrary\n",
      "Saved the embedding for contrary.\n",
      "['con', '##tri', '##te'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2928,  0.2381, -0.1829,  ...,  0.1428, -1.6248,  1.1058])\n",
      "contrite\n",
      "Saved the embedding for contrite.\n",
      "['controlled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6710, -0.1310, -0.1320,  ..., -0.8410, -0.4929, -0.5732])\n",
      "controlled\n",
      "Saved the embedding for controlled.\n",
      "['controlling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7141, -0.0089, -0.0468,  ...,  0.5543, -0.1955, -0.4269])\n",
      "controlling\n",
      "Saved the embedding for controlling.\n",
      "['controversial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7673, -0.3240,  0.6642,  ..., -0.9176, -0.4362, -1.0620])\n",
      "controversial\n",
      "Saved the embedding for controversial.\n",
      "['con', '##tum', '##acious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2323,  0.3129, -0.1141,  ..., -0.2267, -0.7684,  0.7267])\n",
      "contumacious\n",
      "Saved the embedding for contumacious.\n",
      "['convinced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1154, -0.0552,  0.1837,  ...,  0.2407, -0.0780,  0.1415])\n",
      "convinced\n",
      "Saved the embedding for convinced.\n",
      "['cool'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3865,  0.7326,  0.2338,  ..., -0.2535, -1.0689,  0.1487])\n",
      "cool\n",
      "Saved the embedding for cool.\n",
      "['cooperative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1147,  0.6432,  0.1670,  ..., -1.1683, -1.0087,  0.1465])\n",
      "cooperative\n",
      "Saved the embedding for cooperative.\n",
      "['cord', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3079, -0.0374, -0.3556,  ..., -0.8363, -0.7838,  0.7946])\n",
      "cordial\n",
      "Saved the embedding for cordial.\n",
      "['courageous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1120,  0.5094,  1.0292,  ...,  0.6131, -0.5760,  0.0026])\n",
      "courageous\n",
      "Saved the embedding for courageous.\n",
      "['covert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1809, -0.3431, -0.3485,  ..., -0.0714, -0.7014,  0.0601])\n",
      "covert\n",
      "Saved the embedding for covert.\n",
      "['coward', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1591,  0.6471,  0.5226,  ...,  0.3043, -0.6709, -0.0494])\n",
      "cowardly\n",
      "Saved the embedding for cowardly.\n",
      "['co', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3087, -0.3549,  0.2529,  ...,  0.4649,  0.4987,  0.1607])\n",
      "coy\n",
      "Saved the embedding for coy.\n",
      "['crab', '##by'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6656, -0.4521, -0.6387,  ..., -0.2129,  0.1483, -0.3717])\n",
      "crabby\n",
      "Saved the embedding for crabby.\n",
      "['craft', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5855,  0.3078, -0.3984,  ..., -0.9531, -0.4460,  0.1678])\n",
      "crafty\n",
      "Saved the embedding for crafty.\n",
      "['crank', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1098,  0.6409, -0.1901,  ..., -0.0154, -0.0878,  0.1422])\n",
      "cranky\n",
      "Saved the embedding for cranky.\n",
      "['crazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3063,  0.2256,  0.6303,  ..., -0.6959, -1.0746,  0.1031])\n",
      "crazed\n",
      "Saved the embedding for crazed.\n",
      "['crazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0188, -0.1518,  0.2484,  ..., -0.3954, -0.4355, -0.1203])\n",
      "crazy\n",
      "Saved the embedding for crazy.\n",
      "['cr', '##ed', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0195,  0.1285, -0.2019,  ..., -0.2585, -0.2278,  1.0706])\n",
      "credulous\n",
      "Saved the embedding for credulous.\n",
      "['creepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2070,  0.7533,  0.1958,  ...,  0.2373, -0.8154, -0.0605])\n",
      "creepy\n",
      "Saved the embedding for creepy.\n",
      "['crest', '##fall', '##en'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0364, -0.2027, -0.2771,  ..., -0.5960, -1.0246, -0.1966])\n",
      "crestfallen\n",
      "Saved the embedding for crestfallen.\n",
      "['cr', '##inging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7918,  0.5529,  0.4161,  ..., -0.4607, -0.8004,  0.4718])\n",
      "cringing\n",
      "Saved the embedding for cringing.\n",
      "['critical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8033,  1.3540,  0.3510,  ...,  0.4846, -0.8269, -0.0267])\n",
      "critical\n",
      "Saved the embedding for critical.\n",
      "['cross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0102,  0.8825, -0.0046,  ...,  0.7781, -0.8738, -0.5853])\n",
      "cross\n",
      "Saved the embedding for cross.\n",
      "['crotch', '##ety'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0124,  0.1092, -0.1173,  ..., -0.5457, -0.5942, -0.2241])\n",
      "crotchety\n",
      "Saved the embedding for crotchety.\n",
      "['crude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4792,  0.3017,  0.7318,  ..., -1.0264, -0.3970,  0.2974])\n",
      "crude\n",
      "Saved the embedding for crude.\n",
      "['cruel'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3354,  0.6362,  1.0216,  ..., -0.0067, -0.5553, -0.3295])\n",
      "cruel\n",
      "Saved the embedding for cruel.\n",
      "['crushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3227, -0.0126, -0.0663,  ...,  0.0383, -0.8134, -1.0391])\n",
      "crushed\n",
      "Saved the embedding for crushed.\n",
      "['cry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0628,  0.0950, -0.3633,  ..., -0.5697,  0.1553, -0.0077])\n",
      "cry\n",
      "Saved the embedding for cry.\n",
      "['crying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2280,  0.4956,  0.5235,  ..., -0.1810, -0.6875, -0.9183])\n",
      "crying\n",
      "Saved the embedding for crying.\n",
      "['cryptic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4587, -0.1178,  0.2407,  ...,  0.0017,  0.5797, -0.6394])\n",
      "cryptic\n",
      "Saved the embedding for cryptic.\n",
      "['cu', '##lp', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4357, -0.4776, -0.0230,  ..., -0.5015, -0.4138, -0.3248])\n",
      "culpable\n",
      "Saved the embedding for culpable.\n",
      "['cunning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3955,  0.5040,  0.5676,  ...,  0.1614, -0.1841,  0.3841])\n",
      "cunning\n",
      "Saved the embedding for cunning.\n",
      "['cu', '##rio', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0232, -0.0855, -0.5489,  ..., -0.2934, -1.2310,  0.6475])\n",
      "curios\n",
      "Saved the embedding for curios.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curiosity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0260,  0.4663,  0.1062,  ..., -0.2582, -0.4133,  0.1888])\n",
      "curiosity\n",
      "Saved the embedding for curiosity.\n",
      "['curious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3915,  0.5542, -0.2298,  ..., -0.2876, -0.0526, -0.4310])\n",
      "curious\n",
      "Saved the embedding for curious.\n",
      "['cutting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0116, -0.5079,  0.6580,  ...,  0.8731, -0.4706, -0.1316])\n",
      "cutting\n",
      "Saved the embedding for cutting.\n",
      "['cy', '##nic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8576,  0.0209,  0.1143,  ..., -0.4855, -0.7006,  0.5070])\n",
      "cynic\n",
      "Saved the embedding for cynic.\n",
      "['cynical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3641,  0.2279,  0.8325,  ..., -0.3694, -0.3807, -0.5860])\n",
      "cynical\n",
      "Saved the embedding for cynical.\n",
      "['cy', '##nic', '##ism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.1619, -0.3869,  0.0356,  ..., -0.8346, -0.6371,  0.7830])\n",
      "cynicism\n",
      "Saved the embedding for cynicism.\n",
      "['dal', '##lian', '##ce'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5153,  0.1741, -0.8812,  ..., -0.9837, -0.4267, -0.1111])\n",
      "dalliance\n",
      "Saved the embedding for dalliance.\n",
      "['dan', '##dy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2992, -0.0227,  0.1245,  ...,  0.1955, -0.0323, -0.6564])\n",
      "dandy\n",
      "Saved the embedding for dandy.\n",
      "['dangerous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2817,  0.7428,  0.3413,  ..., -0.7227, -1.2058,  0.2993])\n",
      "dangerous\n",
      "Saved the embedding for dangerous.\n",
      "['darkly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9398,  0.0329,  0.1740,  ..., -0.7643,  0.4593, -0.4151])\n",
      "darkly\n",
      "Saved the embedding for darkly.\n",
      "['da', '##unt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7692, -0.2864, -0.7070,  ..., -1.0123,  0.0965,  0.7216])\n",
      "daunted\n",
      "Saved the embedding for daunted.\n",
      "['day', '##dre', '##am'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2718,  0.0593,  0.2132,  ..., -0.3321,  0.0991,  0.5107])\n",
      "daydream\n",
      "Saved the embedding for daydream.\n",
      "['day', '##dre', '##ami', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3877,  0.2147,  0.3585,  ..., -0.4967, -0.2065,  0.3257])\n",
      "daydreaming\n",
      "Saved the embedding for daydreaming.\n",
      "['dazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0490,  0.3580, -0.4273,  ...,  0.3157,  0.1731, -0.0350])\n",
      "dazed\n",
      "Saved the embedding for dazed.\n",
      "['da', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7694, -0.2903, -0.2590,  ..., -0.9144, -0.6440,  0.4782])\n",
      "dazzled\n",
      "Saved the embedding for dazzled.\n",
      "['deadly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0044,  0.2604,  0.9735,  ..., -0.7293, -0.0853, -0.9364])\n",
      "deadly\n",
      "Saved the embedding for deadly.\n",
      "['dead', '##pan'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2028,  0.1859, -0.4438,  ..., -0.7437, -0.2929,  0.8379])\n",
      "deadpan\n",
      "Saved the embedding for deadpan.\n",
      "['debate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4334,  0.3660,  0.8448,  ...,  0.2692, -0.5493, -0.4147])\n",
      "debate\n",
      "Saved the embedding for debate.\n",
      "['debating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4661,  0.4344, -0.4085,  ..., -0.3638, -0.0584,  0.0787])\n",
      "debating\n",
      "Saved the embedding for debating.\n",
      "['de', '##bau', '##ched'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7097,  0.4290,  0.0656,  ..., -0.1103,  0.4676,  0.6990])\n",
      "debauched\n",
      "Saved the embedding for debauched.\n",
      "['dec', '##eit', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4436,  0.6674, -0.0486,  ...,  0.4328,  0.0693, -0.2413])\n",
      "deceitful\n",
      "Saved the embedding for deceitful.\n",
      "['dec', '##ei', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3657,  0.6560,  0.1506,  ...,  0.2417,  0.7080, -0.3512])\n",
      "deceived\n",
      "Saved the embedding for deceived.\n",
      "['dec', '##ei', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0143,  0.6125,  0.1789,  ..., -0.3908, -0.0129,  0.0299])\n",
      "deceiving\n",
      "Saved the embedding for deceiving.\n",
      "['dec', '##ei', '##ving', '##ly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2016,  0.1971,  0.0929,  ..., -0.1380, -0.3371,  0.3085])\n",
      "deceivingly\n",
      "Saved the embedding for deceivingly.\n",
      "['deception'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3512, -0.0824,  0.1789,  ...,  0.0431, -0.4808, -1.0366])\n",
      "deception\n",
      "Saved the embedding for deception.\n",
      "['dec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7602,  0.5947, -0.1252,  ..., -0.5225,  0.4202, -0.5358])\n",
      "deceptive\n",
      "Saved the embedding for deceptive.\n",
      "['deciding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1389,  0.2257, -0.3279,  ..., -0.5056, -0.8241, -0.9715])\n",
      "deciding\n",
      "Saved the embedding for deciding.\n",
      "['decisive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6493,  0.9705,  0.1455,  ..., -0.4978, -0.2320,  0.1974])\n",
      "decisive\n",
      "Saved the embedding for decisive.\n",
      "['dedicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1160,  0.7310,  0.3136,  ...,  0.1828, -0.3259,  0.4297])\n",
      "dedicated\n",
      "Saved the embedding for dedicated.\n",
      "['defeat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0392, -0.3067,  0.4374,  ...,  1.0664, -0.8407, -1.5301])\n",
      "defeat\n",
      "Saved the embedding for defeat.\n",
      "['defeated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1878, -0.5838,  0.3615,  ..., -0.2825, -0.7801, -1.9154])\n",
      "defeated\n",
      "Saved the embedding for defeated.\n",
      "['defense', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2003,  0.6283, -0.3716,  ..., -0.7924,  0.1457, -0.3000])\n",
      "defenseless\n",
      "Saved the embedding for defenseless.\n",
      "['defensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0896, -0.0482,  0.5699,  ..., -0.2224,  0.2874, -1.1224])\n",
      "defensive\n",
      "Saved the embedding for defensive.\n",
      "['defiance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1074,  0.3508,  0.3303,  ...,  0.4615,  0.7000,  0.1883])\n",
      "defiance\n",
      "Saved the embedding for defiance.\n",
      "['defiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1030,  0.1795, -0.0378,  ..., -0.1802, -0.7526, -0.0841])\n",
      "defiant\n",
      "Saved the embedding for defiant.\n",
      "['def', '##lated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2377, -0.8282,  0.9770,  ..., -0.2848,  0.2299, -0.6344])\n",
      "deflated\n",
      "Saved the embedding for deflated.\n",
      "['de', '##ga', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6935,  0.2191,  0.2591,  ...,  0.1541, -0.6244,  0.3760])\n",
      "degage\n",
      "Saved the embedding for degage.\n",
      "['de', '##grad', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6294,  0.2501,  0.3553,  ...,  0.2389, -0.1837,  0.2810])\n",
      "degrading\n",
      "Saved the embedding for degrading.\n",
      "['de', '##jected'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9335, -0.1324,  0.3510,  ..., -0.3133,  0.0080,  0.3486])\n",
      "dejected\n",
      "Saved the embedding for dejected.\n",
      "['de', '##ject', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9263,  0.6372,  0.3106,  ...,  0.4745,  0.3785,  0.1491])\n",
      "dejection\n",
      "Saved the embedding for dejection.\n",
      "['deliberate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7468,  0.0434,  1.1228,  ..., -0.7315, -0.5694, -0.3966])\n",
      "deliberate\n",
      "Saved the embedding for deliberate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['del', '##ibe', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0467,  0.5301,  0.1428,  ..., -1.0922, -0.6665,  0.4631])\n",
      "deliberating\n",
      "Saved the embedding for deliberating.\n",
      "['delight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3881,  0.7654, -0.0803,  ..., -0.1026, -0.0562, -0.1091])\n",
      "delight\n",
      "Saved the embedding for delight.\n",
      "['delighted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0511,  0.3958,  0.3848,  ..., -0.5845, -0.9858,  0.1364])\n",
      "delighted\n",
      "Saved the embedding for delighted.\n",
      "['delightful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4578,  0.0725,  0.2304,  ..., -0.5234, -0.6216,  0.6086])\n",
      "delightful\n",
      "Saved the embedding for delightful.\n",
      "['del', '##iri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3033,  0.3092, -0.4302,  ..., -1.0609, -0.2014,  0.4564])\n",
      "delirious\n",
      "Saved the embedding for delirious.\n",
      "['del', '##iri', '##um'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7016,  0.4953, -0.3075,  ..., -0.6141, -0.0457,  1.0322])\n",
      "delirium\n",
      "Saved the embedding for delirium.\n",
      "['del', '##ude'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5943,  0.1563, -0.1958,  ..., -0.2266,  0.6183,  0.7177])\n",
      "delude\n",
      "Saved the embedding for delude.\n",
      "['del', '##usion', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0782,  0.2949, -0.2937,  ..., -0.8368, -0.2035,  0.7059])\n",
      "delusional\n",
      "Saved the embedding for delusional.\n",
      "['demanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3159,  0.7921,  0.0526,  ..., -0.6182, -0.9259, -0.4555])\n",
      "demanding\n",
      "Saved the embedding for demanding.\n",
      "['dem', '##ean', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3579, -0.2816, -0.5120,  ..., -0.7935, -0.2933,  0.5696])\n",
      "demeaning\n",
      "Saved the embedding for demeaning.\n",
      "['dem', '##ented'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5668, -0.9672, -0.4986,  ..., -0.5373, -0.1644,  0.1878])\n",
      "demented\n",
      "Saved the embedding for demented.\n",
      "['demise', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0540,  0.3641,  0.3978,  ..., -0.6298,  0.6381, -0.8301])\n",
      "demised\n",
      "Saved the embedding for demised.\n",
      "['demo', '##ral', '##ized'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4145,  0.4421,  0.3789,  ..., -0.6133, -0.5024, -0.2071])\n",
      "demoralized\n",
      "Saved the embedding for demoralized.\n",
      "['dem', '##ure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5345, -0.2582, -0.5667,  ..., -0.6394, -0.4099,  0.4240])\n",
      "demure\n",
      "Saved the embedding for demure.\n",
      "['denied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4032, -0.7989, -0.5009,  ..., -0.8703, -0.3097, -0.5325])\n",
      "denied\n",
      "Saved the embedding for denied.\n",
      "['den', '##oun', '##cing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7620,  0.2249, -0.2506,  ..., -0.8195, -0.4667, -0.1567])\n",
      "denouncing\n",
      "Saved the embedding for denouncing.\n",
      "['depleted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5001,  0.0103, -0.6212,  ..., -0.0453,  0.0249, -0.8573])\n",
      "depleted\n",
      "Saved the embedding for depleted.\n",
      "['de', '##pl', '##ora', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5621,  0.4184,  0.3809,  ..., -0.3533, -0.1716,  0.0743])\n",
      "deplorable\n",
      "Saved the embedding for deplorable.\n",
      "['de', '##pre', '##cating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8044,  0.5797, -0.2359,  ...,  0.5442,  0.5362,  0.2085])\n",
      "deprecating\n",
      "Saved the embedding for deprecating.\n",
      "['depressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0671,  0.4681,  0.5150,  ..., -0.3886, -0.8108,  0.0485])\n",
      "depressed\n",
      "Saved the embedding for depressed.\n",
      "['depression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1294,  0.7312, -0.3455,  ..., -0.7410, -0.2926, -1.2796])\n",
      "depression\n",
      "Saved the embedding for depression.\n",
      "['deprived'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0422,  0.1738,  0.5450,  ...,  1.1252,  0.0418, -0.0492])\n",
      "deprived\n",
      "Saved the embedding for deprived.\n",
      "['der', '##ange', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1950,  0.6670, -0.5574,  ..., -0.3010, -0.2324,  0.3763])\n",
      "deranged\n",
      "Saved the embedding for deranged.\n",
      "['der', '##ision'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1837,  0.5074, -0.6142,  ..., -0.3454, -0.4317,  0.4316])\n",
      "derision\n",
      "Saved the embedding for derision.\n",
      "['der', '##isi', '##ve'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3285,  0.9175, -0.5955,  ...,  0.1374,  0.0661,  0.0824])\n",
      "derisive\n",
      "Saved the embedding for derisive.\n",
      "['der', '##oga', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1793,  0.4133, -0.5212,  ..., -0.3444, -0.3406,  0.5305])\n",
      "derogatory\n",
      "Saved the embedding for derogatory.\n",
      "['desire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3783,  0.7099, -0.2024,  ...,  0.0248, -1.1579,  0.1056])\n",
      "desire\n",
      "Saved the embedding for desire.\n",
      "['des', '##iring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6883,  0.2963, -0.6912,  ..., -0.1445,  0.2389,  0.5641])\n",
      "desiring\n",
      "Saved the embedding for desiring.\n",
      "['des', '##iro', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7278,  0.2956, -0.5438,  ...,  0.0093, -0.4602,  0.5151])\n",
      "desirous\n",
      "Saved the embedding for desirous.\n",
      "['des', '##olate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7170,  0.2019, -0.4307,  ...,  0.0511,  0.2348,  0.5729])\n",
      "desolate\n",
      "Saved the embedding for desolate.\n",
      "['despair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2311,  0.2407, -0.0219,  ...,  0.4735, -0.3839, -0.1684])\n",
      "despair\n",
      "Saved the embedding for despair.\n",
      "['despair', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3004,  0.0235,  0.1046,  ..., -0.2557, -0.6926,  0.1426])\n",
      "despaired\n",
      "Saved the embedding for despaired.\n",
      "['despair', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4449, -0.0493,  0.0341,  ..., -0.5390, -0.6478,  0.1802])\n",
      "despairing\n",
      "Saved the embedding for despairing.\n",
      "['desperate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0056,  0.4172,  0.7716,  ..., -0.2754, -0.0486, -0.2775])\n",
      "desperate\n",
      "Saved the embedding for desperate.\n",
      "['desperation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1888,  0.1068,  0.2245,  ..., -0.2744, -0.7629,  0.1288])\n",
      "desperation\n",
      "Saved the embedding for desperation.\n",
      "['des', '##pis', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7631,  0.3956, -0.4482,  ..., -0.1834, -0.1570,  0.7505])\n",
      "despise\n",
      "Saved the embedding for despise.\n",
      "['des', '##pon', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7577,  0.2706, -0.4036,  ..., -0.3242,  0.0299,  0.7136])\n",
      "despondent\n",
      "Saved the embedding for despondent.\n",
      "['des', '##ti', '##tute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7375,  0.3793, -0.3821,  ...,  0.1894, -0.0317,  1.1495])\n",
      "destitute\n",
      "Saved the embedding for destitute.\n",
      "['destroyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2195, -0.4557, -0.3914,  ..., -0.7022,  0.2458, -0.1421])\n",
      "destroyed\n",
      "Saved the embedding for destroyed.\n",
      "['detached'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2068, -0.2980, -1.2565,  ..., -0.2521,  1.1970,  0.1733])\n",
      "detached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for detached.\n",
      "['determination'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7843,  1.0054,  0.1698,  ..., -0.4316, -0.3155, -0.0524])\n",
      "determination\n",
      "Saved the embedding for determination.\n",
      "['determined'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3260,  0.5767,  0.6342,  ..., -1.8545, -0.5249, -0.2131])\n",
      "determined\n",
      "Saved the embedding for determined.\n",
      "['determining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2251,  0.3140,  0.4599,  ..., -1.3758, -0.6726,  0.3906])\n",
      "determining\n",
      "Saved the embedding for determining.\n",
      "['deter', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4679,  0.8405,  0.0123,  ..., -0.8547, -1.1477,  0.2733])\n",
      "deterred\n",
      "Saved the embedding for deterred.\n",
      "['det', '##est'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1119,  0.3799, -0.5378,  ..., -0.3284, -0.9373,  0.7880])\n",
      "detest\n",
      "Saved the embedding for detest.\n",
      "['det', '##est', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0144,  0.1722, -0.7336,  ..., -0.5079, -1.0067,  1.1796])\n",
      "detestable\n",
      "Saved the embedding for detestable.\n",
      "['det', '##est', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3959,  0.3088, -0.8939,  ..., -0.6196, -0.9981,  0.7743])\n",
      "detesting\n",
      "Saved the embedding for detesting.\n",
      "['det', '##rim', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0936,  0.2894, -0.6026,  ..., -0.8025, -0.4816,  0.4098])\n",
      "detriment\n",
      "Saved the embedding for detriment.\n",
      "['devastated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1749, -0.3778,  0.6662,  ..., -0.7018, -0.6333, -0.2980])\n",
      "devastated\n",
      "Saved the embedding for devastated.\n",
      "['devi', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7389,  0.0166,  0.3229,  ..., -1.7223, -0.6813,  0.0377])\n",
      "deviant\n",
      "Saved the embedding for deviant.\n",
      "['devil', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0908,  0.2052,  0.5189,  ..., -0.0465, -0.2365, -0.0379])\n",
      "devilish\n",
      "Saved the embedding for devilish.\n",
      "['devi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4590, -0.1967,  0.3656,  ..., -1.2702, -0.2147,  0.1222])\n",
      "devious\n",
      "Saved the embedding for devious.\n",
      "['devi', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6451, -0.3085,  0.4287,  ..., -1.1102, -0.8859,  0.5694])\n",
      "devising\n",
      "Saved the embedding for devising.\n",
      "['di', '##ffi', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2180, -0.1163, -0.1637,  ..., -0.2264, -0.1240,  1.1400])\n",
      "diffident\n",
      "Saved the embedding for diffident.\n",
      "['dil', '##atory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0331, -0.2939, -0.0980,  ..., -0.9870, -1.0525,  0.6720])\n",
      "dilatory\n",
      "Saved the embedding for dilatory.\n",
      "['dil', '##igen', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2956, -0.0654,  0.0975,  ..., -0.8693, -0.8148,  0.7258])\n",
      "diligent\n",
      "Saved the embedding for diligent.\n",
      "['dim', '##wi', '##tted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2814,  0.1649, -0.4775,  ..., -0.4637, -0.5040, -0.1294])\n",
      "dimwitted\n",
      "Saved the embedding for dimwitted.\n",
      "['dire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2877,  0.2089, -0.0347,  ..., -0.7177,  0.2166, -0.2456])\n",
      "dire\n",
      "Saved the embedding for dire.\n",
      "['disagree'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0066,  0.1801,  0.0670,  ..., -0.5950, -0.8251,  0.0878])\n",
      "disagree\n",
      "Saved the embedding for disagree.\n",
      "['disagree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2673,  0.2818,  0.1332,  ..., -0.6716, -1.4478,  0.3749])\n",
      "disagreeable\n",
      "Saved the embedding for disagreeable.\n",
      "['disagreement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3247,  0.5049, -0.0732,  ...,  0.1610, -1.4539, -0.5855])\n",
      "disagreement\n",
      "Saved the embedding for disagreement.\n",
      "['disappointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0533,  0.1555,  0.6798,  ..., -0.6446, -0.6717, -0.0638])\n",
      "disappointed\n",
      "Saved the embedding for disappointed.\n",
      "['disappointing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5729, -0.5348, -0.3746,  ...,  0.3358, -0.6303,  0.1321])\n",
      "disappointing\n",
      "Saved the embedding for disappointing.\n",
      "['disappointment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1104,  0.6085,  0.9229,  ...,  0.0168,  0.7031, -0.3522])\n",
      "disappointment\n",
      "Saved the embedding for disappointment.\n",
      "['disapproval'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1338,  0.2358,  0.0676,  ..., -0.4139, -0.8688,  0.2829])\n",
      "disapproval\n",
      "Saved the embedding for disapproval.\n",
      "['di', '##sa', '##pp', '##roving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2921,  0.4961, -0.3275,  ..., -0.0608, -0.0032,  0.3130])\n",
      "disapproving\n",
      "Saved the embedding for disapproving.\n",
      "['disbelief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3124,  0.6925, -0.3075,  ...,  0.1258, -0.0131, -0.5741])\n",
      "disbelief\n",
      "Saved the embedding for disbelief.\n",
      "['di', '##sb', '##eli', '##eve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0632,  0.6288, -0.2734,  ...,  0.0141, -0.1874,  0.6270])\n",
      "disbelieve\n",
      "Saved the embedding for disbelieve.\n",
      "['di', '##sb', '##eli', '##eving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1248,  0.6931, -0.4599,  ..., -0.3044,  0.0830,  0.3189])\n",
      "disbelieving\n",
      "Saved the embedding for disbelieving.\n",
      "['disc', '##ern', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3236,  0.3256,  0.7730,  ..., -0.5666, -0.5288, -0.9418])\n",
      "discerning\n",
      "Saved the embedding for discerning.\n",
      "['disco', '##mbo', '##bula', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0244, -0.3813,  0.0895,  ..., -1.0784, -0.2749, -0.7106])\n",
      "discombobulated\n",
      "Saved the embedding for discombobulated.\n",
      "['disco', '##m', '##fi', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2672, -0.3833,  0.3069,  ..., -1.0208, -0.5865, -0.9096])\n",
      "discomfited\n",
      "Saved the embedding for discomfited.\n",
      "['discomfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2306,  0.3317, -0.1144,  ...,  0.1780, -0.3763,  0.9559])\n",
      "discomfort\n",
      "Saved the embedding for discomfort.\n",
      "['discomfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5459,  0.4034, -0.0377,  ..., -0.6052, -0.2639,  0.0232])\n",
      "discomforted\n",
      "Saved the embedding for discomforted.\n",
      "['disco', '##nce', '##rted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2757,  0.0736, -0.2006,  ..., -0.8121, -0.4754, -0.7105])\n",
      "disconcerted\n",
      "Saved the embedding for disconcerted.\n",
      "['disconnected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4416,  0.0483,  0.8702,  ..., -0.2873, -0.0651, -0.7562])\n",
      "disconnected\n",
      "Saved the embedding for disconnected.\n",
      "['disco', '##ns', '##olate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3941, -0.2488,  0.4735,  ..., -0.8221, -0.3852, -0.7393])\n",
      "disconsolate\n",
      "Saved the embedding for disconsolate.\n",
      "['discontent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0648,  0.1521,  1.0179,  ..., -0.3512, -0.7281, -0.1650])\n",
      "discontent\n",
      "Saved the embedding for discontent.\n",
      "['discontent', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1325,  0.2491,  1.0653,  ..., -0.3970, -0.6439, -0.3995])\n",
      "discontented\n",
      "Saved the embedding for discontented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discount', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6870, -0.2808,  0.2275,  ..., -0.7159, -0.7378, -0.3773])\n",
      "discounted\n",
      "Saved the embedding for discounted.\n",
      "['discouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6556, -0.0557, -0.0534,  ...,  0.0797, -0.8085, -0.3167])\n",
      "discouraged\n",
      "Saved the embedding for discouraged.\n",
      "['discovery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2440, -0.2262,  0.0570,  ...,  0.3216, -0.8525,  0.2160])\n",
      "discovery\n",
      "Saved the embedding for discovery.\n",
      "['disc', '##rim', '##inating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1812,  0.5229, -0.5024,  ..., -0.7321,  0.1689,  0.7420])\n",
      "discriminating\n",
      "Saved the embedding for discriminating.\n",
      "['discussed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3958, -0.0018,  0.1367,  ..., -0.5279, -0.6644, -0.3301])\n",
      "discussed\n",
      "Saved the embedding for discussed.\n",
      "['disdain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1723,  0.6404,  0.4046,  ...,  0.0497, -0.2086,  0.6265])\n",
      "disdain\n",
      "Saved the embedding for disdain.\n",
      "['disdain', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0160,  0.3834,  0.7576,  ...,  1.0241, -0.8322, -0.1324])\n",
      "disdained\n",
      "Saved the embedding for disdained.\n",
      "['disdain', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1735,  0.5504,  0.0218,  ...,  0.1520, -0.5432,  0.2227])\n",
      "disdainful\n",
      "Saved the embedding for disdainful.\n",
      "['disdain', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0273,  0.5455, -0.1238,  ...,  0.4932, -0.5042,  0.1515])\n",
      "disdainfully\n",
      "Saved the embedding for disdainfully.\n",
      "['di', '##sen', '##chan', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1861,  0.1250, -0.5313,  ...,  0.0236, -0.3114,  0.2586])\n",
      "disenchanted\n",
      "Saved the embedding for disenchanted.\n",
      "['di', '##sen', '##ga', '##ged'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3581,  0.0900, -0.3288,  ..., -0.0328, -0.1517,  0.4853])\n",
      "disengaged\n",
      "Saved the embedding for disengaged.\n",
      "['disgrace', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0098,  0.6927,  0.8189,  ...,  0.3839, -0.5785, -1.0555])\n",
      "disgraced\n",
      "Saved the embedding for disgraced.\n",
      "['di', '##sg', '##run', '##tled'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4407,  0.3569, -0.0973,  ..., -0.2127, -0.4859,  0.2125])\n",
      "disgruntled\n",
      "Saved the embedding for disgruntled.\n",
      "['di', '##sg', '##run', '##tlement'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3524,  0.3771, -0.3553,  ...,  0.1432, -1.0982,  1.0023])\n",
      "disgruntlement\n",
      "Saved the embedding for disgruntlement.\n",
      "['disgust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4259,  0.6235, -0.8992,  ..., -0.2177,  0.0594,  0.1785])\n",
      "disgust\n",
      "Saved the embedding for disgust.\n",
      "['disgusted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5919,  0.3705,  0.6142,  ...,  0.0277, -0.3860, -0.0217])\n",
      "disgusted\n",
      "Saved the embedding for disgusted.\n",
      "['disgusted', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3721,  0.6236,  0.3469,  ..., -0.4593, -0.8461,  0.0979])\n",
      "disgustedly\n",
      "Saved the embedding for disgustedly.\n",
      "['disgusting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1504,  0.1381,  0.2549,  ..., -0.1400, -1.0216, -0.1602])\n",
      "disgusting\n",
      "Saved the embedding for disgusting.\n",
      "['dish', '##ear', '##ten', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2486, -0.5856, -0.2991,  ..., -0.3542,  0.1722,  0.4126])\n",
      "disheartened\n",
      "Saved the embedding for disheartened.\n",
      "['dish', '##ones', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3815, -0.5664, -0.0114,  ..., -0.5146,  0.0265,  0.0382])\n",
      "dishonest\n",
      "Saved the embedding for dishonest.\n",
      "['di', '##sil', '##lusion', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1756,  0.1262,  0.0757,  ..., -0.1933, -0.9603,  0.1938])\n",
      "disillusioned\n",
      "Saved the embedding for disillusioned.\n",
      "['di', '##sin', '##cl', '##ined'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2520,  0.2608, -0.1131,  ...,  0.7095, -0.2141,  0.9931])\n",
      "disinclined\n",
      "Saved the embedding for disinclined.\n",
      "['di', '##sing', '##en', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2245,  0.0124, -0.3222,  ..., -0.3297, -0.3968,  0.6522])\n",
      "disingenuous\n",
      "Saved the embedding for disingenuous.\n",
      "['di', '##sin', '##ter', '##est'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2774,  0.5911, -0.2652,  ...,  0.0376, -0.6779,  1.0595])\n",
      "disinterest\n",
      "Saved the embedding for disinterest.\n",
      "['di', '##sin', '##ter', '##ested'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0702,  0.4281, -0.1088,  ..., -0.0086, -0.5750,  0.8740])\n",
      "disinterested\n",
      "Saved the embedding for disinterested.\n",
      "['di', '##s', '##jo', '##int', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0857,  0.2606, -0.3315,  ...,  0.1117, -0.1112,  1.0452])\n",
      "disjointed\n",
      "Saved the embedding for disjointed.\n",
      "['dislike'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1567,  0.1701, -0.1306,  ..., -0.1326, -1.0706,  0.4492])\n",
      "dislike\n",
      "Saved the embedding for dislike.\n",
      "['disliked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0897,  0.1685,  0.1865,  ..., -0.0803, -0.9021,  0.0305])\n",
      "disliked\n",
      "Saved the embedding for disliked.\n",
      "['di', '##sl', '##iki', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3914,  0.2755, -0.3146,  ..., -0.5340, -0.4248,  0.6128])\n",
      "disliking\n",
      "Saved the embedding for disliking.\n",
      "['di', '##sma', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0336,  0.2743,  0.0293,  ..., -0.4099, -0.8759,  0.2969])\n",
      "dismal\n",
      "Saved the embedding for dismal.\n",
      "['di', '##sman'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0963, -0.1522, -0.3869,  ..., -0.2008, -0.2241,  0.7805])\n",
      "disman\n",
      "Saved the embedding for disman.\n",
      "['dismay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1501,  0.6610,  0.0993,  ...,  0.4346,  0.3963, -0.1783])\n",
      "dismay\n",
      "Saved the embedding for dismay.\n",
      "['dismay', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.0626, 0.8745, 0.3431,  ..., 0.2082, 0.2211, 0.0897])\n",
      "dismayed\n",
      "Saved the embedding for dismayed.\n",
      "['dismiss', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2446, -0.0600,  0.3311,  ..., -1.0252, -0.2276,  0.5913])\n",
      "dismissive\n",
      "Saved the embedding for dismissive.\n",
      "['di', '##so', '##bed', '##ient'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3112,  0.1940, -0.1422,  ...,  0.0613, -0.0125,  0.4325])\n",
      "disobedient\n",
      "Saved the embedding for disobedient.\n",
      "['disorder', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1327, -0.4334,  0.7693,  ..., -0.9941, -0.2033, -1.2324])\n",
      "disorderly\n",
      "Saved the embedding for disorderly.\n",
      "['di', '##sor', '##iente', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1712,  0.3294, -0.0415,  ..., -0.3518, -0.2098,  0.7572])\n",
      "disoriented\n",
      "Saved the embedding for disoriented.\n",
      "['di', '##sp', '##air'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1814,  0.3245, -0.3509,  ..., -0.9727,  0.2066,  0.2709])\n",
      "dispair\n",
      "Saved the embedding for dispair.\n",
      "['di', '##spar', '##aging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1788,  0.1367,  0.0041,  ..., -0.3728, -0.7933,  0.2323])\n",
      "disparaging\n",
      "Saved the embedding for disparaging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['di', '##sp', '##ass', '##ion', '##ate'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0395,  0.2929,  0.0902,  ...,  0.5661, -0.4155,  0.8880])\n",
      "dispassionate\n",
      "Saved the embedding for dispassionate.\n",
      "['di', '##sp', '##iri', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3214,  0.0795, -0.5101,  ..., -0.3486, -0.3124,  0.5629])\n",
      "dispirited\n",
      "Saved the embedding for dispirited.\n",
      "['di', '##sp', '##iri', '##ted', '##ness'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.1573,  0.1145, -0.2657,  ..., -0.3661, -0.2659,  1.1185])\n",
      "dispiritedness\n",
      "Saved the embedding for dispiritedness.\n",
      "['di', '##sp', '##lea', '##sed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0863, -0.0326,  0.0566,  ..., -0.3708, -0.3891,  0.1196])\n",
      "displeased\n",
      "Saved the embedding for displeased.\n",
      "['displeasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4387,  0.3654,  0.9921,  ..., -0.0697, -1.0713, -0.2539])\n",
      "displeasure\n",
      "Saved the embedding for displeasure.\n",
      "['di', '##s', '##qui', '##et'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0323,  0.2500, -0.3382,  ...,  0.8293,  0.0473,  0.5446])\n",
      "disquiet\n",
      "Saved the embedding for disquiet.\n",
      "['di', '##s', '##qui', '##ete', '##d'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0918,  0.1659, -0.0952,  ...,  0.4544,  0.3210,  0.4607])\n",
      "disquieted\n",
      "Saved the embedding for disquieted.\n",
      "['disregard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4963,  0.9002, -0.0779,  ..., -0.4631, -0.1969, -0.3947])\n",
      "disregard\n",
      "Saved the embedding for disregard.\n",
      "['di', '##sr', '##es', '##pe', '##ct', '##ful'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([-0.0429,  0.6117, -0.2909,  ..., -0.0137, -0.2442,  0.8952])\n",
      "disrespectful\n",
      "Saved the embedding for disrespectful.\n",
      "['disrupted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1819,  0.5862, -0.3231,  ..., -0.5524, -0.6158,  0.2246])\n",
      "disrupted\n",
      "Saved the embedding for disrupted.\n",
      "['disrupt', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6504,  0.3842,  0.2912,  ..., -0.0765, -0.6799,  0.2887])\n",
      "disruptive\n",
      "Saved the embedding for disruptive.\n",
      "['dissatisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6115,  0.3240,  0.9468,  ..., -0.3839, -0.7488, -0.3601])\n",
      "dissatisfaction\n",
      "Saved the embedding for dissatisfaction.\n",
      "['dissatisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3589,  0.4298,  0.3274,  ..., -0.3507, -0.9997,  0.0465])\n",
      "dissatisfied\n",
      "Saved the embedding for dissatisfied.\n",
      "['di', '##ssa', '##tis', '##fy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2097,  0.6059,  0.2291,  ...,  0.6288, -0.4291,  0.9557])\n",
      "dissatisfy\n",
      "Saved the embedding for dissatisfy.\n",
      "['di', '##sse', '##cting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2800,  0.1723, -0.3144,  ...,  0.4631,  0.0686,  1.1640])\n",
      "dissecting\n",
      "Saved the embedding for dissecting.\n",
      "['di', '##sso', '##cia', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2728,  0.3379,  0.1492,  ...,  0.3599, -0.0108,  0.6174])\n",
      "dissociated\n",
      "Saved the embedding for dissociated.\n",
      "['di', '##sson', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0138,  0.4307, -0.2196,  ...,  0.5193, -0.1020,  1.1429])\n",
      "dissonant\n",
      "Saved the embedding for dissonant.\n",
      "['di', '##sta', '##in'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1426,  0.3383, -0.6024,  ..., -0.9333, -0.1273,  0.7550])\n",
      "distain\n",
      "Saved the embedding for distain.\n",
      "['distant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0738,  0.0709, -0.2793,  ...,  0.1238, -0.0668, -0.1789])\n",
      "distant\n",
      "Saved the embedding for distant.\n",
      "['di', '##sta', '##ste'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2534,  0.3278, -0.1813,  ..., -0.9054, -0.4670,  0.8468])\n",
      "distaste\n",
      "Saved the embedding for distaste.\n",
      "['di', '##sta', '##ste', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3226,  0.3189, -0.0990,  ..., -0.7068, -0.9643,  0.3922])\n",
      "distasteful\n",
      "Saved the embedding for distasteful.\n",
      "['distracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3127,  0.8419,  0.3649,  ..., -0.1198, -0.2118, -0.1349])\n",
      "distracted\n",
      "Saved the embedding for distracted.\n",
      "['distraught'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3557, -0.0359,  0.4343,  ..., -0.5864, -0.4048, -0.0969])\n",
      "distraught\n",
      "Saved the embedding for distraught.\n",
      "['distress'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1827,  0.6352,  0.1186,  ..., -0.3461, -0.8898, -0.1347])\n",
      "distress\n",
      "Saved the embedding for distress.\n",
      "['distressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3868,  0.2413,  0.4596,  ...,  0.3746, -0.4781, -0.2746])\n",
      "distressed\n",
      "Saved the embedding for distressed.\n",
      "['distress', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1872,  0.4593,  0.4482,  ..., -0.8919, -0.9964, -0.0738])\n",
      "distressing\n",
      "Saved the embedding for distressing.\n",
      "['distrust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1882,  0.1894,  0.1712,  ..., -0.1702, -0.7389, -0.1425])\n",
      "distrust\n",
      "Saved the embedding for distrust.\n",
      "['distrust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1286,  0.0104,  0.1150,  ..., -0.6301, -0.7205, -0.1418])\n",
      "distrustful\n",
      "Saved the embedding for distrustful.\n",
      "['distrust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0549,  0.2540,  0.2615,  ..., -0.9013, -0.7528,  0.1411])\n",
      "distrusting\n",
      "Saved the embedding for distrusting.\n",
      "['disturbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2904,  0.5979, -0.3658,  ..., -0.1709, -0.1938,  0.1624])\n",
      "disturbed\n",
      "Saved the embedding for disturbed.\n",
      "['diverted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9603, -0.6084, -0.1001,  ..., -0.4992, -0.2855,  0.0797])\n",
      "diverted\n",
      "Saved the embedding for diverted.\n",
      "['dod', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1822, -0.1841, -0.6586,  ...,  0.0131,  0.0699,  0.1964])\n",
      "dodgy\n",
      "Saved the embedding for dodgy.\n",
      "['do', '##le', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0756, -0.2689, -0.2909,  ..., -0.6264,  0.4158,  0.3837])\n",
      "doleful\n",
      "Saved the embedding for doleful.\n",
      "['do', '##lt', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0603, -0.8647, -0.8721,  ..., -0.3755,  0.7047,  0.8162])\n",
      "doltish\n",
      "Saved the embedding for doltish.\n",
      "['dominant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2008,  0.6900,  0.3835,  ...,  0.6978, -0.4360, -0.4096])\n",
      "dominant\n",
      "Saved the embedding for dominant.\n",
      "['dominating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0432,  0.4027,  0.9969,  ...,  0.0916, -0.9863, -0.3028])\n",
      "dominating\n",
      "Saved the embedding for dominating.\n",
      "['dom', '##ine', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1862,  0.4050, -0.4427,  ..., -0.4767, -0.4684,  0.5069])\n",
      "domineering\n",
      "Saved the embedding for domineering.\n",
      "['done'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2703, -0.1061, -0.6670,  ..., -0.6304, -0.4389, -0.0064])\n",
      "done\n",
      "Saved the embedding for done.\n",
      "['doomed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4823, -0.5654,  0.2712,  ..., -0.3314, -0.0436, -0.6626])\n",
      "doomed\n",
      "Saved the embedding for doomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2886, -0.0036, -1.1624,  ..., -0.2556,  0.1008,  0.7322])\n",
      "dopey\n",
      "Saved the embedding for dopey.\n",
      "['dot', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4754,  0.0516, -0.8333,  ..., -0.4947, -0.1900, -0.1857])\n",
      "doting\n",
      "Saved the embedding for doting.\n",
      "['doubt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1681,  0.3056,  0.2218,  ..., -0.9208, -0.8872,  0.3164])\n",
      "doubt\n",
      "Saved the embedding for doubt.\n",
      "['doubt', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5449,  0.4106,  0.2355,  ..., -1.6421, -0.6299,  0.3549])\n",
      "doubter\n",
      "Saved the embedding for doubter.\n",
      "['doubtful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5290, -0.0093,  0.0561,  ...,  0.0789, -0.4798, -0.2905])\n",
      "doubtful\n",
      "Saved the embedding for doubtful.\n",
      "['doubtful', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5360, -0.1303, -0.0352,  ...,  0.3392,  0.1152, -0.1935])\n",
      "doubtfully\n",
      "Saved the embedding for doubtfully.\n",
      "['doubtful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3011,  0.0191, -0.3524,  ..., -0.2097, -0.2181, -0.2235])\n",
      "doubtfulness\n",
      "Saved the embedding for doubtfulness.\n",
      "['doubt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2687,  0.3939,  0.1169,  ..., -0.8727, -0.7248,  0.3337])\n",
      "doubting\n",
      "Saved the embedding for doubting.\n",
      "['do', '##ur'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0871, -0.2594, -0.8857,  ..., -1.1006, -0.1203,  0.4018])\n",
      "dour\n",
      "Saved the embedding for dour.\n",
      "['down'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6884,  0.0690, -0.2155,  ...,  0.1106, -0.5422,  0.0335])\n",
      "down\n",
      "Saved the embedding for down.\n",
      "['down', '##cast'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3630, -0.1576,  0.2132,  ..., -0.0817, -0.7667,  0.0665])\n",
      "downcast\n",
      "Saved the embedding for downcast.\n",
      "['down', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3900, -0.3744, -0.0254,  ..., -1.3950, -1.2135, -0.6505])\n",
      "downhearted\n",
      "Saved the embedding for downhearted.\n",
      "['down', '##hearted', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0831,  0.1015, -0.4996,  ..., -0.4357, -0.4502, -0.0749])\n",
      "downheartedness\n",
      "Saved the embedding for downheartedness.\n",
      "['down', '##tro', '##dden'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0900,  0.1444,  0.1950,  ..., -1.2834, -0.6851,  0.3321])\n",
      "downtrodden\n",
      "Saved the embedding for downtrodden.\n",
      "['do', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1775, -0.6882, -0.6678,  ..., -0.5261, -0.5233,  0.6967])\n",
      "dozing\n",
      "Saved the embedding for dozing.\n",
      "['drained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0262, -0.0293, -0.5274,  ...,  0.7165, -0.4599, -0.3438])\n",
      "drained\n",
      "Saved the embedding for drained.\n",
      "['dramatic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5896,  0.1523, -0.2627,  ..., -0.9316,  0.4154,  0.2014])\n",
      "dramatic\n",
      "Saved the embedding for dramatic.\n",
      "['drawn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4659,  0.5076,  0.3270,  ...,  0.0774, -0.1094, -0.5031])\n",
      "drawn\n",
      "Saved the embedding for drawn.\n",
      "['dread'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5026,  0.3883,  0.4954,  ..., -0.5091, -0.6860, -0.5538])\n",
      "dread\n",
      "Saved the embedding for dread.\n",
      "['dreadful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5369,  0.4369, -0.2393,  ..., -0.9458,  0.1792,  0.0023])\n",
      "dreadful\n",
      "Saved the embedding for dreadful.\n",
      "['dread', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3634,  0.3373,  0.3648,  ..., -1.0964, -0.6407,  0.0533])\n",
      "dreading\n",
      "Saved the embedding for dreading.\n",
      "['dreaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2367,  0.5058,  0.5107,  ...,  0.6891, -0.5655,  0.3012])\n",
      "dreaming\n",
      "Saved the embedding for dreaming.\n",
      "['dream', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1544,  0.1890, -0.0420,  ..., -0.3736, -0.8485,  0.1546])\n",
      "dreamy\n",
      "Saved the embedding for dreamy.\n",
      "['dr', '##ear', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1361,  0.4626, -0.2416,  ..., -0.3268,  0.1534,  0.7492])\n",
      "dreary\n",
      "Saved the embedding for dreary.\n",
      "['driven'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3849, -0.1793,  0.2071,  ..., -0.5975,  0.4830, -0.9197])\n",
      "driven\n",
      "Saved the embedding for driven.\n",
      "['dr', '##ows', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1803,  0.0160, -0.3392,  ..., -0.3649, -0.0354,  0.4078])\n",
      "drowsy\n",
      "Saved the embedding for drowsy.\n",
      "['drugged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6280, -0.3586, -0.0373,  ...,  0.6984, -0.0224, -0.2552])\n",
      "drugged\n",
      "Saved the embedding for drugged.\n",
      "['drunk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1079,  0.4962, -0.4811,  ..., -0.7248, -0.1423,  0.6017])\n",
      "drunk\n",
      "Saved the embedding for drunk.\n",
      "['drunken', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0961,  0.7652,  0.0464,  ...,  0.0330, -0.4853, -0.0272])\n",
      "drunkenness\n",
      "Saved the embedding for drunkenness.\n",
      "['dub', '##ie', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6157,  0.5715, -0.4723,  ..., -0.5893, -0.6468,  0.0930])\n",
      "dubiety\n",
      "Saved the embedding for dubiety.\n",
      "['dubious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4564,  0.0515, -0.2530,  ..., -0.0691, -0.7285, -0.1971])\n",
      "dubious\n",
      "Saved the embedding for dubious.\n",
      "['dubious', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3237,  0.1611, -0.1122,  ...,  0.2127, -0.4118, -0.3418])\n",
      "dubiously\n",
      "Saved the embedding for dubiously.\n",
      "['dull'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2636,  0.0772,  0.5357,  ..., -0.5359, -0.8559, -0.4037])\n",
      "dull\n",
      "Saved the embedding for dull.\n",
      "['dumb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0405,  0.6233, -0.7861,  ..., -1.0158, -0.9151,  0.6872])\n",
      "dumb\n",
      "Saved the embedding for dumb.\n",
      "['dumb', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3165,  0.4847, -0.4578,  ...,  0.5134, -0.3715,  0.4986])\n",
      "dumbfound\n",
      "Saved the embedding for dumbfound.\n",
      "['dumb', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2744,  0.4417,  0.0713,  ..., -0.3017, -0.3918,  0.0014])\n",
      "dumbfounded\n",
      "Saved the embedding for dumbfounded.\n",
      "['dumb', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1788,  0.6158, -0.2031,  ..., -0.0700, -0.2650,  0.3186])\n",
      "dumbstruck\n",
      "Saved the embedding for dumbstruck.\n",
      "['du', '##m', '##founded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1914,  0.2098,  0.4419,  ..., -0.4689,  0.1694,  0.1529])\n",
      "dumfounded\n",
      "Saved the embedding for dumfounded.\n",
      "['du', '##pe'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5792,  0.3447, -0.6130,  ...,  0.4284,  0.0184,  0.1670])\n",
      "dupe\n",
      "Saved the embedding for dupe.\n",
      "['du', '##pl', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.4405,  0.4770, -0.5409,  ...,  0.0214, -0.2100,  0.9297])\n",
      "duplicitous\n",
      "Saved the embedding for duplicitous.\n",
      "['d', '##ys', '##ph', '##oric'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5860,  0.0020, -0.3268,  ..., -1.3951, -0.4072, -0.3300])\n",
      "dysphoric\n",
      "Saved the embedding for dysphoric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eager'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6368,  0.6383,  0.4946,  ..., -0.3456, -0.5453, -0.2687])\n",
      "eager\n",
      "Saved the embedding for eager.\n",
      "['eager', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1254,  0.4464,  0.4982,  ..., -0.6493, -0.8224,  0.0136])\n",
      "eagerness\n",
      "Saved the embedding for eagerness.\n",
      "['earnest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4530,  0.8569,  0.2034,  ..., -0.6237, -0.2755, -0.1975])\n",
      "earnest\n",
      "Saved the embedding for earnest.\n",
      "['easy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1076, -0.0028,  0.4765,  ...,  0.2620, -0.3975,  0.0949])\n",
      "easy\n",
      "Saved the embedding for easy.\n",
      "['e', '##bu', '##llie', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5499, -0.0541, -0.1461,  ..., -0.3321, -0.3411,  0.3621])\n",
      "ebullient\n",
      "Saved the embedding for ebullient.\n",
      "['ecstasy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4661,  0.4456,  1.2884,  ..., -0.5198, -0.0188, -0.7224])\n",
      "ecstasy\n",
      "Saved the embedding for ecstasy.\n",
      "['ec', '##static'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4249,  0.3731,  0.5737,  ..., -1.4706, -1.1565, -0.4576])\n",
      "ecstatic\n",
      "Saved the embedding for ecstatic.\n",
      "['ec', '##static', '##ally'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2930,  0.3084,  0.2983,  ..., -1.2572,  0.2279, -0.2728])\n",
      "ecstatically\n",
      "Saved the embedding for ecstatically.\n",
      "['ed', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0234, -0.3372, -0.2438,  ...,  0.2810, -0.2599,  0.7533])\n",
      "edgy\n",
      "Saved the embedding for edgy.\n",
      "['eerie'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4971,  0.2454, -0.2390,  ..., -0.5937, -0.7211, -0.4065])\n",
      "eerie\n",
      "Saved the embedding for eerie.\n",
      "['e', '##ff', '##ul', '##gent'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2879, -0.2231, -0.4629,  ..., -0.8942, -0.6054,  1.0393])\n",
      "effulgent\n",
      "Saved the embedding for effulgent.\n",
      "['ego', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3923, -0.3397, -0.2304,  ...,  0.5542, -0.3676, -0.0009])\n",
      "egoistic\n",
      "Saved the embedding for egoistic.\n",
      "['ego', '##tist', '##ical'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6502, -0.0403, -0.5180,  ...,  1.2811, -0.2000,  0.4613])\n",
      "egotistical\n",
      "Saved the embedding for egotistical.\n",
      "['e', '##gre', '##gio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1261, -0.3789, -0.0407,  ...,  0.1705, -0.6076,  1.0297])\n",
      "egregious\n",
      "Saved the embedding for egregious.\n",
      "['el', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5579, -0.0723, -0.2514,  ..., -0.7118, -0.9064, -0.0249])\n",
      "elated\n",
      "Saved the embedding for elated.\n",
      "['el', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1953,  0.1674, -0.3937,  ..., -1.5649, -0.9164,  0.5319])\n",
      "elation\n",
      "Saved the embedding for elation.\n",
      "['electrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8266, -0.1768, -0.2905,  ...,  0.5383, -1.0658,  0.5545])\n",
      "electrified\n",
      "Saved the embedding for electrified.\n",
      "['elusive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1389,  0.1179,  0.4379,  ...,  0.1215,  0.0012, -0.2507])\n",
      "elusive\n",
      "Saved the embedding for elusive.\n",
      "['embarrassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5109,  0.3330,  0.3522,  ..., -0.0945, -0.1202, -0.7354])\n",
      "embarrassed\n",
      "Saved the embedding for embarrassed.\n",
      "['embarrassment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7972,  0.3788, -0.6399,  ..., -0.3586, -0.2653,  0.5319])\n",
      "embarrassment\n",
      "Saved the embedding for embarrassment.\n",
      "['em', '##bit', '##tered'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2511, -0.0777, -0.3754,  ..., -0.7771, -0.2165, -0.4294])\n",
      "embittered\n",
      "Saved the embedding for embittered.\n",
      "['em', '##body'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4035,  0.1106,  0.1196,  ..., -0.4421, -1.1364,  0.4133])\n",
      "embody\n",
      "Saved the embedding for embody.\n",
      "['emotional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2153, -0.0846,  0.3582,  ..., -0.1177, -0.8646, -0.7577])\n",
      "emotional\n",
      "Saved the embedding for emotional.\n",
      "['emotion', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3675,  0.2375, -0.5826,  ..., -0.4609, -0.5715, -0.5188])\n",
      "emotionless\n",
      "Saved the embedding for emotionless.\n",
      "['em', '##path', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1501, -0.0798, -0.6363,  ..., -0.6544, -0.0735,  0.4592])\n",
      "empathetic\n",
      "Saved the embedding for empathetic.\n",
      "['em', '##pathic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2892, -0.0098, -0.5419,  ..., -0.5238, -0.3591,  0.1223])\n",
      "empathic\n",
      "Saved the embedding for empathic.\n",
      "['empathy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7100,  0.0011,  0.3977,  ...,  0.2269, -0.9431, -0.8348])\n",
      "empathy\n",
      "Saved the embedding for empathy.\n",
      "['emptiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.4038,  0.1267, -0.3572,  ..., -0.1334, -0.0801,  0.6015])\n",
      "emptiness\n",
      "Saved the embedding for emptiness.\n",
      "['empty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3725,  0.6547, -0.0719,  ..., -0.3891,  0.2842,  0.8571])\n",
      "empty\n",
      "Saved the embedding for empty.\n",
      "['en', '##amo', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2675,  0.5421, -0.2252,  ...,  0.0580, -0.2603, -0.1012])\n",
      "enamored\n",
      "Saved the embedding for enamored.\n",
      "['enchanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2862,  0.7380,  0.6863,  ..., -0.6245, -0.7607,  0.2855])\n",
      "enchanted\n",
      "Saved the embedding for enchanted.\n",
      "['encouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2758,  0.2660,  0.0932,  ..., -1.0307, -0.8533, -0.3934])\n",
      "encouraged\n",
      "Saved the embedding for encouraged.\n",
      "['encouragement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2300,  0.5735,  0.5084,  ..., -0.2304, -1.1236, -0.0456])\n",
      "encouragement\n",
      "Saved the embedding for encouragement.\n",
      "['encouraging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5433,  0.6487,  0.5019,  ..., -0.5149, -0.7908,  0.1595])\n",
      "encouraging\n",
      "Saved the embedding for encouraging.\n",
      "['end', '##ear', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1698, -0.0354,  0.0142,  ..., -0.8485, -1.0202, -0.0557])\n",
      "endeared\n",
      "Saved the embedding for endeared.\n",
      "['end', '##earing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3891, -0.1270,  0.3050,  ..., -1.3599, -0.1961, -0.2306])\n",
      "endearing\n",
      "Saved the embedding for endearing.\n",
      "['enduring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4558,  0.6959,  1.0305,  ..., -0.3990, -0.5561, -0.1136])\n",
      "enduring\n",
      "Saved the embedding for enduring.\n",
      "['energetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1423,  0.9039,  0.1692,  ...,  0.2775,  0.1084, -0.6959])\n",
      "energetic\n",
      "Saved the embedding for energetic.\n",
      "['en', '##er', '##gi', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0765,  0.2160, -0.4728,  ..., -0.5095,  0.0138,  0.6334])\n",
      "energized\n",
      "Saved the embedding for energized.\n",
      "['engaged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6215, -0.0081, -0.0430,  ..., -0.2737,  0.6475,  0.5429])\n",
      "engaged\n",
      "Saved the embedding for engaged.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', '##ross', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1102,  0.2332, -0.5452,  ..., -0.3526, -0.4899,  0.6991])\n",
      "engrossed\n",
      "Saved the embedding for engrossed.\n",
      "['eng', '##ross', '##ment'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0360,  0.4183, -0.4674,  ...,  0.0159,  0.0543,  0.8158])\n",
      "engrossment\n",
      "Saved the embedding for engrossment.\n",
      "['enigma', '##tic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6274,  0.7620,  0.2764,  ..., -0.3871, -0.3221, -0.1838])\n",
      "enigmatic\n",
      "Saved the embedding for enigmatic.\n",
      "['enjoy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0036,  0.1937,  0.8522,  ..., -1.0339, -0.4508, -0.7457])\n",
      "enjoy\n",
      "Saved the embedding for enjoy.\n",
      "['enjoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1645,  0.7945,  0.3872,  ..., -0.1155,  0.1368, -0.7387])\n",
      "enjoying\n",
      "Saved the embedding for enjoying.\n",
      "['enjoyment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2380,  0.8722, -0.2163,  ..., -0.2773, -0.4812, -0.7593])\n",
      "enjoyment\n",
      "Saved the embedding for enjoyment.\n",
      "['en', '##light', '##ened'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1953,  0.3283, -0.5768,  ..., -0.1138,  0.1773,  0.5528])\n",
      "enlightened\n",
      "Saved the embedding for enlightened.\n",
      "['en', '##mity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2238,  0.3023, -0.5274,  ...,  0.0594,  0.2459,  0.7492])\n",
      "enmity\n",
      "Saved the embedding for enmity.\n",
      "['en', '##nu', '##i'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0912,  0.4072, -0.5499,  ..., -0.1705, -0.2012,  0.3833])\n",
      "ennui\n",
      "Saved the embedding for ennui.\n",
      "['enraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1836,  0.8310, -0.2116,  ...,  0.0167, -0.7373, -0.2495])\n",
      "enraged\n",
      "Saved the embedding for enraged.\n",
      "['en', '##rag', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1347,  0.2295, -0.2210,  ..., -0.6103, -0.0337,  0.2763])\n",
      "enraging\n",
      "Saved the embedding for enraging.\n",
      "['en', '##ra', '##pt', '##ured'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2155, -0.0645, -0.7634,  ..., -0.0831, -0.2580,  0.5903])\n",
      "enraptured\n",
      "Saved the embedding for enraptured.\n",
      "['entertained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3456,  0.0713, -0.3170,  ..., -0.4612, -0.0961, -0.6025])\n",
      "entertained\n",
      "Saved the embedding for entertained.\n",
      "['en', '##th', '##ral', '##led'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6751,  0.5630, -0.6692,  ..., -0.7327, -0.4600,  0.3614])\n",
      "enthralled\n",
      "Saved the embedding for enthralled.\n",
      "['en', '##thus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4636,  0.1810, -0.6238,  ..., -0.8929, -0.2287,  0.0083])\n",
      "enthused\n",
      "Saved the embedding for enthused.\n",
      "['enthusiasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1222,  0.3707,  1.0255,  ..., -0.9101, -0.2116, -0.0430])\n",
      "enthusiasm\n",
      "Saved the embedding for enthusiasm.\n",
      "['enthusiastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3853,  0.1841,  0.8022,  ..., -0.8680, -0.4457, -0.4148])\n",
      "enthusiastic\n",
      "Saved the embedding for enthusiastic.\n",
      "['en', '##tic', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4255,  0.2251, -0.4711,  ..., -0.3544,  0.0671,  0.2651])\n",
      "enticed\n",
      "Saved the embedding for enticed.\n",
      "['entrance', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0657,  0.2088, -1.1019,  ...,  0.4063, -0.9907, -0.1402])\n",
      "entranced\n",
      "Saved the embedding for entranced.\n",
      "['en', '##vious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1140,  0.2433, -0.6526,  ...,  0.0553,  0.0967,  0.7820])\n",
      "envious\n",
      "Saved the embedding for envious.\n",
      "['envy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4151,  0.7029, -0.2164,  ..., -0.0418,  0.8688,  0.0647])\n",
      "envy\n",
      "Saved the embedding for envy.\n",
      "['erotic', '##ally'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3268,  0.0380,  0.5532,  ..., -1.0586, -0.0952,  0.3033])\n",
      "erotically\n",
      "Saved the embedding for erotically.\n",
      "['estranged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0947, -0.2472,  0.3214,  ..., -0.3652,  0.2016, -0.8107])\n",
      "estranged\n",
      "Saved the embedding for estranged.\n",
      "['etched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8381,  0.1692, -0.3901,  ..., -0.4379, -0.2871, -0.3724])\n",
      "etched\n",
      "Saved the embedding for etched.\n",
      "['eu', '##ph', '##oric'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1439, -0.1393,  0.8141,  ..., -0.6563, -0.7602,  0.1078])\n",
      "euphoric\n",
      "Saved the embedding for euphoric.\n",
      "['evaluating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1429,  0.3648,  0.1365,  ..., -0.5890, -0.8726, -0.2152])\n",
      "evaluating\n",
      "Saved the embedding for evaluating.\n",
      "['eva', '##sive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2204, -0.6197,  0.2424,  ..., -1.0927, -0.5759,  0.3920])\n",
      "evasive\n",
      "Saved the embedding for evasive.\n",
      "['evil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4232,  0.9417,  0.3278,  ...,  0.6877, -0.5950, -0.3736])\n",
      "evil\n",
      "Saved the embedding for evil.\n",
      "['ev', '##oke'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2744, -0.2719, -0.8590,  ..., -0.0775, -0.1570, -0.0414])\n",
      "evoke\n",
      "Saved the embedding for evoke.\n",
      "['ex', '##ace', '##rba', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2579, -0.1554,  0.1864,  ..., -0.6577, -0.4536,  0.7462])\n",
      "exacerbated\n",
      "Saved the embedding for exacerbated.\n",
      "['ex', '##al', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1296, -0.3722, -0.2931,  ..., -0.1994, -0.1013,  0.1855])\n",
      "exalted\n",
      "Saved the embedding for exalted.\n",
      "['examining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0710,  0.1150, -0.9232,  ..., -0.6231, -0.6400,  0.4609])\n",
      "examining\n",
      "Saved the embedding for examining.\n",
      "['ex', '##as', '##per', '##ate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1217, -0.2091,  0.0303,  ..., -0.2079,  0.0659,  0.3055])\n",
      "exasperate\n",
      "Saved the embedding for exasperate.\n",
      "['exasperated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2290,  0.4704,  0.5807,  ..., -0.4768, -0.4885,  0.3458])\n",
      "exasperated\n",
      "Saved the embedding for exasperated.\n",
      "['ex', '##as', '##peration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0487, -0.2754,  0.0786,  ..., -0.3649, -0.7303,  0.4258])\n",
      "exasperation\n",
      "Saved the embedding for exasperation.\n",
      "['excited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1166,  0.6734, -0.2255,  ...,  0.2912,  0.6160, -0.2173])\n",
      "excited\n",
      "Saved the embedding for excited.\n",
      "['excitedly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1712,  0.3472, -0.1214,  ..., -0.1235,  0.0566, -0.5306])\n",
      "excitedly\n",
      "Saved the embedding for excitedly.\n",
      "['excitement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2150,  0.5593, -0.3228,  ..., -0.0625, -1.5417, -0.5481])\n",
      "excitement\n",
      "Saved the embedding for excitement.\n",
      "['ex', '##cl', '##ama', '##tion'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0719, -0.2150,  0.0167,  ...,  0.1957,  0.2297,  0.5651])\n",
      "exclamation\n",
      "Saved the embedding for exclamation.\n",
      "['ex', '##cl', '##ama', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1311, -0.1379,  0.1321,  ..., -0.1336,  0.4479,  0.4871])\n",
      "exclamatory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for exclamatory.\n",
      "['exhausted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1804, -0.2645, -0.2613,  ...,  0.2504, -0.7891, -0.2675])\n",
      "exhausted\n",
      "Saved the embedding for exhausted.\n",
      "['exhaustion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0488, -0.2125, -0.7826,  ..., -0.2741, -0.4550,  0.3178])\n",
      "exhaustion\n",
      "Saved the embedding for exhaustion.\n",
      "['exhaust', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1645, -0.6185, -0.3525,  ..., -0.6509, -0.1731, -0.7790])\n",
      "exhaustive\n",
      "Saved the embedding for exhaustive.\n",
      "['ex', '##hila', '##rated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1079, -0.1116,  0.6021,  ..., -0.6616, -0.2394,  0.3647])\n",
      "exhilarated\n",
      "Saved the embedding for exhilarated.\n",
      "['ex', '##hila', '##ration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1375, -0.0309,  0.2881,  ..., -0.2237,  0.1774,  0.6742])\n",
      "exhilaration\n",
      "Saved the embedding for exhilaration.\n",
      "['exited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3030,  0.0888, -0.0735,  ...,  0.3768, -0.1512,  0.2812])\n",
      "exited\n",
      "Saved the embedding for exited.\n",
      "['expect', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8380,  0.6343,  0.4578,  ..., -1.2729, -0.5385,  0.2106])\n",
      "expectant\n",
      "Saved the embedding for expectant.\n",
      "['expectation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3402,  0.5223, -0.0480,  ...,  0.0860, -0.0524,  0.0754])\n",
      "expectation\n",
      "Saved the embedding for expectation.\n",
      "['expecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2116,  0.9429,  1.4394,  ...,  0.5936, -0.3349, -0.2653])\n",
      "expecting\n",
      "Saved the embedding for expecting.\n",
      "['explain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7297, -0.5203,  0.8067,  ..., -1.1892, -0.6378,  0.1019])\n",
      "explain\n",
      "Saved the embedding for explain.\n",
      "['explaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4990,  0.0659,  0.2861,  ..., -0.5740, -0.6812, -0.1433])\n",
      "explaining\n",
      "Saved the embedding for explaining.\n",
      "['exploit', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2292,  0.7180, -0.5909,  ...,  0.5071,  0.0208, -0.4761])\n",
      "exploitive\n",
      "Saved the embedding for exploitive.\n",
      "['explosive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0456,  0.1824, -0.5680,  ..., -0.7135, -0.2049, -0.9787])\n",
      "explosive\n",
      "Saved the embedding for explosive.\n",
      "['exposure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5035,  1.1114, -0.4487,  ...,  0.0151, -0.0162, -0.0145])\n",
      "exposure\n",
      "Saved the embedding for exposure.\n",
      "['expressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1054,  0.8906,  0.0855,  ..., -0.2193, -0.8267, -1.1673])\n",
      "expressive\n",
      "Saved the embedding for expressive.\n",
      "['ex', '##uber', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0563, -0.3628,  0.2817,  ..., -0.4690,  0.5848,  0.3406])\n",
      "exuberant\n",
      "Saved the embedding for exuberant.\n",
      "['ex', '##ult', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4672, -0.3520,  0.3546,  ..., -0.2954,  0.7656,  0.6031])\n",
      "exultant\n",
      "Saved the embedding for exultant.\n",
      "['ex', '##ult', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3116, -0.6066,  0.6747,  ..., -0.4995,  0.4784,  0.5530])\n",
      "exulted\n",
      "Saved the embedding for exulted.\n",
      "['eye'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3548, -0.0081, -0.8737,  ..., -0.2251, -0.5472,  0.2310])\n",
      "eye\n",
      "Saved the embedding for eye.\n",
      "['eyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0862,  0.1489, -0.1128,  ...,  0.4276,  0.2474,  0.2050])\n",
      "eyed\n",
      "Saved the embedding for eyed.\n",
      "['faced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2870,  0.5895,  0.2118,  ..., -0.1336, -0.8658, -0.5103])\n",
      "faced\n",
      "Saved the embedding for faced.\n",
      "['face', '##tious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2370, -0.1902,  0.4275,  ..., -0.5701, -0.7440,  0.1613])\n",
      "facetious\n",
      "Saved the embedding for facetious.\n",
      "['failure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1365,  0.5363, -0.1967,  ..., -1.0201, -0.5370, -0.2678])\n",
      "failure\n",
      "Saved the embedding for failure.\n",
      "['faint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5040,  0.3439,  0.3692,  ...,  0.1973, -0.8712, -1.0742])\n",
      "faint\n",
      "Saved the embedding for faint.\n",
      "['fair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3835,  0.8616,  0.6921,  ..., -0.3710, -1.1789, -0.5465])\n",
      "fair\n",
      "Saved the embedding for fair.\n",
      "['fake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0463,  0.3222, -0.7894,  ..., -0.3162, -0.3739,  0.3200])\n",
      "fake\n",
      "Saved the embedding for fake.\n",
      "['fa', '##king'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5558,  0.8801, -1.2363,  ...,  0.3459, -0.1634,  0.7359])\n",
      "faking\n",
      "Saved the embedding for faking.\n",
      "['fa', '##lter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1144,  0.6649, -0.5490,  ..., -0.9186, -0.5970,  1.0797])\n",
      "falter\n",
      "Saved the embedding for falter.\n",
      "['fa', '##mis', '##hed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0822,  0.5284, -0.8861,  ..., -0.6411, -0.0431,  0.2784])\n",
      "famished\n",
      "Saved the embedding for famished.\n",
      "['fan', '##atic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6150, -0.4024,  0.5717,  ..., -1.1223, -0.3662,  0.2401])\n",
      "fanatic\n",
      "Saved the embedding for fanatic.\n",
      "['fan', '##ciful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7594, -0.4144,  0.6233,  ..., -0.9955,  0.2450,  0.3497])\n",
      "fanciful\n",
      "Saved the embedding for fanciful.\n",
      "['far', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5364,  0.1270,  0.1303,  ..., -0.8910,  0.2706,  0.4588])\n",
      "fart\n",
      "Saved the embedding for fart.\n",
      "['fascinated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4585,  0.3309, -0.1589,  ..., -0.4527, -0.5512, -0.0928])\n",
      "fascinated\n",
      "Saved the embedding for fascinated.\n",
      "['fast', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1480, -0.3587,  0.5314,  ..., -0.3893, -0.1631, -0.4363])\n",
      "fastidious\n",
      "Saved the embedding for fastidious.\n",
      "['fatigue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5140,  0.2454, -0.0517,  ..., -0.4887, -0.7818, -0.3407])\n",
      "fatigue\n",
      "Saved the embedding for fatigue.\n",
      "['fatigue', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3925,  0.3874,  0.1403,  ..., -0.9442, -0.6201, -0.3492])\n",
      "fatigued\n",
      "Saved the embedding for fatigued.\n",
      "['fault', '##fin', '##ding'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7695,  0.2003,  0.1426,  ..., -0.9917, -0.2776, -0.0315])\n",
      "faultfinding\n",
      "Saved the embedding for faultfinding.\n",
      "['favorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1670,  0.7112,  0.2039,  ..., -0.2607, -0.4879, -0.1655])\n",
      "favorable\n",
      "Saved the embedding for favorable.\n",
      "['fa', '##wn', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0790,  1.0022, -1.5173,  ..., -0.2954,  0.0604,  0.1893])\n",
      "fawning\n",
      "Saved the embedding for fawning.\n",
      "['fa', '##zed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1852,  0.5379,  0.0539,  ..., -0.6993, -0.5652,  0.5816])\n",
      "fazed\n",
      "Saved the embedding for fazed.\n",
      "['fear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1673,  0.6717,  0.3453,  ...,  0.1252, -0.9906, -0.2115])\n",
      "fear\n",
      "Saved the embedding for fear.\n",
      "['feared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1415,  0.4654,  0.9874,  ..., -0.5411, -0.6040, -0.3832])\n",
      "feared\n",
      "Saved the embedding for feared.\n",
      "['fearful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2111,  0.2667,  0.4619,  ..., -0.4575, -0.8493,  0.0567])\n",
      "fearful\n",
      "Saved the embedding for fearful.\n",
      "['fearing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0218,  0.5108,  0.4832,  ..., -0.6564, -1.0610, -0.0852])\n",
      "fearing\n",
      "Saved the embedding for fearing.\n",
      "['fearless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2295,  0.1290,  0.6818,  ...,  0.0683, -0.3687,  0.3013])\n",
      "fearless\n",
      "Saved the embedding for fearless.\n",
      "['fears', '##ome'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1652,  0.6135,  0.7280,  ..., -0.5401, -0.2982, -1.1351])\n",
      "fearsome\n",
      "Saved the embedding for fearsome.\n",
      "['fe', '##ckle', '##ss'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2694,  0.4274, -0.3690,  ..., -0.3962,  0.6364,  0.1277])\n",
      "feckless\n",
      "Saved the embedding for feckless.\n",
      "['fed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0011, -0.0126, -0.6828,  ...,  0.6281, -0.4529, -0.8162])\n",
      "fed\n",
      "Saved the embedding for fed.\n",
      "['fee', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5320, -0.3256, -0.3140,  ..., -0.2154, -0.2819,  0.0974])\n",
      "feeble\n",
      "Saved the embedding for feeble.\n",
      "['fei', '##gn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1804,  0.4498, -0.2518,  ..., -0.2266, -0.9593,  0.5075])\n",
      "feign\n",
      "Saved the embedding for feign.\n",
      "['fe', '##lic', '##ito', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0186, -0.0327, -0.0436,  ..., -0.4039,  0.1146,  0.5327])\n",
      "felicitous\n",
      "Saved the embedding for felicitous.\n",
      "['ferocious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2960,  0.2663,  0.5104,  ..., -0.2735, -0.6425, -0.5187])\n",
      "ferocious\n",
      "Saved the embedding for ferocious.\n",
      "['fe', '##rocity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3280,  0.5530,  0.1407,  ..., -0.9967, -1.0580,  0.9173])\n",
      "ferocity\n",
      "Saved the embedding for ferocity.\n",
      "['fest', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2062,  0.3330,  0.4871,  ..., -0.5209, -0.2567,  0.8168])\n",
      "festive\n",
      "Saved the embedding for festive.\n",
      "['fi', '##dget', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2817,  0.2075,  0.2595,  ...,  0.0635,  0.0829, -0.5515])\n",
      "fidgety\n",
      "Saved the embedding for fidgety.\n",
      "['fi', '##end', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0352,  0.0493, -1.0642,  ..., -1.0052,  0.0782,  0.4478])\n",
      "fiendish\n",
      "Saved the embedding for fiendish.\n",
      "['fierce'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2677, -0.0795,  0.5716,  ...,  0.2614, -0.3978, -0.8018])\n",
      "fierce\n",
      "Saved the embedding for fierce.\n",
      "['fiery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3948, -0.0620, -0.0442,  ...,  0.2864, -0.0092, -0.2793])\n",
      "fiery\n",
      "Saved the embedding for fiery.\n",
      "['fighting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1539,  0.9514, -0.2702,  ...,  0.8511, -0.2366,  0.0386])\n",
      "fighting\n",
      "Saved the embedding for fighting.\n",
      "['fine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1575,  0.1316,  0.5003,  ..., -0.1391, -0.5366, -0.0183])\n",
      "fine\n",
      "Saved the embedding for fine.\n",
      "['finished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1904, -1.0375,  0.1429,  ..., -0.1161, -0.1350, -0.2223])\n",
      "finished\n",
      "Saved the embedding for finished.\n",
      "['firm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1532,  0.7055,  0.3792,  ...,  0.7357,  0.0679, -0.1569])\n",
      "firm\n",
      "Saved the embedding for firm.\n",
      "['fish', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2561,  0.0908, -0.5375,  ..., -0.4707, -1.1481,  0.4904])\n",
      "fishy\n",
      "Saved the embedding for fishy.\n",
      "['fix', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1050, -0.2421,  0.8560,  ..., -0.4641,  0.1245,  0.4807])\n",
      "fixated\n",
      "Saved the embedding for fixated.\n",
      "['fixed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3689,  0.1126,  0.1755,  ..., -0.7305, -0.6677,  0.1949])\n",
      "fixed\n",
      "Saved the embedding for fixed.\n",
      "['fl', '##ab', '##berg', '##ast', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.1747, -0.2470, -1.0735,  ...,  0.1431,  0.0853,  0.4246])\n",
      "flabbergasted\n",
      "Saved the embedding for flabbergasted.\n",
      "['flaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3331,  0.2945, -1.0229,  ..., -1.0045,  0.3975,  0.0404])\n",
      "flaming\n",
      "Saved the embedding for flaming.\n",
      "['flat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2612,  0.0777,  0.5822,  ..., -0.6096, -0.3635,  0.2561])\n",
      "flat\n",
      "Saved the embedding for flat.\n",
      "['fl', '##au', '##nting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1337,  0.3588, -1.0568,  ..., -1.1191, -0.2534,  0.3484])\n",
      "flaunting\n",
      "Saved the embedding for flaunting.\n",
      "['flight', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1303,  0.8194,  0.5090,  ..., -0.1289, -0.8831,  0.1448])\n",
      "flighty\n",
      "Saved the embedding for flighty.\n",
      "['flip', '##pan', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3361,  0.5639, -0.1136,  ..., -0.7877, -1.0212, -0.2803])\n",
      "flippant\n",
      "Saved the embedding for flippant.\n",
      "['flipped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3605,  0.1303, -0.4455,  ..., -1.1727,  0.5062,  0.0147])\n",
      "flipped\n",
      "Saved the embedding for flipped.\n",
      "['flirt', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3196, -0.5892,  0.1369,  ..., -0.3233,  0.3148, -0.3181])\n",
      "flirtation\n",
      "Saved the embedding for flirtation.\n",
      "['flirt', '##ati', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5684, -0.3259,  0.1915,  ...,  0.0972, -0.2879, -0.3892])\n",
      "flirtatious\n",
      "Saved the embedding for flirtatious.\n",
      "['flirt', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2676, -0.4642,  0.1631,  ..., -0.2844,  0.2292, -0.8823])\n",
      "flirty\n",
      "Saved the embedding for flirty.\n",
      "['floor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0808, -0.5137, -1.5571,  ..., -0.0988, -0.3896, -0.2168])\n",
      "floored\n",
      "Saved the embedding for floored.\n",
      "['flu', '##mm', '##ox', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.8641,  0.1285,  0.5698,  ..., -0.7932, -0.2789,  0.7742])\n",
      "flummoxed\n",
      "Saved the embedding for flummoxed.\n",
      "['flu', '##stered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8196,  1.0647,  0.5896,  ..., -0.4566, -0.1420,  0.4279])\n",
      "flustered\n",
      "Saved the embedding for flustered.\n",
      "['focus'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3544,  0.0992, -0.6502,  ...,  0.4954, -0.7800, -0.5463])\n",
      "focus\n",
      "Saved the embedding for focus.\n",
      "['focused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3333,  0.1072, -0.3334,  ..., -0.1851, -0.1994, -0.3670])\n",
      "focused\n",
      "Saved the embedding for focused.\n",
      "['focusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4990,  0.4177, -0.5286,  ..., -0.4352, -0.9725,  0.0508])\n",
      "focusing\n",
      "Saved the embedding for focusing.\n",
      "['foil', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0673,  0.2948, -0.0416,  ..., -0.8086, -1.4017,  0.5226])\n",
      "foiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for foiled.\n",
      "['foolish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4577,  0.4468,  0.2078,  ...,  0.5730, -0.2981, -0.6793])\n",
      "foolish\n",
      "Saved the embedding for foolish.\n",
      "['for', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3498,  0.3516,  0.5257,  ..., -1.1977, -0.7480,  0.3929])\n",
      "forbearing\n",
      "Saved the embedding for forbearing.\n",
      "['forbid', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5441,  0.0873, -0.3038,  ..., -0.6322, -1.0997,  0.8923])\n",
      "forbidding\n",
      "Saved the embedding for forbidding.\n",
      "['forced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1411,  0.0068, -0.0403,  ..., -0.5266, -0.3567, -0.1449])\n",
      "forced\n",
      "Saved the embedding for forced.\n",
      "['forceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5771,  0.2690,  0.4058,  ..., -0.3871, -0.8267, -0.6809])\n",
      "forceful\n",
      "Saved the embedding for forceful.\n",
      "['for', '##feit', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3119, -0.4806, -0.0468,  ..., -1.5114, -0.4290,  0.3036])\n",
      "forfeited\n",
      "Saved the embedding for forfeited.\n",
      "['for', '##lor', '##n'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2259,  0.2975, -0.1792,  ..., -1.4371, -0.7197,  0.2377])\n",
      "forlorn\n",
      "Saved the embedding for forlorn.\n",
      "['fortunate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3742,  0.4682,  0.5018,  ...,  0.2063, -0.2312,  0.2602])\n",
      "fortunate\n",
      "Saved the embedding for fortunate.\n",
      "['forward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6533,  0.3562, -0.5770,  ..., -0.1755,  1.0052, -0.8484])\n",
      "forward\n",
      "Saved the embedding for forward.\n",
      "['foul'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1806,  0.4536,  0.7143,  ..., -0.5958, -0.4868, -1.0289])\n",
      "foul\n",
      "Saved the embedding for foul.\n",
      "['fra', '##ct', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3121,  0.6820,  0.7567,  ..., -0.5637, -0.4962, -0.1061])\n",
      "fractious\n",
      "Saved the embedding for fractious.\n",
      "['fragile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5863, -0.0633,  0.4804,  ..., -0.3859, -0.7699, -0.6962])\n",
      "fragile\n",
      "Saved the embedding for fragile.\n",
      "['frantic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4010, -0.1860,  0.2412,  ...,  0.1106,  0.3045, -0.7093])\n",
      "frantic\n",
      "Saved the embedding for frantic.\n",
      "['fraudulent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1230, -0.1893,  0.3226,  ..., -1.0165, -0.4493, -0.0320])\n",
      "fraudulent\n",
      "Saved the embedding for fraudulent.\n",
      "['fra', '##ught'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3799,  0.6382,  0.5548,  ..., -0.5135, -0.3376, -0.4676])\n",
      "fraught\n",
      "Saved the embedding for fraught.\n",
      "['fra', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0626,  0.4588,  0.5304,  ..., -0.5279, -0.7726, -0.6508])\n",
      "frazzled\n",
      "Saved the embedding for frazzled.\n",
      "['freaked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0373,  0.2841,  0.4225,  ..., -0.1708, -0.5978, -0.7503])\n",
      "freaked\n",
      "Saved the embedding for freaked.\n",
      "['fr', '##en', '##zie', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2756,  0.4422, -0.5225,  ..., -0.1453, -0.3319,  1.0176])\n",
      "frenzied\n",
      "Saved the embedding for frenzied.\n",
      "['fr', '##et', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4107,  0.3722, -0.3436,  ..., -0.7092, -0.8949,  0.3307])\n",
      "fretful\n",
      "Saved the embedding for fretful.\n",
      "['friend', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2517,  0.3572,  0.0291,  ..., -0.5394,  0.0442,  0.7733])\n",
      "friendliness\n",
      "Saved the embedding for friendliness.\n",
      "['friendly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2107,  0.6104, -0.6179,  ..., -0.3222, -0.5211, -0.1316])\n",
      "friendly\n",
      "Saved the embedding for friendly.\n",
      "['fright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5172,  1.0863, -0.1467,  ..., -0.0778, -0.3781,  0.4595])\n",
      "fright\n",
      "Saved the embedding for fright.\n",
      "['frightened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1802, -0.1488,  0.6851,  ...,  0.2823, -0.5301, -0.5200])\n",
      "frightened\n",
      "Saved the embedding for frightened.\n",
      "['frightening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3854,  0.3183,  0.1928,  ..., -0.1077, -0.3331, -0.6681])\n",
      "frightening\n",
      "Saved the embedding for frightening.\n",
      "['fr', '##ig', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2525,  0.2093, -0.6566,  ...,  0.0482, -0.9384,  0.5022])\n",
      "frigid\n",
      "Saved the embedding for frigid.\n",
      "['fr', '##isk', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1545,  0.0710,  0.0122,  ...,  0.2857, -0.4635,  0.1792])\n",
      "frisky\n",
      "Saved the embedding for frisky.\n",
      "['fr', '##olic', '##ker'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4195,  0.4936, -0.0618,  ...,  0.6596, -0.8265,  0.5757])\n",
      "frolicker\n",
      "Saved the embedding for frolicker.\n",
      "['frown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7541,  0.4036, -0.3075,  ...,  1.0591,  0.0597,  0.5933])\n",
      "frown\n",
      "Saved the embedding for frown.\n",
      "['frowning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2291,  0.5118, -0.0302,  ..., -0.0746, -0.6174,  0.4906])\n",
      "frowning\n",
      "Saved the embedding for frowning.\n",
      "['frozen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4229,  0.0505, -0.9180,  ...,  0.1700, -0.3972, -0.1839])\n",
      "frozen\n",
      "Saved the embedding for frozen.\n",
      "['fr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0228,  0.1843, -0.2576,  ...,  0.2032, -0.7917,  0.1237])\n",
      "frumpy\n",
      "Saved the embedding for frumpy.\n",
      "['frustrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1170,  0.4909,  0.1491,  ..., -0.0603, -0.9334,  0.0924])\n",
      "frustrated\n",
      "Saved the embedding for frustrated.\n",
      "['frustration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1982,  0.4506,  0.0175,  ...,  0.0136, -1.1425,  0.2815])\n",
      "frustration\n",
      "Saved the embedding for frustration.\n",
      "['fulfilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5371,  0.0035, -0.0267,  ..., -0.6907, -0.6105,  0.3704])\n",
      "fulfilled\n",
      "Saved the embedding for fulfilled.\n",
      "['fu', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7738,  0.1386, -1.0570,  ..., -0.8985, -1.1803, -0.3470])\n",
      "fumed\n",
      "Saved the embedding for fumed.\n",
      "['fu', '##ming'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5835,  0.7812, -0.9219,  ...,  0.0410, -0.5222,  0.0578])\n",
      "fuming\n",
      "Saved the embedding for fuming.\n",
      "['fun'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3774,  0.8227,  1.1074,  ..., -1.3554, -0.5931,  0.9640])\n",
      "fun\n",
      "Saved the embedding for fun.\n",
      "['funny'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3001,  0.8008,  0.2903,  ..., -0.4119, -0.5018,  0.3185])\n",
      "funny\n",
      "Saved the embedding for funny.\n",
      "['furious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2277,  0.3624,  0.5597,  ...,  0.1511, -0.3250, -0.5264])\n",
      "furious\n",
      "Saved the embedding for furious.\n",
      "['furiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0340,  0.3125, -0.2569,  ..., -0.5431, -0.7959,  0.1720])\n",
      "furiously\n",
      "Saved the embedding for furiously.\n",
      "['furious', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0014,  0.4900,  0.5861,  ..., -0.6051, -0.8898, -0.0982])\n",
      "furiousness\n",
      "Saved the embedding for furiousness.\n",
      "['furrowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0914,  0.6159, -0.3188,  ...,  0.1775, -0.8807, -0.1411])\n",
      "furrowed\n",
      "Saved the embedding for furrowed.\n",
      "['fur', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.3175,  0.0549, -0.3583,  ..., -0.1895, -0.7998, -0.2307])\n",
      "furtive\n",
      "Saved the embedding for furtive.\n",
      "['fury'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1949,  1.0272,  0.5878,  ...,  0.6209, -0.4646,  0.2646])\n",
      "fury\n",
      "Saved the embedding for fury.\n",
      "['fuss', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0030,  0.6034, -0.2090,  ..., -0.7710, -0.9754,  0.7929])\n",
      "fussy\n",
      "Saved the embedding for fussy.\n",
      "['gall', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4562,  0.5528, -0.5322,  ..., -0.2764, -0.8653,  0.7020])\n",
      "galled\n",
      "Saved the embedding for galled.\n",
      "['gall', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2856,  0.6523, -0.6515,  ..., -0.5136, -0.8085,  0.4973])\n",
      "galling\n",
      "Saved the embedding for galling.\n",
      "['gasp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0706,  0.0915, -0.6074,  ...,  0.3928,  0.1197, -0.8154])\n",
      "gasp\n",
      "Saved the embedding for gasp.\n",
      "['gasped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4089, -0.0405,  0.4895,  ..., -0.6865, -0.7071, -0.5234])\n",
      "gasped\n",
      "Saved the embedding for gasped.\n",
      "['gasping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0434,  0.6620,  0.5835,  ..., -0.3185, -0.7988, -0.1479])\n",
      "gasping\n",
      "Saved the embedding for gasping.\n",
      "['gay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6483,  0.7252, -0.1909,  ..., -0.5649, -0.7262,  0.3423])\n",
      "gay\n",
      "Saved the embedding for gay.\n",
      "['gazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0142,  0.5006, -0.1863,  ..., -0.1221, -0.3604,  0.1526])\n",
      "gazing\n",
      "Saved the embedding for gazing.\n",
      "['gen', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4734,  0.0587, -0.9903,  ..., -0.0838, -0.4821,  0.5927])\n",
      "genial\n",
      "Saved the embedding for genial.\n",
      "['gentle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2011,  0.6748,  0.4353,  ..., -0.2813, -0.8582, -0.5571])\n",
      "gentle\n",
      "Saved the embedding for gentle.\n",
      "['genuine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0412, -0.4369,  0.3445,  ..., -0.7353, -0.6727, -0.8593])\n",
      "genuine\n",
      "Saved the embedding for genuine.\n",
      "['g', '##has', '##tly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3224, -0.7661, -0.8406,  ..., -1.1344,  0.1557,  0.7957])\n",
      "ghastly\n",
      "Saved the embedding for ghastly.\n",
      "['gi', '##ddy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4203, -0.0398, -0.8018,  ..., -1.1598, -1.1537,  0.0455])\n",
      "giddy\n",
      "Saved the embedding for giddy.\n",
      "['giggle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2112, -0.2604, -0.6539,  ..., -0.8042, -0.6352, -0.0242])\n",
      "giggle\n",
      "Saved the embedding for giggle.\n",
      "['giggling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3091,  0.0724, -0.2624,  ..., -0.0088, -0.8467,  0.2978])\n",
      "giggling\n",
      "Saved the embedding for giggling.\n",
      "['glad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5620,  0.8033, -0.2486,  ...,  0.8801,  0.1283,  0.6783])\n",
      "glad\n",
      "Saved the embedding for glad.\n",
      "['glad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4330,  0.6470, -0.0762,  ...,  0.0731, -0.6284,  0.6625])\n",
      "gladdened\n",
      "Saved the embedding for gladdened.\n",
      "['glad', '##iol', '##a'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5408,  0.4488, -1.1283,  ...,  0.3774, -0.8927,  0.8714])\n",
      "gladiola\n",
      "Saved the embedding for gladiola.\n",
      "['glad', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3061,  0.8713, -0.1372,  ..., -0.0804, -0.7702,  1.2982])\n",
      "gladness\n",
      "Saved the embedding for gladness.\n",
      "['glad', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3501,  0.6566, -0.2970,  ..., -0.3315,  0.0408,  0.2074])\n",
      "gladsome\n",
      "Saved the embedding for gladsome.\n",
      "['glare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0810,  0.2877, -0.0338,  ..., -0.1547, -0.4756,  0.8893])\n",
      "glare\n",
      "Saved the embedding for glare.\n",
      "['glaring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4215,  0.6350, -0.1785,  ...,  0.4057, -0.6119, -0.3311])\n",
      "glaring\n",
      "Saved the embedding for glaring.\n",
      "['glazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0840, -0.2727, -0.6517,  ...,  0.0850, -0.5101, -0.0665])\n",
      "glazed\n",
      "Saved the embedding for glazed.\n",
      "['glee'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.3390, -0.8370, -0.1958,  ..., -0.8066, -0.7496, -0.1332])\n",
      "glee\n",
      "Saved the embedding for glee.\n",
      "['glee', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8959, -1.1032, -0.2473,  ..., -1.3595, -0.5326, -0.5187])\n",
      "gleeful\n",
      "Saved the embedding for gleeful.\n",
      "['glee', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0068, -1.2703, -0.4568,  ..., -0.4730, -0.3792, -0.4764])\n",
      "gleefully\n",
      "Saved the embedding for gleefully.\n",
      "['g', '##lib'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1095, -0.7189, -0.3215,  ..., -0.4086, -0.9692,  0.4009])\n",
      "glib\n",
      "Saved the embedding for glib.\n",
      "['g', '##lo', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3625, -0.8151,  0.8293,  ..., -1.2585, -0.2902,  0.1860])\n",
      "gloating\n",
      "Saved the embedding for gloating.\n",
      "['gloom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0696,  1.2658, -0.2639,  ..., -0.3367, -0.4370,  0.7355])\n",
      "gloom\n",
      "Saved the embedding for gloom.\n",
      "['gloom', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2950,  1.0548,  0.0642,  ..., -0.3883, -0.6782,  0.4824])\n",
      "gloomy\n",
      "Saved the embedding for gloomy.\n",
      "['glow', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6654,  0.3188, -0.6224,  ..., -0.4740, -0.9814,  0.2962])\n",
      "glowering\n",
      "Saved the embedding for glowering.\n",
      "['glowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2727,  0.3310, -0.5207,  ..., -0.9956, -0.7077,  0.3882])\n",
      "glowing\n",
      "Saved the embedding for glowing.\n",
      "['g', '##lum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4422, -0.9326,  0.5460,  ..., -0.2969, -0.9867,  0.0415])\n",
      "glum\n",
      "Saved the embedding for glum.\n",
      "['g', '##nar', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3002, -0.8021, -0.0807,  ..., -0.5927, -1.0433,  0.1791])\n",
      "gnarl\n",
      "Saved the embedding for gnarl.\n",
      "['go', '##bs', '##mack', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4414, -0.6930, -0.6805,  ..., -0.4939,  0.0087,  0.1071])\n",
      "gobsmacked\n",
      "Saved the embedding for gobsmacked.\n",
      "['good'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5922,  0.3097,  0.1429,  ..., -0.2524, -0.7196,  0.2832])\n",
      "good\n",
      "Saved the embedding for good.\n",
      "['goofy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0589, -0.2195,  0.2132,  ..., -0.9218, -1.3621,  0.0826])\n",
      "goofy\n",
      "Saved the embedding for goofy.\n",
      "['gossip', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9791, -0.0909, -0.0021,  ...,  0.2071, -0.2025, -0.7988])\n",
      "gossipy\n",
      "Saved the embedding for gossipy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grand', '##ios', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1948,  0.1671, -0.3199,  ..., -0.9076, -0.4265, -0.4202])\n",
      "grandiose\n",
      "Saved the embedding for grandiose.\n",
      "['grateful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0537,  0.2159,  0.1231,  ..., -0.3781, -0.9277,  0.0168])\n",
      "grateful\n",
      "Saved the embedding for grateful.\n",
      "['gr', '##ati', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4331,  0.3317,  0.0547,  ..., -0.8302, -0.0899,  0.1982])\n",
      "gratified\n",
      "Saved the embedding for gratified.\n",
      "['grave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5372,  0.4498,  1.1044,  ..., -0.0295, -0.6849, -0.2153])\n",
      "grave\n",
      "Saved the embedding for grave.\n",
      "['great'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3993,  0.5754,  0.6903,  ..., -0.4586, -0.4790,  0.5805])\n",
      "great\n",
      "Saved the embedding for great.\n",
      "['greedy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0455,  1.1092, -0.6538,  ...,  0.6062,  0.2952,  0.4571])\n",
      "greedy\n",
      "Saved the embedding for greedy.\n",
      "['greeting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3224,  0.3890,  0.3533,  ...,  0.4455, -0.6061, -0.0486])\n",
      "greeting\n",
      "Saved the embedding for greeting.\n",
      "['grief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2099,  0.2376,  0.0843,  ..., -0.1877, -0.3281, -0.0482])\n",
      "grief\n",
      "Saved the embedding for grief.\n",
      "['gr', '##ie', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1510,  0.5910, -0.7453,  ..., -0.2916,  0.1616,  0.3808])\n",
      "grieved\n",
      "Saved the embedding for grieved.\n",
      "['gr', '##ieving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0608,  0.0364,  0.3549,  ..., -0.9289, -0.4714,  0.1717])\n",
      "grieving\n",
      "Saved the embedding for grieving.\n",
      "['grim'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.0673,  0.5300,  0.3481,  ..., -1.0922, -0.8490,  0.0508])\n",
      "grim\n",
      "Saved the embedding for grim.\n",
      "['grimace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2908, -0.0899, -0.2517,  ...,  0.3843, -0.2576, -0.4732])\n",
      "grimace\n",
      "Saved the embedding for grimace.\n",
      "['grim', '##acing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8429,  0.6517,  0.4966,  ..., -0.8155, -0.9289,  0.2188])\n",
      "grimacing\n",
      "Saved the embedding for grimacing.\n",
      "['grin'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0870,  0.7754,  0.0693,  ...,  1.1288, -1.1808,  0.0133])\n",
      "grin\n",
      "Saved the embedding for grin.\n",
      "['grinning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0460,  0.2690, -0.0732,  ...,  0.7526,  0.1754,  0.1065])\n",
      "grinning\n",
      "Saved the embedding for grinning.\n",
      "['grip', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2925, -0.4531,  0.6807,  ..., -0.6884, -0.6078, -0.3934])\n",
      "griping\n",
      "Saved the embedding for griping.\n",
      "['gross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3394,  0.3552, -0.1722,  ..., -0.6396, -0.4638,  0.1639])\n",
      "gross\n",
      "Saved the embedding for gross.\n",
      "['grossed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8156, -0.5220,  0.2189,  ..., -0.4690, -0.3965, -0.1333])\n",
      "grossed\n",
      "Saved the embedding for grossed.\n",
      "['gr', '##ou', '##chy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0470,  0.1165, -0.9159,  ..., -0.7934, -0.2245,  0.8433])\n",
      "grouchy\n",
      "Saved the embedding for grouchy.\n",
      "['growl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2730,  0.0745,  0.2806,  ...,  0.7792,  0.4290,  0.0495])\n",
      "growl\n",
      "Saved the embedding for growl.\n",
      "['growling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0700,  0.0549,  0.8971,  ..., -0.3282, -0.2521, -0.6201])\n",
      "growling\n",
      "Saved the embedding for growling.\n",
      "['gr', '##udge'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1864, -0.1919, -0.5752,  ..., -0.1706, -0.2599,  0.4127])\n",
      "grudge\n",
      "Saved the embedding for grudge.\n",
      "['gr', '##ud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2809,  0.4890, -0.3187,  ..., -0.7208, -0.7345,  0.2360])\n",
      "grudging\n",
      "Saved the embedding for grudging.\n",
      "['gruff'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3937,  0.3769, -0.1098,  ...,  0.0390, -0.0818,  0.2852])\n",
      "gruff\n",
      "Saved the embedding for gruff.\n",
      "['gr', '##umb', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0033,  0.2788, -0.5624,  ..., -0.2991, -0.0496,  0.4930])\n",
      "grumbling\n",
      "Saved the embedding for grumbling.\n",
      "['gr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2954,  0.2956, -0.1586,  ..., -0.1270, -0.2397,  0.2716])\n",
      "grumpy\n",
      "Saved the embedding for grumpy.\n",
      "['grunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3726,  0.1876,  0.1332,  ..., -0.8199, -0.1331,  0.3465])\n",
      "grunt\n",
      "Saved the embedding for grunt.\n",
      "['grunt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6811,  0.4554,  0.4553,  ..., -0.9667, -0.6756,  0.3755])\n",
      "grunting\n",
      "Saved the embedding for grunting.\n",
      "['guarded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0024,  0.1799, -0.5396,  ..., -0.8810, -0.3848,  0.5662])\n",
      "guarded\n",
      "Saved the embedding for guarded.\n",
      "['guilty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8360, -0.2114, -0.7311,  ..., -0.1062,  0.5178, -0.2250])\n",
      "guilty\n",
      "Saved the embedding for guilty.\n",
      "['gulp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1536, -0.3573, -0.2671,  ...,  0.1344, -0.7872, -0.0517])\n",
      "gulp\n",
      "Saved the embedding for gulp.\n",
      "['haggard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4100, -0.9696,  0.1705,  ..., -0.5642,  0.4020, -1.0656])\n",
      "haggard\n",
      "Saved the embedding for haggard.\n",
      "['half', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2821, -1.3974, -0.7114,  ..., -0.1648, -0.4708, -0.3861])\n",
      "halfhearted\n",
      "Saved the embedding for halfhearted.\n",
      "['halted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4963,  0.1533,  0.3958,  ...,  0.5096,  0.1666, -0.7361])\n",
      "halted\n",
      "Saved the embedding for halted.\n",
      "['ha', '##ples', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1718,  0.1737, -0.5508,  ..., -0.8761,  0.5772,  0.9180])\n",
      "hapless\n",
      "Saved the embedding for hapless.\n",
      "['happiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2105,  0.0885,  0.2065,  ...,  0.1775, -0.4726, -1.2276])\n",
      "happiness\n",
      "Saved the embedding for happiness.\n",
      "['happy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1359,  0.4344, -0.3129,  ..., -0.6050, -1.4466, -0.2004])\n",
      "happy\n",
      "Saved the embedding for happy.\n",
      "['harassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2444,  0.3895,  0.5280,  ..., -0.5891, -1.3990, -0.1861])\n",
      "harassed\n",
      "Saved the embedding for harassed.\n",
      "['hard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8958,  0.3955, -0.2410,  ...,  0.0951, -0.9203,  0.4844])\n",
      "hard\n",
      "Saved the embedding for hard.\n",
      "['hardened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3225,  0.1630,  0.5774,  ..., -0.3129, -0.9942, -0.0380])\n",
      "hardened\n",
      "Saved the embedding for hardened.\n",
      "['harmful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1547,  0.7792,  0.3834,  ..., -0.4645, -0.7485,  0.0510])\n",
      "harmful\n",
      "Saved the embedding for harmful.\n",
      "['ha', '##rrie', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2451,  0.0229, -0.1548,  ..., -0.6971,  0.1703,  0.8527])\n",
      "harried\n",
      "Saved the embedding for harried.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harsh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0160,  0.3555,  0.5828,  ..., -0.5847, -0.9461,  0.4166])\n",
      "harsh\n",
      "Saved the embedding for harsh.\n",
      "['hate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4766,  0.4677,  0.0235,  ..., -0.3260, -0.8997, -0.5799])\n",
      "hate\n",
      "Saved the embedding for hate.\n",
      "['hate', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4743,  0.4472, -0.2136,  ..., -1.2979, -0.9517, -0.3469])\n",
      "hateful\n",
      "Saved the embedding for hateful.\n",
      "['hating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2491,  0.3186, -0.0459,  ..., -0.3127, -0.2251, -0.6733])\n",
      "hating\n",
      "Saved the embedding for hating.\n",
      "['hatred'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3547,  0.6880,  0.0952,  ...,  0.0828, -0.1843,  0.2075])\n",
      "hatred\n",
      "Saved the embedding for hatred.\n",
      "['ha', '##ught', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0509,  0.3532, -0.7766,  ..., -0.6198, -0.2234,  0.9296])\n",
      "haughty\n",
      "Saved the embedding for haughty.\n",
      "['haunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5120,  0.4035, -0.3045,  ..., -0.3824, -0.2444,  0.3707])\n",
      "haunted\n",
      "Saved the embedding for haunted.\n",
      "['hazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0772,  0.2949, -0.1839,  ..., -0.4287, -0.1135,  0.3790])\n",
      "hazy\n",
      "Saved the embedding for hazy.\n",
      "['heads', '##hak', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5552,  0.8944, -0.4699,  ..., -0.3449, -0.2277,  1.0590])\n",
      "headshake\n",
      "Saved the embedding for headshake.\n",
      "['heart', '##ache'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2036, -0.1817,  0.1158,  ..., -1.0226, -1.0853,  0.9645])\n",
      "heartache\n",
      "Saved the embedding for heartache.\n",
      "['heart', '##broken'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1550, -0.1609,  0.0673,  ..., -0.7125, -1.2620,  0.0826])\n",
      "heartbroken\n",
      "Saved the embedding for heartbroken.\n",
      "['hearted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3628,  0.7677,  0.0357,  ..., -0.1860, -0.6593, -0.1395])\n",
      "hearted\n",
      "Saved the embedding for hearted.\n",
      "['hearts', '##ick'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3413, -0.4638,  0.5177,  ..., -0.7424, -0.4941, -0.2757])\n",
      "heartsick\n",
      "Saved the embedding for heartsick.\n",
      "['heated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1411,  1.2728, -0.2556,  ...,  0.8549, -0.4374, -0.0254])\n",
      "heated\n",
      "Saved the embedding for heated.\n",
      "['heavy', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0297,  0.7081, -1.1345,  ..., -0.0818,  0.0602, -0.7921])\n",
      "heavyhearted\n",
      "Saved the embedding for heavyhearted.\n",
      "['heck', '##le'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1130,  1.3433, -0.5189,  ..., -1.1633, -0.7244,  0.4133])\n",
      "heckle\n",
      "Saved the embedding for heckle.\n",
      "['hee', '##df', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2046,  0.2936, -0.2100,  ...,  0.5651,  0.0014,  0.5363])\n",
      "heedful\n",
      "Saved the embedding for heedful.\n",
      "['he', '##ino', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3019, -0.0867, -0.9909,  ...,  0.2116, -0.0367,  0.9117])\n",
      "heinous\n",
      "Saved the embedding for heinous.\n",
      "['helpful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3926,  0.2638,  0.1256,  ..., -0.4927, -0.9132,  0.8121])\n",
      "helpful\n",
      "Saved the embedding for helpful.\n",
      "['helpless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0255, -0.1638,  0.0946,  ..., -0.7491, -1.2378, -0.1882])\n",
      "helpless\n",
      "Saved the embedding for helpless.\n",
      "['hesitant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4299,  0.6577, -0.0168,  ..., -0.2301, -0.8314,  0.0315])\n",
      "hesitant\n",
      "Saved the embedding for hesitant.\n",
      "['hesitantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1617,  0.3465,  0.0443,  ...,  0.9296, -0.2330, -0.4364])\n",
      "hesitantly\n",
      "Saved the embedding for hesitantly.\n",
      "['he', '##sit', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1904,  0.2028,  0.0275,  ..., -0.1592, -0.3275, -0.0492])\n",
      "hesitating\n",
      "Saved the embedding for hesitating.\n",
      "['hesitation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2547,  0.5169,  0.1320,  ...,  0.0376, -0.6194,  0.4054])\n",
      "hesitation\n",
      "Saved the embedding for hesitation.\n",
      "['high'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3125,  0.5511,  0.3277,  ..., -0.5489, -0.4815,  0.2295])\n",
      "high\n",
      "Saved the embedding for high.\n",
      "['ho', '##ller', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3188,  0.5339, -0.2796,  ..., -0.2759, -0.4047,  0.5756])\n",
      "hollering\n",
      "Saved the embedding for hollering.\n",
      "['ho', '##mic', '##idal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2709,  0.0256, -0.3207,  ...,  0.5309, -0.7689,  0.2495])\n",
      "homicidal\n",
      "Saved the embedding for homicidal.\n",
      "['honest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5178,  0.1124, -0.0638,  ...,  0.0986, -0.6682,  0.3923])\n",
      "honest\n",
      "Saved the embedding for honest.\n",
      "['honorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4748,  0.7661,  0.4500,  ...,  0.1995,  0.0591,  0.4218])\n",
      "honorable\n",
      "Saved the embedding for honorable.\n",
      "['hope'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3964,  0.5847,  0.0021,  ...,  0.1794, -1.1428, -0.1734])\n",
      "hope\n",
      "Saved the embedding for hope.\n",
      "['hopeful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4427, -0.0436,  0.1796,  ..., -0.2102,  0.1237, -1.0206])\n",
      "hopeful\n",
      "Saved the embedding for hopeful.\n",
      "['hopeful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2065,  0.2721, -0.1625,  ...,  0.3803,  0.1135, -0.1225])\n",
      "hopefulness\n",
      "Saved the embedding for hopefulness.\n",
      "['hopeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0612,  0.3850,  0.3334,  ...,  0.0555, -0.8539, -0.1013])\n",
      "hopeless\n",
      "Saved the embedding for hopeless.\n",
      "['hoping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0056,  0.5900,  0.3918,  ..., -0.1309, -0.6997,  0.2795])\n",
      "hoping\n",
      "Saved the embedding for hoping.\n",
      "['horn', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3962,  0.2624, -0.2243,  ..., -0.0793,  0.1194, -0.1201])\n",
      "horny\n",
      "Saved the embedding for horny.\n",
      "['horrible'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4698,  0.3263, -0.0673,  ..., -0.1429,  0.1864, -0.4055])\n",
      "horrible\n",
      "Saved the embedding for horrible.\n",
      "['horrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3791,  0.1077, -0.7061,  ..., -0.9244, -0.3186,  0.3182])\n",
      "horrified\n",
      "Saved the embedding for horrified.\n",
      "['ho', '##rri', '##fy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1272,  0.6873, -0.0454,  ..., -0.6188, -0.6538,  0.1626])\n",
      "horrify\n",
      "Saved the embedding for horrify.\n",
      "['ho', '##rri', '##fying'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1754,  0.4655, -0.3892,  ..., -0.7536, -0.0614,  0.7751])\n",
      "horrifying\n",
      "Saved the embedding for horrifying.\n",
      "['horror'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3308,  0.1504, -0.1309,  ..., -0.1896,  0.0385, -0.4741])\n",
      "horror\n",
      "Saved the embedding for horror.\n",
      "['hostile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0413,  0.5375, -0.1367,  ...,  0.6267, -0.7462, -0.2907])\n",
      "hostile\n",
      "Saved the embedding for hostile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hostility'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3324,  0.4256,  0.0864,  ..., -0.6426, -0.9671,  0.0702])\n",
      "hostility\n",
      "Saved the embedding for hostility.\n",
      "['hot'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0822,  0.4994,  0.3051,  ...,  0.4011,  0.3865, -0.5241])\n",
      "hot\n",
      "Saved the embedding for hot.\n",
      "['hot', '##shot'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2833, -0.3765,  0.3147,  ...,  0.2540, -0.0717,  0.3343])\n",
      "hotshot\n",
      "Saved the embedding for hotshot.\n",
      "['huff', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5318,  0.6589,  0.5174,  ..., -1.2567, -0.8081,  0.4129])\n",
      "huffiness\n",
      "Saved the embedding for huffiness.\n",
      "['huff', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5812,  0.5229,  0.0406,  ..., -0.6793, -0.1727, -0.0469])\n",
      "huffy\n",
      "Saved the embedding for huffy.\n",
      "['humble'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4077,  0.5756, -0.2413,  ..., -0.2116, -0.1234,  0.2550])\n",
      "humble\n",
      "Saved the embedding for humble.\n",
      "['humble', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5335,  0.6727,  0.1404,  ...,  0.0051, -0.3498,  0.0863])\n",
      "humbled\n",
      "Saved the embedding for humbled.\n",
      "['hum', '##drum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2815, -0.0461,  0.5647,  ..., -0.1373, -0.7650,  0.0373])\n",
      "humdrum\n",
      "Saved the embedding for humdrum.\n",
      "['humiliated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1982,  0.5830,  1.0455,  ...,  1.0396, -0.3456, -0.4277])\n",
      "humiliated\n",
      "Saved the embedding for humiliated.\n",
      "['hum', '##ility'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.1298e-01,  6.0131e-04,  6.6850e-01,  ..., -7.9682e-01,\n",
      "        -7.1593e-01,  1.7548e-02])\n",
      "humility\n",
      "Saved the embedding for humility.\n",
      "['humming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4208, -0.3405, -0.2599,  ..., -0.1539, -0.2908, -0.0544])\n",
      "humming\n",
      "Saved the embedding for humming.\n",
      "['humor'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2576,  1.0692, -0.0100,  ..., -1.4780, -1.1475,  0.6410])\n",
      "humor\n",
      "Saved the embedding for humor.\n",
      "['humor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4760,  0.6807, -0.1538,  ...,  0.0246, -0.2325,  0.5934])\n",
      "humored\n",
      "Saved the embedding for humored.\n",
      "['humorous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2867, -0.2792,  0.1106,  ...,  0.3236,  0.5883, -0.5052])\n",
      "humorous\n",
      "Saved the embedding for humorous.\n",
      "['hunger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3812,  1.1942,  0.1931,  ..., -0.4954, -0.9239, -0.0103])\n",
      "hunger\n",
      "Saved the embedding for hunger.\n",
      "['hungry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2821,  0.7238,  0.1599,  ..., -0.4653, -0.7447,  0.1923])\n",
      "hungry\n",
      "Saved the embedding for hungry.\n",
      "['hunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1932, -0.0158, -0.0537,  ..., -0.1213, -0.9225,  0.2098])\n",
      "hunted\n",
      "Saved the embedding for hunted.\n",
      "['hurt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4840,  0.4047, -0.3337,  ...,  0.8336, -0.3677,  0.1630])\n",
      "hurt\n",
      "Saved the embedding for hurt.\n",
      "['hurt', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3054,  0.0499, -0.3673,  ..., -0.8569, -0.8518,  0.0458])\n",
      "hurtful\n",
      "Saved the embedding for hurtful.\n",
      "['hurting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1999,  0.6067, -0.3233,  ...,  0.5621, -1.2164, -0.3501])\n",
      "hurting\n",
      "Saved the embedding for hurting.\n",
      "['hush'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1657,  0.1098, -0.6950,  ..., -0.2706, -1.1429,  0.2118])\n",
      "hush\n",
      "Saved the embedding for hush.\n",
      "['hushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1569, -0.0451, -0.5337,  ...,  0.1504, -0.0426, -0.3549])\n",
      "hushed\n",
      "Saved the embedding for hushed.\n",
      "['hyper'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7363, -0.0838,  0.4723,  ..., -0.0450, -1.5854, -0.0272])\n",
      "hyper\n",
      "Saved the embedding for hyper.\n",
      "['hyper', '##active'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3242,  0.0245,  0.6134,  ..., -0.8961, -1.6146,  0.0238])\n",
      "hyperactive\n",
      "Saved the embedding for hyperactive.\n",
      "['h', '##yp', '##not', '##ized'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5524, -0.1312,  0.2985,  ..., -0.9678,  0.2424, -0.3718])\n",
      "hypnotized\n",
      "Saved the embedding for hypnotized.\n",
      "['h', '##yp', '##oc', '##rit', '##ical'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.3811, -0.3706, -0.1545,  ..., -0.1990,  0.6493,  1.1110])\n",
      "hypocritical\n",
      "Saved the embedding for hypocritical.\n",
      "['hysteria'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0027,  0.0831,  0.7663,  ..., -1.4652, -0.2486, -0.1453])\n",
      "hysteria\n",
      "Saved the embedding for hysteria.\n",
      "['hysterical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1980,  0.3566,  0.2665,  ...,  0.1630, -0.5761, -0.4110])\n",
      "hysterical\n",
      "Saved the embedding for hysterical.\n",
      "['idiot', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2692, -0.0213, -0.2707,  ..., -0.3955, -0.4078,  0.9628])\n",
      "idiotic\n",
      "Saved the embedding for idiotic.\n",
      "['ignorant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0520,  0.0650, -0.0938,  ..., -0.6187, -0.2749, -0.0768])\n",
      "ignorant\n",
      "Saved the embedding for ignorant.\n",
      "['ignoring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-9.1537e-04,  4.6699e-01, -2.1266e-01,  ..., -1.0530e+00,\n",
      "        -3.1342e-01,  1.7326e-01])\n",
      "ignoring\n",
      "Saved the embedding for ignoring.\n",
      "['ill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1467,  0.2954,  0.8250,  ...,  0.3791, -0.3954,  0.2451])\n",
      "ill\n",
      "Saved the embedding for ill.\n",
      "['imaginative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6352,  0.3459,  0.6241,  ..., -1.1878, -0.3740, -0.9231])\n",
      "imaginative\n",
      "Saved the embedding for imaginative.\n",
      "['immature'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7907,  0.0853, -0.0754,  ...,  0.2700, -0.8488, -0.4924])\n",
      "immature\n",
      "Saved the embedding for immature.\n",
      "['immersed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0466,  0.0515, -0.0355,  ..., -0.3349, -0.8652, -0.0893])\n",
      "immersed\n",
      "Saved the embedding for immersed.\n",
      "['impacted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0899,  0.5478, -0.0751,  ..., -1.1441, -0.2633, -0.1116])\n",
      "impacted\n",
      "Saved the embedding for impacted.\n",
      "['imp', '##art', '##ial'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1218, -0.5165,  0.5825,  ..., -0.3499, -0.1731, -0.0091])\n",
      "impartial\n",
      "Saved the embedding for impartial.\n",
      "['imp', '##ass', '##ioned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1876, -0.6436,  0.7538,  ..., -0.5904, -0.0837, -0.1272])\n",
      "impassioned\n",
      "Saved the embedding for impassioned.\n",
      "['imp', '##ass', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3680, -0.4954,  1.1118,  ..., -0.1724, -0.3549, -0.4246])\n",
      "impassive\n",
      "Saved the embedding for impassive.\n",
      "['impatience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1843,  0.2162,  0.5811,  ...,  0.1612, -0.0689, -0.2179])\n",
      "impatience\n",
      "Saved the embedding for impatience.\n",
      "['impatient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0377,  0.2649,  1.1722,  ..., -0.3977, -0.2190, -0.5543])\n",
      "impatient\n",
      "Saved the embedding for impatient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imp', '##eri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4961, -0.1650,  1.1762,  ..., -0.7587, -0.1341, -0.2666])\n",
      "imperious\n",
      "Saved the embedding for imperious.\n",
      "['imp', '##erson', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6640, -0.5208,  0.5667,  ...,  0.0109, -0.2720,  0.0873])\n",
      "impersonal\n",
      "Saved the embedding for impersonal.\n",
      "['imp', '##ert', '##inen', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0065, -0.2487,  0.6225,  ..., -1.0823, -0.1917,  0.0641])\n",
      "impertinent\n",
      "Saved the embedding for impertinent.\n",
      "['imp', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 3.3578e-04, -3.6638e-01,  9.1053e-01,  ...,  3.9484e-02,\n",
      "        -2.9258e-01,  1.2628e-01])\n",
      "impish\n",
      "Saved the embedding for impish.\n",
      "['implicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4064, -0.3793, -0.0720,  ..., -0.7444,  0.6975, -0.9587])\n",
      "implicated\n",
      "Saved the embedding for implicated.\n",
      "['imp', '##lor', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2307,  0.0325,  1.0318,  ..., -0.1362, -0.4801, -0.3478])\n",
      "imploring\n",
      "Saved the embedding for imploring.\n",
      "['important'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2197,  0.8958,  0.4062,  ..., -0.1101, -0.4601, -0.2136])\n",
      "important\n",
      "Saved the embedding for important.\n",
      "['impressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3860,  0.1466, -1.2646,  ...,  0.1299, -0.3110,  0.6812])\n",
      "impressed\n",
      "Saved the embedding for impressed.\n",
      "['imp', '##ulsive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3149, -0.4858,  0.5864,  ..., -0.2855, -0.1107, -0.3576])\n",
      "impulsive\n",
      "Saved the embedding for impulsive.\n",
      "['inactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3566,  0.5117,  0.2870,  ..., -0.1393, -0.5572, -0.3366])\n",
      "inactive\n",
      "Saved the embedding for inactive.\n",
      "['inadequate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1987, -0.2419,  0.6884,  ..., -2.0327, -1.2528,  0.4254])\n",
      "inadequate\n",
      "Saved the embedding for inadequate.\n",
      "['ina', '##rti', '##cula', '##te'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1264,  0.3428,  0.4300,  ..., -0.2883, -0.3291, -0.1727])\n",
      "inarticulate\n",
      "Saved the embedding for inarticulate.\n",
      "['ina', '##tten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4427,  0.4965,  0.5307,  ...,  0.6096,  0.2410, -0.1280])\n",
      "inattentive\n",
      "Saved the embedding for inattentive.\n",
      "['ina', '##udi', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.1535, 0.5938, 0.6211,  ..., 0.2296, 0.0039, 0.2813])\n",
      "inaudible\n",
      "Saved the embedding for inaudible.\n",
      "['ina', '##uth', '##ent', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3619,  0.1904,  0.3891,  ...,  0.4754, -0.2457, -0.3370])\n",
      "inauthentic\n",
      "Saved the embedding for inauthentic.\n",
      "['incapable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0136, -0.2329,  0.4452,  ..., -0.8042, -0.6389, -0.1181])\n",
      "incapable\n",
      "Saved the embedding for incapable.\n",
      "['incense', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1085, -0.3924,  0.4784,  ..., -0.3016, -0.5459, -0.4622])\n",
      "incensed\n",
      "Saved the embedding for incensed.\n",
      "['inc', '##ert', '##ain'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4569,  0.6267,  0.1354,  ..., -0.2735, -0.2156,  0.6933])\n",
      "incertain\n",
      "Saved the embedding for incertain.\n",
      "['inc', '##ert', '##itude'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4315,  0.4382,  0.0940,  ...,  0.0350, -0.1746,  1.4320])\n",
      "incertitude\n",
      "Saved the embedding for incertitude.\n",
      "['inc', '##ited'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6522, -0.4293,  0.0426,  ..., -0.7380, -0.4705,  0.4297])\n",
      "incited\n",
      "Saved the embedding for incited.\n",
      "['inc', '##omp', '##re', '##hen', '##sible'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.5243,  0.3702,  0.2635,  ...,  0.3888,  0.4291,  0.6112])\n",
      "incomprehensible\n",
      "Saved the embedding for incomprehensible.\n",
      "['inc', '##ons', '##pic', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3610,  0.4004,  0.4395,  ..., -0.0386,  0.0965,  0.4163])\n",
      "inconspicuous\n",
      "Saved the embedding for inconspicuous.\n",
      "['inc', '##red', '##uli', '##ty'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4330,  0.1509,  0.2931,  ..., -0.2984, -0.4807,  0.9234])\n",
      "incredulity\n",
      "Saved the embedding for incredulity.\n",
      "['inc', '##red', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3432,  0.5153,  0.2085,  ..., -0.0697,  0.1931,  0.1862])\n",
      "incredulous\n",
      "Saved the embedding for incredulous.\n",
      "['inc', '##red', '##ulously'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2972,  0.4973,  0.3316,  ..., -0.2083,  0.3738,  0.2336])\n",
      "incredulously\n",
      "Saved the embedding for incredulously.\n",
      "['inc', '##ul', '##pate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8286,  0.7569,  0.1585,  ..., -0.5903, -0.5337,  0.4091])\n",
      "inculpate\n",
      "Saved the embedding for inculpate.\n",
      "['inc', '##uri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3795,  0.4913,  0.3494,  ..., -0.2995, -0.5555,  0.7487])\n",
      "incurious\n",
      "Saved the embedding for incurious.\n",
      "['ind', '##ec', '##ip', '##her', '##able'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2607,  0.1864,  0.0411,  ..., -0.5521, -0.3918,  1.1325])\n",
      "indecipherable\n",
      "Saved the embedding for indecipherable.\n",
      "['ind', '##ec', '##ision'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2374, -0.0865,  0.0937,  ...,  0.0168, -1.1850,  1.2441])\n",
      "indecision\n",
      "Saved the embedding for indecision.\n",
      "['ind', '##ec', '##isi', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2918,  0.0808, -0.0868,  ...,  0.0349, -0.4717,  0.8217])\n",
      "indecisive\n",
      "Saved the embedding for indecisive.\n",
      "['indifferent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.5761, 1.1129, 0.0862,  ..., 0.4040, 0.0803, 0.9454])\n",
      "indifferent\n",
      "Saved the embedding for indifferent.\n",
      "['indifferent', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.2397, 0.9025, 0.5315,  ..., 0.0148, 0.0568, 1.0872])\n",
      "indifferently\n",
      "Saved the embedding for indifferently.\n",
      "['ind', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1890,  0.0052,  0.0424,  ...,  0.0389, -0.7402,  0.1646])\n",
      "indignant\n",
      "Saved the embedding for indignant.\n",
      "['indo', '##lent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5676,  0.1899,  0.2149,  ..., -0.6137, -0.4412,  0.8220])\n",
      "indolent\n",
      "Saved the embedding for indolent.\n",
      "['in', '##eb', '##riated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1084, -0.5873, -0.0728,  ..., -1.2881, -0.9025,  0.7732])\n",
      "inebriated\n",
      "Saved the embedding for inebriated.\n",
      "['in', '##ert'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3781,  0.0191,  0.0196,  ..., -1.2798, -0.3801,  0.1516])\n",
      "inert\n",
      "Saved the embedding for inert.\n",
      "['in', '##fat', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0841, -0.0054,  0.7553,  ..., -1.8186, -1.0521,  0.3290])\n",
      "infatuating\n",
      "Saved the embedding for infatuating.\n",
      "['inferior'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5948, -0.1995,  0.9663,  ..., -0.8217, -0.6819, -0.3697])\n",
      "inferior\n",
      "Saved the embedding for inferior.\n",
      "['inferior', '##ity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1282, -0.4930,  0.5467,  ..., -0.5235, -0.7492,  0.0769])\n",
      "inferiority\n",
      "Saved the embedding for inferiority.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', '##fl', '##ame', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1280, -0.2611, -0.5078,  ..., -0.3981,  0.1285, -0.0436])\n",
      "inflamed\n",
      "Saved the embedding for inflamed.\n",
      "['informal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0705,  0.2588, -0.5947,  ..., -0.9175, -0.8820,  0.4459])\n",
      "informal\n",
      "Saved the embedding for informal.\n",
      "['informing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9433,  0.7942,  0.7381,  ..., -1.0194, -0.4618, -0.1002])\n",
      "informing\n",
      "Saved the embedding for informing.\n",
      "['in', '##fur', '##iated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2585, -0.0659,  0.5493,  ..., -1.6056,  0.0327,  0.3747])\n",
      "infuriated\n",
      "Saved the embedding for infuriated.\n",
      "['inhibit', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0702,  0.2004, -0.1079,  ..., -0.2670, -1.1686,  0.3664])\n",
      "inhibited\n",
      "Saved the embedding for inhibited.\n",
      "['inhibit', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5175,  0.3343,  0.3414,  ..., -0.7506, -1.2373, -0.1681])\n",
      "inhibiting\n",
      "Saved the embedding for inhibiting.\n",
      "['in', '##imi', '##cal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0549,  0.0444,  0.2372,  ..., -0.9018, -1.0982,  0.7729])\n",
      "inimical\n",
      "Saved the embedding for inimical.\n",
      "['injured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5575, -0.3984, -0.1995,  ..., -0.6057,  0.2924, -0.2642])\n",
      "injured\n",
      "Saved the embedding for injured.\n",
      "['innocent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5438,  0.7968,  0.0349,  ...,  0.4959,  0.1069, -0.5032])\n",
      "innocent\n",
      "Saved the embedding for innocent.\n",
      "['in', '##patient'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1444, -0.5102,  0.2989,  ..., -0.5270, -0.1240,  0.4226])\n",
      "inpatient\n",
      "Saved the embedding for inpatient.\n",
      "['in', '##qui', '##ring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2592,  0.4795,  0.3054,  ..., -1.0183, -1.3109,  0.5558])\n",
      "inquiring\n",
      "Saved the embedding for inquiring.\n",
      "['in', '##qui', '##sit', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0253, -0.0235,  0.0370,  ..., -0.1380, -0.4222,  0.4283])\n",
      "inquisitive\n",
      "Saved the embedding for inquisitive.\n",
      "['insane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0030,  0.5607,  0.4107,  ...,  0.1925, -1.0027, -0.2979])\n",
      "insane\n",
      "Saved the embedding for insane.\n",
      "['ins', '##cr', '##utable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4283,  0.3698,  0.1483,  ...,  0.0631, -0.4471, -0.1171])\n",
      "inscrutable\n",
      "Saved the embedding for inscrutable.\n",
      "['ins', '##ecure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4794, -0.1725,  0.1600,  ..., -0.9084, -0.3686, -0.3023])\n",
      "insecure\n",
      "Saved the embedding for insecure.\n",
      "['ins', '##ec', '##urity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5999,  0.0840, -0.2995,  ..., -0.7041, -0.6269,  0.4737])\n",
      "insecurity\n",
      "Saved the embedding for insecurity.\n",
      "['ins', '##ens', '##itive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4580, -0.1528, -0.1757,  ..., -0.2072, -0.2730, -0.3126])\n",
      "insensitive\n",
      "Saved the embedding for insensitive.\n",
      "['ins', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6666,  0.2872,  0.3803,  ..., -0.7734, -0.2789, -0.4440])\n",
      "insidious\n",
      "Saved the embedding for insidious.\n",
      "['ins', '##in', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3241,  0.0258,  0.4476,  ..., -0.3338, -0.4995, -0.2338])\n",
      "insinuating\n",
      "Saved the embedding for insinuating.\n",
      "['insistence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5491, -0.2445,  0.1424,  ..., -1.5157,  1.0174,  0.0461])\n",
      "insistence\n",
      "Saved the embedding for insistence.\n",
      "['insistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9278, -0.4359,  0.2351,  ..., -1.0172,  0.5316,  0.0292])\n",
      "insistent\n",
      "Saved the embedding for insistent.\n",
      "['insisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0174, -0.0277,  0.0392,  ...,  0.1142, -0.8563,  0.0876])\n",
      "insisting\n",
      "Saved the embedding for insisting.\n",
      "['ins', '##ole', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4143,  0.5832,  0.2913,  ..., -0.6897, -0.0967, -0.7157])\n",
      "insolent\n",
      "Saved the embedding for insolent.\n",
      "['ins', '##ou', '##cian', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6340,  0.3954, -0.1883,  ..., -0.7034,  0.0614,  0.4692])\n",
      "insouciance\n",
      "Saved the embedding for insouciance.\n",
      "['ins', '##ou', '##cian', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5219,  0.1257, -0.0997,  ..., -0.5796,  0.2862,  0.8002])\n",
      "insouciant\n",
      "Saved the embedding for insouciant.\n",
      "['inspired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5055,  0.5196, -0.3683,  ..., -0.2441, -0.0185, -0.2290])\n",
      "inspired\n",
      "Saved the embedding for inspired.\n",
      "['inspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 3.8101e-01,  9.2856e-01,  3.8022e-01,  ..., -4.9686e-01,\n",
      "         9.4965e-03,  1.5895e-04])\n",
      "inspiring\n",
      "Saved the embedding for inspiring.\n",
      "['ins', '##ti', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3151,  0.4609, -0.3193,  ..., -0.8608, -0.7435, -0.2017])\n",
      "instigating\n",
      "Saved the embedding for instigating.\n",
      "['ins', '##tructing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5326,  0.3068,  0.0930,  ..., -0.7368, -0.5153,  0.3754])\n",
      "instructing\n",
      "Saved the embedding for instructing.\n",
      "['ins', '##ub', '##ord', '##inate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7450,  0.0795, -0.1547,  ..., -0.4005,  0.2528,  0.4536])\n",
      "insubordinate\n",
      "Saved the embedding for insubordinate.\n",
      "['ins', '##ular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6928, -0.1887, -0.3296,  ..., -0.7660,  0.0637,  1.0018])\n",
      "insular\n",
      "Saved the embedding for insular.\n",
      "['insulted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0466,  0.6418,  0.1821,  ..., -0.0098, -0.6605, -0.1545])\n",
      "insulted\n",
      "Saved the embedding for insulted.\n",
      "['insulting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2933,  0.5609,  0.2000,  ..., -0.6163, -0.5238, -0.4726])\n",
      "insulting\n",
      "Saved the embedding for insulting.\n",
      "['intelligence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5223,  0.9685, -0.9337,  ...,  0.5501, -0.3940, -0.1362])\n",
      "intelligence\n",
      "Saved the embedding for intelligence.\n",
      "['intense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1615,  0.6533,  0.0225,  ..., -0.1458, -1.0667, -0.0171])\n",
      "intense\n",
      "Saved the embedding for intense.\n",
      "['intensely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0598,  0.5247,  0.3060,  ..., -0.4525, -0.3054, -0.4379])\n",
      "intensely\n",
      "Saved the embedding for intensely.\n",
      "['intensity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4992,  0.9151,  0.2172,  ..., -0.2842, -1.0187, -0.5338])\n",
      "intensity\n",
      "Saved the embedding for intensity.\n",
      "['intensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2955,  0.3003,  0.6399,  ...,  0.3496, -1.1345,  0.1345])\n",
      "intensive\n",
      "Saved the embedding for intensive.\n",
      "['intent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2739,  0.4661, -0.1310,  ...,  0.5902, -0.2600,  0.4799])\n",
      "intent\n",
      "Saved the embedding for intent.\n",
      "['intentional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0894,  0.3968,  0.7106,  ..., -0.8840,  0.3162, -0.4635])\n",
      "intentional\n",
      "Saved the embedding for intentional.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interacting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5653,  0.5284,  0.2661,  ..., -0.3479, -0.2889, -0.8289])\n",
      "interacting\n",
      "Saved the embedding for interacting.\n",
      "['interest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2915,  1.0307,  0.0777,  ...,  1.4320, -1.0794, -0.5132])\n",
      "interest\n",
      "Saved the embedding for interest.\n",
      "['interested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1165,  0.9277,  0.4718,  ...,  0.6607, -0.9263, -0.5157])\n",
      "interested\n",
      "Saved the embedding for interested.\n",
      "['inter', '##ject', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0531,  0.3989, -0.0243,  ..., -1.0493, -0.1389, -0.0261])\n",
      "interjecting\n",
      "Saved the embedding for interjecting.\n",
      "['internal', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8263,  0.1699,  0.1535,  ..., -1.6444, -1.1420, -0.1601])\n",
      "internalizing\n",
      "Saved the embedding for internalizing.\n",
      "['inter', '##ro', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1987,  0.5587, -0.4162,  ..., -0.6538, -0.2764,  0.4804])\n",
      "interrogating\n",
      "Saved the embedding for interrogating.\n",
      "['interrupting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5222,  0.4269, -0.5448,  ..., -0.3250, -0.6560,  0.1522])\n",
      "interrupting\n",
      "Saved the embedding for interrupting.\n",
      "['intimidated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0023,  0.0614,  0.1609,  ..., -0.0362, -1.0342,  0.1070])\n",
      "intimidated\n",
      "Saved the embedding for intimidated.\n",
      "['intimidating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3387,  0.3856,  0.2284,  ..., -0.2374, -0.5973, -0.4308])\n",
      "intimidating\n",
      "Saved the embedding for intimidating.\n",
      "['into', '##ler', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4354, -0.0700,  0.1753,  ..., -1.2966, -0.5719,  0.3442])\n",
      "intolerant\n",
      "Saved the embedding for intolerant.\n",
      "['into', '##xi', '##cated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2867,  0.0744,  0.5350,  ..., -0.4128, -0.4879, -0.1410])\n",
      "intoxicated\n",
      "Saved the embedding for intoxicated.\n",
      "['int', '##rigue'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0256,  0.3237, -1.1018,  ..., -0.2826,  0.0316,  0.2508])\n",
      "intrigue\n",
      "Saved the embedding for intrigue.\n",
      "['intrigued'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 4.2655e-01,  4.2643e-01,  5.3972e-01,  ..., -1.2615e+00,\n",
      "        -1.0543e+00, -1.5950e-04])\n",
      "intrigued\n",
      "Saved the embedding for intrigued.\n",
      "['intriguing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4007,  0.0615,  0.5878,  ..., -0.3261, -1.0221, -0.2002])\n",
      "intriguing\n",
      "Saved the embedding for intriguing.\n",
      "['intro', '##sp', '##ect', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4979, -0.4631, -0.0208,  ..., -0.4701, -0.0201, -0.0790])\n",
      "introspective\n",
      "Saved the embedding for introspective.\n",
      "['invested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0584,  0.3886,  0.9326,  ...,  0.2123, -1.0516, -0.1196])\n",
      "invested\n",
      "Saved the embedding for invested.\n",
      "['investigate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1750,  0.0640,  0.2336,  ..., -0.5317,  0.2030,  0.4350])\n",
      "investigate\n",
      "Saved the embedding for investigate.\n",
      "['investigative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3155, -0.2635, -0.7789,  ...,  0.1001,  0.3930, -0.5324])\n",
      "investigative\n",
      "Saved the embedding for investigative.\n",
      "['investigator', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3013,  0.6606,  0.3675,  ..., -0.2878, -0.0727,  0.1836])\n",
      "investigatory\n",
      "Saved the embedding for investigatory.\n",
      "['in', '##vi', '##gor', '##ated'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0258, -0.4960, -0.1755,  ..., -0.6273, -0.5050,  0.6962])\n",
      "invigorated\n",
      "Saved the embedding for invigorated.\n",
      "['involved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0171,  0.3944,  0.4076,  ..., -0.5159, -0.4132,  0.4556])\n",
      "involved\n",
      "Saved the embedding for involved.\n",
      "['ira', '##sc', '##ible'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5732,  0.2891, -1.3482,  ..., -0.8973, -0.7848,  0.1296])\n",
      "irascible\n",
      "Saved the embedding for irascible.\n",
      "['ira', '##te'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7402,  0.5908, -1.3521,  ..., -0.6148, -0.7524,  0.4120])\n",
      "irate\n",
      "Saved the embedding for irate.\n",
      "['ir', '##e'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-2.0289e-02, -3.2120e-02, -1.5116e-04,  ..., -7.9414e-01,\n",
      "        -1.0795e+00,  2.1810e-01])\n",
      "ire\n",
      "Saved the embedding for ire.\n",
      "['ir', '##ef', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1460, -0.1235, -0.1512,  ..., -0.6385,  0.0196,  0.3758])\n",
      "ireful\n",
      "Saved the embedding for ireful.\n",
      "['ir', '##ked'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4733, -0.3701, -0.3939,  ..., -0.2265, -0.9558,  0.0348])\n",
      "irked\n",
      "Saved the embedding for irked.\n",
      "['ironic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3433,  0.1011, -0.6181,  ..., -0.4668,  0.4141, -0.2295])\n",
      "ironic\n",
      "Saved the embedding for ironic.\n",
      "['irony'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2225,  0.0494,  0.1536,  ..., -0.5503,  0.3679, -0.8130])\n",
      "irony\n",
      "Saved the embedding for irony.\n",
      "['ir', '##res', '##ol', '##ute'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2774, -0.0375, -0.1096,  ...,  0.2883, -1.1966, -0.3888])\n",
      "irresolute\n",
      "Saved the embedding for irresolute.\n",
      "['ir', '##rita', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0750,  0.2381, -0.0524,  ..., -0.2161, -0.0066, -0.3565])\n",
      "irritable\n",
      "Saved the embedding for irritable.\n",
      "['ir', '##rita', '##bly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0006, -0.0789,  0.2290,  ..., -0.5072,  0.2872, -0.5242])\n",
      "irritably\n",
      "Saved the embedding for irritably.\n",
      "['irritated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0625,  0.6414,  0.9256,  ..., -0.3620, -0.4583,  0.5451])\n",
      "irritated\n",
      "Saved the embedding for irritated.\n",
      "['irritation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2627,  0.9530,  0.2705,  ..., -0.3202, -0.3777,  0.1380])\n",
      "irritation\n",
      "Saved the embedding for irritation.\n",
      "['isolated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3448,  0.3882,  0.9921,  ..., -1.2936, -1.0842,  0.0120])\n",
      "isolated\n",
      "Saved the embedding for isolated.\n",
      "['ja', '##bbed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3085, -1.0700, -0.9052,  ..., -0.5454, -0.8678, -0.0626])\n",
      "jabbed\n",
      "Saved the embedding for jabbed.\n",
      "['jade', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0770,  0.3357, -0.1264,  ..., -0.5143, -0.7483,  0.1163])\n",
      "jaded\n",
      "Saved the embedding for jaded.\n",
      "['jar', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0130,  0.1701, -0.1443,  ...,  0.0032, -0.0738, -0.0852])\n",
      "jarred\n",
      "Saved the embedding for jarred.\n",
      "['jar', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0757,  0.1164, -0.0352,  ...,  0.0338, -0.0875, -0.0828])\n",
      "jarring\n",
      "Saved the embedding for jarring.\n",
      "['ja', '##unt', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0271, -0.2186, -0.9914,  ..., -0.7603, -0.0248,  0.6024])\n",
      "jaunty\n",
      "Saved the embedding for jaunty.\n",
      "['jaw', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0591,  0.8428, -0.8177,  ..., -0.5802, -0.0607,  0.6250])\n",
      "jawed\n",
      "Saved the embedding for jawed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jealous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2804,  0.4477,  0.0273,  ...,  0.4621, -0.2881,  0.1454])\n",
      "jealous\n",
      "Saved the embedding for jealous.\n",
      "['je', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3740,  0.2051, -1.0138,  ...,  0.0084,  0.2328,  0.7492])\n",
      "jeering\n",
      "Saved the embedding for jeering.\n",
      "['je', '##sti', '##ng'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4978,  0.1962, -0.3347,  ..., -0.0518,  0.0036,  0.4491])\n",
      "jesting\n",
      "Saved the embedding for jesting.\n",
      "['ji', '##lt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4654, -0.1867, -0.7257,  ..., -0.9153, -1.1995,  0.5948])\n",
      "jilted\n",
      "Saved the embedding for jilted.\n",
      "['ji', '##tter', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1323,  0.1583, -0.5876,  ..., -0.3573, -0.2638,  0.2115])\n",
      "jittery\n",
      "Saved the embedding for jittery.\n",
      "['jo', '##cular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2358, -0.5145, -0.9794,  ..., -0.7371, -0.5821,  0.6228])\n",
      "jocular\n",
      "Saved the embedding for jocular.\n",
      "['joking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3257,  0.1301,  0.3941,  ..., -0.1187, -0.9251,  0.6943])\n",
      "joking\n",
      "Saved the embedding for joking.\n",
      "['jolly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3013,  0.8576, -0.1006,  ...,  0.4553,  0.3286,  0.8362])\n",
      "jolly\n",
      "Saved the embedding for jolly.\n",
      "['jolted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3640,  0.3850, -0.2332,  ..., -0.0203,  0.5417, -0.6554])\n",
      "jolted\n",
      "Saved the embedding for jolted.\n",
      "['jo', '##vial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3964, -0.4715, -0.6565,  ..., -1.1106, -0.7579,  0.4873])\n",
      "jovial\n",
      "Saved the embedding for jovial.\n",
      "['joy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1081,  0.4591,  0.0596,  ..., -0.6633, -0.6422, -0.0240])\n",
      "joy\n",
      "Saved the embedding for joy.\n",
      "['joy', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0794,  0.2294,  0.0814,  ..., -0.5329, -0.2062,  0.3124])\n",
      "joyful\n",
      "Saved the embedding for joyful.\n",
      "['joy', '##fulness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4235,  0.1162,  0.1128,  ...,  0.1469, -0.0731,  0.4683])\n",
      "joyfulness\n",
      "Saved the embedding for joyfulness.\n",
      "['joy', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2945,  0.2427, -0.0764,  ..., -0.5917, -0.3220,  0.3670])\n",
      "joyless\n",
      "Saved the embedding for joyless.\n",
      "['joy', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2142,  0.2260,  0.2123,  ..., -0.6664, -0.6161,  0.5453])\n",
      "joyous\n",
      "Saved the embedding for joyous.\n",
      "['ju', '##bil', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0890,  0.3433,  0.5011,  ..., -0.3455, -1.2421,  0.2261])\n",
      "jubilant\n",
      "Saved the embedding for jubilant.\n",
      "['ju', '##bil', '##ation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2142, -0.0846, -0.0711,  ..., -0.1432, -0.5970,  0.3203])\n",
      "jubilation\n",
      "Saved the embedding for jubilation.\n",
      "['judgement', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3714,  0.6195,  0.2611,  ..., -0.6338, -0.5698,  0.9599])\n",
      "judgemental\n",
      "Saved the embedding for judgemental.\n",
      "['judging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6182, -0.2395, -0.1947,  ..., -0.2434, -0.3504, -0.3665])\n",
      "judging\n",
      "Saved the embedding for judging.\n",
      "['judgment', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1463,  0.3735,  0.1406,  ..., -0.1941, -0.6297,  0.8519])\n",
      "judgmental\n",
      "Saved the embedding for judgmental.\n",
      "['ju', '##dic', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2337,  0.1175,  0.1286,  ...,  0.1588, -0.1589, -0.2152])\n",
      "judicious\n",
      "Saved the embedding for judicious.\n",
      "['jump', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2059,  1.0504, -0.8233,  ..., -0.3811,  0.2404, -0.0207])\n",
      "jumpy\n",
      "Saved the embedding for jumpy.\n",
      "['justified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0131, -0.0041,  0.1033,  ..., -1.0869,  0.2713, -1.0021])\n",
      "justified\n",
      "Saved the embedding for justified.\n",
      "['keen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4389,  0.0654,  0.4267,  ...,  0.3954, -0.1600, -0.2997])\n",
      "keen\n",
      "Saved the embedding for keen.\n",
      "['kind'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5367,  0.1159, -0.0166,  ...,  0.4769, -0.1428, -0.8406])\n",
      "kind\n",
      "Saved the embedding for kind.\n",
      "['kind', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3084, -0.2926,  0.4327,  ..., -0.2951, -0.7408, -0.6282])\n",
      "kindhearted\n",
      "Saved the embedding for kindhearted.\n",
      "['kiss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0427,  0.5149, -0.5102,  ..., -1.0061,  0.2598, -0.0196])\n",
      "kiss\n",
      "Saved the embedding for kiss.\n",
      "['knowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1076,  0.4189, -0.1690,  ..., -0.0736, -0.7146,  0.0864])\n",
      "knowing\n",
      "Saved the embedding for knowing.\n",
      "['know', '##led', '##ga', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4157,  0.0358, -0.1550,  ..., -0.4811, -0.0492,  0.0958])\n",
      "knowledgable\n",
      "Saved the embedding for knowledgable.\n",
      "['knowledge', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3620,  1.0463,  0.7713,  ..., -0.1940, -0.6252,  0.4203])\n",
      "knowledgeable\n",
      "Saved the embedding for knowledgeable.\n",
      "['ko', '##sher'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3206, -0.1265, -0.7575,  ..., -1.3780, -0.9337,  0.9933])\n",
      "kosher\n",
      "Saved the embedding for kosher.\n",
      "['lack', '##ada', '##isi', '##cal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0273, -0.0590, -0.3184,  ..., -0.0297, -0.1037,  0.2988])\n",
      "lackadaisical\n",
      "Saved the embedding for lackadaisical.\n",
      "['lack', '##lus', '##ter'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0809, -0.5541, -0.7130,  ..., -0.0024,  0.2251,  0.2259])\n",
      "lackluster\n",
      "Saved the embedding for lackluster.\n",
      "['lac', '##onic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6234, -0.2099,  0.5100,  ..., -0.5556, -0.5846,  0.2931])\n",
      "laconic\n",
      "Saved the embedding for laconic.\n",
      "['lamb', '##ast', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5170,  0.2756, -0.3019,  ..., -0.0157, -0.7868, -0.8143])\n",
      "lambaste\n",
      "Saved the embedding for lambaste.\n",
      "['lame', '##nta', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0250, -0.4420,  0.4738,  ..., -1.2744, -0.7856,  0.4849])\n",
      "lamentable\n",
      "Saved the embedding for lamentable.\n",
      "['lame', '##nting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 2.0162e-02, -9.5504e-04,  3.0143e-01,  ..., -1.9842e+00,\n",
      "        -5.4119e-01, -1.9277e-01])\n",
      "lamenting\n",
      "Saved the embedding for lamenting.\n",
      "['las', '##ci', '##vious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0224,  0.4883,  0.2290,  ..., -0.1673, -0.3597,  0.4949])\n",
      "lascivious\n",
      "Saved the embedding for lascivious.\n",
      "['laugh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0904,  0.0986, -0.2687,  ..., -1.4542, -1.1218,  0.8200])\n",
      "laugh\n",
      "Saved the embedding for laugh.\n",
      "['laughing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1690,  0.4152, -0.0909,  ..., -0.6499, -0.4973, -0.2174])\n",
      "laughing\n",
      "Saved the embedding for laughing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['laughter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1718,  0.1534, -0.2944,  ..., -0.6027, -0.3239,  0.4660])\n",
      "laughter\n",
      "Saved the embedding for laughter.\n",
      "['lazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1624,  1.3352, -0.0448,  ..., -0.2263, -0.2032,  0.6231])\n",
      "lazy\n",
      "Saved the embedding for lazy.\n",
      "['leaving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4892,  0.1696,  0.1829,  ...,  1.1452, -0.8735, -0.5866])\n",
      "leaving\n",
      "Saved the embedding for leaving.\n",
      "['le', '##cher', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7797,  0.0332, -0.3809,  ...,  0.2339, -0.1752, -0.1155])\n",
      "lecherous\n",
      "Saved the embedding for lecherous.\n",
      "['le', '##cturing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1425, -0.3282, -0.5656,  ..., -0.0834, -0.3856,  0.5180])\n",
      "lecturing\n",
      "Saved the embedding for lecturing.\n",
      "['lee', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2169, -0.3765, -0.1955,  ..., -0.2950, -0.1334,  0.3057])\n",
      "leering\n",
      "Saved the embedding for leering.\n",
      "['lee', '##ry'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0446, -0.1268, -0.3694,  ..., -0.4127, -0.3637,  0.0655])\n",
      "leery\n",
      "Saved the embedding for leery.\n",
      "['let', '##down'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5569,  0.4543, -0.1407,  ..., -0.3327, -0.3238,  0.6597])\n",
      "letdown\n",
      "Saved the embedding for letdown.\n",
      "['let', '##har', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1886, -0.2709, -0.7274,  ..., -0.5519,  0.0673,  0.6197])\n",
      "lethargic\n",
      "Saved the embedding for lethargic.\n",
      "['level', '##head', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1297, -0.2014,  0.3557,  ...,  0.2414, -1.1058,  0.5051])\n",
      "levelheaded\n",
      "Saved the embedding for levelheaded.\n",
      "['lew', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5830,  1.1013,  0.3263,  ..., -0.2311, -0.8358, -0.3613])\n",
      "lewd\n",
      "Saved the embedding for lewd.\n",
      "['li', '##bid', '##ino', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2948, -0.4490, -0.3666,  ..., -0.3395,  0.2968,  0.5950])\n",
      "libidinous\n",
      "Saved the embedding for libidinous.\n",
      "['lifeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3084,  0.7167, -0.0597,  ...,  0.0227, -0.6209,  0.1058])\n",
      "lifeless\n",
      "Saved the embedding for lifeless.\n",
      "['light', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5867,  0.5655,  0.1911,  ...,  0.2402, -0.7270,  0.4180])\n",
      "lighthearted\n",
      "Saved the embedding for lighthearted.\n",
      "['lip', '##ped'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3432, -0.7871, -0.8277,  ...,  0.1923, -0.2380, -0.0896])\n",
      "lipped\n",
      "Saved the embedding for lipped.\n",
      "['listening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2177,  0.3826, -0.0514,  ...,  1.3745, -0.2402, -0.6246])\n",
      "listening\n",
      "Saved the embedding for listening.\n",
      "['list', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0216, -0.1418,  0.1032,  ..., -0.1086, -0.2401,  0.4322])\n",
      "listless\n",
      "Saved the embedding for listless.\n",
      "['lively'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2563, -0.5184, -0.0203,  ..., -0.6851,  0.4975, -0.5383])\n",
      "lively\n",
      "Saved the embedding for lively.\n",
      "['liv', '##id'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1735,  0.9584, -0.5236,  ...,  0.3219,  0.2685,  1.3991])\n",
      "livid\n",
      "Saved the embedding for livid.\n",
      "['loaded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6334,  0.2982,  0.1012,  ..., -0.1616, -0.8674, -0.0031])\n",
      "loaded\n",
      "Saved the embedding for loaded.\n",
      "['lo', '##ath'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3748,  0.3315, -0.0682,  ..., -0.3918, -0.4008,  1.0329])\n",
      "loath\n",
      "Saved the embedding for loath.\n",
      "['lo', '##ath', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6139, -0.0940, -0.0633,  ...,  0.5043,  0.0219,  0.4750])\n",
      "loathe\n",
      "Saved the embedding for loathe.\n",
      "['lo', '##athing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8066,  0.5110, -0.0035,  ..., -0.3611, -0.9571,  1.0207])\n",
      "loathing\n",
      "Saved the embedding for loathing.\n",
      "['lo', '##ath', '##some'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5266, -0.1273, -0.2241,  ...,  0.7117,  0.1793,  0.2450])\n",
      "loathsome\n",
      "Saved the embedding for loathsome.\n",
      "['locked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1632,  0.3107, -0.5100,  ..., -1.1861, -0.3590,  0.5432])\n",
      "locked\n",
      "Saved the embedding for locked.\n",
      "['loneliness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6218,  0.3260,  0.5200,  ..., -0.8619, -0.7236, -0.0596])\n",
      "loneliness\n",
      "Saved the embedding for loneliness.\n",
      "['lonely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2477,  0.3837, -0.3233,  ..., -0.3000, -0.5542, -0.1946])\n",
      "lonely\n",
      "Saved the embedding for lonely.\n",
      "['longing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0778, -0.3493, -0.5070,  ..., -0.0222,  0.1456, -0.3314])\n",
      "longing\n",
      "Saved the embedding for longing.\n",
      "['looking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3170,  0.4357, -1.2022,  ..., -0.2109, -0.6085,  0.3008])\n",
      "looking\n",
      "Saved the embedding for looking.\n",
      "['lo', '##ony'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9242, -0.3225,  0.1342,  ...,  0.3298, -0.1136,  0.7544])\n",
      "loony\n",
      "Saved the embedding for loony.\n",
      "['loss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0053,  0.4925,  0.4849,  ..., -0.9811, -0.7617, -0.8502])\n",
      "loss\n",
      "Saved the embedding for loss.\n",
      "['lost'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4173, -0.5161,  0.4120,  ..., -1.0127,  0.1578, -0.9940])\n",
      "lost\n",
      "Saved the embedding for lost.\n",
      "['loud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5413,  0.4484, -0.4832,  ...,  0.2242, -0.2539, -0.4298])\n",
      "loud\n",
      "Saved the embedding for loud.\n",
      "['lou', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4030, -0.1515, -0.1521,  ..., -0.2021,  0.1671,  0.4092])\n",
      "lousy\n",
      "Saved the embedding for lousy.\n",
      "['love'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7175,  0.5592,  0.1439,  ...,  0.2243, -0.2223,  0.1475])\n",
      "love\n",
      "Saved the embedding for love.\n",
      "['loving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7645,  0.6353,  0.5185,  ..., -0.4562, -0.8417, -0.7259])\n",
      "loving\n",
      "Saved the embedding for loving.\n",
      "['low', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0362,  0.5353,  0.6303,  ..., -0.7939, -1.3626, -0.1527])\n",
      "lowliness\n",
      "Saved the embedding for lowliness.\n",
      "['lu', '##rid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0277,  0.4036, -0.0736,  ..., -0.4953, -0.2563,  0.1502])\n",
      "lurid\n",
      "Saved the embedding for lurid.\n",
      "['lust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6025, -0.0030, -0.3248,  ..., -0.2083, -0.1665,  0.1345])\n",
      "lustful\n",
      "Saved the embedding for lustful.\n",
      "['lust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8845,  0.0226, -0.0203,  ...,  0.6104,  0.1641, -0.2052])\n",
      "lusting\n",
      "Saved the embedding for lusting.\n",
      "['lust', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2512,  0.0326, -0.3570,  ...,  0.2732, -0.1355,  0.0254])\n",
      "lusty\n",
      "Saved the embedding for lusty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0229,  0.7143, -0.1414,  ...,  0.5851,  0.2836, -0.4342])\n",
      "lying\n",
      "Saved the embedding for lying.\n",
      "['mad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0988,  0.6161,  0.3298,  ..., -0.6297, -0.3663, -0.0365])\n",
      "mad\n",
      "Saved the embedding for mad.\n",
      "['madden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0955, -0.5860, -0.4872,  ..., -0.0458, -0.4508,  0.3686])\n",
      "maddened\n",
      "Saved the embedding for maddened.\n",
      "['madness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4387, -0.2444,  0.1812,  ..., -0.6731, -0.6414,  0.5440])\n",
      "madness\n",
      "Saved the embedding for madness.\n",
      "['mal', '##con', '##ten', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6905, -0.3561, -0.5045,  ..., -0.5386, -0.2964,  0.6761])\n",
      "malcontent\n",
      "Saved the embedding for malcontent.\n",
      "['male', '##fi', '##cent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1062, -0.3331, -0.4100,  ...,  0.1559, -0.1820, -0.5569])\n",
      "maleficent\n",
      "Saved the embedding for maleficent.\n",
      "['male', '##vo', '##lent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4226, -0.0531, -0.4214,  ..., -0.0346, -0.2171, -0.1877])\n",
      "malevolent\n",
      "Saved the embedding for malevolent.\n",
      "['malice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.6244, 0.8747, 0.0919,  ..., 0.3806, 0.0081, 0.0068])\n",
      "malice\n",
      "Saved the embedding for malice.\n",
      "['malicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1423, -0.1484, -0.0969,  ...,  0.1158,  0.3081, -0.2012])\n",
      "malicious\n",
      "Saved the embedding for malicious.\n",
      "['mali', '##gnant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5641, -0.3081,  0.5516,  ..., -1.2614, -0.1042,  0.4629])\n",
      "malignant\n",
      "Saved the embedding for malignant.\n",
      "['mania', '##cal'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0898,  0.0854, -0.1855,  ..., -0.4743, -0.2769,  0.2560])\n",
      "maniacal\n",
      "Saved the embedding for maniacal.\n",
      "['mani', '##pu', '##lative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3255, -0.9878, -0.3508,  ..., -0.8621, -0.7555,  0.8222])\n",
      "manipulative\n",
      "Saved the embedding for manipulative.\n",
      "['marvel', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2809,  1.3189, -0.3965,  ..., -0.2147, -0.8558, -0.7248])\n",
      "marveled\n",
      "Saved the embedding for marveled.\n",
      "['master'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6150,  0.1087,  0.5889,  ..., -0.5885, -0.1617,  0.2231])\n",
      "master\n",
      "Saved the embedding for master.\n",
      "['mean'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6413,  0.1174,  0.9427,  ...,  0.0296, -0.2710,  0.3119])\n",
      "mean\n",
      "Saved the embedding for mean.\n",
      "['meaningful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3764,  0.3303,  0.1155,  ..., -0.8922, -0.8656, -0.6224])\n",
      "meaningful\n",
      "Saved the embedding for meaningful.\n",
      "['med', '##itative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0536, -1.3627, -0.3232,  ..., -0.2813,  0.2858,  0.1286])\n",
      "meditative\n",
      "Saved the embedding for meditative.\n",
      "['meek'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0121,  0.6437,  0.0159,  ..., -0.2114, -0.8487, -0.3819])\n",
      "meek\n",
      "Saved the embedding for meek.\n",
      "['mel', '##an', '##cho', '##lic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0011, -0.2305, -0.0914,  ..., -0.4780,  0.3144, -0.2501])\n",
      "melancholic\n",
      "Saved the embedding for melancholic.\n",
      "['melancholy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4188,  0.1803,  0.3819,  ..., -0.2437, -0.1599, -0.3151])\n",
      "melancholy\n",
      "Saved the embedding for melancholy.\n",
      "['mel', '##low'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2445, -0.5174, -0.4108,  ..., -0.2562, -0.0020, -0.1188])\n",
      "mellow\n",
      "Saved the embedding for mellow.\n",
      "['menace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1600,  0.7444,  0.8891,  ...,  0.7485, -0.8443, -0.8960])\n",
      "menace\n",
      "Saved the embedding for menace.\n",
      "['menacing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1863,  0.3527,  0.6561,  ..., -0.0938, -0.6774, -0.6972])\n",
      "menacing\n",
      "Saved the embedding for menacing.\n",
      "['mental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7247,  0.4335, -0.2910,  ..., -0.8036,  0.1422,  0.0420])\n",
      "mental\n",
      "Saved the embedding for mental.\n",
      "['mer', '##rily'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3414,  0.6745,  0.5771,  ..., -1.3956,  0.1375,  0.4206])\n",
      "merrily\n",
      "Saved the embedding for merrily.\n",
      "['merry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1273,  0.4318,  0.4340,  ...,  0.0574,  0.1827, -0.0525])\n",
      "merry\n",
      "Saved the embedding for merry.\n",
      "['me', '##sm', '##eri', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1797, -0.2544, -0.2646,  ..., -0.7474,  0.1444, -0.0960])\n",
      "mesmerized\n",
      "Saved the embedding for mesmerized.\n",
      "['mi', '##ffed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3350, -0.3412,  0.2723,  ..., -0.5939, -0.9551,  0.3780])\n",
      "miffed\n",
      "Saved the embedding for miffed.\n",
      "['mild'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2122, -0.0022,  0.1734,  ...,  0.0592, -0.6871,  0.0475])\n",
      "mild\n",
      "Saved the embedding for mild.\n",
      "['min', '##cing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6317, -0.0849,  0.0250,  ..., -1.2026, -1.4930,  0.0015])\n",
      "mincing\n",
      "Saved the embedding for mincing.\n",
      "['mind', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3536,  0.4644, -0.0630,  ..., -0.0560, -0.7727, -0.0245])\n",
      "mindful\n",
      "Saved the embedding for mindful.\n",
      "['mind', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3381,  0.0087, -0.0808,  ...,  0.3379, -0.6593,  0.1419])\n",
      "mindless\n",
      "Saved the embedding for mindless.\n",
      "['mirrored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3491, -0.2864, -1.2246,  ...,  0.5225, -0.2077,  0.2827])\n",
      "mirrored\n",
      "Saved the embedding for mirrored.\n",
      "['mir', '##th'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5711,  0.5912, -0.6538,  ..., -0.7942, -0.6934,  0.1640])\n",
      "mirth\n",
      "Saved the embedding for mirth.\n",
      "['mir', '##th', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3989,  0.1415, -0.6560,  ..., -1.6677,  0.3640,  0.4998])\n",
      "mirthful\n",
      "Saved the embedding for mirthful.\n",
      "['mis', '##ant', '##hr', '##op', '##ic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.5623, -0.3192, -0.7388,  ...,  0.1272,  0.0139,  0.2552])\n",
      "misanthropic\n",
      "Saved the embedding for misanthropic.\n",
      "['mischief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2056,  0.8585,  0.3543,  ..., -0.3260, -0.9832, -0.3365])\n",
      "mischief\n",
      "Saved the embedding for mischief.\n",
      "['mischievous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3446,  0.3737,  0.1428,  ...,  0.2712, -0.4551,  0.1074])\n",
      "mischievous\n",
      "Saved the embedding for mischievous.\n",
      "['mischievous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2058,  0.8345, -0.5973,  ..., -0.9648, -1.0118,  0.6954])\n",
      "mischievousness\n",
      "Saved the embedding for mischievousness.\n",
      "['miserable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5518,  0.1743,  0.7570,  ..., -0.0517,  0.0572, -0.6253])\n",
      "miserable\n",
      "Saved the embedding for miserable.\n",
      "['misery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3874,  0.6067,  0.6859,  ..., -0.2971, -0.6187,  0.4060])\n",
      "misery\n",
      "Saved the embedding for misery.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mis', '##giving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1486,  0.2985, -0.8108,  ...,  0.0638,  0.1832,  0.3438])\n",
      "misgiving\n",
      "Saved the embedding for misgiving.\n",
      "['mis', '##lea', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2967,  0.0209, -0.5250,  ..., -0.5025, -0.0024,  0.2638])\n",
      "mislead\n",
      "Saved the embedding for mislead.\n",
      "['mist', '##rus', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5533,  0.5415, -0.0498,  ..., -0.1732, -0.5620,  0.3139])\n",
      "mistrust\n",
      "Saved the embedding for mistrust.\n",
      "['mist', '##rus', '##tf', '##ul'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4406,  0.5743, -0.0846,  ..., -0.1635, -0.1341,  0.2649])\n",
      "mistrustful\n",
      "Saved the embedding for mistrustful.\n",
      "['mist', '##rus', '##ting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6999,  0.7680,  0.2958,  ...,  0.1180, -0.6603,  0.3158])\n",
      "mistrusting\n",
      "Saved the embedding for mistrusting.\n",
      "['misunderstood'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4924,  0.3892,  0.8401,  ..., -0.4910, -0.7239, -0.1511])\n",
      "misunderstood\n",
      "Saved the embedding for misunderstood.\n",
      "['mock', '##ery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3368,  0.8618,  0.1547,  ..., -0.7178, -1.2475,  0.4274])\n",
      "mockery\n",
      "Saved the embedding for mockery.\n",
      "['mocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5269,  0.0978,  0.5273,  ..., -1.0819, -0.6001,  0.3008])\n",
      "mocking\n",
      "Saved the embedding for mocking.\n",
      "['mocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5193,  0.4171,  0.6158,  ..., -0.7336, -1.0089,  0.2407])\n",
      "mockingly\n",
      "Saved the embedding for mockingly.\n",
      "['modest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9329, -0.0502, -0.3799,  ..., -0.7975, -0.5038,  0.8330])\n",
      "modest\n",
      "Saved the embedding for modest.\n",
      "['mono', '##tone'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0410, -0.0364, -0.3951,  ..., -0.0010,  0.0222,  0.4850])\n",
      "monotone\n",
      "Saved the embedding for monotone.\n",
      "['monster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1288, -0.2321, -0.0259,  ..., -0.1968, -0.3453, -0.0946])\n",
      "monster\n",
      "Saved the embedding for monster.\n",
      "['moody'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4255, -0.5253,  0.1757,  ..., -0.1399,  0.2866, -0.8614])\n",
      "moody\n",
      "Saved the embedding for moody.\n",
      "['mo', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3645,  0.6926, -1.1427,  ..., -0.1288, -0.3444,  0.5840])\n",
      "mopey\n",
      "Saved the embedding for mopey.\n",
      "['mor', '##ose'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3815,  0.5250, -0.8621,  ..., -0.0158, -0.1380,  0.9825])\n",
      "morose\n",
      "Saved the embedding for morose.\n",
      "['mort', '##ified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8649,  0.6346,  0.3706,  ..., -0.5072, -0.6866, -0.4420])\n",
      "mortified\n",
      "Saved the embedding for mortified.\n",
      "['motivated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2484,  0.2065, -0.4888,  ..., -0.1489, -0.2838, -0.6181])\n",
      "motivated\n",
      "Saved the embedding for motivated.\n",
      "['mo', '##urn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2042,  0.3694, -1.0794,  ..., -0.0633, -0.4019,  0.3823])\n",
      "mournful\n",
      "Saved the embedding for mournful.\n",
      "['mo', '##urn', '##fulness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1576,  0.4088, -1.0765,  ..., -0.1237, -0.1377,  0.7593])\n",
      "mournfulness\n",
      "Saved the embedding for mournfulness.\n",
      "['mourning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1212,  0.6595, -0.4157,  ...,  0.5473,  0.3350, -0.1399])\n",
      "mourning\n",
      "Saved the embedding for mourning.\n",
      "['mouthed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6930,  0.1902, -0.9634,  ..., -1.2478, -0.0172,  0.4518])\n",
      "mouthed\n",
      "Saved the embedding for mouthed.\n",
      "['moved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0478,  0.3001, -0.5996,  ...,  0.0441, -0.6074,  0.4581])\n",
      "moved\n",
      "Saved the embedding for moved.\n",
      "['mud', '##dled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 5.5936e-01, -1.3248e-04,  9.6490e-02,  ..., -1.1276e+00,\n",
      "        -8.8453e-01,  6.6998e-01])\n",
      "muddled\n",
      "Saved the embedding for muddled.\n",
      "['mum'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4998,  0.6802, -0.7737,  ..., -0.2764, -0.2399,  0.5645])\n",
      "mum\n",
      "Saved the embedding for mum.\n",
      "['murderous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2811,  0.0038,  0.8925,  ..., -0.2936, -0.5791, -0.6926])\n",
      "murderous\n",
      "Saved the embedding for murderous.\n",
      "['musical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7624, -0.0950,  0.3290,  ..., -0.1815, -0.4184, -0.0789])\n",
      "musical\n",
      "Saved the embedding for musical.\n",
      "['mu', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0910,  0.6635, -0.0890,  ..., -0.6076, -1.1528,  0.4735])\n",
      "musing\n",
      "Saved the embedding for musing.\n",
      "['muster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9063, -0.0146,  0.7395,  ..., -0.4950, -0.9015,  0.1381])\n",
      "muster\n",
      "Saved the embedding for muster.\n",
      "['mute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4815, -0.5157, -0.4262,  ...,  0.0897, -0.1074,  0.4266])\n",
      "mute\n",
      "Saved the embedding for mute.\n",
      "['muted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3210,  0.1414, -0.9139,  ...,  0.3522, -0.0554,  0.5495])\n",
      "muted\n",
      "Saved the embedding for muted.\n",
      "['muttering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2118, -0.0078,  0.6375,  ..., -0.8454, -0.9092, -0.0202])\n",
      "muttering\n",
      "Saved the embedding for muttering.\n",
      "['mysterious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1988,  0.0445,  0.2883,  ..., -1.2703, -0.8628,  0.2647])\n",
      "mysterious\n",
      "Saved the embedding for mysterious.\n",
      "['mystical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2319, -0.0869,  0.0389,  ..., -0.4064, -0.3381, -0.4339])\n",
      "mystical\n",
      "Saved the embedding for mystical.\n",
      "['my', '##sti', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1486,  0.3222, -0.0567,  ..., -0.8188, -0.2066, -0.0398])\n",
      "mystified\n",
      "Saved the embedding for mystified.\n",
      "['naive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3607, -0.0498,  0.7887,  ..., -0.9149,  0.1628, -0.6778])\n",
      "naive\n",
      "Saved the embedding for naive.\n",
      "['nap', '##ping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0785, -0.0469,  0.0641,  ..., -0.9701, -1.2072,  0.2386])\n",
      "napping\n",
      "Saved the embedding for napping.\n",
      "['narrow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0355, -0.4398, -0.3954,  ..., -0.4911, -0.1761,  0.0278])\n",
      "narrow\n",
      "Saved the embedding for narrow.\n",
      "['nasty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0830, -0.0047,  0.0303,  ..., -0.0428, -0.9998,  0.0282])\n",
      "nasty\n",
      "Saved the embedding for nasty.\n",
      "['natural'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8178,  0.2309,  0.1588,  ..., -0.7067, -0.4982,  0.7094])\n",
      "natural\n",
      "Saved the embedding for natural.\n",
      "['nature', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1625,  0.1946, -0.3071,  ..., -0.8668, -0.1663,  0.9874])\n",
      "natured\n",
      "Saved the embedding for natured.\n",
      "['naughty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0356,  0.2053, -0.1045,  ..., -0.0417,  0.4679,  0.1344])\n",
      "naughty\n",
      "Saved the embedding for naughty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nausea'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0843,  0.5707,  0.7484,  ..., -1.3576, -0.9315,  0.4976])\n",
      "nausea\n",
      "Saved the embedding for nausea.\n",
      "['nausea', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1417,  0.5234,  0.2608,  ..., -1.5976, -1.4198,  0.4095])\n",
      "nauseated\n",
      "Saved the embedding for nauseated.\n",
      "['na', '##use', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2890,  0.0388, -0.2285,  ..., -0.7129, -0.4439,  0.8379])\n",
      "nauseous\n",
      "Saved the embedding for nauseous.\n",
      "['needy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6276,  0.8658,  0.5791,  ..., -0.7478, -0.6379, -0.2796])\n",
      "needy\n",
      "Saved the embedding for needy.\n",
      "['ne', '##far', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1289,  0.0049,  0.0759,  ..., -0.8566, -0.0093, -0.2501])\n",
      "nefarious\n",
      "Saved the embedding for nefarious.\n",
      "['ne', '##gating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0090, -0.2005, -0.0512,  ..., -0.9826, -0.5065,  0.3565])\n",
      "negating\n",
      "Saved the embedding for negating.\n",
      "['negative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5349,  0.3602,  1.0960,  ..., -0.0725, -1.3978,  0.0798])\n",
      "negative\n",
      "Saved the embedding for negative.\n",
      "['ne', '##gat', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5064,  0.3501,  0.4398,  ...,  0.0616, -0.3965, -0.1061])\n",
      "negativity\n",
      "Saved the embedding for negativity.\n",
      "['neglected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0106,  1.0319, -0.5095,  ...,  0.4632, -0.2708,  0.5723])\n",
      "neglected\n",
      "Saved the embedding for neglected.\n",
      "['ne', '##rdy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1119, -0.0234, -0.0861,  ..., -0.5100, -0.9130, -0.1936])\n",
      "nerdy\n",
      "Saved the embedding for nerdy.\n",
      "['nerve', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3565, -0.2299, -0.0890,  ..., -0.5741, -1.7564,  0.7085])\n",
      "nerved\n",
      "Saved the embedding for nerved.\n",
      "['nerves'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1730,  0.0322, -0.4516,  ...,  0.3900, -0.5890, -0.4532])\n",
      "nerves\n",
      "Saved the embedding for nerves.\n",
      "['nervous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1349,  0.3404, -0.4522,  ..., -0.4774, -0.8509,  0.3936])\n",
      "nervous\n",
      "Saved the embedding for nervous.\n",
      "['nervously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3180,  0.0597, -0.0830,  ...,  0.4865,  1.4197, -0.4628])\n",
      "nervously\n",
      "Saved the embedding for nervously.\n",
      "['nervous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3644,  0.6319, -0.8299,  ..., -1.1527, -1.4691,  0.5679])\n",
      "nervousness\n",
      "Saved the embedding for nervousness.\n",
      "['nes', '##cie', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7507, -0.1226, -1.1402,  ..., -0.4343, -0.3729, -0.4831])\n",
      "nescient\n",
      "Saved the embedding for nescient.\n",
      "['net', '##tled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0056, -0.9305, -0.0226,  ..., -0.4182, -0.0727,  0.6215])\n",
      "nettled\n",
      "Saved the embedding for nettled.\n",
      "['neutral'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2769,  0.3930, -0.7691,  ...,  0.2832, -0.1666, -0.3943])\n",
      "neutral\n",
      "Saved the embedding for neutral.\n",
      "['neutrality'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3462, -0.0300, -0.0689,  ...,  0.2126, -0.1106,  0.4807])\n",
      "neutrality\n",
      "Saved the embedding for neutrality.\n",
      "['nice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0415,  0.8176, -0.3419,  ..., -0.5303, -0.7370,  0.3245])\n",
      "nice\n",
      "Saved the embedding for nice.\n",
      "['noisy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2927,  0.6084, -0.1932,  ..., -0.2305,  0.3480,  0.0477])\n",
      "noisy\n",
      "Saved the embedding for noisy.\n",
      "['non', '##bel', '##ie', '##f'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2398, -0.4553, -0.9282,  ..., -0.4439, -0.8356,  1.0892])\n",
      "nonbelief\n",
      "Saved the embedding for nonbelief.\n",
      "['non', '##chal', '##ance'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1940, -0.0671, -0.4651,  ..., -0.6739,  0.0847,  0.8750])\n",
      "nonchalance\n",
      "Saved the embedding for nonchalance.\n",
      "['non', '##chal', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0933, -0.3347,  0.1066,  ..., -0.7271, -0.0371,  0.6404])\n",
      "nonchalant\n",
      "Saved the embedding for nonchalant.\n",
      "['non', '##com', '##mit', '##tal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1384, -0.6107,  0.0404,  ...,  0.0084, -0.1165,  0.2186])\n",
      "noncommittal\n",
      "Saved the embedding for noncommittal.\n",
      "['non', '##com', '##pl', '##ian', '##t'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.1059, -0.5444, -0.3998,  ..., -0.3204, -0.4717,  1.1078])\n",
      "noncompliant\n",
      "Saved the embedding for noncompliant.\n",
      "['non', '##pl', '##uss', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4330, -0.6163, -0.6097,  ...,  0.0563, -0.2865,  0.9310])\n",
      "nonplussed\n",
      "Saved the embedding for nonplussed.\n",
      "['non', '##sen', '##sic', '##al'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3337, -0.5913, -0.1829,  ..., -0.2143,  0.0065,  0.6757])\n",
      "nonsensical\n",
      "Saved the embedding for nonsensical.\n",
      "['normal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6651,  0.1286,  0.5097,  ...,  0.0956, -0.6855, -0.9123])\n",
      "normal\n",
      "Saved the embedding for normal.\n",
      "['nose', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1553,  0.1164, -0.1263,  ..., -0.4191, -0.9527,  0.1367])\n",
      "nosey\n",
      "Saved the embedding for nosey.\n",
      "['nos', '##tal', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1580,  0.3836,  0.0283,  ...,  0.2691, -0.5574,  0.4792])\n",
      "nostalgic\n",
      "Saved the embedding for nostalgic.\n",
      "['nos', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2216,  0.6780,  0.2256,  ..., -0.4547, -1.1680,  0.5772])\n",
      "nosy\n",
      "Saved the embedding for nosy.\n",
      "['numb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0170, -0.2104, -0.1069,  ..., -1.0390, -0.6870,  0.3224])\n",
      "numb\n",
      "Saved the embedding for numb.\n",
      "['obe', '##die', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6001,  1.0856, -0.0889,  ..., -0.0689, -0.1130, -0.3211])\n",
      "obedient\n",
      "Saved the embedding for obedient.\n",
      "['object', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4588,  0.3979,  0.2355,  ..., -0.4673, -0.3355,  0.5550])\n",
      "objecting\n",
      "Saved the embedding for objecting.\n",
      "['objection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3388,  0.2537,  0.4726,  ..., -0.2311, -0.5331,  0.3215])\n",
      "objection\n",
      "Saved the embedding for objection.\n",
      "['objective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3932,  0.5252,  0.0910,  ...,  0.4094, -0.5298,  0.2919])\n",
      "objective\n",
      "Saved the embedding for objective.\n",
      "['obliged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2613, -0.1214,  0.3413,  ...,  0.1850, -0.6721, -1.2144])\n",
      "obliged\n",
      "Saved the embedding for obliged.\n",
      "['ob', '##li', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2321, -0.1047, -0.3253,  ..., -0.8390, -0.5552,  0.0762])\n",
      "obliging\n",
      "Saved the embedding for obliging.\n",
      "['oblivious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0675,  0.2778, -0.2978,  ..., -0.3863, -0.3185, -0.7642])\n",
      "oblivious\n",
      "Saved the embedding for oblivious.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ob', '##ser', '##vant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0278,  0.1275, -0.5911,  ..., -0.1768,  0.0661,  0.4063])\n",
      "observant\n",
      "Saved the embedding for observant.\n",
      "['observing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4261,  0.8198,  0.2474,  ...,  0.1001,  0.8190, -0.2577])\n",
      "observing\n",
      "Saved the embedding for observing.\n",
      "['obsessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3643, -0.0733,  0.9175,  ..., -0.6175, -0.4773, -0.8750])\n",
      "obsessed\n",
      "Saved the embedding for obsessed.\n",
      "['ob', '##sti', '##nate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2430,  0.2623, -0.3482,  ..., -0.8847, -0.6419,  0.4363])\n",
      "obstinate\n",
      "Saved the embedding for obstinate.\n",
      "['occupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4557,  0.5894, -0.0432,  ..., -0.4301, -0.9943, -0.2437])\n",
      "occupied\n",
      "Saved the embedding for occupied.\n",
      "['odd'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0254,  0.8077, -0.5519,  ...,  0.0853,  0.2413,  0.4003])\n",
      "odd\n",
      "Saved the embedding for odd.\n",
      "['odi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4725, -1.1030, -0.3400,  ..., -0.2245, -0.0133, -0.4003])\n",
      "odious\n",
      "Saved the embedding for odious.\n",
      "['off'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3265, -0.4625, -0.2217,  ...,  0.2673, -0.8111, -0.6633])\n",
      "off\n",
      "Saved the embedding for off.\n",
      "['offended'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1715,  0.5540,  0.1502,  ..., -0.1697, -1.2748,  0.4922])\n",
      "offended\n",
      "Saved the embedding for offended.\n",
      "['offensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5283,  0.5274,  0.5834,  ..., -0.2974, -1.3267, -0.6199])\n",
      "offensive\n",
      "Saved the embedding for offensive.\n",
      "['og', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4031,  1.2949, -1.0943,  ..., -0.2414, -0.8022,  0.5074])\n",
      "ogling\n",
      "Saved the embedding for ogling.\n",
      "['okay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1590, -0.1798, -0.3755,  ..., -1.3458, -1.1180,  0.7096])\n",
      "okay\n",
      "Saved the embedding for okay.\n",
      "['on'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4835, -0.3921,  0.3154,  ..., -0.0955, -0.0975, -0.3474])\n",
      "on\n",
      "Saved the embedding for on.\n",
      "['open'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1494,  0.4480, -0.5439,  ..., -1.5842, -0.9791, -0.0601])\n",
      "open\n",
      "Saved the embedding for open.\n",
      "['open', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0889,  0.7350, -0.7569,  ..., -1.0106, -0.6810,  0.6105])\n",
      "openness\n",
      "Saved the embedding for openness.\n",
      "['opposed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6862, -0.0859,  0.2910,  ..., -0.6542, -0.1352, -0.1933])\n",
      "opposed\n",
      "Saved the embedding for opposed.\n",
      "['opposition', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2515,  0.5532, -0.4303,  ...,  0.7041, -1.1117,  0.1390])\n",
      "oppositional\n",
      "Saved the embedding for oppositional.\n",
      "['op', '##pressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2249,  0.0322, -0.4300,  ...,  0.9977,  0.2742,  0.4150])\n",
      "oppressed\n",
      "Saved the embedding for oppressed.\n",
      "['optimism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7985,  0.0632,  0.4351,  ..., -0.5609, -0.4080,  0.2061])\n",
      "optimism\n",
      "Saved the embedding for optimism.\n",
      "['optimistic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0909, -0.1834, -0.1932,  ..., -0.9567, -0.4503, -0.0612])\n",
      "optimistic\n",
      "Saved the embedding for optimistic.\n",
      "['ordering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2751, -0.0052,  0.1448,  ..., -0.4432,  0.8401,  0.0229])\n",
      "ordering\n",
      "Saved the embedding for ordering.\n",
      "['orgasm', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5111,  0.3448,  0.1749,  ..., -0.4007, -0.1857,  0.2140])\n",
      "orgasmic\n",
      "Saved the embedding for orgasmic.\n",
      "['or', '##nery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8424,  0.0860, -0.5579,  ..., -0.9081, -0.4744,  0.2268])\n",
      "ornery\n",
      "Saved the embedding for ornery.\n",
      "['ou', '##ch'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4429,  1.0222, -0.3538,  ...,  0.0543, -0.8526,  0.8415])\n",
      "ouch\n",
      "Saved the embedding for ouch.\n",
      "['out'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2815, -0.2794, -0.0894,  ..., -0.2755,  0.0568,  0.2055])\n",
      "out\n",
      "Saved the embedding for out.\n",
      "['outburst'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1739,  0.4210,  0.4357,  ..., -0.3879, -0.6719,  0.3494])\n",
      "outburst\n",
      "Saved the embedding for outburst.\n",
      "['out', '##cr', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0791,  0.2953, -0.1056,  ..., -0.5930, -0.5885,  0.3653])\n",
      "outcry\n",
      "Saved the embedding for outcry.\n",
      "['out', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5031, -0.4323, -0.2139,  ...,  0.0965,  0.3714, -0.2434])\n",
      "outed\n",
      "Saved the embedding for outed.\n",
      "['out', '##land', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0066, -0.0779, -0.2877,  ..., -0.0418,  0.1735,  0.4208])\n",
      "outlandish\n",
      "Saved the embedding for outlandish.\n",
      "['outrage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1883,  0.3914, -0.2498,  ..., -0.9222, -0.3162,  0.0416])\n",
      "outrage\n",
      "Saved the embedding for outrage.\n",
      "['outraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3027,  0.5449,  0.5591,  ..., -0.7008, -0.4097, -0.4007])\n",
      "outraged\n",
      "Saved the embedding for outraged.\n",
      "['outspoken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5330,  0.0494, -0.2047,  ..., -0.3256, -0.2006, -0.9125])\n",
      "outspoken\n",
      "Saved the embedding for outspoken.\n",
      "['over', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0109,  0.3068,  0.6847,  ..., -1.1333, -0.5676,  0.4986])\n",
      "overbearing\n",
      "Saved the embedding for overbearing.\n",
      "['over', '##ex', '##cite', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2472, -0.1860, -0.2055,  ..., -0.4961, -0.3500, -0.3424])\n",
      "overexcited\n",
      "Saved the embedding for overexcited.\n",
      "['over', '##joy', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5493,  0.3607, -0.2470,  ..., -0.7846,  0.3300,  0.4227])\n",
      "overjoyed\n",
      "Saved the embedding for overjoyed.\n",
      "['overshadowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4003,  0.1526,  0.6969,  ..., -0.2794,  0.3650, -1.1133])\n",
      "overshadowed\n",
      "Saved the embedding for overshadowed.\n",
      "['overs', '##tr', '##ung'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0230, -1.1886,  1.0447,  ..., -0.5119, -1.1381, -0.5129])\n",
      "overstrung\n",
      "Saved the embedding for overstrung.\n",
      "['overwhelmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0185,  0.0597,  0.1749,  ..., -0.3842, -0.6743, -0.3280])\n",
      "overwhelmed\n",
      "Saved the embedding for overwhelmed.\n",
      "['over', '##work', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0250, -0.2406, -0.2826,  ..., -0.4806, -0.4536, -0.2267])\n",
      "overworked\n",
      "Saved the embedding for overworked.\n",
      "['over', '##wr', '##ough', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1036, -0.2064, -0.4567,  ..., -0.8556, -0.3739,  0.2347])\n",
      "overwrought\n",
      "Saved the embedding for overwrought.\n",
      "['pain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0064,  0.6387, -0.3941,  ..., -0.8150, -0.4051, -0.6195])\n",
      "pain\n",
      "Saved the embedding for pain.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1408, -0.0573, -0.7228,  ..., -0.5580,  0.1712, -0.4631])\n",
      "pained\n",
      "Saved the embedding for pained.\n",
      "['painful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1000, -0.0625,  0.1629,  ...,  0.1689, -0.6947,  0.0955])\n",
      "painful\n",
      "Saved the embedding for painful.\n",
      "['painfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2259,  0.1839,  1.0978,  ..., -0.4918, -0.0920, -0.9088])\n",
      "painfully\n",
      "Saved the embedding for painfully.\n",
      "['panic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3428,  0.4048, -0.3584,  ...,  0.0702, -1.0125,  0.5610])\n",
      "panic\n",
      "Saved the embedding for panic.\n",
      "['panicked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1056, -0.1386,  0.0266,  ...,  0.1332, -0.0201, -0.4966])\n",
      "panicked\n",
      "Saved the embedding for panicked.\n",
      "['panic', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0907,  0.3937, -0.5632,  ..., -0.9171, -1.0576,  0.6674])\n",
      "panicky\n",
      "Saved the embedding for panicky.\n",
      "['paralyzed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2572, -0.1058, -0.0088,  ..., -0.2216, -0.3887, -0.4253])\n",
      "paralyzed\n",
      "Saved the embedding for paralyzed.\n",
      "['paranoid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3099,  0.4134,  0.3121,  ...,  0.0651, -1.2205,  0.4046])\n",
      "paranoid\n",
      "Saved the embedding for paranoid.\n",
      "['passionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2642,  0.2183,  0.3543,  ..., -0.1585, -0.5553, -0.2460])\n",
      "passionate\n",
      "Saved the embedding for passionate.\n",
      "['passive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0855,  0.2642,  0.2414,  ..., -0.2988, -1.3928, -0.1997])\n",
      "passive\n",
      "Saved the embedding for passive.\n",
      "['patience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1744,  1.0911,  1.3593,  ..., -0.0387, -1.1532, -0.2477])\n",
      "patience\n",
      "Saved the embedding for patience.\n",
      "['patient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0681, -0.3348,  1.0322,  ..., -0.7443, -0.2735,  0.6304])\n",
      "patient\n",
      "Saved the embedding for patient.\n",
      "['patron', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2946,  0.1923,  1.5315,  ...,  0.8610, -0.2136, -0.4882])\n",
      "patronizing\n",
      "Saved the embedding for patronizing.\n",
      "['pause'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0297,  0.1672, -0.3443,  ..., -0.6635, -0.9338, -0.1820])\n",
      "pause\n",
      "Saved the embedding for pause.\n",
      "['pausing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3962,  0.3546, -0.8835,  ..., -0.6386, -0.0327, -0.0087])\n",
      "pausing\n",
      "Saved the embedding for pausing.\n",
      "['peaceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0596,  1.1553, -0.2846,  ..., -0.2513, -0.6150,  0.4124])\n",
      "peaceful\n",
      "Saved the embedding for peaceful.\n",
      "['peculiar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0900, -0.0213,  0.1799,  ..., -0.6899, -0.3367,  0.7267])\n",
      "peculiar\n",
      "Saved the embedding for peculiar.\n",
      "['peering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2767,  0.1094, -0.5833,  ..., -0.3094, -0.2691, -0.4378])\n",
      "peering\n",
      "Saved the embedding for peering.\n",
      "['pee', '##ved'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3043,  0.0266, -0.4694,  ..., -0.5687,  0.0127,  0.3279])\n",
      "peeved\n",
      "Saved the embedding for peeved.\n",
      "['pee', '##vish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6525, -0.1224, -0.2266,  ..., -0.6360, -0.1999,  0.5316])\n",
      "peevish\n",
      "Saved the embedding for peevish.\n",
      "['pens', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1526,  0.0571,  0.3994,  ...,  0.1542, -0.5233,  0.3937])\n",
      "pensive\n",
      "Saved the embedding for pensive.\n",
      "['pep', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7483, -0.1851,  0.5071,  ..., -0.3727, -0.9032,  0.2378])\n",
      "peppy\n",
      "Saved the embedding for peppy.\n",
      "['per', '##ceptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0060, -0.2711, -0.6054,  ...,  0.2040, -0.5411,  0.8847])\n",
      "perceptive\n",
      "Saved the embedding for perceptive.\n",
      "['per', '##fi', '##dio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0250, -0.3457, -0.5397,  ..., -0.6384, -0.0223,  0.0871])\n",
      "perfidious\n",
      "Saved the embedding for perfidious.\n",
      "['per', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3046, -0.0361, -0.5981,  ...,  0.1299, -0.3239, -0.0869])\n",
      "perky\n",
      "Saved the embedding for perky.\n",
      "['per', '##plex', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0026, -0.2247, -0.4463,  ..., -0.5254, -0.1242,  0.3730])\n",
      "perplexed\n",
      "Saved the embedding for perplexed.\n",
      "['per', '##plex', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1601, -0.1363, -0.2459,  ..., -0.3676, -0.0680,  0.5092])\n",
      "perplexing\n",
      "Saved the embedding for perplexing.\n",
      "['persistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1146,  0.5046,  1.3651,  ..., -1.2489, -0.3042, -0.2008])\n",
      "persistent\n",
      "Saved the embedding for persistent.\n",
      "['persona', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4499, -0.4585,  0.1847,  ..., -0.9454, -0.5678, -0.1959])\n",
      "personable\n",
      "Saved the embedding for personable.\n",
      "['per', '##tur', '##bed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2255, -0.1468, -0.3190,  ...,  0.3621, -0.2666,  0.4459])\n",
      "perturbed\n",
      "Saved the embedding for perturbed.\n",
      "['per', '##verse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1208, -0.1899, -0.6007,  ..., -0.8088, -0.5427,  0.5675])\n",
      "perverse\n",
      "Saved the embedding for perverse.\n",
      "['pe', '##sky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2916, -0.6501, -1.4536,  ..., -0.4631, -0.9348,  0.2158])\n",
      "pesky\n",
      "Saved the embedding for pesky.\n",
      "['pe', '##ssi', '##mism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5459, -0.3949, -0.9262,  ..., -0.4249, -0.0245,  0.4539])\n",
      "pessimism\n",
      "Saved the embedding for pessimism.\n",
      "['pe', '##ssi', '##mist', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0225, -0.6577, -0.8548,  ...,  0.2303,  0.3526,  0.4203])\n",
      "pessimistic\n",
      "Saved the embedding for pessimistic.\n",
      "['pest', '##ered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6975,  0.6075, -0.5120,  ..., -0.5025, -1.2126, -0.0651])\n",
      "pestered\n",
      "Saved the embedding for pestered.\n",
      "['petition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1406, -0.5857,  0.1339,  ..., -0.5621,  0.1263,  0.0985])\n",
      "petitioning\n",
      "Saved the embedding for petitioning.\n",
      "['pet', '##rified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5922, -0.4224,  0.1508,  ...,  0.7550,  0.2789, -0.4372])\n",
      "petrified\n",
      "Saved the embedding for petrified.\n",
      "['petty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0572,  0.3847, -0.3053,  ..., -0.3067, -1.1753, -0.2451])\n",
      "petty\n",
      "Saved the embedding for petty.\n",
      "['pet', '##ula', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2838, -0.4478,  0.3784,  ...,  0.2057,  0.1952, -0.1537])\n",
      "petulant\n",
      "Saved the embedding for petulant.\n",
      "['picked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4295, -0.0833, -0.5683,  ...,  1.0390,  0.2717, -0.3667])\n",
      "picked\n",
      "Saved the embedding for picked.\n",
      "['piercing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.0914,  0.0643, -0.0469,  ..., -0.2658, -0.7045, -0.0494])\n",
      "piercing\n",
      "Saved the embedding for piercing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pinched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1917,  0.4420, -0.9684,  ...,  0.2475, -0.3644, -0.1377])\n",
      "pinched\n",
      "Saved the embedding for pinched.\n",
      "['pious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2322, -0.0637,  0.9110,  ..., -0.1279, -1.1780, -0.0300])\n",
      "pious\n",
      "Saved the embedding for pious.\n",
      "['pi', '##que', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0327, -0.1452, -0.6025,  ..., -0.7176, -0.5692,  1.3150])\n",
      "piqued\n",
      "Saved the embedding for piqued.\n",
      "['pissed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0566,  0.2042,  0.9819,  ..., -0.1151, -0.7360,  0.1616])\n",
      "pissed\n",
      "Saved the embedding for pissed.\n",
      "['pit', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2229, -1.1339,  0.0533,  ..., -0.8407, -0.8072, -0.6487])\n",
      "pitiable\n",
      "Saved the embedding for pitiable.\n",
      "['pit', '##iful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2034, -1.1289,  0.4190,  ..., -0.3911, -0.0165,  0.4403])\n",
      "pitiful\n",
      "Saved the embedding for pitiful.\n",
      "['pity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2304,  1.2682,  0.7281,  ...,  0.6957, -0.1193, -0.3605])\n",
      "pity\n",
      "Saved the embedding for pity.\n",
      "['pity', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3741,  0.7607,  0.6366,  ...,  0.2116, -0.8493, -0.0471])\n",
      "pitying\n",
      "Saved the embedding for pitying.\n",
      "['pl', '##aca', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0813, -0.5497, -0.4779,  ..., -0.3106, -0.0481,  0.3362])\n",
      "placated\n",
      "Saved the embedding for placated.\n",
      "['pl', '##aca', '##tion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0774, -0.3850, -0.5669,  ..., -0.0512,  0.6927,  0.5606])\n",
      "placation\n",
      "Saved the embedding for placation.\n",
      "['pl', '##ac', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5490, -0.5479, -0.5803,  ..., -0.5307,  0.5074,  0.7377])\n",
      "placid\n",
      "Saved the embedding for placid.\n",
      "['plain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4594, -0.1901, -0.3838,  ...,  0.0307, -0.3869, -0.5812])\n",
      "plain\n",
      "Saved the embedding for plain.\n",
      "['plain', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1966, -0.1616,  0.6159,  ..., -1.1453, -1.3232, -0.7489])\n",
      "plaintive\n",
      "Saved the embedding for plaintive.\n",
      "['planning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2956,  0.3196,  0.1624,  ..., -0.9754, -0.4741,  0.1486])\n",
      "planning\n",
      "Saved the embedding for planning.\n",
      "['playful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8150,  0.3945, -0.0622,  ..., -0.3333,  0.5969, -0.5737])\n",
      "playful\n",
      "Saved the embedding for playful.\n",
      "['playfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9428, -0.1795,  0.0243,  ..., -0.9810,  0.0996, -0.1284])\n",
      "playfully\n",
      "Saved the embedding for playfully.\n",
      "['pleading'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4424, -0.1325,  0.0762,  ...,  0.4002,  0.6797, -0.1109])\n",
      "pleading\n",
      "Saved the embedding for pleading.\n",
      "['pleasant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0929,  0.5854,  0.3937,  ...,  0.4426, -0.1831, -0.1779])\n",
      "pleasant\n",
      "Saved the embedding for pleasant.\n",
      "['pleased'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6397,  0.5803, -0.2086,  ..., -0.2363, -0.6698,  0.6250])\n",
      "pleased\n",
      "Saved the embedding for pleased.\n",
      "['pleasing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4214,  0.4333,  0.3374,  ..., -0.7657, -0.6900,  0.1847])\n",
      "pleasing\n",
      "Saved the embedding for pleasing.\n",
      "['pleas', '##urable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3599,  0.5016,  0.0160,  ..., -0.8993,  0.8102, -0.4531])\n",
      "pleasurable\n",
      "Saved the embedding for pleasurable.\n",
      "['pleasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5599,  0.5052, -0.2346,  ..., -0.2610,  0.8395,  0.0277])\n",
      "pleasure\n",
      "Saved the embedding for pleasure.\n",
      "['pleasure', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3067,  0.4071,  0.0242,  ..., -0.3999,  0.9054,  0.2032])\n",
      "pleasured\n",
      "Saved the embedding for pleasured.\n",
      "['pl', '##ian', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1345, -0.0887, -0.4956,  ..., -0.4079,  0.6856,  0.6507])\n",
      "pliant\n",
      "Saved the embedding for pliant.\n",
      "['plotting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3858,  0.7948,  0.3257,  ..., -0.4240, -0.0677, -0.8054])\n",
      "plotting\n",
      "Saved the embedding for plotting.\n",
      "['po', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8285,  0.2257, -0.4064,  ..., -1.0182, -0.5676,  0.8825])\n",
      "poignant\n",
      "Saved the embedding for poignant.\n",
      "['pointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1205,  0.0785, -0.1046,  ..., -0.6535, -0.7063,  0.2832])\n",
      "pointed\n",
      "Saved the embedding for pointed.\n",
      "['poised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5177,  0.2101,  1.0178,  ..., -0.3310, -0.5331, -0.0974])\n",
      "poised\n",
      "Saved the embedding for poised.\n",
      "['polite'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5383,  0.5043, -0.1902,  ..., -0.7580,  0.1029,  0.6897])\n",
      "polite\n",
      "Saved the embedding for polite.\n",
      "['po', '##mp', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3801,  0.5175, -0.0732,  ..., -1.0156, -0.2172,  0.9574])\n",
      "pompous\n",
      "Saved the embedding for pompous.\n",
      "['ponder'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8097,  0.3733,  0.2128,  ..., -0.9536, -1.2356,  0.4950])\n",
      "ponder\n",
      "Saved the embedding for ponder.\n",
      "['ponder', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7760,  0.7555,  0.4682,  ..., -0.6601, -0.8257,  0.6192])\n",
      "pondering\n",
      "Saved the embedding for pondering.\n",
      "['po', '##oping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3284,  0.2263, -0.7614,  ..., -1.2839, -1.2422,  0.3711])\n",
      "pooping\n",
      "Saved the embedding for pooping.\n",
      "['pop'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1300, -0.0608,  0.0426,  ..., -0.1338,  0.4713,  0.3286])\n",
      "pop\n",
      "Saved the embedding for pop.\n",
      "['posing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0561,  0.2835,  0.0708,  ..., -0.6823, -0.6355,  0.1296])\n",
      "posing\n",
      "Saved the embedding for posing.\n",
      "['positive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1142,  0.8610,  0.1612,  ..., -0.6185, -1.3185,  0.7150])\n",
      "positive\n",
      "Saved the embedding for positive.\n",
      "['po', '##sit', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2416,  0.5992, -0.4586,  ..., -1.4839, -1.0764,  0.8331])\n",
      "positivity\n",
      "Saved the embedding for positivity.\n",
      "['possibly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3305,  0.2292, -0.0494,  ..., -1.2587, -1.0422, -0.0698])\n",
      "possibly\n",
      "Saved the embedding for possibly.\n",
      "['po', '##ut'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8056,  0.3732, -0.6279,  ..., -1.3218, -0.9646,  1.3669])\n",
      "pout\n",
      "Saved the embedding for pout.\n",
      "['po', '##uting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6487,  0.4467, -0.4313,  ..., -1.3670, -1.0866,  1.3953])\n",
      "pouting\n",
      "Saved the embedding for pouting.\n",
      "['po', '##ut', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7805,  0.4606, -0.7178,  ..., -0.6752, -0.9596,  0.8733])\n",
      "pouty\n",
      "Saved the embedding for pouty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['powerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2738,  0.1499,  0.3632,  ..., -0.2916, -0.2934, -0.0113])\n",
      "powerful\n",
      "Saved the embedding for powerful.\n",
      "['powerless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1958, -0.0694,  0.2071,  ..., -0.8406, -1.2324, -0.8519])\n",
      "powerless\n",
      "Saved the embedding for powerless.\n",
      "['prank', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3485, -0.4001, -0.5206,  ..., -0.6240, -1.0012,  0.4618])\n",
      "pranking\n",
      "Saved the embedding for pranking.\n",
      "['pre', '##car', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4103,  0.2443, -0.2399,  ..., -0.5389, -0.7691,  0.3849])\n",
      "precarious\n",
      "Saved the embedding for precarious.\n",
      "['predatory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3917,  0.2845, -0.1428,  ...,  0.9762,  0.3138, -0.0302])\n",
      "predatory\n",
      "Saved the embedding for predatory.\n",
      "['prejudice', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2106,  0.7043, -0.3834,  ..., -0.7624, -0.6543,  0.1333])\n",
      "prejudiced\n",
      "Saved the embedding for prejudiced.\n",
      "['preoccupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-3.1069e-02,  7.6771e-05, -6.9230e-01,  ...,  2.4071e-01,\n",
      "         1.2960e-01,  1.8697e-01])\n",
      "preoccupied\n",
      "Saved the embedding for preoccupied.\n",
      "['prepared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2776, -0.2758,  0.0984,  ..., -0.7499, -1.4153,  0.1264])\n",
      "prepared\n",
      "Saved the embedding for prepared.\n",
      "['preparing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0679,  0.2514,  0.2339,  ..., -0.5893, -0.6467,  0.2031])\n",
      "preparing\n",
      "Saved the embedding for preparing.\n",
      "['pretending'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2311,  0.6489, -0.0246,  ..., -0.0948,  0.0340, -0.6738])\n",
      "pretending\n",
      "Saved the embedding for pretending.\n",
      "['pre', '##ten', '##tious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5210, -0.5265, -0.0618,  ..., -0.3425, -0.0016, -0.1062])\n",
      "pretentious\n",
      "Saved the embedding for pretentious.\n",
      "['pride', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0062,  0.8080, -0.0667,  ..., -0.6333, -1.5388,  0.2819])\n",
      "prideful\n",
      "Saved the embedding for prideful.\n",
      "['pri', '##gg', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0171, -0.4264, -0.8209,  ..., -0.4908,  0.0723,  1.1475])\n",
      "priggish\n",
      "Saved the embedding for priggish.\n",
      "['prime', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2929,  0.4650,  0.6849,  ..., -0.4628,  0.4525,  1.0510])\n",
      "primed\n",
      "Saved the embedding for primed.\n",
      "['private'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1885,  0.0467, -0.5147,  ...,  0.1435, -0.1821,  0.6442])\n",
      "private\n",
      "Saved the embedding for private.\n",
      "['processing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3900,  0.6329, -0.2891,  ...,  0.0654,  0.2673,  0.2767])\n",
      "processing\n",
      "Saved the embedding for processing.\n",
      "['proposition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4208,  0.4612,  0.5776,  ..., -0.1938, -0.2929,  0.9267])\n",
      "propositioning\n",
      "Saved the embedding for propositioning.\n",
      "['proud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6018, -0.2137,  0.9503,  ..., -0.6139, -0.9058, -0.2226])\n",
      "proud\n",
      "Saved the embedding for proud.\n",
      "['provocative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1612,  0.1032,  0.1644,  ..., -0.7355, -0.4268, -0.5505])\n",
      "provocative\n",
      "Saved the embedding for provocative.\n",
      "['provoke'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0136, -0.0259,  0.3733,  ...,  0.6003, -0.4485,  0.1681])\n",
      "provoke\n",
      "Saved the embedding for provoke.\n",
      "['provoked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3023, -0.1718,  0.3198,  ...,  0.0567, -0.2980, -0.6654])\n",
      "provoked\n",
      "Saved the embedding for provoked.\n",
      "['pro', '##voking'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0143, -0.3007, -0.7276,  ..., -0.1102, -0.0644, -0.5224])\n",
      "provoking\n",
      "Saved the embedding for provoking.\n",
      "['pry', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5366,  0.0937, -0.5933,  ..., -0.4205, -0.9857, -0.2934])\n",
      "prying\n",
      "Saved the embedding for prying.\n",
      "['psycho'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0831,  0.5634,  0.4781,  ..., -0.5632, -0.3895,  0.3325])\n",
      "psycho\n",
      "Saved the embedding for psycho.\n",
      "['psychotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2527,  0.7485,  0.5800,  ..., -0.6448, -0.3618, -1.2794])\n",
      "psychotic\n",
      "Saved the embedding for psychotic.\n",
      "['puck', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2607, -0.4170, -0.2030,  ..., -0.7476, -0.7489, -0.0255])\n",
      "puckish\n",
      "Saved the embedding for puckish.\n",
      "['pu', '##eri', '##le'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2236, -0.0375,  0.7123,  ..., -1.3111, -0.6965,  0.2166])\n",
      "puerile\n",
      "Saved the embedding for puerile.\n",
      "['pu', '##gna', '##cious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3847, -0.5711,  0.5260,  ..., -1.0482, -0.1836,  0.5265])\n",
      "pugnacious\n",
      "Saved the embedding for pugnacious.\n",
      "['punished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2475,  0.6840,  0.1152,  ...,  0.9375,  0.6791, -0.2219])\n",
      "punished\n",
      "Saved the embedding for punished.\n",
      "['punish', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2112,  0.6964, -0.0470,  ..., -0.6567, -0.1718,  0.6707])\n",
      "punishing\n",
      "Saved the embedding for punishing.\n",
      "['pun', '##itive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6028, -0.0428, -0.0370,  ..., -1.0383, -1.7749,  0.3138])\n",
      "punitive\n",
      "Saved the embedding for punitive.\n",
      "['punk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3829,  0.7505, -0.1211,  ...,  0.1249, -0.5998, -0.6217])\n",
      "punk\n",
      "Saved the embedding for punk.\n",
      "['puppy', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0051,  0.0069, -0.8251,  ...,  0.1539, -0.2801, -0.0353])\n",
      "puppyish\n",
      "Saved the embedding for puppyish.\n",
      "['purpose', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1210,  0.5242,  0.1173,  ...,  0.3010,  0.1219, -0.3637])\n",
      "purposeful\n",
      "Saved the embedding for purposeful.\n",
      "['pursed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3630,  0.6411, -0.2699,  ..., -0.6317, -0.0518, -0.5231])\n",
      "pursed\n",
      "Saved the embedding for pursed.\n",
      "['put'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2436, -0.4704, -0.2022,  ...,  0.9176,  0.1554, -0.2225])\n",
      "put\n",
      "Saved the embedding for put.\n",
      "['putting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5311, -0.1699,  0.1942,  ...,  0.6974, -0.3471, -0.3985])\n",
      "putting\n",
      "Saved the embedding for putting.\n",
      "['puzzled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1897,  0.3126,  0.1088,  ...,  0.5322, -0.2038,  0.0364])\n",
      "puzzled\n",
      "Saved the embedding for puzzled.\n",
      "['puzzle', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0408, -0.5155, -0.2885,  ..., -0.1491,  0.2633,  0.5223])\n",
      "puzzlement\n",
      "Saved the embedding for puzzlement.\n",
      "['qu', '##al', '##ms'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6044, -0.2377,  0.1644,  ...,  0.0603,  0.0565,  0.0681])\n",
      "qualms\n",
      "Saved the embedding for qualms.\n",
      "['quarrel', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1611,  0.0092,  0.6413,  ..., -0.6614, -0.2559, -0.1571])\n",
      "quarrelsome\n",
      "Saved the embedding for quarrelsome.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['que', '##as', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3352,  0.7063,  0.4106,  ..., -0.3011, -1.2740,  0.4996])\n",
      "queasy\n",
      "Saved the embedding for queasy.\n",
      "['que', '##nched'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3224, -0.1415, -0.2204,  ..., -0.0678, -0.9388,  0.6537])\n",
      "quenched\n",
      "Saved the embedding for quenched.\n",
      "['questionable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3475,  0.3021, -0.8337,  ..., -0.2981, -0.7257,  0.0645])\n",
      "questionable\n",
      "Saved the embedding for questionable.\n",
      "['questioning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2904, -0.2818, -0.8300,  ..., -0.8781,  0.1882, -0.8806])\n",
      "questioning\n",
      "Saved the embedding for questioning.\n",
      "['questioning', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2076,  0.1097, -0.4106,  ..., -0.1952, -0.1543, -0.3169])\n",
      "questioningly\n",
      "Saved the embedding for questioningly.\n",
      "['quiet'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2192,  0.0727, -0.2329,  ..., -0.0702,  0.7330,  0.1304])\n",
      "quiet\n",
      "Saved the embedding for quiet.\n",
      "['quiet', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2560,  0.0546,  0.0550,  ...,  0.2019,  0.3519, -0.0264])\n",
      "quietness\n",
      "Saved the embedding for quietness.\n",
      "['quilt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5910,  0.1467, -0.0656,  ..., -0.1184, -0.4922,  0.2392])\n",
      "quilt\n",
      "Saved the embedding for quilt.\n",
      "['qui', '##rky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1406, -0.6494, -0.4388,  ..., -1.2970, -0.3254,  0.2176])\n",
      "quirky\n",
      "Saved the embedding for quirky.\n",
      "['quiz', '##zic', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4011, -0.7985,  0.1432,  ...,  0.1451, -0.4363, -0.1966])\n",
      "quizzical\n",
      "Saved the embedding for quizzical.\n",
      "['ra', '##bid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7672, -0.4008,  0.7571,  ..., -1.5804, -0.7358, -0.1427])\n",
      "rabid\n",
      "Saved the embedding for rabid.\n",
      "['rack', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5988, -0.6513, -0.7073,  ..., -0.5189, -0.3907, -0.5810])\n",
      "racked\n",
      "Saved the embedding for racked.\n",
      "['radiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4298,  0.0567,  0.0119,  ...,  0.2009, -0.3408,  0.2765])\n",
      "radiant\n",
      "Saved the embedding for radiant.\n",
      "['rage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3241,  0.7523,  0.4507,  ..., -0.2959, -0.4856, -0.1302])\n",
      "rage\n",
      "Saved the embedding for rage.\n",
      "['raged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2095,  0.0717,  0.2595,  ..., -0.3915, -0.2003,  0.3011])\n",
      "raged\n",
      "Saved the embedding for raged.\n",
      "['ragged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1872, -0.0211, -0.1298,  ..., -0.5032, -0.6134,  0.1498])\n",
      "ragged\n",
      "Saved the embedding for ragged.\n",
      "['raging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0225,  0.7689,  0.0091,  ..., -0.3450,  0.5383, -0.2151])\n",
      "raging\n",
      "Saved the embedding for raging.\n",
      "['ran', '##cor', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0828, -0.2945,  0.1214,  ..., -0.4027, -0.1181,  0.0470])\n",
      "rancorous\n",
      "Saved the embedding for rancorous.\n",
      "['randy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1534, -0.3719, -0.2188,  ..., -0.4724, -0.6383,  0.0199])\n",
      "randy\n",
      "Saved the embedding for randy.\n",
      "['rap', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5664,  0.4464,  0.0646,  ...,  0.9017, -0.3976,  0.4190])\n",
      "rapt\n",
      "Saved the embedding for rapt.\n",
      "['rattled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1181,  0.2848,  0.0514,  ..., -1.3174, -0.6683,  0.2621])\n",
      "rattled\n",
      "Saved the embedding for rattled.\n",
      "['ravi', '##ng'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.4173, 0.7710, 0.2468,  ..., 0.3689, 0.0478, 0.5894])\n",
      "raving\n",
      "Saved the embedding for raving.\n",
      "['reactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5913,  1.2853, -0.1127,  ..., -0.4219, -1.3025, -0.3163])\n",
      "reactive\n",
      "Saved the embedding for reactive.\n",
      "['ready'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0578,  0.3006,  0.2292,  ..., -0.4059, -1.0505, -0.2612])\n",
      "ready\n",
      "Saved the embedding for ready.\n",
      "['realization'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 8.4188e-01,  4.7465e-01, -3.2038e-01,  ..., -1.5595e+00,\n",
      "         3.2586e-01,  5.2311e-04])\n",
      "realization\n",
      "Saved the embedding for realization.\n",
      "['reassured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4154,  0.1781, -0.2156,  ...,  0.8033,  0.2477, -0.1724])\n",
      "reassured\n",
      "Saved the embedding for reassured.\n",
      "['rebellious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2963,  0.6399,  0.4615,  ..., -0.2853, -1.3605, -0.4815])\n",
      "rebellious\n",
      "Saved the embedding for rebellious.\n",
      "['re', '##bu', '##ke'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3046, -0.9193, -0.1783,  ..., -0.9219, -0.4920,  0.3052])\n",
      "rebuke\n",
      "Saved the embedding for rebuke.\n",
      "['recalling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1856,  0.6375,  0.4375,  ..., -0.0126,  0.1432, -0.2240])\n",
      "recalling\n",
      "Saved the embedding for recalling.\n",
      "['rec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0310,  0.3299,  0.2839,  ..., -0.7959, -0.1840, -0.4926])\n",
      "receptive\n",
      "Saved the embedding for receptive.\n",
      "['reckless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2486,  0.2396, -0.0108,  ..., -0.9395, -0.7333, -0.2631])\n",
      "reckless\n",
      "Saved the embedding for reckless.\n",
      "['recoil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0905,  0.6753, -1.0834,  ..., -0.5895,  0.2048, -0.3752])\n",
      "recoil\n",
      "Saved the embedding for recoil.\n",
      "['recoil', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2374,  0.8165, -0.8245,  ..., -1.0042, -0.0465, -1.2805])\n",
      "recoiling\n",
      "Saved the embedding for recoiling.\n",
      "['reflecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3889,  0.2219, -0.3799,  ..., -0.5784,  0.0611,  0.1382])\n",
      "reflecting\n",
      "Saved the embedding for reflecting.\n",
      "['reflection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8423,  0.3086,  0.7738,  ..., -0.3156, -0.3944, -0.2562])\n",
      "reflection\n",
      "Saved the embedding for reflection.\n",
      "['reflective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7967,  0.3966,  0.5175,  ...,  0.3003, -0.7207, -0.3139])\n",
      "reflective\n",
      "Saved the embedding for reflective.\n",
      "['ref', '##ul', '##gent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0998,  0.2822, -0.6139,  ..., -1.2969, -0.0443,  0.6163])\n",
      "refulgent\n",
      "Saved the embedding for refulgent.\n",
      "['refusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1430, -0.0296, -0.1924,  ...,  0.5067, -0.1715, -0.2468])\n",
      "refusing\n",
      "Saved the embedding for refusing.\n",
      "['regret'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1054,  0.1053, -0.1548,  ..., -0.1182,  0.3022, -0.9416])\n",
      "regret\n",
      "Saved the embedding for regret.\n",
      "['regret', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3468,  0.1471,  0.0213,  ..., -0.4981, -0.0588, -0.5064])\n",
      "regretful\n",
      "Saved the embedding for regretful.\n",
      "['rejected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1789, -0.0935,  0.3109,  ..., -0.0920, -0.5543, -0.7212])\n",
      "rejected\n",
      "Saved the embedding for rejected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rejecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1185, -0.0544,  0.4597,  ..., -1.1933, -0.6023, -0.3045])\n",
      "rejecting\n",
      "Saved the embedding for rejecting.\n",
      "['rejection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4581,  0.2062,  0.7343,  ..., -0.4371, -1.4314, -0.7342])\n",
      "rejection\n",
      "Saved the embedding for rejection.\n",
      "['re', '##jo', '##icing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3760, -0.1161, -0.1103,  ..., -0.7016,  0.0017,  0.7511])\n",
      "rejoicing\n",
      "Saved the embedding for rejoicing.\n",
      "['relaxation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0997,  0.6427, -0.2189,  ...,  0.7120, -0.2075,  0.3611])\n",
      "relaxation\n",
      "Saved the embedding for relaxation.\n",
      "['relaxed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2606, -0.0365, -0.8659,  ..., -0.0367,  0.0330,  0.6860])\n",
      "relaxed\n",
      "Saved the embedding for relaxed.\n",
      "['relentless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0176, -0.0148,  0.9881,  ..., -0.6197, -0.0933, -0.0508])\n",
      "relentless\n",
      "Saved the embedding for relentless.\n",
      "['relief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0451,  0.5323,  0.6641,  ...,  0.5769, -0.5803,  0.3920])\n",
      "relief\n",
      "Saved the embedding for relief.\n",
      "['relieved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6518,  0.5278,  0.0088,  ...,  0.7935, -1.1445, -0.2785])\n",
      "relieved\n",
      "Saved the embedding for relieved.\n",
      "['re', '##li', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2504, -0.6437, -0.4416,  ..., -0.7396,  0.5346,  0.3122])\n",
      "relived\n",
      "Saved the embedding for relived.\n",
      "['reluctant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8717,  0.2943,  0.4062,  ...,  0.4467,  0.2710, -0.6138])\n",
      "reluctant\n",
      "Saved the embedding for reluctant.\n",
      "['reluctantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8466,  0.0929,  0.2631,  ...,  0.9846, -0.0379,  0.0198])\n",
      "reluctantly\n",
      "Saved the embedding for reluctantly.\n",
      "['remorse'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3034,  0.1471,  0.6949,  ...,  0.0675, -0.8626, -0.9233])\n",
      "remorse\n",
      "Saved the embedding for remorse.\n",
      "['remorse', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0336,  0.0510,  0.2161,  ..., -0.5058, -0.4890, -0.6722])\n",
      "remorseful\n",
      "Saved the embedding for remorseful.\n",
      "['rep', '##elled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1146, -0.2231,  0.1111,  ..., -0.7488, -0.4086, -0.2537])\n",
      "repelled\n",
      "Saved the embedding for repelled.\n",
      "['rep', '##ressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4770, -0.3512,  0.0246,  ..., -0.7080,  0.0399, -0.0840])\n",
      "repressed\n",
      "Saved the embedding for repressed.\n",
      "['rep', '##ro', '##ach'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0939,  0.3633, -0.0585,  ...,  0.2752, -0.3832, -0.1142])\n",
      "reproach\n",
      "Saved the embedding for reproach.\n",
      "['rep', '##ro', '##ach', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1638,  0.5242,  0.0526,  ..., -0.3302, -0.1018,  0.2531])\n",
      "reproachful\n",
      "Saved the embedding for reproachful.\n",
      "['rep', '##ug', '##nan', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0916, -0.1097,  0.0492,  ..., -0.1988, -0.3522,  0.9310])\n",
      "repugnance\n",
      "Saved the embedding for repugnance.\n",
      "['rep', '##ug', '##nant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3078, -0.1420,  0.0498,  ..., -0.3834, -0.4331,  0.6522])\n",
      "repugnant\n",
      "Saved the embedding for repugnant.\n",
      "['repulsed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2516,  0.6708, -0.7518,  ...,  1.1813, -0.7132,  0.4022])\n",
      "repulsed\n",
      "Saved the embedding for repulsed.\n",
      "['rep', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2003,  0.0337,  0.0652,  ..., -0.8686, -1.0668,  0.3693])\n",
      "repulsion\n",
      "Saved the embedding for repulsion.\n",
      "['res', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4777, -0.2119, -0.0037,  ..., -1.2873, -0.7727,  0.6738])\n",
      "resent\n",
      "Saved the embedding for resent.\n",
      "['res', '##ent', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7517,  0.2204,  0.4910,  ..., -1.5362, -0.7078,  0.2560])\n",
      "resentful\n",
      "Saved the embedding for resentful.\n",
      "['res', '##enting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8889,  0.2551,  0.3527,  ..., -0.4245, -0.8719,  0.0370])\n",
      "resenting\n",
      "Saved the embedding for resenting.\n",
      "['resentment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1959,  0.0410,  0.4014,  ...,  0.7416, -0.8737, -0.4472])\n",
      "resentment\n",
      "Saved the embedding for resentment.\n",
      "['reserved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4685,  0.0357, -0.3632,  ..., -0.1613, -0.6847, -0.0752])\n",
      "reserved\n",
      "Saved the embedding for reserved.\n",
      "['resignation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6261, -0.3086,  0.2484,  ...,  0.3611, -0.7800, -0.1749])\n",
      "resignation\n",
      "Saved the embedding for resignation.\n",
      "['resigned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2311, -0.3341, -0.1326,  ...,  0.8561, -0.3020,  0.0068])\n",
      "resigned\n",
      "Saved the embedding for resigned.\n",
      "['res', '##ili', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7641,  0.2537, -0.6104,  ..., -0.6677, -0.6163,  0.4459])\n",
      "resilience\n",
      "Saved the embedding for resilience.\n",
      "['resistance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0089,  0.9941,  0.4235,  ..., -1.1768, -0.9460,  0.1112])\n",
      "resistance\n",
      "Saved the embedding for resistance.\n",
      "['resistant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5298,  0.0058, -0.2167,  ..., -0.2018, -0.2148, -0.8191])\n",
      "resistant\n",
      "Saved the embedding for resistant.\n",
      "['resist', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3985,  1.0561,  0.0770,  ..., -0.4248, -1.3106, -0.2307])\n",
      "resistent\n",
      "Saved the embedding for resistent.\n",
      "['resisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3844,  0.0610,  0.0987,  ..., -0.0699, -0.7974, -0.1675])\n",
      "resisting\n",
      "Saved the embedding for resisting.\n",
      "['res', '##ol', '##ute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5590,  0.5328, -1.0313,  ...,  0.3315,  0.6808, -0.0400])\n",
      "resolute\n",
      "Saved the embedding for resolute.\n",
      "['resolved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0990,  0.0575, -0.4849,  ..., -0.3743,  0.0158, -0.7959])\n",
      "resolved\n",
      "Saved the embedding for resolved.\n",
      "['responsive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3400,  0.2283,  0.6506,  ...,  0.4275, -0.5042, -0.0281])\n",
      "responsive\n",
      "Saved the embedding for responsive.\n",
      "['rest', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5257, -0.0139, -0.5685,  ..., -1.4550,  0.3541,  0.2533])\n",
      "restful\n",
      "Saved the embedding for restful.\n",
      "['resting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2553,  0.2035,  0.2298,  ..., -0.4495, -0.9741, -0.1214])\n",
      "resting\n",
      "Saved the embedding for resting.\n",
      "['restless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1358,  0.2609,  0.2580,  ..., -0.3153, -0.3436,  0.0394])\n",
      "restless\n",
      "Saved the embedding for restless.\n",
      "['restless', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3074,  0.2218,  0.5041,  ..., -0.6917, -0.9146,  0.1633])\n",
      "restlessness\n",
      "Saved the embedding for restlessness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['restrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2817,  0.0823, -1.0393,  ...,  0.5340, -0.4884, -0.2083])\n",
      "restrained\n",
      "Saved the embedding for restrained.\n",
      "['restraint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0465,  0.0752, -0.5417,  ..., -0.2845, -0.1667,  0.6699])\n",
      "restraint\n",
      "Saved the embedding for restraint.\n",
      "['re', '##tal', '##iating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2190, -0.1833,  0.1695,  ..., -1.1697, -0.4748,  0.5674])\n",
      "retaliating\n",
      "Saved the embedding for retaliating.\n",
      "['re', '##tal', '##ia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3747, -0.7415, -0.4554,  ..., -0.5400, -0.2639,  0.7654])\n",
      "retaliatory\n",
      "Saved the embedding for retaliatory.\n",
      "['re', '##thi', '##nk', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.8047, -0.5670, -0.5228,  ..., -0.9315, -0.3610,  0.1427])\n",
      "rethinking\n",
      "Saved the embedding for rethinking.\n",
      "['re', '##tic', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6870, -0.5241, -0.5371,  ..., -0.5986, -0.8030,  0.5555])\n",
      "reticence\n",
      "Saved the embedding for reticence.\n",
      "['re', '##tic', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5080, -0.8193,  0.3988,  ..., -1.0543, -0.4944,  0.2295])\n",
      "reticent\n",
      "Saved the embedding for reticent.\n",
      "['revenge', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2174,  0.5589,  0.5274,  ..., -0.6543, -1.2490,  0.3142])\n",
      "revengeful\n",
      "Saved the embedding for revengeful.\n",
      "['rev', '##ere', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3453,  0.7910,  0.5104,  ..., -0.4076,  0.1633,  0.0080])\n",
      "reverent\n",
      "Saved the embedding for reverent.\n",
      "['revolt', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1835,  0.6141,  0.1011,  ..., -0.5078, -1.6201, -0.2207])\n",
      "revolted\n",
      "Saved the embedding for revolted.\n",
      "['rev', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3475,  0.3956, -0.0323,  ..., -0.4283,  0.7019,  0.4134])\n",
      "revulsion\n",
      "Saved the embedding for revulsion.\n",
      "['righteous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1986,  0.8749, -0.2457,  ...,  1.1395, -0.2299,  0.2600])\n",
      "righteous\n",
      "Saved the embedding for righteous.\n",
      "['rigid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4425,  0.0147,  0.8578,  ..., -0.1084, -0.5239,  0.5185])\n",
      "rigid\n",
      "Saved the embedding for rigid.\n",
      "['ri', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3178,  0.3686, -0.0538,  ..., -0.8276, -0.9979,  0.4811])\n",
      "riled\n",
      "Saved the embedding for riled.\n",
      "['riot', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7689,  0.2789,  0.0684,  ..., -0.7492, -0.3346,  0.7354])\n",
      "riotous\n",
      "Saved the embedding for riotous.\n",
      "['ri', '##vet', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0145,  0.0974, -0.4052,  ..., -0.8906, -0.6592, -0.0314])\n",
      "riveted\n",
      "Saved the embedding for riveted.\n",
      "['roar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5454,  0.1619, -0.2326,  ..., -0.2518, -0.0339,  0.3825])\n",
      "roar\n",
      "Saved the embedding for roar.\n",
      "['ro', '##gui', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0206, -0.1622, -0.2423,  ..., -1.3724, -0.8792,  0.3917])\n",
      "roguish\n",
      "Saved the embedding for roguish.\n",
      "['roi', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7280,  0.5498, -0.0785,  ..., -0.6412, -0.1078,  0.5758])\n",
      "roiled\n",
      "Saved the embedding for roiled.\n",
      "['rough'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1843,  0.3259,  0.3207,  ..., -0.5982, -0.7118,  0.0361])\n",
      "rough\n",
      "Saved the embedding for rough.\n",
      "['rouse', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3365,  0.0444,  0.1858,  ...,  0.0210,  0.1868, -0.5262])\n",
      "roused\n",
      "Saved the embedding for roused.\n",
      "['rude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4385,  0.6330,  0.1496,  ..., -0.0336, -0.6475,  0.0543])\n",
      "rude\n",
      "Saved the embedding for rude.\n",
      "['rue', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6799,  0.4935, -0.4586,  ..., -0.2315, -0.1739, -1.7298])\n",
      "rueful\n",
      "Saved the embedding for rueful.\n",
      "['ru', '##ffled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5301, -0.8001, -0.3512,  ..., -0.6472, -0.9526, -0.0491])\n",
      "ruffled\n",
      "Saved the embedding for ruffled.\n",
      "['rum', '##inating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2926, -0.0453, -0.0069,  ...,  0.3124, -0.1667,  0.3705])\n",
      "ruminating\n",
      "Saved the embedding for ruminating.\n",
      "['rust', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0025,  0.3429,  0.1818,  ..., -1.1061, -1.3233, -0.4370])\n",
      "rustled\n",
      "Saved the embedding for rustled.\n",
      "['ruthless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0544,  0.2912,  0.9876,  ...,  0.3130,  0.4122, -0.9174])\n",
      "ruthless\n",
      "Saved the embedding for ruthless.\n",
      "['sad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4184,  0.6986,  0.1776,  ..., -0.6074, -0.4293,  0.1924])\n",
      "sad\n",
      "Saved the embedding for sad.\n",
      "['sad', '##den'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1725,  0.5593, -0.3221,  ..., -0.8582, -0.1129,  0.3067])\n",
      "sadden\n",
      "Saved the embedding for sadden.\n",
      "['sad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0194,  0.3835,  0.2613,  ..., -0.1963, -0.9440, -0.0279])\n",
      "saddened\n",
      "Saved the embedding for saddened.\n",
      "['sad', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2714,  0.0221,  0.1927,  ...,  0.0158, -0.3370,  0.2500])\n",
      "sadistic\n",
      "Saved the embedding for sadistic.\n",
      "['sadness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1950,  0.6940,  0.2470,  ...,  0.7337, -0.2107, -0.9925])\n",
      "sadness\n",
      "Saved the embedding for sadness.\n",
      "['sal', '##acious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2961, -0.1507,  0.3669,  ..., -1.8144, -1.4205,  0.5698])\n",
      "salacious\n",
      "Saved the embedding for salacious.\n",
      "['saliva', '##ting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8027,  0.2550,  0.1596,  ..., -1.5259, -1.1747,  0.0809])\n",
      "salivating\n",
      "Saved the embedding for salivating.\n",
      "['san', '##ct', '##imo', '##nio', '##us'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.9339,  0.7061,  0.2047,  ...,  0.3846,  0.0571,  0.4973])\n",
      "sanctimonious\n",
      "Saved the embedding for sanctimonious.\n",
      "['sane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2039,  0.8656,  0.9257,  ..., -0.1515, -0.8834, -0.8061])\n",
      "sane\n",
      "Saved the embedding for sane.\n",
      "['sang', '##uin', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2776, -0.8752, -0.5586,  ...,  0.6329,  0.6105,  0.5778])\n",
      "sanguine\n",
      "Saved the embedding for sanguine.\n",
      "['sap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8050,  0.1305, -0.3171,  ..., -0.4897, -0.3702, -0.7159])\n",
      "sappy\n",
      "Saved the embedding for sappy.\n",
      "['sarcasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1544,  0.2469, -0.4014,  ..., -0.5398, -0.7978, -0.2104])\n",
      "sarcasm\n",
      "Saved the embedding for sarcasm.\n",
      "['sarcastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6995,  0.0959, -0.0350,  ...,  0.2626, -0.9103, -0.0846])\n",
      "sarcastic\n",
      "Saved the embedding for sarcastic.\n",
      "['sar', '##don', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2854,  0.2778, -0.1732,  ..., -0.1811, -0.5375,  0.1608])\n",
      "sardonic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for sardonic.\n",
      "['sas', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0438,  0.1940, -0.1508,  ..., -0.4937, -0.2421,  0.0228])\n",
      "sassy\n",
      "Saved the embedding for sassy.\n",
      "['sat', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0456, -0.4159, -0.0143,  ..., -1.1127, -0.2302, -0.1753])\n",
      "sated\n",
      "Saved the embedding for sated.\n",
      "['sat', '##iated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1335, -0.1739,  0.1618,  ..., -1.2501,  0.3649, -0.3027])\n",
      "satiated\n",
      "Saved the embedding for satiated.\n",
      "['satirical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4114, -0.5536, -0.0288,  ...,  0.1422,  1.0783, -1.1552])\n",
      "satirical\n",
      "Saved the embedding for satirical.\n",
      "['satisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8650,  0.5797,  0.9009,  ..., -0.2483,  0.0111, -0.7514])\n",
      "satisfaction\n",
      "Saved the embedding for satisfaction.\n",
      "['satisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2703,  1.2270,  0.0906,  ..., -0.1777, -0.1685,  1.5842])\n",
      "satisfied\n",
      "Saved the embedding for satisfied.\n",
      "['satisfy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2839,  1.1281,  0.4639,  ..., -0.4778, -0.1904,  1.1529])\n",
      "satisfy\n",
      "Saved the embedding for satisfy.\n",
      "['saturn', '##ine'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5878,  0.8520, -0.1552,  ...,  0.5511,  1.3734, -1.0919])\n",
      "saturnine\n",
      "Saved the embedding for saturnine.\n",
      "['sa', '##uc', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2117, -0.0723, -0.2587,  ..., -0.5706, -0.7388,  0.4104])\n",
      "saucy\n",
      "Saved the embedding for saucy.\n",
      "['savage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5759,  0.7648,  0.3457,  ..., -1.6133, -0.6795, -0.5720])\n",
      "savage\n",
      "Saved the embedding for savage.\n",
      "['scandal', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3697, -0.3168,  0.2536,  ..., -0.7760, -0.5551, -0.2160])\n",
      "scandalized\n",
      "Saved the embedding for scandalized.\n",
      "['scare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1531,  0.0281,  0.4152,  ..., -0.3561, -1.4165, -0.7960])\n",
      "scare\n",
      "Saved the embedding for scare.\n",
      "['scared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0571,  0.1255, -0.3883,  ..., -0.4321, -0.9426,  0.3021])\n",
      "scared\n",
      "Saved the embedding for scared.\n",
      "['scary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3709,  0.1634,  0.2385,  ...,  0.2418, -0.1853, -0.0209])\n",
      "scary\n",
      "Saved the embedding for scary.\n",
      "['scattered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1282,  0.0103,  0.4411,  ..., -0.0304,  0.5570, -0.6011])\n",
      "scattered\n",
      "Saved the embedding for scattered.\n",
      "['sc', '##had', '##en', '##fr', '##eu', '##de'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([-0.5435,  0.3488, -0.0149,  ..., -0.0501, -0.3843,  0.7268])\n",
      "schadenfreude\n",
      "Saved the embedding for schadenfreude.\n",
      "['sc', '##hem', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2225,  0.4949, -0.1214,  ...,  0.2895, -0.5935,  1.0622])\n",
      "scheming\n",
      "Saved the embedding for scheming.\n",
      "['sc', '##off', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5362, -0.0126, -0.3327,  ...,  0.0464, -0.3820,  0.4956])\n",
      "scoffer\n",
      "Saved the embedding for scoffer.\n",
      "['sc', '##off', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4451,  0.0153, -0.2615,  ..., -0.4234, -0.7327,  0.5502])\n",
      "scoffing\n",
      "Saved the embedding for scoffing.\n",
      "['sc', '##orn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5066,  0.2610, -0.0649,  ..., -0.2318, -0.7321,  0.6158])\n",
      "scorn\n",
      "Saved the embedding for scorn.\n",
      "['sc', '##orne', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6812,  0.2377,  0.4395,  ..., -0.1071, -0.8864,  0.3944])\n",
      "scorned\n",
      "Saved the embedding for scorned.\n",
      "['sc', '##orn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2890,  0.8189,  0.2572,  ..., -0.5965, -1.5071,  0.5379])\n",
      "scornful\n",
      "Saved the embedding for scornful.\n",
      "['scowl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8297,  0.2589, -0.1282,  ..., -0.0456,  0.2113, -0.4564])\n",
      "scowl\n",
      "Saved the embedding for scowl.\n",
      "['scowl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-2.5169e-01,  2.2563e-01, -2.5546e-01,  ..., -1.1997e-01,\n",
      "         1.9030e-04,  2.0420e-01])\n",
      "scowling\n",
      "Saved the embedding for scowling.\n",
      "['scream'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5662,  0.4714, -0.3578,  ..., -0.0044,  0.0591, -0.0310])\n",
      "scream\n",
      "Saved the embedding for scream.\n",
      "['screaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2527, -0.1761,  0.0740,  ..., -0.4009, -0.0643, -0.9038])\n",
      "screaming\n",
      "Saved the embedding for screaming.\n",
      "['sc', '##rut', '##ini', '##zing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4683,  0.0627, -0.2184,  ..., -0.2233, -0.6998,  0.5998])\n",
      "scrutinizing\n",
      "Saved the embedding for scrutinizing.\n",
      "['sealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1697, -0.2653, -0.4027,  ..., -0.4193, -0.1862, -0.7726])\n",
      "sealed\n",
      "Saved the embedding for sealed.\n",
      "['searching'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1353,  0.3739, -0.2339,  ..., -0.2328,  0.3599,  0.1121])\n",
      "searching\n",
      "Saved the embedding for searching.\n",
      "['secretive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2226,  0.1702, -0.5348,  ...,  0.0722, -0.7091,  0.1171])\n",
      "secretive\n",
      "Saved the embedding for secretive.\n",
      "['secretive', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4536,  0.3268, -0.7406,  ..., -0.2675, -0.9912,  1.0763])\n",
      "secretively\n",
      "Saved the embedding for secretively.\n",
      "['secure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7276,  0.1719,  0.2783,  ..., -0.4943, -0.2251, -0.4190])\n",
      "secure\n",
      "Saved the embedding for secure.\n",
      "['se', '##date'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6943, -0.4189, -0.2381,  ..., -0.4946, -0.7128,  0.2930])\n",
      "sedate\n",
      "Saved the embedding for sedate.\n",
      "['seduction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5625, -0.0531, -0.2643,  ..., -0.1185,  0.7329, -0.6129])\n",
      "seduction\n",
      "Saved the embedding for seduction.\n",
      "['seductive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6571, -0.7210, -0.3798,  ..., -0.6001, -0.2375, -0.6064])\n",
      "seductive\n",
      "Saved the embedding for seductive.\n",
      "['see', '##thing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2209, -0.4324, -0.2282,  ..., -0.9627, -0.6056, -0.3129])\n",
      "seething\n",
      "Saved the embedding for seething.\n",
      "['self'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7821,  0.5029,  0.0737,  ...,  0.2959, -0.7644, -0.8398])\n",
      "self\n",
      "Saved the embedding for self.\n",
      "['sensual'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3156, -0.3551, -0.6465,  ..., -0.1515,  0.3242,  0.1313])\n",
      "sensual\n",
      "Saved the embedding for sensual.\n",
      "['sentimental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6372, -0.1870,  0.0897,  ..., -1.0607, -0.6819, -0.1206])\n",
      "sentimental\n",
      "Saved the embedding for sentimental.\n",
      "['serene'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3182,  0.3418,  0.0224,  ...,  0.1514, -0.9680,  0.2536])\n",
      "serene\n",
      "Saved the embedding for serene.\n",
      "['serious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2806,  0.2318,  0.2433,  ..., -0.1999, -0.8650,  0.3792])\n",
      "serious\n",
      "Saved the embedding for serious.\n",
      "['seriousness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1871,  0.3898, -0.0788,  ..., -0.3346, -0.4517,  0.0957])\n",
      "seriousness\n",
      "Saved the embedding for seriousness.\n",
      "['ser', '##vil', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3149,  0.4809,  0.2202,  ...,  0.0530,  0.4653, -0.3795])\n",
      "servile\n",
      "Saved the embedding for servile.\n",
      "['set'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3708,  0.7113,  0.2428,  ..., -0.4708, -0.0215, -0.8212])\n",
      "set\n",
      "Saved the embedding for set.\n",
      "['severe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2007, -0.4291,  0.5088,  ..., -0.1023, -0.3207, -0.7126])\n",
      "severe\n",
      "Saved the embedding for severe.\n",
      "['sha', '##bby'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0878,  0.2394, -0.4753,  ..., -0.3655, -0.2148, -0.2427])\n",
      "shabby\n",
      "Saved the embedding for shabby.\n",
      "['shady'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1355,  0.0597,  0.0551,  ...,  0.1789, -0.1022,  0.0734])\n",
      "shady\n",
      "Saved the embedding for shady.\n",
      "['shaken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2354,  0.4050, -0.5435,  ..., -0.2012, -0.6905, -0.0554])\n",
      "shaken\n",
      "Saved the embedding for shaken.\n",
      "['shaky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4138,  0.1778,  0.8433,  ..., -0.3339, -1.2100, -0.5283])\n",
      "shaky\n",
      "Saved the embedding for shaky.\n",
      "['shame'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0865,  0.8528,  0.0462,  ...,  0.0615, -0.3868, -0.3533])\n",
      "shame\n",
      "Saved the embedding for shame.\n",
      "['shame', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2858,  1.0846,  0.3611,  ..., -0.3550, -1.2453, -0.0869])\n",
      "shamed\n",
      "Saved the embedding for shamed.\n",
      "['shame', '##face', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2882,  0.3488,  0.1078,  ..., -0.6011, -0.5834,  0.0112])\n",
      "shamefaced\n",
      "Saved the embedding for shamefaced.\n",
      "['shame', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0263,  0.8372, -0.0924,  ...,  0.2779, -1.0077, -0.1459])\n",
      "shameful\n",
      "Saved the embedding for shameful.\n",
      "['shame', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2762,  0.8134,  0.1918,  ..., -0.6145, -1.5302, -0.2146])\n",
      "shameless\n",
      "Saved the embedding for shameless.\n",
      "['sharp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2317,  0.1098,  0.2893,  ...,  0.1899, -0.2010, -0.2599])\n",
      "sharp\n",
      "Saved the embedding for sharp.\n",
      "['sheep', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0693,  0.1692, -0.7242,  ..., -0.4557, -0.8133, -0.0049])\n",
      "sheepish\n",
      "Saved the embedding for sheepish.\n",
      "['sheep', '##ish', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3478,  0.3649, -0.3210,  ..., -0.7178, -0.4191,  0.5773])\n",
      "sheepishness\n",
      "Saved the embedding for sheepishness.\n",
      "['shell', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1815,  0.6368, -0.9918,  ..., -0.0290, -0.9618,  0.3476])\n",
      "shelled\n",
      "Saved the embedding for shelled.\n",
      "['shift', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4749,  0.7955, -0.2438,  ..., -1.1453, -0.6784,  0.3446])\n",
      "shifty\n",
      "Saved the embedding for shifty.\n",
      "['shock'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0779,  0.6604, -0.9958,  ..., -0.2118, -0.6383,  0.1007])\n",
      "shock\n",
      "Saved the embedding for shock.\n",
      "['shocked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4191,  0.2901, -0.4862,  ..., -0.4066, -0.1701,  0.3114])\n",
      "shocked\n",
      "Saved the embedding for shocked.\n",
      "['shocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1891,  0.4554,  0.4453,  ..., -0.2489, -0.8268, -0.0099])\n",
      "shocking\n",
      "Saved the embedding for shocking.\n",
      "['shocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0485,  0.5851,  0.2326,  ..., -0.6246, -0.5206,  0.2017])\n",
      "shockingly\n",
      "Saved the embedding for shockingly.\n",
      "['shook'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2398,  0.1675, -0.6484,  ...,  0.1390, -0.9380,  0.4536])\n",
      "shook\n",
      "Saved the embedding for shook.\n",
      "['shout'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3029, -0.1998, -0.7805,  ..., -1.1582, -0.1670,  0.1191])\n",
      "shout\n",
      "Saved the embedding for shout.\n",
      "['shouting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3240,  0.1246,  0.1704,  ...,  0.5275,  0.0524, -0.1933])\n",
      "shouting\n",
      "Saved the embedding for shouting.\n",
      "['sh', '##rew', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1290, -0.4742, -0.3050,  ..., -0.7104,  0.0613,  0.2764])\n",
      "shrewd\n",
      "Saved the embedding for shrewd.\n",
      "['shy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1818,  0.2809,  0.0266,  ..., -0.6795, -1.2670, -0.0179])\n",
      "shy\n",
      "Saved the embedding for shy.\n",
      "['shy', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0406,  0.0056,  0.0144,  ..., -1.3801, -1.0604, -0.1035])\n",
      "shyness\n",
      "Saved the embedding for shyness.\n",
      "['sick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2686,  0.2039,  0.1556,  ..., -0.7401,  0.1968, -1.1474])\n",
      "sick\n",
      "Saved the embedding for sick.\n",
      "['sick', '##en'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1073,  0.2064,  0.0401,  ..., -0.7196, -0.4102, -0.2720])\n",
      "sicken\n",
      "Saved the embedding for sicken.\n",
      "['sick', '##ened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0170,  0.0797, -0.1027,  ..., -0.2917,  0.1676, -0.0766])\n",
      "sickened\n",
      "Saved the embedding for sickened.\n",
      "['sigh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2514,  0.4651,  0.1561,  ...,  0.0175,  0.4777, -0.4368])\n",
      "sigh\n",
      "Saved the embedding for sigh.\n",
      "['silenced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2473,  0.4607, -1.3018,  ..., -0.7023, -0.4063, -0.5565])\n",
      "silenced\n",
      "Saved the embedding for silenced.\n",
      "['silent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3456, -0.0972, -0.1593,  ..., -0.5201, -0.5103, -0.9263])\n",
      "silent\n",
      "Saved the embedding for silent.\n",
      "['si', '##llin', '##ess'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0852,  0.4120, -0.3533,  ..., -0.4744, -0.8280,  1.0321])\n",
      "silliness\n",
      "Saved the embedding for silliness.\n",
      "['silly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5600,  0.3810,  0.2879,  ...,  0.0123, -0.8626, -0.2131])\n",
      "silly\n",
      "Saved the embedding for silly.\n",
      "['sim', '##mering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1547, -0.3974, -0.1149,  ..., -0.4785, -0.0978,  0.2020])\n",
      "simmering\n",
      "Saved the embedding for simmering.\n",
      "['sim', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4025, -0.0428,  0.2034,  ..., -0.5793, -0.2729, -0.3239])\n",
      "simper\n",
      "Saved the embedding for simper.\n",
      "['sim', '##per', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2168, -0.4525,  0.1040,  ..., -0.6792, -0.0135, -0.1105])\n",
      "simpering\n",
      "Saved the embedding for simpering.\n",
      "['simple'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5120,  0.0334, -0.2205,  ..., -0.8807, -0.0270,  0.5977])\n",
      "simple\n",
      "Saved the embedding for simple.\n",
      "['simplicity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1020,  0.5383, -0.0219,  ..., -0.3036,  0.1683,  0.5232])\n",
      "simplicity\n",
      "Saved the embedding for simplicity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sincere'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1200,  0.7180, -0.0134,  ...,  0.0899, -0.0935,  0.6546])\n",
      "sincere\n",
      "Saved the embedding for sincere.\n",
      "['sin', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.2329,  0.3198, -0.3996,  ..., -0.4892,  0.2043,  0.0141])\n",
      "sinful\n",
      "Saved the embedding for sinful.\n",
      "['singing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1661, -0.8219, -0.5743,  ...,  0.2603,  0.7173, -0.1210])\n",
      "singing\n",
      "Saved the embedding for singing.\n",
      "['sinister'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.0293,  0.5042,  0.3203,  ..., -0.3881, -1.4783, -1.4583])\n",
      "sinister\n",
      "Saved the embedding for sinister.\n",
      "['sinister', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6327,  0.2551,  0.0035,  ..., -0.5263, -0.2029, -0.0593])\n",
      "sinisterly\n",
      "Saved the embedding for sinisterly.\n",
      "['si', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2801,  0.5869,  0.1033,  ...,  0.2056, -0.7277,  0.9769])\n",
      "sizing\n",
      "Saved the embedding for sizing.\n",
      "['sk', '##ept', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1829, -0.3872, -0.7086,  ...,  0.0928, -0.5112,  0.3866])\n",
      "skeptic\n",
      "Saved the embedding for skeptic.\n",
      "['skeptical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1307,  0.2138, -0.6971,  ..., -0.3075, -0.7623,  0.6756])\n",
      "skeptical\n",
      "Saved the embedding for skeptical.\n",
      "['skeptical', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2258,  0.5576, -0.1515,  ..., -0.7085, -0.8391,  0.8362])\n",
      "skeptically\n",
      "Saved the embedding for skeptically.\n",
      "['skepticism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2092,  0.2651, -0.7059,  ..., -0.3670, -0.7372,  0.6239])\n",
      "skepticism\n",
      "Saved the embedding for skepticism.\n",
      "['sketch', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5788,  0.4431, -0.9328,  ..., -1.1791, -1.1478,  0.5804])\n",
      "sketchy\n",
      "Saved the embedding for sketchy.\n",
      "['ski', '##tti', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8050, -0.5364,  0.1538,  ...,  0.4755,  0.0666, -0.0325])\n",
      "skittish\n",
      "Saved the embedding for skittish.\n",
      "['slack'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6092,  0.8536,  0.3560,  ..., -0.1430, -0.1486,  0.3102])\n",
      "slack\n",
      "Saved the embedding for slack.\n",
      "['sl', '##ea', '##zy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4296,  0.5982, -0.6873,  ..., -0.1850, -0.1325,  0.8435])\n",
      "sleazy\n",
      "Saved the embedding for sleazy.\n",
      "['sleepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2674,  1.0224, -0.3937,  ..., -0.4155, -0.6077,  0.3786])\n",
      "sleepy\n",
      "Saved the embedding for sleepy.\n",
      "['slick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6318, -0.1952, -0.1058,  ..., -0.9992,  0.0385,  0.3795])\n",
      "slick\n",
      "Saved the embedding for slick.\n",
      "['slot', '##h', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1430, -0.4393, -0.2700,  ..., -1.2053,  0.1956, -0.2644])\n",
      "slothful\n",
      "Saved the embedding for slothful.\n",
      "['slow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2479, -0.0995, -0.3646,  ..., -0.5978,  0.1750, -0.6425])\n",
      "slow\n",
      "Saved the embedding for slow.\n",
      "['slug', '##gis', '##h'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4143,  0.7036, -0.3654,  ...,  0.6088, -0.2794,  0.3859])\n",
      "sluggish\n",
      "Saved the embedding for sluggish.\n",
      "['sly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1096,  0.3318, -0.0641,  ..., -0.4594,  0.0213, -0.0375])\n",
      "sly\n",
      "Saved the embedding for sly.\n",
      "['sm', '##arm', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5104,  0.0724, -0.5636,  ...,  0.2771, -0.0723,  0.3458])\n",
      "smarmy\n",
      "Saved the embedding for smarmy.\n",
      "['smart'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1508,  0.2359,  0.2695,  ..., -0.6678, -0.1337,  0.2634])\n",
      "smart\n",
      "Saved the embedding for smart.\n",
      "['smashed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0108, -0.2828, -0.1551,  ..., -0.0151, -0.1356, -0.3452])\n",
      "smashed\n",
      "Saved the embedding for smashed.\n",
      "['smile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0484,  0.4198,  0.1428,  ...,  0.0791, -1.0520,  0.3279])\n",
      "smile\n",
      "Saved the embedding for smile.\n",
      "['smiley'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2470,  0.4157,  0.4168,  ..., -0.6366, -0.3326,  0.0373])\n",
      "smiley\n",
      "Saved the embedding for smiley.\n",
      "['smiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1065,  0.2835, -0.2024,  ..., -0.1423, -0.5186, -0.2885])\n",
      "smiling\n",
      "Saved the embedding for smiling.\n",
      "['smirk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3139,  0.3274, -0.4965,  ...,  0.0843,  0.0878, -0.5594])\n",
      "smirk\n",
      "Saved the embedding for smirk.\n",
      "['smirk', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0971,  0.4277, -0.8124,  ..., -0.2135,  0.1427,  0.0053])\n",
      "smirking\n",
      "Saved the embedding for smirking.\n",
      "['sm', '##old', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0762,  0.0363, -0.6146,  ..., -1.6151, -0.1602,  0.7242])\n",
      "smoldering\n",
      "Saved the embedding for smoldering.\n",
      "['sm', '##oo', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4369,  0.0595, -0.5128,  ..., -0.3696, -0.4832,  0.6765])\n",
      "smooching\n",
      "Saved the embedding for smooching.\n",
      "['smooth'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3325,  0.4372,  0.3546,  ...,  0.0551, -0.3125, -0.8188])\n",
      "smooth\n",
      "Saved the embedding for smooth.\n",
      "['smug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0790,  0.6186,  0.4227,  ..., -0.0837, -0.7339,  0.0938])\n",
      "smug\n",
      "Saved the embedding for smug.\n",
      "['smug', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3413,  0.8279, -0.0460,  ..., -1.0339, -0.7667, -0.0295])\n",
      "smugness\n",
      "Saved the embedding for smugness.\n",
      "['snake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4586,  0.5631,  0.2052,  ..., -0.4393, -0.6289, -0.1098])\n",
      "snake\n",
      "Saved the embedding for snake.\n",
      "['snap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2747, -0.7755,  0.2746,  ..., -0.0758,  0.0476, -0.2388])\n",
      "snappy\n",
      "Saved the embedding for snappy.\n",
      "['s', '##nar', '##ky'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1020, -0.1749,  0.0845,  ..., -0.4266, -0.6117,  0.8216])\n",
      "snarky\n",
      "Saved the embedding for snarky.\n",
      "['snarl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3933,  0.4658, -0.2061,  ..., -0.8435, -0.3422,  0.5222])\n",
      "snarl\n",
      "Saved the embedding for snarl.\n",
      "['snarled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6952, -0.0286,  0.1228,  ..., -0.4065, -0.2319, -0.0840])\n",
      "snarled\n",
      "Saved the embedding for snarled.\n",
      "['snarl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6674,  0.3537, -0.1697,  ..., -0.6567, -0.4839,  0.0177])\n",
      "snarling\n",
      "Saved the embedding for snarling.\n",
      "['snarl', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1830,  0.1794, -0.0550,  ..., -0.4839, -0.3084, -0.0005])\n",
      "snarly\n",
      "Saved the embedding for snarly.\n",
      "['sneak', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7768,  0.3270, -0.7717,  ..., -0.5744, -0.6600,  0.1909])\n",
      "sneaky\n",
      "Saved the embedding for sneaky.\n",
      "['s', '##neer'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2868,  0.1050,  0.0626,  ..., -0.8134, -1.1603,  0.6426])\n",
      "sneer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for sneer.\n",
      "['s', '##neer', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4242, -0.1950,  0.0203,  ..., -0.8040, -0.4864,  0.0769])\n",
      "sneering\n",
      "Saved the embedding for sneering.\n",
      "['s', '##nee', '##ze'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4711,  0.2463,  0.0877,  ..., -0.6244, -0.6009,  0.3075])\n",
      "sneeze\n",
      "Saved the embedding for sneeze.\n",
      "['s', '##nee', '##zing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2309, -0.0862, -0.2068,  ..., -0.9098, -0.4103,  0.2620])\n",
      "sneezing\n",
      "Saved the embedding for sneezing.\n",
      "['s', '##nick', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6130, -0.1989, -0.2863,  ..., -0.6643, -0.1115,  0.5918])\n",
      "snicker\n",
      "Saved the embedding for snicker.\n",
      "['sq', '##ue', '##ami', '##sh'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0921,  0.6798, -0.2824,  ...,  0.4469, -0.4379,  0.5928])\n",
      "squeamish\n",
      "Saved the embedding for squeamish.\n",
      "['staggered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2442,  0.1611,  0.1747,  ..., -0.1579, -1.4123, -0.0630])\n",
      "staggered\n",
      "Saved the embedding for staggered.\n",
      "['stalker'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7211,  0.0143,  0.8567,  ..., -0.1397, -0.3774, -0.3633])\n",
      "stalker\n",
      "Saved the embedding for stalker.\n",
      "['stare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2521,  0.3972,  0.0840,  ..., -0.8394,  0.0766, -0.1390])\n",
      "stare\n",
      "Saved the embedding for stare.\n",
      "['staring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0780,  0.3191, -0.4195,  ...,  1.1208,  0.5754,  0.3927])\n",
      "staring\n",
      "Saved the embedding for staring.\n",
      "['stars', '##tr', '##uck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.9016,  0.0626, -0.4411,  ..., -0.3284, -0.0973, -0.6528])\n",
      "starstruck\n",
      "Saved the embedding for starstruck.\n",
      "['started'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3122, -0.0128, -0.5672,  ..., -0.2210, -0.3409,  0.2704])\n",
      "started\n",
      "Saved the embedding for started.\n",
      "['startled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1360,  0.2181, -0.2340,  ...,  0.5900, -0.4566,  0.3082])\n",
      "startled\n",
      "Saved the embedding for startled.\n",
      "['state', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1254,  0.4082, -0.1575,  ..., -1.2125, -1.4686,  0.2231])\n",
      "stately\n",
      "Saved the embedding for stately.\n",
      "['ste', '##ad', '##fast'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4083,  0.9165,  0.1131,  ..., -1.2572,  0.0706,  0.5949])\n",
      "steadfast\n",
      "Saved the embedding for steadfast.\n",
      "['steady'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4955,  0.6038, -0.3132,  ..., -0.1551, -0.1774,  0.2721])\n",
      "steady\n",
      "Saved the embedding for steady.\n",
      "['stealth', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3215,  0.1375, -0.5035,  ..., -0.5373,  0.6592, -0.0487])\n",
      "stealthy\n",
      "Saved the embedding for stealthy.\n",
      "['steamed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0751,  0.3037, -0.6361,  ...,  0.3509, -0.4634,  0.0111])\n",
      "steamed\n",
      "Saved the embedding for steamed.\n",
      "['steaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3839,  0.0706,  0.1484,  ..., -0.0588, -0.8866, -0.3162])\n",
      "steaming\n",
      "Saved the embedding for steaming.\n",
      "['steel', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5765,  0.0331,  0.5578,  ..., -0.0519, -0.9739, -0.0527])\n",
      "steeling\n",
      "Saved the embedding for steeling.\n",
      "['steel', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4390,  0.0985,  0.5119,  ..., -0.6719, -0.3783,  0.1642])\n",
      "steely\n",
      "Saved the embedding for steely.\n",
      "['stern'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2544,  0.0924, -0.8738,  ..., -0.4278, -0.0040,  0.0013])\n",
      "stern\n",
      "Saved the embedding for stern.\n",
      "['stiff'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0170, -0.0432,  0.8634,  ..., -0.0948, -0.7836, -0.1391])\n",
      "stiff\n",
      "Saved the embedding for stiff.\n",
      "['stifled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0813, -0.2928, -0.6691,  ...,  0.1741, -0.8737,  0.5026])\n",
      "stifled\n",
      "Saved the embedding for stifled.\n",
      "['st', '##if', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6812,  0.5338, -0.1725,  ..., -0.5533, -0.7181,  0.7506])\n",
      "stifling\n",
      "Saved the embedding for stifling.\n",
      "['still'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2693,  0.2624, -0.1167,  ..., -0.1896,  0.7487,  0.0664])\n",
      "still\n",
      "Saved the embedding for still.\n",
      "['stillness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5096,  0.0029,  0.1992,  ...,  0.1225, -0.0702,  0.5153])\n",
      "stillness\n",
      "Saved the embedding for stillness.\n",
      "['stimulated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0483,  0.6768, -0.1439,  ..., -0.0080, -0.2209, -0.3978])\n",
      "stimulated\n",
      "Saved the embedding for stimulated.\n",
      "['stink', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0837,  0.4761, -0.2703,  ..., -0.0804, -0.4099,  0.2837])\n",
      "stinky\n",
      "Saved the embedding for stinky.\n",
      "['stirred'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0808,  0.1362, -0.5793,  ...,  0.2313, -0.1092, -0.2733])\n",
      "stirred\n",
      "Saved the embedding for stirred.\n",
      "['st', '##oic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3541,  0.2003, -0.1015,  ..., -0.4233, -0.2427,  0.5832])\n",
      "stoic\n",
      "Saved the embedding for stoic.\n",
      "['st', '##oic', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2562,  0.3526, -0.2571,  ..., -0.3887, -0.1898,  0.2932])\n",
      "stoical\n",
      "Saved the embedding for stoical.\n",
      "['st', '##oli', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3756,  0.6340, -0.1618,  ..., -0.3321, -0.0464,  0.1407])\n",
      "stolid\n",
      "Saved the embedding for stolid.\n",
      "['stone', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4070,  0.0041, -0.8568,  ...,  0.0143, -0.0340, -0.4269])\n",
      "stoned\n",
      "Saved the embedding for stoned.\n",
      "['storm', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1993,  0.6454,  0.1772,  ..., -1.4318, -1.3425, -0.1486])\n",
      "storming\n",
      "Saved the embedding for storming.\n",
      "['stormy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1218,  0.2787,  0.4022,  ...,  0.1209, -1.1826, -0.1600])\n",
      "stormy\n",
      "Saved the embedding for stormy.\n",
      "['stout'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1019, -0.4855,  0.3816,  ...,  0.1831, -0.7482, -0.7620])\n",
      "stout\n",
      "Saved the embedding for stout.\n",
      "['straight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0503, -0.1738, -0.1166,  ...,  0.3126, -0.2585, -1.3370])\n",
      "straight\n",
      "Saved the embedding for straight.\n",
      "['strained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3702,  0.4176, -0.7890,  ..., -0.1005, -0.8844, -0.1937])\n",
      "strained\n",
      "Saved the embedding for strained.\n",
      "['strange'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4748,  0.5240,  0.2501,  ..., -0.0639, -0.0674, -0.0880])\n",
      "strange\n",
      "Saved the embedding for strange.\n",
      "['stressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1100,  0.7410,  1.2812,  ..., -0.6912, -1.5427, -0.4946])\n",
      "stressed\n",
      "Saved the embedding for stressed.\n",
      "['stricken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1335, -0.0965,  0.3213,  ..., -0.5613,  0.1204, -0.4234])\n",
      "stricken\n",
      "Saved the embedding for stricken.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strict'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6179,  0.5700,  0.4778,  ..., -0.1759, -0.6239, -0.4757])\n",
      "strict\n",
      "Saved the embedding for strict.\n",
      "['strong'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1234,  0.5532,  0.5631,  ..., -0.2607, -1.3304, -0.5509])\n",
      "strong\n",
      "Saved the embedding for strong.\n",
      "['struck'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3018,  0.2384, -0.0854,  ..., -0.6200,  0.2721,  0.1383])\n",
      "struck\n",
      "Saved the embedding for struck.\n",
      "['stubborn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0442,  0.3723, -0.2966,  ..., -0.3460, -0.0067,  0.5375])\n",
      "stubborn\n",
      "Saved the embedding for stubborn.\n",
      "['stubborn', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1971,  0.3531, -0.5590,  ..., -0.9929, -1.1900,  1.5029])\n",
      "stubbornness\n",
      "Saved the embedding for stubbornness.\n",
      "['studio', '##us'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7128, -0.2143,  0.2438,  ...,  0.0802, -0.2880, -0.2171])\n",
      "studious\n",
      "Saved the embedding for studious.\n",
      "['studying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0875,  0.0482,  0.7850,  ..., -0.0788, -0.7652,  0.2393])\n",
      "studying\n",
      "Saved the embedding for studying.\n",
      "['stump', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1664, -0.4830, -0.6644,  ..., -0.4179,  0.0599, -0.9480])\n",
      "stumped\n",
      "Saved the embedding for stumped.\n",
      "['stung'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4068, -0.0850, -0.0730,  ...,  0.0165,  0.0219, -0.3920])\n",
      "stung\n",
      "Saved the embedding for stung.\n",
      "['stunned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5948,  0.2205,  0.0498,  ...,  0.2422, -0.2595,  0.3845])\n",
      "stunned\n",
      "Saved the embedding for stunned.\n",
      "['stu', '##pe', '##fa', '##ction'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4683, -0.0450, -0.3012,  ..., -0.7722, -0.5670,  0.3580])\n",
      "stupefaction\n",
      "Saved the embedding for stupefaction.\n",
      "['stu', '##pe', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0532, -0.1642, -0.0412,  ..., -1.2816, -0.1504,  0.2765])\n",
      "stupefied\n",
      "Saved the embedding for stupefied.\n",
      "['stu', '##pe', '##fy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2322, -0.2255, -0.0024,  ..., -1.2940, -0.2258,  0.3315])\n",
      "stupefy\n",
      "Saved the embedding for stupefy.\n",
      "['stupid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2724,  0.3061, -0.3370,  ..., -0.3760, -0.6684,  0.3338])\n",
      "stupid\n",
      "Saved the embedding for stupid.\n",
      "['stu', '##por', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1874, -0.2762, -0.0686,  ..., -1.0314, -0.5072,  0.4704])\n",
      "stuporous\n",
      "Saved the embedding for stuporous.\n",
      "['su', '##ave'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0944, -0.3064,  0.0386,  ..., -0.6307, -1.6699,  0.2834])\n",
      "suave\n",
      "Saved the embedding for suave.\n",
      "['subdued'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8835,  0.1434, -0.4184,  ...,  0.2285,  0.2413, -0.7738])\n",
      "subdued\n",
      "Saved the embedding for subdued.\n",
      "['sublime'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6498,  0.9920, -0.0983,  ..., -0.2574,  0.5896, -0.0239])\n",
      "sublime\n",
      "Saved the embedding for sublime.\n",
      "['sub', '##missive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1808,  0.1576, -0.2072,  ..., -0.5311, -0.5081,  0.1901])\n",
      "submissive\n",
      "Saved the embedding for submissive.\n",
      "['suffering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0327,  0.4058,  0.9852,  ...,  0.5761, -0.5090, -0.9670])\n",
      "suffering\n",
      "Saved the embedding for suffering.\n",
      "['suggest', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2245,  0.1341, -0.1744,  ..., -0.9603,  0.1199,  0.1455])\n",
      "suggestive\n",
      "Saved the embedding for suggestive.\n",
      "['sul', '##king'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3585,  0.1581, -0.2860,  ..., -1.0924, -1.0466,  0.2717])\n",
      "sulking\n",
      "Saved the embedding for sulking.\n",
      "['sul', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4363,  0.0915, -0.2382,  ..., -0.4506, -0.0269,  0.1897])\n",
      "sulky\n",
      "Saved the embedding for sulky.\n",
      "['sul', '##len'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3819, -0.0297, -0.0777,  ..., -0.8497, -0.5170,  0.6371])\n",
      "sullen\n",
      "Saved the embedding for sullen.\n",
      "['sul', '##len', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0038,  0.0841, -0.1369,  ..., -0.9571, -0.5026,  0.6841])\n",
      "sullenness\n",
      "Saved the embedding for sullenness.\n",
      "['sunny'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4397,  0.9807,  0.0050,  ..., -0.5406, -0.7658, -0.1621])\n",
      "sunny\n",
      "Saved the embedding for sunny.\n",
      "['superior'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4960,  0.3801,  1.5412,  ..., -0.5219, -0.1317, -0.5396])\n",
      "superior\n",
      "Saved the embedding for superior.\n",
      "['superiority'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1873,  0.3235,  0.3741,  ..., -0.3142, -0.5842, -0.1382])\n",
      "superiority\n",
      "Saved the embedding for superiority.\n",
      "['suppressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0280,  0.3429,  0.1308,  ..., -0.3593, -0.9049, -0.4198])\n",
      "suppressed\n",
      "Saved the embedding for suppressed.\n",
      "['suppress', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3650,  0.5141, -0.4963,  ..., -0.6227, -1.6929, -0.6042])\n",
      "suppressing\n",
      "Saved the embedding for suppressing.\n",
      "['suppression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0513, -0.1456,  0.2202,  ...,  0.2844, -0.6906, -0.6258])\n",
      "suppression\n",
      "Saved the embedding for suppression.\n",
      "['sure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3381,  0.1287, -0.2411,  ..., -0.7576, -0.3993,  0.3763])\n",
      "sure\n",
      "Saved the embedding for sure.\n",
      "['sur', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3742,  0.2990, -0.1698,  ...,  0.3950, -0.2931,  0.3465])\n",
      "surly\n",
      "Saved the embedding for surly.\n",
      "['surprise'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4102,  0.1955,  0.2185,  ...,  0.1981,  0.1232, -0.3489])\n",
      "surprise\n",
      "Saved the embedding for surprise.\n",
      "['surprised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2897,  0.2965,  0.0909,  ...,  1.0020,  0.2363, -0.1227])\n",
      "surprised\n",
      "Saved the embedding for surprised.\n",
      "['surprising'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2037,  0.1434,  0.1580,  ...,  0.5545, -0.2973,  0.2847])\n",
      "surprising\n",
      "Saved the embedding for surprising.\n",
      "['surprisingly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1988,  0.1405,  0.6672,  ..., -0.0604, -0.0815, -0.8990])\n",
      "surprisingly\n",
      "Saved the embedding for surprisingly.\n",
      "['sur', '##re', '##pt', '##iti', '##ous'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0309, -0.1418, -0.2718,  ...,  0.2181, -0.4739,  0.6412])\n",
      "surreptitious\n",
      "Saved the embedding for surreptitious.\n",
      "['suspect'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5316,  0.3793,  0.1740,  ..., -0.8955, -0.7981, -0.0549])\n",
      "suspect\n",
      "Saved the embedding for suspect.\n",
      "['suspect', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2967,  0.3924,  0.3742,  ..., -0.3252, -0.5637, -0.1424])\n",
      "suspecting\n",
      "Saved the embedding for suspecting.\n",
      "['suspense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0315,  0.4075, -0.1767,  ..., -0.6387,  0.4756, -0.7726])\n",
      "suspense\n",
      "Saved the embedding for suspense.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suspicion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2837,  0.7158, -0.0529,  ...,  0.1140, -0.2760,  0.1162])\n",
      "suspicion\n",
      "Saved the embedding for suspicion.\n",
      "['suspicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1826,  0.4406,  0.3361,  ..., -0.9814, -0.8233, -0.2662])\n",
      "suspicious\n",
      "Saved the embedding for suspicious.\n",
      "['suspiciously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1922,  0.6071, -0.4325,  ...,  0.0774, -0.2413,  0.1772])\n",
      "suspiciously\n",
      "Saved the embedding for suspiciously.\n",
      "['suspicious', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1307,  0.4970,  0.0823,  ..., -0.6268, -0.9094, -0.2070])\n",
      "suspiciousness\n",
      "Saved the embedding for suspiciousness.\n",
      "['sw', '##agger', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-4.1232e-01,  7.5793e-01, -5.9758e-01,  ...,  8.0710e-02,\n",
      "         1.2657e-01, -4.7337e-05])\n",
      "swaggering\n",
      "Saved the embedding for swaggering.\n",
      "['swearing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2086,  0.6733, -0.6133,  ...,  0.5401,  0.5021, -0.1525])\n",
      "swearing\n",
      "Saved the embedding for swearing.\n",
      "['sympathetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2069,  0.4038, -0.2699,  ...,  0.2361,  0.4962, -1.5771])\n",
      "sympathetic\n",
      "Saved the embedding for sympathetic.\n",
      "['sy', '##mp', '##athi', '##zing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6826,  0.2693, -0.3575,  ...,  0.1319,  0.2748,  0.6127])\n",
      "sympathizing\n",
      "Saved the embedding for sympathizing.\n",
      "['sympathy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1267,  1.3456,  0.3214,  ..., -0.0099, -0.9415,  0.4335])\n",
      "sympathy\n",
      "Saved the embedding for sympathy.\n",
      "['ta', '##cit', '##urn'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2762, -0.0732,  0.3648,  ..., -0.5434, -0.3379, -0.2466])\n",
      "taciturn\n",
      "Saved the embedding for taciturn.\n",
      "['talk', '##ative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0562, -0.5327,  0.0726,  ..., -0.4296,  0.4120, -0.5669])\n",
      "talkative\n",
      "Saved the embedding for talkative.\n",
      "['talking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5498,  0.3089, -0.6856,  ..., -0.7126, -0.5672,  0.2537])\n",
      "talking\n",
      "Saved the embedding for talking.\n",
      "['tan', '##tal', '##ized'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0226, -0.5316,  0.8779,  ..., -0.0714, -0.8103, -0.1757])\n",
      "tantalized\n",
      "Saved the embedding for tantalized.\n",
      "['tar', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6503, -0.1107, -0.2188,  ..., -1.2041, -0.9774,  1.0741])\n",
      "tart\n",
      "Saved the embedding for tart.\n",
      "['taste', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2149,  0.0376, -0.5613,  ...,  0.3797, -0.6616, -0.2199])\n",
      "tasteful\n",
      "Saved the embedding for tasteful.\n",
      "['ta', '##tt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5382, -0.1395, -0.0327,  ..., -0.2610, -0.5215,  0.2722])\n",
      "tattling\n",
      "Saved the embedding for tattling.\n",
      "['tau', '##nt'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9579, -0.0818, -0.3569,  ..., -0.8646, -0.9069,  0.5820])\n",
      "taunt\n",
      "Saved the embedding for taunt.\n",
      "['taunting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0577,  0.8244,  0.3150,  ...,  0.7394, -0.4301, -0.5844])\n",
      "taunting\n",
      "Saved the embedding for taunting.\n",
      "['taut'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3870,  0.4160,  0.4440,  ..., -0.9120, -0.7125, -0.6049])\n",
      "taut\n",
      "Saved the embedding for taut.\n",
      "['tear', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5422,  0.3925, -0.5461,  ..., -0.7877, -0.2082, -0.0612])\n",
      "tearful\n",
      "Saved the embedding for tearful.\n",
      "['tear', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5386,  0.4181, -0.5122,  ..., -1.0467, -0.4069,  0.0938])\n",
      "teary\n",
      "Saved the embedding for teary.\n",
      "['tease'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3268, -0.0073,  0.1283,  ..., -0.0892,  0.1928,  0.0183])\n",
      "tease\n",
      "Saved the embedding for tease.\n",
      "['teasing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7086, -0.1334, -0.2706,  ..., -0.4810,  0.0048,  0.1950])\n",
      "teasing\n",
      "Saved the embedding for teasing.\n",
      "['tempered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1826,  0.7629,  0.1699,  ...,  0.8903, -0.0255,  0.3770])\n",
      "tempered\n",
      "Saved the embedding for tempered.\n",
      "['tempest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6747,  0.5176, -0.3602,  ...,  0.7980, -0.0601, -0.4179])\n",
      "tempest\n",
      "Saved the embedding for tempest.\n",
      "['tempest', '##uous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6468,  0.6965, -0.4414,  ...,  0.4390,  0.0113,  0.1518])\n",
      "tempestuous\n",
      "Saved the embedding for tempestuous.\n",
      "['tempted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0849,  0.5533,  0.8035,  ...,  0.2224, -0.5380, -0.4390])\n",
      "tempted\n",
      "Saved the embedding for tempted.\n",
      "['ten', '##acious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0660, -0.8767,  0.0954,  ..., -1.5493, -0.7850,  0.4410])\n",
      "tenacious\n",
      "Saved the embedding for tenacious.\n",
      "['tender'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2387,  0.6215, -0.0474,  ..., -0.6819,  0.5829, -0.0501])\n",
      "tender\n",
      "Saved the embedding for tender.\n",
      "['tenderness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5043,  0.8700,  0.2641,  ...,  0.4670, -0.1665, -0.0812])\n",
      "tenderness\n",
      "Saved the embedding for tenderness.\n",
      "['tense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6017,  0.3253, -0.1495,  ..., -0.2428, -0.2361,  0.1471])\n",
      "tense\n",
      "Saved the embedding for tense.\n",
      "['tensed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1606,  0.2467,  0.6525,  ..., -0.4836, -0.6890,  0.2490])\n",
      "tensed\n",
      "Saved the embedding for tensed.\n",
      "['tension'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3765,  0.6327,  0.3492,  ..., -1.1488, -0.2274,  0.2149])\n",
      "tension\n",
      "Saved the embedding for tension.\n",
      "['tentative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2549,  0.7931, -0.4061,  ...,  0.1371, -0.7939, -0.5728])\n",
      "tentative\n",
      "Saved the embedding for tentative.\n",
      "['terrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3407,  0.1511, -0.0096,  ..., -0.2755, -0.0330, -0.5390])\n",
      "terrified\n",
      "Saved the embedding for terrified.\n",
      "['terror'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4036,  0.9602, -0.3689,  ..., -0.6583, -0.6492, -0.0859])\n",
      "terror\n",
      "Saved the embedding for terror.\n",
      "['terror', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3306,  0.8040, -0.2513,  ..., -0.4141, -0.6900,  0.0205])\n",
      "terrorized\n",
      "Saved the embedding for terrorized.\n",
      "['terror', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3921,  1.0123, -0.4084,  ..., -0.6545, -0.8389, -0.0295])\n",
      "terrorizing\n",
      "Saved the embedding for terrorizing.\n",
      "['ter', '##se'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3217, -0.4316,  0.2432,  ..., -0.7216, -0.3056, -0.4983])\n",
      "terse\n",
      "Saved the embedding for terse.\n",
      "['test', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8116,  0.1477,  0.1932,  ..., -0.4330, -1.1536,  0.1422])\n",
      "testy\n",
      "Saved the embedding for testy.\n",
      "['te', '##tch', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5697,  0.4837, -0.2220,  ..., -0.1144, -1.1723,  0.5677])\n",
      "tetchy\n",
      "Saved the embedding for tetchy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thankful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1628,  0.5492, -0.2886,  ..., -0.5089, -0.7057,  0.3853])\n",
      "thankful\n",
      "Saved the embedding for thankful.\n",
      "['thinking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3176,  0.2977,  0.1630,  ...,  0.5015, -0.9690, -0.0370])\n",
      "thinking\n",
      "Saved the embedding for thinking.\n",
      "['thought'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3511,  0.0719,  0.4473,  ...,  0.8665, -0.9827, -0.0242])\n",
      "thought\n",
      "Saved the embedding for thought.\n",
      "['thoughtful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2982,  0.1888,  0.0709,  ..., -0.1188, -0.6362, -0.0546])\n",
      "thoughtful\n",
      "Saved the embedding for thoughtful.\n",
      "['thoughtful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0373,  0.2240, -0.0583,  ..., -0.1586, -0.3395,  0.2474])\n",
      "thoughtfulness\n",
      "Saved the embedding for thoughtfulness.\n",
      "['threat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1121,  0.5613,  0.4172,  ..., -0.6425, -1.0548, -0.2819])\n",
      "threat\n",
      "Saved the embedding for threat.\n",
      "['threatened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3043,  0.0727,  0.1303,  ..., -0.4622, -1.1062, -0.6063])\n",
      "threatened\n",
      "Saved the embedding for threatened.\n",
      "['threatening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0581,  0.6240,  0.3840,  ..., -0.3640, -1.1347, -0.7823])\n",
      "threatening\n",
      "Saved the embedding for threatening.\n",
      "['thrilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3546,  0.4486,  0.2145,  ..., -0.3195, -1.1525, -0.2301])\n",
      "thrilled\n",
      "Saved the embedding for thrilled.\n",
      "['thrown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5309,  0.1160, -0.5821,  ..., -0.0989,  0.0618, -0.1153])\n",
      "thrown\n",
      "Saved the embedding for thrown.\n",
      "['thunder', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8013,  0.7652,  0.0825,  ..., -0.0480, -0.0296, -0.6107])\n",
      "thunderstruck\n",
      "Saved the embedding for thunderstruck.\n",
      "['thwarted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5156, -0.1603,  0.2228,  ..., -0.4485, -0.4218, -0.7443])\n",
      "thwarted\n",
      "Saved the embedding for thwarted.\n",
      "['ticked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6471,  0.8507,  0.3518,  ...,  0.4459, -0.6265, -0.9470])\n",
      "ticked\n",
      "Saved the embedding for ticked.\n",
      "['tick', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3184,  0.8007, -1.0572,  ...,  0.0878, -0.3606,  0.3676])\n",
      "tickled\n",
      "Saved the embedding for tickled.\n",
      "['tied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0157,  0.1195, -0.0942,  ...,  0.5127,  0.3040,  0.2530])\n",
      "tied\n",
      "Saved the embedding for tied.\n",
      "['tier', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1719, -0.8688,  0.3984,  ..., -0.9203, -0.4974, -0.0964])\n",
      "tiered\n",
      "Saved the embedding for tiered.\n",
      "['tight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0923, -0.1793,  0.0636,  ..., -0.4326, -0.3398, -0.0050])\n",
      "tight\n",
      "Saved the embedding for tight.\n",
      "['tight', '##lip', '##ped'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2372, -0.2566,  0.1999,  ..., -0.8319, -0.8414,  0.4545])\n",
      "tightlipped\n",
      "Saved the embedding for tightlipped.\n",
      "['tim', '##id'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4347, -0.1682,  0.0453,  ..., -1.1755, -1.2844,  0.3839])\n",
      "timid\n",
      "Saved the embedding for timid.\n",
      "['tim', '##id', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6597,  0.0720,  0.0310,  ..., -1.0220,  0.1970,  0.2712])\n",
      "timidly\n",
      "Saved the embedding for timidly.\n",
      "['tim', '##id', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1977,  0.0372, -0.3125,  ..., -0.8427, -0.6409,  0.9581])\n",
      "timidness\n",
      "Saved the embedding for timidness.\n",
      "['tired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2927,  0.2119, -0.2202,  ..., -0.7144, -0.4902,  0.8038])\n",
      "tired\n",
      "Saved the embedding for tired.\n",
      "['tired', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4427, -0.0308, -0.0110,  ..., -0.6552, -0.6549,  0.2165])\n",
      "tiredly\n",
      "Saved the embedding for tiredly.\n",
      "['tired', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1110,  0.2088, -0.2483,  ..., -0.9904, -1.2930,  0.7378])\n",
      "tiredness\n",
      "Saved the embedding for tiredness.\n",
      "['ti', '##till', '##ated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4584, -0.5491, -0.1851,  ...,  0.1926, -0.4814,  0.7610])\n",
      "titillated\n",
      "Saved the embedding for titillated.\n",
      "['tolerant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0171,  0.1355,  0.6726,  ..., -0.4716, -1.0055, -0.1579])\n",
      "tolerant\n",
      "Saved the embedding for tolerant.\n",
      "['tongue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5270,  0.3726,  0.0639,  ..., -0.1023,  0.1977,  0.0490])\n",
      "tongue\n",
      "Saved the embedding for tongue.\n",
      "['tormented'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4463,  0.2472,  0.5284,  ..., -0.5378,  0.1912, -0.6715])\n",
      "tormented\n",
      "Saved the embedding for tormented.\n",
      "['touched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0750,  0.2035, -1.1217,  ..., -0.4613, -0.5191,  0.6882])\n",
      "touched\n",
      "Saved the embedding for touched.\n",
      "['tough'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3430,  0.0177, -0.1125,  ..., -0.6616, -0.8023,  0.1598])\n",
      "tough\n",
      "Saved the embedding for tough.\n",
      "['toy', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4230,  0.8738, -0.2483,  ...,  0.0974, -0.8075,  0.0280])\n",
      "toying\n",
      "Saved the embedding for toying.\n",
      "['tragic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0241, -0.3183,  0.2052,  ..., -0.4559,  0.6436, -0.8333])\n",
      "tragic\n",
      "Saved the embedding for tragic.\n",
      "['tragic', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4264, -0.2011,  0.1541,  ..., -1.4513,  0.5470, -0.9144])\n",
      "tragical\n",
      "Saved the embedding for tragical.\n",
      "['tran', '##quil'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2368,  0.6527,  0.8831,  ..., -0.6191, -0.9911,  0.4041])\n",
      "tranquil\n",
      "Saved the embedding for tranquil.\n",
      "['tran', '##quil', '##ity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7165,  0.7824,  0.8104,  ...,  0.3683, -0.8155,  0.0871])\n",
      "tranquility\n",
      "Saved the embedding for tranquility.\n",
      "['trans', '##fixed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1800, -0.2913, -0.0011,  ..., -0.8237, -0.1247, -0.6066])\n",
      "transfixed\n",
      "Saved the embedding for transfixed.\n",
      "['trauma', '##tized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3336,  0.1388,  0.3407,  ..., -0.8461, -0.3427, -0.3171])\n",
      "traumatized\n",
      "Saved the embedding for traumatized.\n",
      "['trembling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2315,  0.3471,  0.3750,  ...,  0.0648, -0.6104, -0.4052])\n",
      "trembling\n",
      "Saved the embedding for trembling.\n",
      "['tre', '##pid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6757, -0.3984, -0.6319,  ..., -0.1962, -0.7011,  1.1135])\n",
      "trepid\n",
      "Saved the embedding for trepid.\n",
      "['tre', '##pid', '##ation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.9366, -0.1936, -0.6626,  ..., -0.6714, -0.9041,  0.8861])\n",
      "trepidation\n",
      "Saved the embedding for trepidation.\n",
      "['tricks', '##ter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2833,  0.1048,  0.3675,  ...,  0.3027, -0.4204, -0.2637])\n",
      "trickster\n",
      "Saved the embedding for trickster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tricky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0343, -0.0995,  0.6134,  ...,  0.3390, -0.1536,  0.1458])\n",
      "tricky\n",
      "Saved the embedding for tricky.\n",
      "['triumphant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2170,  0.5429, -0.1384,  ..., -1.1918,  0.2806, -0.2118])\n",
      "triumphant\n",
      "Saved the embedding for triumphant.\n",
      "['troubled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4330,  0.8130, -0.7814,  ..., -0.4786, -0.5199,  0.4505])\n",
      "troubled\n",
      "Saved the embedding for troubled.\n",
      "['troubles', '##ome'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7822,  0.5786,  0.0603,  ..., -0.5149, -0.3670,  0.4227])\n",
      "troublesome\n",
      "Saved the embedding for troublesome.\n",
      "['tr', '##ou', '##bling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0855,  0.2538,  0.0584,  ..., -0.2724, -0.3464,  0.7572])\n",
      "troubling\n",
      "Saved the embedding for troubling.\n",
      "['trusting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2435,  0.1390,  0.6880,  ..., -0.0554, -0.7500,  0.1329])\n",
      "trusting\n",
      "Saved the embedding for trusting.\n",
      "['trust', '##worthy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5093,  0.0126,  0.1811,  ..., -0.4172, -0.4935, -0.0041])\n",
      "trustworthy\n",
      "Saved the embedding for trustworthy.\n",
      "['tu', '##mu', '##lt', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3855, -0.2064, -0.3727,  ..., -0.9365, -0.5899,  0.5249])\n",
      "tumultuous\n",
      "Saved the embedding for tumultuous.\n",
      "['turbulent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0561,  0.5327, -0.2683,  ...,  0.9227, -0.2332, -0.2973])\n",
      "turbulent\n",
      "Saved the embedding for turbulent.\n",
      "['twin', '##k', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4485, -0.5578, -0.2761,  ...,  0.3260,  0.6657,  0.9359])\n",
      "twinkly\n",
      "Saved the embedding for twinkly.\n",
      "['um', '##bra', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4349, -0.3495, -0.4540,  ..., -0.7756, -0.7547,  0.7861])\n",
      "umbrage\n",
      "Saved the embedding for umbrage.\n",
      "['um', '##bra', '##ge', '##ous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1013, -0.6880, -0.5609,  ..., -0.5486, -0.5707,  0.7674])\n",
      "umbrageous\n",
      "Saved the embedding for umbrageous.\n",
      "['unaffected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0055, -0.0341, -0.1514,  ..., -0.8328, -0.7860,  0.2893])\n",
      "unaffected\n",
      "Saved the embedding for unaffected.\n",
      "['una', '##git', '##ated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4779, -0.1884, -0.2396,  ...,  0.2020, -0.1068,  0.1097])\n",
      "unagitated\n",
      "Saved the embedding for unagitated.\n",
      "['una', '##mus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3839,  0.0241, -0.2393,  ...,  0.1371,  0.1263, -0.3728])\n",
      "unamused\n",
      "Saved the embedding for unamused.\n",
      "['una', '##pp', '##re', '##cia', '##tive'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.5436, -0.0571, -0.4504,  ...,  0.3907,  0.1984, -0.1102])\n",
      "unappreciative\n",
      "Saved the embedding for unappreciative.\n",
      "['una', '##pp', '##ro', '##ach', '##able'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.4646,  0.4795, -0.2461,  ...,  0.0984,  0.0318,  0.2889])\n",
      "unapproachable\n",
      "Saved the embedding for unapproachable.\n",
      "['una', '##sser', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3912,  0.1443, -0.7261,  ..., -0.3995, -0.0634, -0.5835])\n",
      "unassertive\n",
      "Saved the embedding for unassertive.\n",
      "['una', '##ss', '##uming'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4268, -0.0814, -0.4687,  ..., -0.4665, -0.1597, -0.0158])\n",
      "unassuming\n",
      "Saved the embedding for unassuming.\n",
      "['unaware'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2349,  0.1863,  0.0895,  ..., -0.6942, -0.4455, -0.5044])\n",
      "unaware\n",
      "Saved the embedding for unaware.\n",
      "['un', '##bel', '##ie', '##f'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2929, -0.1415, -1.5687,  ..., -0.0424, -0.2985,  0.2735])\n",
      "unbelief\n",
      "Saved the embedding for unbelief.\n",
      "['unbelievable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7065,  0.0999,  0.0305,  ..., -0.3025, -1.2719, -0.3910])\n",
      "unbelievable\n",
      "Saved the embedding for unbelievable.\n",
      "['un', '##bel', '##ieving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5478, -0.1255, -0.9298,  ..., -0.5983, -0.2447, -0.1446])\n",
      "unbelieving\n",
      "Saved the embedding for unbelieving.\n",
      "['un', '##bot', '##hered'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0556, -0.0358, -1.1392,  ..., -0.1993,  0.0768,  0.0625])\n",
      "unbothered\n",
      "Saved the embedding for unbothered.\n",
      "['un', '##car', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3759,  0.1974, -1.0192,  ...,  0.1130, -0.1056,  0.4376])\n",
      "uncaring\n",
      "Saved the embedding for uncaring.\n",
      "['uncertain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0761,  0.1977,  0.5515,  ..., -0.1577,  0.0669, -0.8404])\n",
      "uncertain\n",
      "Saved the embedding for uncertain.\n",
      "['uncertain', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1682, -0.3610,  0.5754,  ..., -0.6589,  0.1475, -0.1072])\n",
      "uncertainly\n",
      "Saved the embedding for uncertainly.\n",
      "['uncertainty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1626,  0.3612, -0.0119,  ...,  0.0457, -0.0694, -0.4035])\n",
      "uncertainty\n",
      "Saved the embedding for uncertainty.\n",
      "['un', '##ci', '##vil'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2655,  0.3600, -0.9343,  ..., -0.2124,  0.0446,  0.6879])\n",
      "uncivil\n",
      "Saved the embedding for uncivil.\n",
      "['uncomfortable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5629, -0.4518,  0.1320,  ..., -0.2751, -0.0476, -0.2004])\n",
      "uncomfortable\n",
      "Saved the embedding for uncomfortable.\n",
      "['un', '##com', '##mit', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0065, -0.2220, -1.0404,  ..., -0.1790,  0.2243, -0.5775])\n",
      "uncommitted\n",
      "Saved the embedding for uncommitted.\n",
      "['un', '##com', '##mun', '##icative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1411, -0.1395, -0.9868,  ..., -0.1347,  0.0520, -0.1372])\n",
      "uncommunicative\n",
      "Saved the embedding for uncommunicative.\n",
      "['un', '##com', '##pre', '##hend', '##ing'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0092, -0.3583, -0.7940,  ..., -0.3329,  0.5447, -0.6308])\n",
      "uncomprehending\n",
      "Saved the embedding for uncomprehending.\n",
      "['un', '##com', '##promising'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0470, -0.2952, -1.2380,  ..., -0.5962,  0.5460, -0.1390])\n",
      "uncompromising\n",
      "Saved the embedding for uncompromising.\n",
      "['un', '##con', '##cer', '##ned'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0763,  0.1138, -1.1812,  ...,  0.2060,  0.4785,  0.0530])\n",
      "unconcerned\n",
      "Saved the embedding for unconcerned.\n",
      "['un', '##con', '##fide', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1538,  0.2261, -1.1953,  ...,  0.2185,  0.2035,  0.2585])\n",
      "unconfident\n",
      "Saved the embedding for unconfident.\n",
      "['un', '##con', '##vin', '##ced'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4041, -0.0183, -0.3627,  ..., -0.2828,  0.4282, -0.5547])\n",
      "unconvinced\n",
      "Saved the embedding for unconvinced.\n",
      "['un', '##co', '##oper', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2648, -0.0038, -1.2130,  ..., -0.3984, -0.0312,  0.5645])\n",
      "uncooperative\n",
      "Saved the embedding for uncooperative.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un', '##cu', '##rio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2441,  0.0896, -1.0311,  ..., -0.0097,  0.2784,  0.5465])\n",
      "uncurious\n",
      "Saved the embedding for uncurious.\n",
      "['und', '##ec', '##ided'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6635,  0.3374, -0.3854,  ...,  0.0876, -0.5049,  0.4243])\n",
      "undecided\n",
      "Saved the embedding for undecided.\n",
      "['under', '##hand', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1627, -0.0654, -0.7017,  ...,  0.0025, -0.9553,  0.8798])\n",
      "underhanded\n",
      "Saved the embedding for underhanded.\n",
      "['understanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2486,  0.7745,  0.7579,  ...,  0.4240, -0.6672, -0.1672])\n",
      "understanding\n",
      "Saved the embedding for understanding.\n",
      "['und', '##es', '##ira', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3857,  0.3759, -0.0988,  ..., -0.5175, -0.2648,  0.3105])\n",
      "undesirable\n",
      "Saved the embedding for undesirable.\n",
      "['unease'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0195,  0.0606,  0.3581,  ..., -0.0488, -0.3164, -0.2903])\n",
      "unease\n",
      "Saved the embedding for unease.\n",
      "['une', '##asi', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7539, -0.1713,  0.0286,  ..., -0.1543,  0.2629, -0.3183])\n",
      "uneasily\n",
      "Saved the embedding for uneasily.\n",
      "['une', '##asi', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6189,  0.0141, -0.2744,  ..., -0.4850, -0.0523, -0.0140])\n",
      "uneasiness\n",
      "Saved the embedding for uneasiness.\n",
      "['uneasy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6139, -0.1802, -0.0067,  ...,  0.1513,  0.2007, -0.2337])\n",
      "uneasy\n",
      "Saved the embedding for uneasy.\n",
      "['une', '##mot', '##ional'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4259, -0.2443, -0.2711,  ..., -0.2137, -0.1471,  0.0501])\n",
      "unemotional\n",
      "Saved the embedding for unemotional.\n",
      "['une', '##nt', '##hus', '##ias', '##tic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.4240, -0.1774, -0.0600,  ..., -0.1654,  0.3958, -0.0986])\n",
      "unenthusiastic\n",
      "Saved the embedding for unenthusiastic.\n",
      "['une', '##x', '##cite', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3872, -0.4796,  0.0101,  ..., -0.3079,  0.1665, -0.4871])\n",
      "unexcited\n",
      "Saved the embedding for unexcited.\n",
      "['unexpected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0921,  0.5371,  0.4329,  ..., -0.3756, -0.7302, -0.2236])\n",
      "unexpected\n",
      "Saved the embedding for unexpected.\n",
      "['unfamiliar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3491,  0.6875,  0.4176,  ...,  0.1001,  0.1033, -0.1749])\n",
      "unfamiliar\n",
      "Saved the embedding for unfamiliar.\n",
      "['un', '##fat', '##hom', '##able'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2125, -0.2356, -0.5662,  ..., -0.8073, -0.0565,  0.1414])\n",
      "unfathomable\n",
      "Saved the embedding for unfathomable.\n",
      "['un', '##fa', '##zed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3623, -0.3554, -0.3042,  ..., -0.5499,  0.3623, -0.4866])\n",
      "unfazed\n",
      "Saved the embedding for unfazed.\n",
      "['un', '##fe', '##elin', '##g'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1601, -0.1784, -1.3278,  ..., -0.5215, -0.3056,  0.1268])\n",
      "unfeeling\n",
      "Saved the embedding for unfeeling.\n",
      "['un', '##fo', '##cus', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3624, -0.4452, -1.0163,  ..., -0.1734,  0.5322,  0.1317])\n",
      "unfocused\n",
      "Saved the embedding for unfocused.\n",
      "['un', '##for', '##ese', '##en'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-4.7230e-01,  7.5198e-02, -1.0905e+00,  ...,  5.0736e-04,\n",
      "         4.0780e-02,  5.5159e-01])\n",
      "unforeseen\n",
      "Saved the embedding for unforeseen.\n",
      "['un', '##for', '##giving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1488, -0.0695, -0.8184,  ...,  0.5168,  0.4239, -0.2320])\n",
      "unforgiving\n",
      "Saved the embedding for unforgiving.\n",
      "['un', '##forth', '##coming'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1515,  0.1898, -1.1220,  ..., -0.0149,  0.4106,  0.1975])\n",
      "unforthcoming\n",
      "Saved the embedding for unforthcoming.\n",
      "['unfortunate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3424,  0.3322,  0.5197,  ..., -1.1195, -0.2313, -0.2668])\n",
      "unfortunate\n",
      "Saved the embedding for unfortunate.\n",
      "['un', '##fr', '##ien', '##dly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0182, -0.1583, -0.4911,  ..., -0.8571, -0.0997, -0.6208])\n",
      "unfriendly\n",
      "Saved the embedding for unfriendly.\n",
      "['unhappy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2731,  0.4476,  0.0854,  ..., -0.1790, -1.3670, -1.0154])\n",
      "unhappy\n",
      "Saved the embedding for unhappy.\n",
      "['un', '##hing', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5986,  0.0099, -1.1428,  ..., -0.5819, -0.2613,  0.7405])\n",
      "unhinged\n",
      "Saved the embedding for unhinged.\n",
      "['un', '##im', '##pressed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2421, -0.2417, -0.6328,  ..., -0.7241,  0.0397, -0.1062])\n",
      "unimpressed\n",
      "Saved the embedding for unimpressed.\n",
      "['un', '##in', '##formed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0264, -0.2180, -0.6948,  ..., -0.0240, -0.2747,  0.6077])\n",
      "uninformed\n",
      "Saved the embedding for uninformed.\n",
      "['un', '##ins', '##pired'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2081, -0.2403, -0.7164,  ..., -0.1637,  0.0503,  0.1940])\n",
      "uninspired\n",
      "Saved the embedding for uninspired.\n",
      "['un', '##int', '##eres', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0723, -0.2069, -0.9665,  ..., -0.2848,  0.4443, -0.0462])\n",
      "uninterested\n",
      "Saved the embedding for uninterested.\n",
      "['un', '##in', '##vo', '##lved'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2985, -0.1011, -1.0916,  ..., -0.4055, -0.0418, -0.1572])\n",
      "uninvolved\n",
      "Saved the embedding for uninvolved.\n",
      "['unique'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5139, -0.1546,  0.6515,  ..., -0.0845, -0.9483, -0.3907])\n",
      "unique\n",
      "Saved the embedding for unique.\n",
      "['unlike', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0994, -0.3403,  0.6254,  ..., -0.1057, -0.9361, -0.0986])\n",
      "unlikeable\n",
      "Saved the embedding for unlikeable.\n",
      "['un', '##mo', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4435, -0.0110, -0.9447,  ..., -0.1437, -0.3942, -0.1654])\n",
      "unmoved\n",
      "Saved the embedding for unmoved.\n",
      "['un', '##ner', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2155, -0.0479, -0.8312,  ..., -0.3261, -0.0158,  0.2277])\n",
      "unnerved\n",
      "Saved the embedding for unnerved.\n",
      "['unpleasant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4104,  0.3593,  0.2473,  ..., -0.0955, -0.2948, -0.1501])\n",
      "unpleasant\n",
      "Saved the embedding for unpleasant.\n",
      "['un', '##pre', '##par', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0631, -0.3454, -1.0559,  ..., -0.0270,  0.0415,  0.0762])\n",
      "unprepared\n",
      "Saved the embedding for unprepared.\n",
      "['un', '##qui', '##et'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0857, -0.0483, -0.8671,  ...,  0.0899,  0.1533, -0.1035])\n",
      "unquiet\n",
      "Saved the embedding for unquiet.\n",
      "['un', '##rea', '##ctive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0120, -0.0872, -0.9291,  ..., -0.3055,  0.3382,  0.2311])\n",
      "unreactive\n",
      "Saved the embedding for unreactive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un', '##res', '##olved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3734, -0.3464, -1.0613,  ...,  0.0439,  0.3188,  0.6544])\n",
      "unresolved\n",
      "Saved the embedding for unresolved.\n",
      "['unrest', '##rained'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0159,  0.5127,  0.8307,  ..., -0.8984, -0.7770, -0.5736])\n",
      "unrestrained\n",
      "Saved the embedding for unrestrained.\n",
      "['un', '##ruff', '##led'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-7.9039e-01,  1.5122e-04, -1.4045e+00,  ...,  1.8214e-01,\n",
      "         2.3196e-01,  3.0026e-01])\n",
      "unruffled\n",
      "Saved the embedding for unruffled.\n",
      "['un', '##sat', '##is', '##fied'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-9.7142e-04, -7.7382e-02, -1.1457e+00,  ..., -1.7301e-01,\n",
      "        -2.4074e-01,  9.0319e-02])\n",
      "unsatisfied\n",
      "Saved the embedding for unsatisfied.\n",
      "['un', '##sett', '##led'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4939,  0.1283, -0.6983,  ..., -0.3367, -0.0338,  0.8334])\n",
      "unsettled\n",
      "Saved the embedding for unsettled.\n",
      "['un', '##so', '##cia', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5959,  0.0475, -0.7627,  ..., -0.8026,  0.1255,  0.2663])\n",
      "unsociable\n",
      "Saved the embedding for unsociable.\n",
      "['un', '##sp', '##eak', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1228,  0.1706, -1.3926,  ..., -0.3234,  0.1529, -0.3521])\n",
      "unspeaking\n",
      "Saved the embedding for unspeaking.\n",
      "['unspoken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4340,  0.0340, -0.2872,  ..., -0.3625, -0.5120, -0.6047])\n",
      "unspoken\n",
      "Saved the embedding for unspoken.\n",
      "['un', '##st', '##run', '##g'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0463,  0.1373, -1.2242,  ..., -0.0042, -0.1048,  1.0578])\n",
      "unstrung\n",
      "Saved the embedding for unstrung.\n",
      "['unsuccessful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1215, -0.2174,  0.6500,  ...,  0.3560, -0.4659, -0.3303])\n",
      "unsuccessful\n",
      "Saved the embedding for unsuccessful.\n",
      "['unsure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2629,  0.1709,  0.1596,  ..., -0.0145,  0.4187, -0.3621])\n",
      "unsure\n",
      "Saved the embedding for unsure.\n",
      "['un', '##sur', '##pr', '##ised'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1837, -0.5157, -0.6888,  ..., -0.7949,  0.1270, -0.2425])\n",
      "unsurprised\n",
      "Saved the embedding for unsurprised.\n",
      "['un', '##sus', '##pe', '##cting'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0745, -0.1443, -1.0737,  ..., -0.1778,  0.1991, -0.1482])\n",
      "unsuspecting\n",
      "Saved the embedding for unsuspecting.\n",
      "['un', '##sw', '##ay', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3116, -0.4359, -1.1130,  ..., -0.1985,  0.0153,  0.6156])\n",
      "unswayed\n",
      "Saved the embedding for unswayed.\n",
      "['un', '##sy', '##mp', '##ath', '##etic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2690,  0.0686, -1.0117,  ..., -0.1558,  0.1673, -0.0782])\n",
      "unsympathetic\n",
      "Saved the embedding for unsympathetic.\n",
      "['untouched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3829,  0.3968, -0.4279,  ..., -0.5255, -0.4861,  0.4440])\n",
      "untouched\n",
      "Saved the embedding for untouched.\n",
      "['un', '##tro', '##ub', '##led'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3995,  0.0313, -1.1183,  ...,  0.0319,  0.3102,  0.4497])\n",
      "untroubled\n",
      "Saved the embedding for untroubled.\n",
      "['un', '##trust', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3387,  0.1836, -1.2021,  ..., -0.4041, -0.2228,  0.1534])\n",
      "untrusting\n",
      "Saved the embedding for untrusting.\n",
      "['unwanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0115,  0.7405,  0.1132,  ..., -0.6834, -0.2684, -0.2118])\n",
      "unwanted\n",
      "Saved the embedding for unwanted.\n",
      "['un', '##wave', '##ring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6237, -0.0279, -1.1241,  ..., -1.0990, -0.0478,  0.6706])\n",
      "unwavering\n",
      "Saved the embedding for unwavering.\n",
      "['un', '##we', '##lco', '##ming'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0702, -0.2905, -1.2772,  ...,  0.0236,  0.1616, -0.1053])\n",
      "unwelcoming\n",
      "Saved the embedding for unwelcoming.\n",
      "['un', '##well'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2747,  0.1977, -1.3325,  ...,  0.2388,  0.0769,  0.7790])\n",
      "unwell\n",
      "Saved the embedding for unwell.\n",
      "['unwilling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6564, -0.2606,  0.3027,  ...,  0.4128, -0.5500, -0.3014])\n",
      "unwilling\n",
      "Saved the embedding for unwilling.\n",
      "['un', '##yi', '##eld', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0026, -0.1860, -1.2050,  ..., -0.2253,  0.5177,  0.0849])\n",
      "unyielding\n",
      "Saved the embedding for unyielding.\n",
      "['up'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4856, -0.2232, -0.3486,  ...,  0.1651, -0.6479, -0.1122])\n",
      "up\n",
      "Saved the embedding for up.\n",
      "['upbeat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8608, -0.6126,  0.1706,  ..., -0.3434, -0.3946, -0.2488])\n",
      "upbeat\n",
      "Saved the embedding for upbeat.\n",
      "['up', '##lifting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1546, -0.1471, -0.5923,  ..., -0.7067, -0.8949,  0.5316])\n",
      "uplifting\n",
      "Saved the embedding for uplifting.\n",
      "['up', '##pit', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4553, -0.2019, -0.2915,  ..., -0.8010, -1.3616,  0.6059])\n",
      "uppity\n",
      "Saved the embedding for uppity.\n",
      "['upset'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0076,  0.3359,  0.8471,  ...,  0.2129, -1.4181, -0.2726])\n",
      "upset\n",
      "Saved the embedding for upset.\n",
      "['up', '##tight'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1989, -0.3404, -0.3513,  ...,  0.3907, -0.5522,  0.1569])\n",
      "uptight\n",
      "Saved the embedding for uptight.\n",
      "['useless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1774,  0.3972, -0.5681,  ..., -0.5721, -0.8970,  0.5594])\n",
      "useless\n",
      "Saved the embedding for useless.\n",
      "['vacant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1337,  0.3401,  0.5297,  ..., -0.9565, -0.8913, -0.5350])\n",
      "vacant\n",
      "Saved the embedding for vacant.\n",
      "['va', '##cu', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1592, -0.2766, -0.3092,  ..., -0.5120, -0.5289,  0.8537])\n",
      "vacuous\n",
      "Saved the embedding for vacuous.\n",
      "['van', '##qui', '##shed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0070,  0.6192, -0.1458,  ...,  0.0740,  0.2797,  0.4726])\n",
      "vanquished\n",
      "Saved the embedding for vanquished.\n",
      "['ve', '##hem', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0493,  0.1222, -0.4084,  ...,  0.3168, -0.9436,  0.6270])\n",
      "vehement\n",
      "Saved the embedding for vehement.\n",
      "['ve', '##nge', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3043,  0.5952, -0.1304,  ..., -0.5616, -0.0644,  0.4018])\n",
      "vengeful\n",
      "Saved the embedding for vengeful.\n",
      "['venom', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7064,  0.2329,  0.6568,  ...,  0.0837, -1.6796, -0.9871])\n",
      "venomous\n",
      "Saved the embedding for venomous.\n",
      "['ve', '##x'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2667,  0.1437,  0.3442,  ..., -0.0730, -1.4652,  0.1125])\n",
      "vex\n",
      "Saved the embedding for vex.\n",
      "['ve', '##xa', '##tion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2405, -0.0183,  0.3748,  ...,  0.5224, -1.3047,  0.1963])\n",
      "vexation\n",
      "Saved the embedding for vexation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ve', '##xed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3974, -0.1700,  0.1356,  ...,  0.0364, -1.4226,  0.5406])\n",
      "vexed\n",
      "Saved the embedding for vexed.\n",
      "['vicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3645,  0.7932,  0.4546,  ..., -0.0928, -0.9104, -0.0656])\n",
      "vicious\n",
      "Saved the embedding for vicious.\n",
      "['victorious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0088, -0.1459,  0.0980,  ..., -0.5282, -0.8872, -0.7480])\n",
      "victorious\n",
      "Saved the embedding for victorious.\n",
      "['vi', '##gil', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 4.0692e-02, -1.2690e-01,  2.3587e-01,  ..., -2.6046e-01,\n",
      "        -3.5716e-01,  3.2761e-04])\n",
      "vigilant\n",
      "Saved the embedding for vigilant.\n",
      "['vile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9707,  0.3933,  1.0464,  ..., -0.2730, -0.5877, -0.5175])\n",
      "vile\n",
      "Saved the embedding for vile.\n",
      "['villain', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0303,  0.9248,  0.7040,  ..., -0.2931, -0.4916,  0.1456])\n",
      "villainous\n",
      "Saved the embedding for villainous.\n",
      "['vin', '##dict', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1097, -0.0618, -0.1854,  ..., -0.3489, -0.3684,  0.6734])\n",
      "vindictive\n",
      "Saved the embedding for vindictive.\n",
      "['violence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2594,  1.0004,  0.0447,  ..., -0.6988, -0.0925,  0.3260])\n",
      "violence\n",
      "Saved the embedding for violence.\n",
      "['violent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4211,  0.6007,  0.4893,  ..., -0.9023,  0.4828, -0.5917])\n",
      "violent\n",
      "Saved the embedding for violent.\n",
      "['viper', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4221,  0.5021, -0.1802,  ..., -1.4826, -1.2598, -0.0307])\n",
      "viperous\n",
      "Saved the embedding for viperous.\n",
      "['vi', '##tu', '##per', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3511, -0.8790,  0.0523,  ..., -0.7630, -0.3190,  0.5286])\n",
      "vituperative\n",
      "Saved the embedding for vituperative.\n",
      "['vocal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3823, -0.6500, -0.7432,  ...,  0.3583, -0.3929,  0.1407])\n",
      "vocal\n",
      "Saved the embedding for vocal.\n",
      "['vocal', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2935, -0.7484,  0.0533,  ...,  0.4667, -0.6849,  0.0323])\n",
      "vocalized\n",
      "Saved the embedding for vocalized.\n",
      "['vulgar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0563,  0.2251,  0.5899,  ..., -0.9244, -0.8618,  0.9406])\n",
      "vulgar\n",
      "Saved the embedding for vulgar.\n",
      "['vulnerability'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1456,  0.1578,  0.6520,  ..., -0.5724, -1.5350, -0.1028])\n",
      "vulnerability\n",
      "Saved the embedding for vulnerability.\n",
      "['vulnerable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0727,  0.4522,  1.2833,  ..., -0.1505, -1.1157, -0.5465])\n",
      "vulnerable\n",
      "Saved the embedding for vulnerable.\n",
      "['wa', '##cky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3018, -0.4577, -0.1167,  ..., -0.5528, -0.3638,  0.6203])\n",
      "wacky\n",
      "Saved the embedding for wacky.\n",
      "['waiting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4947,  0.4859,  0.6569,  ..., -0.3729,  0.1243,  0.2469])\n",
      "waiting\n",
      "Saved the embedding for waiting.\n",
      "['wanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0593,  0.0462,  0.1149,  ...,  0.2320, -0.1996,  0.2454])\n",
      "wanted\n",
      "Saved the embedding for wanted.\n",
      "['wanting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3029,  0.0399,  0.1014,  ..., -0.2034,  0.5832, -0.3432])\n",
      "wanting\n",
      "Saved the embedding for wanting.\n",
      "['want', '##on'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1158,  0.0749, -0.0066,  ..., -0.4026, -0.6851,  0.1899])\n",
      "wanton\n",
      "Saved the embedding for wanton.\n",
      "['war', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7539,  1.2259,  0.6615,  ..., -0.2208, -0.6604,  0.8510])\n",
      "wariness\n",
      "Saved the embedding for wariness.\n",
      "['warm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0726,  0.8950,  0.0523,  ...,  0.2194, -0.0956, -0.2864])\n",
      "warm\n",
      "Saved the embedding for warm.\n",
      "['wary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3410,  0.0523,  0.2546,  ...,  0.3452, -0.8229, -0.3813])\n",
      "wary\n",
      "Saved the embedding for wary.\n",
      "['wasted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0735,  0.3371, -0.1738,  ..., -0.2319, -0.7592, -0.4340])\n",
      "wasted\n",
      "Saved the embedding for wasted.\n",
      "['watch'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3788, -0.0903, -0.4705,  ..., -0.5857, -0.3373,  0.0642])\n",
      "watch\n",
      "Saved the embedding for watch.\n",
      "['watch', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3047, -0.3520,  0.2483,  ..., -0.5465, -0.0148,  0.0770])\n",
      "watchful\n",
      "Saved the embedding for watchful.\n",
      "['watching'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3027, -0.1549, -0.9552,  ..., -0.3623,  0.1176,  0.3355])\n",
      "watching\n",
      "Saved the embedding for watching.\n",
      "['wave', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1843,  0.9336, -0.6568,  ...,  0.0617, -0.5439,  0.7049])\n",
      "wavering\n",
      "Saved the embedding for wavering.\n",
      "['wear', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5472,  0.5515,  0.2297,  ..., -0.8165, -0.5783,  0.0809])\n",
      "weariness\n",
      "Saved the embedding for weariness.\n",
      "['weary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5163, -0.2720,  0.8501,  ...,  0.0841,  0.2055,  0.1121])\n",
      "weary\n",
      "Saved the embedding for weary.\n",
      "['weeping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2532,  0.3145,  0.0775,  ..., -0.1094, -0.4490,  0.5088])\n",
      "weeping\n",
      "Saved the embedding for weeping.\n",
      "['weird'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0634,  0.4958, -0.6077,  ..., -0.3072, -0.4277,  0.5055])\n",
      "weird\n",
      "Saved the embedding for weird.\n",
      "['welcome'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1453,  0.7627,  0.8139,  ...,  0.2923, -1.2624, -0.0444])\n",
      "welcome\n",
      "Saved the embedding for welcome.\n",
      "['welcoming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0920,  0.9371,  1.0682,  ...,  0.3137, -0.7993, -0.2752])\n",
      "welcoming\n",
      "Saved the embedding for welcoming.\n",
      "['whatever'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2998,  0.5215,  0.2154,  ..., -1.2142, -1.0923, -0.0477])\n",
      "whatever\n",
      "Saved the embedding for whatever.\n",
      "['whimper', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0714, -0.0077,  0.1700,  ..., -0.5538,  0.4746, -1.1655])\n",
      "whimpering\n",
      "Saved the embedding for whimpering.\n",
      "['w', '##him', '##sic', '##al'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1574, -0.1338, -0.5873,  ..., -0.3107, -0.0011,  0.7577])\n",
      "whimsical\n",
      "Saved the embedding for whimsical.\n",
      "['whisper'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3384, -0.1763,  0.0032,  ..., -0.4582, -0.4051,  0.2119])\n",
      "whisper\n",
      "Saved the embedding for whisper.\n",
      "['whistle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.0383,  0.0310, -0.5189,  ...,  0.0398,  0.6330, -0.3485])\n",
      "whistle\n",
      "Saved the embedding for whistle.\n",
      "['white'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0399, -0.5689, -0.6053,  ..., -1.3929,  0.0335, -0.7543])\n",
      "white\n",
      "Saved the embedding for white.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wicked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5564,  0.8588,  0.3279,  ...,  0.6275,  0.3978,  0.0556])\n",
      "wicked\n",
      "Saved the embedding for wicked.\n",
      "['wild'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0407,  0.2602, -0.0314,  ..., -0.6516, -0.6798,  0.1538])\n",
      "wild\n",
      "Saved the embedding for wild.\n",
      "['will', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7357,  0.6843,  0.0975,  ...,  0.2560, -0.2128,  0.1917])\n",
      "willful\n",
      "Saved the embedding for willful.\n",
      "['willing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0754,  0.1801,  0.8074,  ..., -0.5072, -0.7769, -0.0117])\n",
      "willing\n",
      "Saved the embedding for willing.\n",
      "['wil', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0458,  0.3267, -0.3480,  ..., -0.5323, -0.5748,  0.6810])\n",
      "wily\n",
      "Saved the embedding for wily.\n",
      "['wink'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3679,  0.3561, -0.4805,  ..., -1.1033, -0.8618,  0.6259])\n",
      "wink\n",
      "Saved the embedding for wink.\n",
      "['wired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1475, -0.5383, -0.0059,  ..., -0.5588, -0.5016,  0.2430])\n",
      "wired\n",
      "Saved the embedding for wired.\n",
      "['wish', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1256,  0.1655, -0.2698,  ..., -0.3842, -0.2642,  0.3361])\n",
      "wishful\n",
      "Saved the embedding for wishful.\n",
      "['wi', '##st', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0509,  0.3071,  0.0987,  ..., -1.1459, -0.3693,  0.5079])\n",
      "wistful\n",
      "Saved the embedding for wistful.\n",
      "['wi', '##st', '##fully'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0852,  0.3100,  0.2508,  ..., -0.7359, -0.2157,  0.4898])\n",
      "wistfully\n",
      "Saved the embedding for wistfully.\n",
      "['withdraw'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3758,  0.9019, -0.2705,  ...,  0.4573, -0.1965,  0.2076])\n",
      "withdraw\n",
      "Saved the embedding for withdraw.\n",
      "['withdrawn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1648, -0.1882, -0.2479,  ...,  0.3813, -0.8612, -0.7160])\n",
      "withdrawn\n",
      "Saved the embedding for withdrawn.\n",
      "['with', '##held'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7733,  0.3185, -0.1153,  ..., -0.7542, -0.5696, -0.2067])\n",
      "withheld\n",
      "Saved the embedding for withheld.\n",
      "['with', '##holding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1815,  0.3501,  0.0618,  ..., -0.5754, -0.6837, -0.1206])\n",
      "withholding\n",
      "Saved the embedding for withholding.\n",
      "['wo', '##e'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4653,  0.5602,  0.2778,  ..., -0.4525, -0.9648,  0.3320])\n",
      "woe\n",
      "Saved the embedding for woe.\n",
      "['wo', '##ef', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2968,  0.3458, -0.1685,  ..., -0.1481, -0.0661,  0.7691])\n",
      "woeful\n",
      "Saved the embedding for woeful.\n",
      "['wonder'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6824,  0.4298, -0.3325,  ..., -0.6135, -1.0029,  0.0380])\n",
      "wonder\n",
      "Saved the embedding for wonder.\n",
      "['wondering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0876,  0.6486, -0.6403,  ...,  0.0436, -1.4493,  0.3349])\n",
      "wondering\n",
      "Saved the embedding for wondering.\n",
      "['wonder', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1844,  0.6457,  0.2964,  ..., -0.6332, -0.6802, -0.1013])\n",
      "wonderment\n",
      "Saved the embedding for wonderment.\n",
      "['wool', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1574,  0.4204, -0.2781,  ..., -0.2859, -1.3590, -0.3878])\n",
      "wooly\n",
      "Saved the embedding for wooly.\n",
      "['woo', '##zy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0192,  0.5278, -0.2362,  ..., -0.8785, -1.1026,  0.5944])\n",
      "woozy\n",
      "Saved the embedding for woozy.\n",
      "['worn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1646, -0.0553, -1.1824,  ..., -0.2846, -0.6134, -0.0124])\n",
      "worn\n",
      "Saved the embedding for worn.\n",
      "['worried'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3643,  0.5012, -0.1309,  ..., -0.3523, -1.2453, -0.0112])\n",
      "worried\n",
      "Saved the embedding for worried.\n",
      "['wo', '##rri', '##some'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1674,  0.2913,  0.1305,  ..., -1.1835, -0.5154,  0.5178])\n",
      "worrisome\n",
      "Saved the embedding for worrisome.\n",
      "['worry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3983,  0.7379, -0.4093,  ..., -0.2057, -1.0404, -0.4062])\n",
      "worry\n",
      "Saved the embedding for worry.\n",
      "['worrying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6837,  0.3039, -0.0147,  ..., -0.0336, -0.1781,  0.7654])\n",
      "worrying\n",
      "Saved the embedding for worrying.\n",
      "['worrying', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5883, -0.1332,  0.4780,  ..., -0.7312, -0.5340, -0.0553])\n",
      "worryingly\n",
      "Saved the embedding for worryingly.\n",
      "['wounded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3542,  0.2941,  0.0853,  ...,  0.0535, -0.1792,  0.7271])\n",
      "wounded\n",
      "Saved the embedding for wounded.\n",
      "['wow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3343,  0.3372, -0.4180,  ..., -0.5409, -0.8755,  0.5605])\n",
      "wow\n",
      "Saved the embedding for wow.\n",
      "['wrath', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3000,  0.8156,  0.0123,  ..., -0.4654, -1.0709,  0.7119])\n",
      "wrathful\n",
      "Saved the embedding for wrathful.\n",
      "['wrath', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1762,  0.8725,  0.0286,  ...,  0.0452, -0.5025,  0.6731])\n",
      "wrathfully\n",
      "Saved the embedding for wrathfully.\n",
      "['wrecked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1455, -0.8409,  0.2238,  ..., -0.8400, -0.6861,  0.1270])\n",
      "wrecked\n",
      "Saved the embedding for wrecked.\n",
      "['wr', '##etched'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3162, -0.1318,  0.5444,  ..., -1.1244, -0.4073,  0.1192])\n",
      "wretched\n",
      "Saved the embedding for wretched.\n",
      "['wrong', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3324,  0.2381, -0.3442,  ..., -1.0950, -0.5074,  0.6915])\n",
      "wronged\n",
      "Saved the embedding for wronged.\n",
      "['wr', '##oth'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4194,  0.3580, -0.3244,  ..., -0.4966, -0.1509, -0.1056])\n",
      "wroth\n",
      "Saved the embedding for wroth.\n",
      "['wry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6474, -0.2864,  0.0221,  ..., -0.8893, -0.1797, -0.3706])\n",
      "wry\n",
      "Saved the embedding for wry.\n",
      "['ya', '##wn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3858,  0.3655,  0.1050,  ..., -0.1914, -1.3791, -0.0866])\n",
      "yawn\n",
      "Saved the embedding for yawn.\n",
      "['ya', '##wn', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6691,  0.4533, -0.6884,  ..., -0.5833, -1.1349,  0.2529])\n",
      "yawning\n",
      "Saved the embedding for yawning.\n",
      "['yearning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2857, -0.3817, -0.0982,  ..., -0.9475, -0.9173, -0.2672])\n",
      "yearning\n",
      "Saved the embedding for yearning.\n",
      "['yell'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1778,  0.3565, -0.0143,  ..., -1.1565, -0.7323,  0.5251])\n",
      "yell\n",
      "Saved the embedding for yell.\n",
      "['yelling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0439,  0.3337, -0.4959,  ..., -0.1348,  0.0562, -0.1390])\n",
      "yelling\n",
      "Saved the embedding for yelling.\n",
      "['yielding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0285,  0.1302,  0.9239,  ..., -0.4719, -0.7397,  0.1066])\n",
      "yielding\n",
      "Saved the embedding for yielding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yu', '##ck'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5949,  0.2492,  0.6811,  ...,  0.0486, -0.6737,  0.6232])\n",
      "yuck\n",
      "Saved the embedding for yuck.\n",
      "['za', '##ny'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6550,  1.2369, -0.9386,  ..., -1.0238, -0.5476,  0.5598])\n",
      "zany\n",
      "Saved the embedding for zany.\n",
      "['ze', '##alo', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8600, -0.2303, -0.6630,  ..., -0.3600,  0.3167, -0.0689])\n",
      "zealous\n",
      "Saved the embedding for zealous.\n",
      "['zen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1668,  0.3055, -0.4071,  ..., -0.5739, -0.3290,  0.5896])\n",
      "zen\n",
      "Saved the embedding for zen.\n",
      "['zone', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4880,  0.6528,  0.2187,  ..., -0.4170, -0.9627, -0.3530])\n",
      "zoned\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Set up input and output paths.\n",
    "vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "layer_combining_function = cat_middle_four1\n",
    "embeddings_file = os.path.join('/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab', layer_combining_function.__name__ + '.txt')\n",
    "if os.path.exists(embeddings_file):\n",
    "    os.remove(embeddings_file)\n",
    "\n",
    "    # Create a list of vocabulary words we want embeddings for.\n",
    "vocab = make_vocab(vocab_file)\n",
    "\n",
    "# Tokenize the vocabulary and look up the BERT token indices.\n",
    "tokenized_text, indexed_tokens = tokenize_text(vocab)\n",
    "\n",
    "# Generate segment IDs for each token.\n",
    "segments_IDs = generate_segments_IDs(tokenized_text)\n",
    "\n",
    "# Generate and write out the contextual embeddings for the vocabulary words.\n",
    "# Embeddings are saved in a standard format that can be used for calcualting\n",
    "# the cosine distances between word vectors.\n",
    "for i in range(len(tokenized_text)):\n",
    "    # Convert indexed tokens and segments to tensors.\n",
    "    # Create a BERT model for the tokens.\n",
    "    # Get the encoded model layers and reshape them.\n",
    "    token_embeddings = generate_embeddings(indexed_tokens[i], segments_IDs[i])\n",
    "    print(f'{tokenized_text[i]} has a token embedding of size {token_embeddings.size()}')\n",
    "\n",
    "    # Extract the contextual embedding for a token.\n",
    "    contextual_embedding = layer_combining_function(token_embeddings)\n",
    "\n",
    "    # Write the embedding to a text file, with the vocabulary word prepended.\n",
    "    vocab_word = reconstruct_tokens(tokenized_text[i])\n",
    "    # Make sure we've got the correct vocabulary word.\n",
    "    assert vocab[i] == vocab_word\n",
    "    write_embedding(embeddings_file, vocab[i], contextual_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
