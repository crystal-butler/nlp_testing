{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Notebooks/crystal/NLP/nlp_testing'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgusted'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]\n",
    "list(tokenizer.vocab.keys())[17733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"disgusted\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreate vocabulary words from their tokenized representations.\n",
    "for t in tokenized_text:\n",
    "    this_word = ''\n",
    "    for token in t:\n",
    "        this_word += token.strip('#')\n",
    "#     print(this_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mark each of the tokens as belonging to sentence \"0\" or \"1\".\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text[3])\n",
    "# segments_ids = [0,0,0]\n",
    "print (segments_ids)\n",
    "print(indexed_tokens)\n",
    "print(tokenized_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens[3]])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 1\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For our token, select its feature values from layer 5.\n",
    "token_i = 1\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# print(vec)\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 1 x 3072\n",
      "tensor([-0.2373,  0.8259, -0.6190,  ..., -0.3836, -0.5039,  0.6153])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_last = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "print(token_vecs_cat_last[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 1 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_last = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_last.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_last), len(token_vecs_sum_last[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the first 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the first 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:4], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_first.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_first), len(token_vecs_sum_first[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[4:8], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle1.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle1), len(token_vecs_sum_middle1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[8:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle2.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle2), len(token_vecs_sum_middle2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate all hidden layers to create word embeddings.\n",
    "token_vecs_cat_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3], token[4], token[5], token[6], token[7], token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_all.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_all), len(token_vecs_cat_all[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum all hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_all.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_all), len(token_vecs_sum_all[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a single vector to represent the pair of sentences by averaging across tokens.\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "sentences_vec = []\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "for s in sentence_embedding:\n",
    "    sentences_vec.append(s)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "print(sentence_embedding[767])\n",
    "print(sentence_embedding[-1])\n",
    "print(f'Shape of sentences vector is: {len(sentences_vec)}')\n",
    "print(sentences_vec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# Test the similarity of a word with itself.\n",
    "# For words trained contextually, self-synonymy is less than 1.\n",
    "similarity = 1 - cosine(token_vecs_cat[0], token_vecs_cat[0])\n",
    "print(f'Similarity of {tokenized_text[8]} and {tokenized_text[8]} in token_vecs_cat is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum[4], token_vecs_sum[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_first[4], token_vecs_cat_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_first[4], token_vecs_sum_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle1[4], token_vecs_cat_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle1[4], token_vecs_sum_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle2[4], token_vecs_cat_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle2[4], token_vecs_sum_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_all[4], token_vecs_cat_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_all is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_all[4], token_vecs_sum_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_all is: {similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "############## BEGIN TESTING STATIC CONTEXTUAL EMBEDDING CREATION ####################\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(vocab_file):\n",
    "    # start = timer()\n",
    "    vocab = []\n",
    "    # vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "    with open(vocab_file, 'r') as v:\n",
    "        vocab = v.read().splitlines()\n",
    "    # end = timer()\n",
    "    # run_time = end - start\n",
    "#     print(f'There are {len(vocab)} words in the vocabulary.\\n')\n",
    "#     print(f'It took {run_time} seconds to read the vocabulary file into memory.')\n",
    "#     print(f'Test word is {vocab[2]}.')\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(vocab):\n",
    "    tokenized_text = []\n",
    "    indexed_tokens = []\n",
    "    for word in vocab:\n",
    "        # Add the special tokens.\n",
    "    #     marked_text = \"[CLS] \" + word + \" [SEP]\"\n",
    "        marked_text = word\n",
    "\n",
    "        # Split the sentence into tokens.\n",
    "        # tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        tokenized_text.append(tokenizer.tokenize(marked_text))\n",
    "#         print(f'Added {tokenized_text[-1]} to the tokenized_text array.')\n",
    "\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens.append(tokenizer.convert_tokens_to_ids(tokenized_text[-1]))\n",
    "\n",
    "        # Display the words with their indeces.\n",
    "    #     print(f'The word {tokenized_text[-1][1]} is at index {indexed_tokens[-1]}.')\n",
    "#         for tup in zip(tokenized_text[-1], indexed_tokens[-1]):\n",
    "#             print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "    return tokenized_text, indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_segments_IDs(tokenized_text):\n",
    "    # Create segment IDs for sentence 1 (there can be a sentence 0 to compare to\n",
    "    # sentence 1, but we're not doing that).\n",
    "    # Check that indices and token indices look correct.\n",
    "    segments_IDs = []\n",
    "    for i in range(len(tokenized_text)):\n",
    "        segments_IDs.append([1] * len(tokenized_text[i]))\n",
    "#     for i in range(len(segments_IDs)):\n",
    "#         print (segments_IDs[i])\n",
    "#         print(tokenized_text[i])\n",
    "    return segments_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(indexed_tokens, segments_IDs):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_IDs])\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "#         print('Type of encoded_layers: ', type(encoded_layers))\n",
    "        # Each layer in the list is a torch tensor.\n",
    "#         print('Tensor shape for each layer: ', encoded_layers[0].size())\n",
    "\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "#     print(token_embeddings.size())\n",
    "    \n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_last_four(token_embeddings): \n",
    "    # Concatenate the last 4 hidden layers to create contextual embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_last = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "    print(token_vecs_cat_last[0])\n",
    "    \n",
    "    return token_vecs_cat_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_first_four(token_embeddings):\n",
    "    token_vecs_cat_first = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "    print(token_vecs_cat_first[0])\n",
    "    \n",
    "    return token_vecs_cat_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_embedding(token_embeddings):\n",
    "    mean_embedding = sum(token_embeddings) / len(token_embeddings)\n",
    "    print(mean_embedding)\n",
    "    \n",
    "    return mean_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_tokens(tokenized_text):\n",
    "    vocab_word = ''\n",
    "    for i in tokenized_text:\n",
    "        vocab_word += i.strip('#')\n",
    "    print(vocab_word)\n",
    "\n",
    "    return vocab_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_embedding(embeddings_file, vocab_word, contextual_embedding):\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(vocab_word)\n",
    "            for value in contextual_embedding[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {vocab_word}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aback'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5053,  0.4971,  0.0317,  ..., -0.9494,  0.5799,  0.7537])\n",
      "aback\n",
      "Saved the embedding for aback.\n",
      "['aba', '##shed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1385,  0.1992, -0.6109,  ..., -0.1529,  0.0258, -0.1901])\n",
      "abashed\n",
      "Saved the embedding for abashed.\n",
      "['ab', '##hor'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0943,  0.3695, -1.2897,  ...,  0.1303,  0.2182,  0.5159])\n",
      "abhor\n",
      "Saved the embedding for abhor.\n",
      "['ab', '##hor', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0665,  0.2880, -1.2760,  ...,  0.0154,  0.2874,  0.4358])\n",
      "abhorred\n",
      "Saved the embedding for abhorred.\n",
      "['ab', '##hor', '##rence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0444,  0.3661, -1.2157,  ..., -0.0860,  0.2170,  0.4015])\n",
      "abhorrence\n",
      "Saved the embedding for abhorrence.\n",
      "['ab', '##hor', '##rent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0299,  0.3516, -1.1975,  ..., -0.1055,  0.1379,  0.5008])\n",
      "abhorrent\n",
      "Saved the embedding for abhorrent.\n",
      "['ab', '##omi', '##nable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1525,  0.3198, -1.2715,  ..., -0.0955,  0.4356,  0.5340])\n",
      "abominable\n",
      "Saved the embedding for abominable.\n",
      "['ab', '##ound'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0638,  0.2629, -1.2453,  ...,  0.0225,  0.1847,  0.4092])\n",
      "abound\n",
      "Saved the embedding for abound.\n",
      "['absent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4521,  0.1061, -0.4779,  ...,  0.2767, -0.0463, -0.0110])\n",
      "absent\n",
      "Saved the embedding for absent.\n",
      "['absorbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7795,  0.8153,  0.0398,  ..., -0.5581, -0.3897,  0.4518])\n",
      "absorbed\n",
      "Saved the embedding for absorbed.\n",
      "['acceptance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1205,  0.5259, -0.0911,  ..., -0.2337, -0.0629,  0.7135])\n",
      "acceptance\n",
      "Saved the embedding for acceptance.\n",
      "['accepted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 3.6161e-04,  4.9226e-01, -2.7979e-01,  ..., -9.9633e-02,\n",
      "         2.3448e-01,  5.4789e-01])\n",
      "accepted\n",
      "Saved the embedding for accepted.\n",
      "['accepting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0763,  0.3260, -0.4907,  ..., -0.1538, -0.0674,  0.4879])\n",
      "accepting\n",
      "Saved the embedding for accepting.\n",
      "['acc', '##om', '##mo', '##dating'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3355, -0.2063, -0.0745,  ...,  0.3892,  0.7441,  0.8218])\n",
      "accommodating\n",
      "Saved the embedding for accommodating.\n",
      "['accomplished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5944,  0.7593, -0.1734,  ..., -0.4961,  0.2025, -0.1727])\n",
      "accomplished\n",
      "Saved the embedding for accomplished.\n",
      "['accord', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3170, -0.1001, -0.0009,  ...,  0.7048,  0.8281,  0.2016])\n",
      "accordant\n",
      "Saved the embedding for accordant.\n",
      "['acc', '##urse', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3793, -0.1344,  0.1207,  ...,  0.5067,  0.7098,  0.9900])\n",
      "accursed\n",
      "Saved the embedding for accursed.\n",
      "['acc', '##usa', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2960, -0.3214,  0.0889,  ...,  0.7691,  0.7250,  0.8146])\n",
      "accusatory\n",
      "Saved the embedding for accusatory.\n",
      "['accused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1689,  0.2206,  0.2253,  ..., -0.1096,  0.1622,  0.0140])\n",
      "accused\n",
      "Saved the embedding for accused.\n",
      "['accusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3663, -0.0284,  0.0976,  ..., -0.3368,  0.4107,  0.0374])\n",
      "accusing\n",
      "Saved the embedding for accusing.\n",
      "['ace', '##rb', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.0707, 0.2103, 0.2219,  ..., 0.1299, 0.4903, 0.3016])\n",
      "acerbic\n",
      "Saved the embedding for acerbic.\n",
      "['acidic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2818,  0.6978, -0.2317,  ..., -0.2214, -0.2032,  0.1642])\n",
      "acidic\n",
      "Saved the embedding for acidic.\n",
      "['active'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2326,  0.9250, -0.1191,  ..., -0.0390,  0.0167,  0.3701])\n",
      "active\n",
      "Saved the embedding for active.\n",
      "['acute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4748,  0.2792,  0.3337,  ..., -0.3865,  0.3020,  0.3140])\n",
      "acute\n",
      "Saved the embedding for acute.\n",
      "['adamant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3846, -0.0636, -0.6831,  ..., -0.5805,  0.6256, -0.0859])\n",
      "adamant\n",
      "Saved the embedding for adamant.\n",
      "['add', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1636, -0.4818, -0.4597,  ...,  0.1920,  0.1332,  0.5782])\n",
      "addled\n",
      "Saved the embedding for addled.\n",
      "['admiration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([1.1107, 0.5495, 0.0098,  ..., 0.3824, 0.7252, 0.2131])\n",
      "admiration\n",
      "Saved the embedding for admiration.\n",
      "['admit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0801, -0.1251,  0.1254,  ...,  0.7289,  0.9093,  1.1929])\n",
      "admit\n",
      "Saved the embedding for admit.\n",
      "['ad', '##oration'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0249,  0.0707, -0.0193,  ..., -0.3659,  0.1235,  1.1537])\n",
      "adoration\n",
      "Saved the embedding for adoration.\n",
      "['ad', '##orin', '##g'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1172, -0.2434, -0.0824,  ...,  0.0838,  0.1723,  1.0008])\n",
      "adoring\n",
      "Saved the embedding for adoring.\n",
      "['ad', '##rift'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2050, -0.3438, -0.0324,  ...,  0.1996,  0.3146,  1.0630])\n",
      "adrift\n",
      "Saved the embedding for adrift.\n",
      "['ad', '##vers', '##aria', '##l'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0666, -0.2499, -0.1469,  ..., -0.2066, -0.0153,  1.1773])\n",
      "adversarial\n",
      "Saved the embedding for adversarial.\n",
      "['af', '##fa', '##bility'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3977,  0.2998, -0.3589,  ..., -0.0217,  0.6209, -0.1415])\n",
      "affability\n",
      "Saved the embedding for affability.\n",
      "['affected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2981,  0.5739, -0.1980,  ..., -0.6815, -0.2972,  0.5221])\n",
      "affected\n",
      "Saved the embedding for affected.\n",
      "['affection', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1900,  0.3582,  0.1356,  ..., -0.4018,  0.5205,  0.6047])\n",
      "affectionate\n",
      "Saved the embedding for affectionate.\n",
      "['af', '##flict', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1690,  0.3284, -0.4128,  ..., -0.1809,  0.6392, -0.2326])\n",
      "afflicted\n",
      "Saved the embedding for afflicted.\n",
      "['af', '##front', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2510,  0.3494, -0.5215,  ...,  0.0173,  0.5817, -0.0752])\n",
      "affronted\n",
      "Saved the embedding for affronted.\n",
      "['afl', '##utter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9138,  0.4283, -0.3716,  ...,  0.0233,  0.0200,  0.2565])\n",
      "aflutter\n",
      "Saved the embedding for aflutter.\n",
      "['afraid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0737,  0.2915, -0.1547,  ..., -0.2382, -0.0785,  0.6777])\n",
      "afraid\n",
      "Saved the embedding for afraid.\n",
      "['ag', '##ape'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0769,  0.9567, -0.1925,  ..., -0.2054,  0.8228,  0.7902])\n",
      "agape\n",
      "Saved the embedding for agape.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggravated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1777,  0.4265, -0.1913,  ..., -0.1204, -0.2994,  0.2673])\n",
      "aggravated\n",
      "Saved the embedding for aggravated.\n",
      "['ag', '##gra', '##vation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0667,  1.0663, -0.3278,  ..., -0.1178,  0.6243,  0.8914])\n",
      "aggravation\n",
      "Saved the embedding for aggravation.\n",
      "['aggression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1853,  1.0595, -0.3109,  ..., -0.1024, -0.0157,  0.5554])\n",
      "aggression\n",
      "Saved the embedding for aggression.\n",
      "['aggressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0088,  0.5032, -0.5507,  ..., -0.0484,  0.1403,  0.2706])\n",
      "aggressive\n",
      "Saved the embedding for aggressive.\n",
      "['ag', '##gr', '##ie', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1614,  0.7959, -0.3026,  ..., -0.2129,  0.8440,  0.9215])\n",
      "aggrieve\n",
      "Saved the embedding for aggrieve.\n",
      "['ag', '##gr', '##ie', '##ved'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1654,  0.7993, -0.3148,  ..., -0.1785,  0.7905,  0.9246])\n",
      "aggrieved\n",
      "Saved the embedding for aggrieved.\n",
      "['ag', '##has', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1019,  0.8534, -0.2746,  ..., -0.1449,  0.9297,  0.8703])\n",
      "aghast\n",
      "Saved the embedding for aghast.\n",
      "['agitated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0096,  0.9270, -0.4666,  ..., -0.3978,  0.0863,  0.7954])\n",
      "agitated\n",
      "Saved the embedding for agitated.\n",
      "['ago', '##g'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4704,  0.7104,  0.0192,  ..., -0.9048,  0.0639,  1.0450])\n",
      "agog\n",
      "Saved the embedding for agog.\n",
      "['ago', '##ni', '##zed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4335,  0.6901, -0.1771,  ..., -0.8478, -0.0159,  1.1202])\n",
      "agonized\n",
      "Saved the embedding for agonized.\n",
      "['agree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4308,  0.4233,  0.2899,  ..., -0.0703,  0.8025,  0.5212])\n",
      "agreeable\n",
      "Saved the embedding for agreeable.\n",
      "['ag', '##ress', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1005,  1.0699, -0.3213,  ..., -0.2663,  0.7951,  0.7708])\n",
      "agressive\n",
      "Saved the embedding for agressive.\n",
      "['air', '##head'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6639,  0.8847,  0.6294,  ..., -0.2565,  0.4113, -0.3863])\n",
      "airhead\n",
      "Saved the embedding for airhead.\n",
      "['alarm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1222,  0.6413, -0.5854,  ..., -0.0542, -0.0137, -0.6760])\n",
      "alarm\n",
      "Saved the embedding for alarm.\n",
      "['alarmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3262,  0.2881, -0.8592,  ..., -0.1767,  0.3700,  0.3378])\n",
      "alarmed\n",
      "Saved the embedding for alarmed.\n",
      "['alarm', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1122,  0.6816, -0.5081,  ..., -0.0787,  0.3642, -0.6778])\n",
      "alarming\n",
      "Saved the embedding for alarming.\n",
      "['alert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2504,  0.4888,  0.3502,  ..., -0.9463,  0.6425, -0.8461])\n",
      "alert\n",
      "Saved the embedding for alert.\n",
      "['alerted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3156,  0.5728, -0.5240,  ..., -0.2714,  0.3028, -0.0503])\n",
      "alerted\n",
      "Saved the embedding for alerted.\n",
      "['alien', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0818,  0.2480,  0.4116,  ..., -0.4162, -0.0440, -0.1612])\n",
      "alienated\n",
      "Saved the embedding for alienated.\n",
      "['allergic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2866,  0.2021,  0.0675,  ..., -0.3051, -0.3642, -0.2076])\n",
      "allergic\n",
      "Saved the embedding for allergic.\n",
      "['alleviate', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2998,  0.2491,  0.1289,  ..., -0.6662, -0.1526,  0.1656])\n",
      "alleviated\n",
      "Saved the embedding for alleviated.\n",
      "['all', '##uring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2253,  0.0058, -0.2638,  ...,  0.4658,  0.1473, -0.0081])\n",
      "alluring\n",
      "Saved the embedding for alluring.\n",
      "['al', '##oof'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5146, -0.0272, -0.0992,  ...,  0.6112,  0.1657,  0.4889])\n",
      "aloof\n",
      "Saved the embedding for aloof.\n",
      "['ama', '##tory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4161, -0.3371, -0.2572,  ..., -0.0369,  0.5298,  0.1601])\n",
      "amatory\n",
      "Saved the embedding for amatory.\n",
      "['amazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5026,  0.1645, -0.4694,  ...,  0.1452,  0.2892,  0.8518])\n",
      "amazed\n",
      "Saved the embedding for amazed.\n",
      "['amazement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6219,  0.6121, -0.0926,  ..., -0.3612,  0.3343,  0.4862])\n",
      "amazement\n",
      "Saved the embedding for amazement.\n",
      "['amazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4215, -0.0483, -0.1648,  ..., -0.0957,  0.1689, -0.1652])\n",
      "amazing\n",
      "Saved the embedding for amazing.\n",
      "['ambition'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3765, -0.2162,  0.2079,  ..., -0.1689,  0.4423,  0.2911])\n",
      "ambition\n",
      "Saved the embedding for ambition.\n",
      "['ambitious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3806,  0.2907,  0.1204,  ..., -0.0781,  0.2049,  0.1305])\n",
      "ambitious\n",
      "Saved the embedding for ambitious.\n",
      "['am', '##bi', '##vale', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0596, -0.2629, -0.1610,  ..., -0.2080,  0.3961,  0.3136])\n",
      "ambivalence\n",
      "Saved the embedding for ambivalence.\n",
      "['am', '##bi', '##valent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0855, -0.3003, -0.0858,  ..., -0.1764,  0.5322,  0.2354])\n",
      "ambivalent\n",
      "Saved the embedding for ambivalent.\n",
      "['am', '##ena', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1398, -0.3007,  0.0014,  ..., -0.1737,  0.6472,  0.2476])\n",
      "amenable\n",
      "Saved the embedding for amenable.\n",
      "['ami', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0493, -0.6528,  0.0585,  ..., -0.0295,  0.6878,  0.6993])\n",
      "amiable\n",
      "Saved the embedding for amiable.\n",
      "['ami', '##cable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1929, -0.6145,  0.3026,  ...,  0.1835,  0.6596,  0.5605])\n",
      "amicable\n",
      "Saved the embedding for amicable.\n",
      "['amused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0135,  0.5777, -0.1599,  ..., -0.6088,  0.7464,  0.6337])\n",
      "amused\n",
      "Saved the embedding for amused.\n",
      "['amusement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1948,  0.9442,  0.1725,  ..., -0.1322,  0.3062,  0.4754])\n",
      "amusement\n",
      "Saved the embedding for amusement.\n",
      "['analytical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0190,  1.4264, -0.0962,  ...,  0.2647, -0.1238,  0.2906])\n",
      "analytical\n",
      "Saved the embedding for analytical.\n",
      "['analyzing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1899,  1.0511,  0.0322,  ..., -0.1180, -0.4331,  0.4083])\n",
      "analyzing\n",
      "Saved the embedding for analyzing.\n",
      "['anger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0792,  1.2233, -0.1786,  ..., -0.0681, -0.1048,  0.4824])\n",
      "anger\n",
      "Saved the embedding for anger.\n",
      "['angered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1072,  0.4118, -0.4205,  ..., -0.0934,  0.0183,  0.2755])\n",
      "angered\n",
      "Saved the embedding for angered.\n",
      "['angrily'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1583, -0.0754, -0.7228,  ..., -0.1329,  0.6738,  0.0101])\n",
      "angrily\n",
      "Saved the embedding for angrily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1087,  0.5733, -0.3362,  ..., -0.0491,  0.3709,  0.4512])\n",
      "angry\n",
      "Saved the embedding for angry.\n",
      "['ang', '##st'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3287,  0.1654, -0.1497,  ..., -0.2954,  0.2572,  0.5989])\n",
      "angst\n",
      "Saved the embedding for angst.\n",
      "['anguish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3491,  0.3474, -0.4197,  ...,  0.1957,  0.3298,  0.0772])\n",
      "anguish\n",
      "Saved the embedding for anguish.\n",
      "['anguish', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2998,  0.3180, -0.4168,  ...,  0.1504,  0.3565,  0.3088])\n",
      "anguished\n",
      "Saved the embedding for anguished.\n",
      "['animated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1402,  0.2226, -0.3230,  ...,  0.6311,  0.7730,  0.6633])\n",
      "animated\n",
      "Saved the embedding for animated.\n",
      "['an', '##imo', '##sity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1607,  0.3769, -0.2438,  ..., -0.3759,  0.1383,  0.7063])\n",
      "animosity\n",
      "Saved the embedding for animosity.\n",
      "['annoyance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2053,  0.1891,  0.1939,  ..., -0.6405,  0.0541,  0.4799])\n",
      "annoyance\n",
      "Saved the embedding for annoyance.\n",
      "['annoyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1482,  0.2925,  0.0670,  ..., -0.4254,  0.1755,  0.5588])\n",
      "annoyed\n",
      "Saved the embedding for annoyed.\n",
      "['annoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0753,  0.2327,  0.2018,  ..., -0.0659, -0.0038,  0.6942])\n",
      "annoying\n",
      "Saved the embedding for annoying.\n",
      "['antagonist', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2095,  0.4188, -0.3818,  ..., -0.1000,  0.1955,  0.7520])\n",
      "antagonistic\n",
      "Saved the embedding for antagonistic.\n",
      "['ant', '##ago', '##ni', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4141,  0.4296, -0.2522,  ..., -0.3733,  0.2298, -0.2282])\n",
      "antagonized\n",
      "Saved the embedding for antagonized.\n",
      "['anticipated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0919,  0.5220, -0.4011,  ..., -0.0329,  0.3526, -0.3940])\n",
      "anticipated\n",
      "Saved the embedding for anticipated.\n",
      "['anticipating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0259,  0.5039, -0.1975,  ..., -0.0035,  0.3437,  0.3652])\n",
      "anticipating\n",
      "Saved the embedding for anticipating.\n",
      "['anticipation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2147,  0.2693, -0.2175,  ..., -0.5441,  0.2814, -0.1097])\n",
      "anticipation\n",
      "Saved the embedding for anticipation.\n",
      "['anti', '##ci', '##pati', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0593,  0.0568,  0.3754,  ..., -0.4786, -0.1632,  0.2918])\n",
      "anticipative\n",
      "Saved the embedding for anticipative.\n",
      "['anti', '##ci', '##pa', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0230, -0.0152,  0.3542,  ..., -0.2529, -0.1224,  0.3169])\n",
      "anticipatory\n",
      "Saved the embedding for anticipatory.\n",
      "['anti', '##pathy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0037,  0.0492,  0.2924,  ..., -0.1397, -0.3223,  0.0923])\n",
      "antipathy\n",
      "Saved the embedding for antipathy.\n",
      "['ants', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0677,  0.3223,  0.0602,  ..., -0.1033,  0.2030, -0.0634])\n",
      "antsy\n",
      "Saved the embedding for antsy.\n",
      "['anxiety'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5603,  0.6207, -0.2761,  ..., -0.5699, -0.4852,  0.3996])\n",
      "anxiety\n",
      "Saved the embedding for anxiety.\n",
      "['anxious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4838,  0.3643, -0.0884,  ..., -0.4135,  0.1575,  0.3860])\n",
      "anxious\n",
      "Saved the embedding for anxious.\n",
      "['anxiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0205, -0.3760, -0.6429,  ..., -0.0343,  0.3875,  0.0926])\n",
      "anxiously\n",
      "Saved the embedding for anxiously.\n",
      "['ap', '##ath', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0879,  0.5116, -0.2899,  ..., -0.6720, -0.2232,  0.2488])\n",
      "apathetic\n",
      "Saved the embedding for apathetic.\n",
      "['ap', '##athy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0215,  0.5857, -0.3594,  ..., -0.7559, -0.1834, -0.0104])\n",
      "apathy\n",
      "Saved the embedding for apathy.\n",
      "['apologetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3353,  0.4886,  0.0352,  ...,  0.5679,  0.6259,  0.4588])\n",
      "apologetic\n",
      "Saved the embedding for apologetic.\n",
      "['appalled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4226,  0.2816, -0.8448,  ..., -0.1593,  0.5125,  0.2620])\n",
      "appalled\n",
      "Saved the embedding for appalled.\n",
      "['app', '##all', '##ingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3095, -0.1918,  0.0156,  ..., -0.4695,  0.6407,  0.6907])\n",
      "appallingly\n",
      "Saved the embedding for appallingly.\n",
      "['app', '##eased'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3802, -0.3281, -0.0518,  ..., -0.2110,  0.9099,  0.7724])\n",
      "appeased\n",
      "Saved the embedding for appeased.\n",
      "['app', '##ea', '##sing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2316, -0.1585,  0.0556,  ..., -0.2788,  0.9482,  0.7155])\n",
      "appeasing\n",
      "Saved the embedding for appeasing.\n",
      "['app', '##re', '##cia', '##tive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3863, -0.1259,  0.0493,  ..., -0.6438,  0.5908,  0.7257])\n",
      "appreciative\n",
      "Saved the embedding for appreciative.\n",
      "['apprehension'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4275,  0.4010, -0.0921,  ..., -0.0405,  0.0957,  0.4274])\n",
      "apprehension\n",
      "Saved the embedding for apprehension.\n",
      "['app', '##re', '##hen', '##sive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2671, -0.1467, -0.1140,  ..., -0.6458,  0.7720,  0.7534])\n",
      "apprehensive\n",
      "Saved the embedding for apprehensive.\n",
      "['approve'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1263,  0.0360,  0.2067,  ...,  0.2497,  0.4604,  0.1057])\n",
      "approve\n",
      "Saved the embedding for approve.\n",
      "['approved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1129,  0.2867,  0.0020,  ...,  0.2296,  0.3400,  0.1344])\n",
      "approved\n",
      "Saved the embedding for approved.\n",
      "['app', '##roving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2056, -0.2875,  0.0824,  ..., -0.3209,  0.8965,  0.6169])\n",
      "approving\n",
      "Saved the embedding for approving.\n",
      "['argue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1291,  0.7469, -0.4794,  ...,  0.3936,  0.5880,  0.8184])\n",
      "argue\n",
      "Saved the embedding for argue.\n",
      "['argument', '##ative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5548,  0.6958, -0.5868,  ...,  0.6235, -0.0118,  1.1090])\n",
      "argumentative\n",
      "Saved the embedding for argumentative.\n",
      "['aroused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0364,  0.5569,  0.2744,  ..., -0.4262,  0.4517,  0.3641])\n",
      "aroused\n",
      "Saved the embedding for aroused.\n",
      "['arrogance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8047,  0.4682, -0.0177,  ..., -0.1153,  0.2640,  0.4821])\n",
      "arrogance\n",
      "Saved the embedding for arrogance.\n",
      "['arrogant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5770,  0.6421,  0.3445,  ..., -0.0454,  0.2287,  0.3213])\n",
      "arrogant\n",
      "Saved the embedding for arrogant.\n",
      "['arrogant', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4500,  0.7433,  0.3558,  ..., -0.1435,  0.3087,  0.4983])\n",
      "arrogantly\n",
      "Saved the embedding for arrogantly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3631,  0.4375, -0.0695,  ..., -0.8754, -0.4007,  0.5359])\n",
      "artificial\n",
      "Saved the embedding for artificial.\n",
      "['ashamed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0583, -0.0833, -0.4251,  ..., -0.1705, -0.1941,  0.0921])\n",
      "ashamed\n",
      "Saved the embedding for ashamed.\n",
      "['aspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3538, -0.2145, -0.2146,  ..., -0.4136,  0.1431, -0.1170])\n",
      "aspiring\n",
      "Saved the embedding for aspiring.\n",
      "['assert', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6213,  0.4932, -0.4482,  ..., -0.3063, -0.0021,  0.6945])\n",
      "assertive\n",
      "Saved the embedding for assertive.\n",
      "['assert', '##ively'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6273,  0.3859, -0.3971,  ...,  0.1550, -0.0304,  0.5407])\n",
      "assertively\n",
      "Saved the embedding for assertively.\n",
      "['assessing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0338,  0.3858,  0.0530,  ..., -0.2291,  0.4045,  0.8602])\n",
      "assessing\n",
      "Saved the embedding for assessing.\n",
      "['assured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1375,  0.1481, -0.2244,  ..., -0.5895,  0.7862,  0.4941])\n",
      "assured\n",
      "Saved the embedding for assured.\n",
      "['astonished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1536,  0.2299, -0.3622,  ..., -0.2241,  0.5853,  0.2651])\n",
      "astonished\n",
      "Saved the embedding for astonished.\n",
      "['astonishment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1233,  0.5736, -0.0812,  ..., -0.4841,  0.5994,  0.4071])\n",
      "astonishment\n",
      "Saved the embedding for astonishment.\n",
      "['as', '##tou', '##nded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0403,  0.1890, -0.1266,  ...,  0.0801,  0.3617,  0.2982])\n",
      "astounded\n",
      "Saved the embedding for astounded.\n",
      "['attempting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3154,  0.5950, -0.4634,  ..., -0.0723,  0.0161,  0.4245])\n",
      "attempting\n",
      "Saved the embedding for attempting.\n",
      "['at', '##ten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1184,  0.2851, -0.1315,  ...,  0.0055,  0.2654,  0.5046])\n",
      "attentive\n",
      "Saved the embedding for attentive.\n",
      "['at', '##ten', '##tive', '##ness'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1545,  0.2835, -0.0912,  ..., -0.0250,  0.1968,  0.5246])\n",
      "attentiveness\n",
      "Saved the embedding for attentiveness.\n",
      "['attracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1138, -0.3897,  0.1672,  ..., -0.4133,  0.0237,  0.4229])\n",
      "attracted\n",
      "Saved the embedding for attracted.\n",
      "['ave', '##nging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1430, -0.0090, -0.5570,  ...,  1.0034,  0.3006,  0.0578])\n",
      "avenging\n",
      "Saved the embedding for avenging.\n",
      "['ave', '##rse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1196, -0.1589, -0.6044,  ...,  1.1218,  0.6229,  0.2566])\n",
      "averse\n",
      "Saved the embedding for averse.\n",
      "['ave', '##rs', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0426,  0.1136, -0.5306,  ...,  0.9676,  0.5314,  0.4534])\n",
      "aversion\n",
      "Saved the embedding for aversion.\n",
      "['ave', '##rs', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0378,  0.1193, -0.5592,  ...,  0.8770,  0.5061,  0.4312])\n",
      "aversive\n",
      "Saved the embedding for aversive.\n",
      "['avid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0518, -0.7379,  0.3371,  ...,  0.1518,  0.4973,  0.1287])\n",
      "avid\n",
      "Saved the embedding for avid.\n",
      "['avoiding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3242, -0.5054, -0.4779,  ..., -0.0201, -0.2882,  0.7462])\n",
      "avoiding\n",
      "Saved the embedding for avoiding.\n",
      "['awaiting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0975, -0.2472,  0.1401,  ..., -0.1901,  0.3376, -0.1917])\n",
      "awaiting\n",
      "Saved the embedding for awaiting.\n",
      "['awakened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0309,  0.7422, -0.5158,  ..., -0.0214,  0.2823,  0.1385])\n",
      "awakened\n",
      "Saved the embedding for awakened.\n",
      "['aware'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1223,  0.4753, -0.0398,  ..., -0.2397, -0.3036,  0.1343])\n",
      "aware\n",
      "Saved the embedding for aware.\n",
      "['awareness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1294,  0.7744,  0.3655,  ...,  0.1701, -0.1737,  0.4233])\n",
      "awareness\n",
      "Saved the embedding for awareness.\n",
      "['awe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2459, 0.7009, 0.2551,  ..., 0.0910, 0.2840, 0.2310])\n",
      "awe\n",
      "Saved the embedding for awe.\n",
      "['awe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1354, 0.7229, 0.2922,  ..., 0.2448, 0.4307, 0.3275])\n",
      "awed\n",
      "Saved the embedding for awed.\n",
      "['awe', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.2379, 0.7491, 0.4337,  ..., 0.3333, 0.5487, 0.4799])\n",
      "awestruck\n",
      "Saved the embedding for awestruck.\n",
      "['awful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5002,  0.1600, -0.4008,  ..., -0.5601,  0.1914,  0.3105])\n",
      "awful\n",
      "Saved the embedding for awful.\n",
      "['awkward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3111,  0.7651, -0.4312,  ..., -0.5308, -0.0651,  0.0896])\n",
      "awkward\n",
      "Saved the embedding for awkward.\n",
      "['awkward', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3561,  0.7948, -0.2785,  ..., -0.3290,  0.0112,  0.1004])\n",
      "awkwardness\n",
      "Saved the embedding for awkwardness.\n",
      "['axe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4197,  0.3965, -0.1863,  ..., -0.0649, -0.0888, -0.1076])\n",
      "axed\n",
      "Saved the embedding for axed.\n",
      "['back', '##hand', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2939,  0.2874, -0.4272,  ...,  0.1999,  0.0178,  0.0996])\n",
      "backhanded\n",
      "Saved the embedding for backhanded.\n",
      "['badly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0858,  0.0806, -0.8409,  ..., -0.3511, -0.3530,  0.3812])\n",
      "badly\n",
      "Saved the embedding for badly.\n",
      "['ba', '##ffle'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4574, -0.1643, -0.3921,  ..., -0.1695, -0.0414,  0.2714])\n",
      "baffle\n",
      "Saved the embedding for baffle.\n",
      "['baffled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6315,  0.3270, -0.5674,  ..., -0.2353,  0.3064,  1.1126])\n",
      "baffled\n",
      "Saved the embedding for baffled.\n",
      "['ba', '##ff', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5036, -0.1726, -0.3729,  ...,  0.1548, -0.1475,  0.4361])\n",
      "baffling\n",
      "Saved the embedding for baffling.\n",
      "['baked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4478,  0.0434, -0.0115,  ...,  0.3419, -0.4385, -0.4968])\n",
      "baked\n",
      "Saved the embedding for baked.\n",
      "['ban', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0354, -0.6492, -0.4903,  ..., -0.1065,  0.1191, -0.2858])\n",
      "banal\n",
      "Saved the embedding for banal.\n",
      "['barking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5607, -0.1913,  0.1277,  ...,  0.2336, -0.0410,  0.3177])\n",
      "barking\n",
      "Saved the embedding for barking.\n",
      "['bash', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7442,  0.2940, -0.4747,  ...,  0.2130,  0.2709,  0.3584])\n",
      "bashful\n",
      "Saved the embedding for bashful.\n",
      "['beaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.5395, 0.6108, 0.4671,  ..., 0.2522, 0.4979, 0.3189])\n",
      "beaming\n",
      "Saved the embedding for beaming.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bear', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3202,  0.2045, -0.1138,  ..., -0.0706,  0.2217,  0.2988])\n",
      "bearish\n",
      "Saved the embedding for bearish.\n",
      "['beat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.4377, 0.1360, 0.2417,  ..., 0.8847, 0.1448, 0.0081])\n",
      "beat\n",
      "Saved the embedding for beat.\n",
      "['beaten'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0072, -0.1867,  0.2120,  ...,  0.4141,  0.0417,  0.3091])\n",
      "beaten\n",
      "Saved the embedding for beaten.\n",
      "['bed', '##ev', '##iled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6281,  0.1020,  0.0128,  ...,  0.5353, -0.1057, -0.0246])\n",
      "bedeviled\n",
      "Saved the embedding for bedeviled.\n",
      "['be', '##fu', '##ddled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3044,  0.2001, -0.5320,  ...,  0.3145,  0.0343,  0.3894])\n",
      "befuddled\n",
      "Saved the embedding for befuddled.\n",
      "['begging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1304, -0.5173,  0.0946,  ...,  0.0033,  0.0161,  0.0175])\n",
      "begging\n",
      "Saved the embedding for begging.\n",
      "['beg', '##rud', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0914, -0.3344, -0.2142,  ...,  0.1852,  0.3603,  0.3807])\n",
      "begrudge\n",
      "Saved the embedding for begrudge.\n",
      "['beg', '##rud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1097, -0.3409, -0.3602,  ...,  0.0870,  0.3886,  0.2483])\n",
      "begrudging\n",
      "Saved the embedding for begrudging.\n",
      "['beg', '##rud', '##gingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1493, -0.3365, -0.2676,  ...,  0.0223,  0.3700,  0.3734])\n",
      "begrudgingly\n",
      "Saved the embedding for begrudgingly.\n",
      "['beg', '##uil', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0783, -0.3585, -0.3461,  ..., -0.2035,  0.4110,  0.2197])\n",
      "beguiled\n",
      "Saved the embedding for beguiled.\n",
      "['bela', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9905, -0.4129, -0.7569,  ..., -0.1830,  0.3659, -0.2595])\n",
      "belated\n",
      "Saved the embedding for belated.\n",
      "['bel', '##itt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8487,  0.6272, -0.3216,  ...,  0.4084,  0.2685,  0.0771])\n",
      "belittling\n",
      "Saved the embedding for belittling.\n",
      "['bell', '##iger', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.1311,  0.2301, -0.0071,  ..., -0.2039, -0.0405, -0.1060])\n",
      "belligerence\n",
      "Saved the embedding for belligerence.\n",
      "['bell', '##iger', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.1758,  0.2619,  0.0462,  ..., -0.0518,  0.0210, -0.0288])\n",
      "belligerent\n",
      "Saved the embedding for belligerent.\n",
      "['belonging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0812, -0.2566,  0.4959,  ..., -0.2849, -0.2897,  0.2991])\n",
      "belonging\n",
      "Saved the embedding for belonging.\n",
      "['be', '##mus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3126,  0.0674, -0.4871,  ...,  0.2517,  0.4064,  0.2392])\n",
      "bemused\n",
      "Saved the embedding for bemused.\n",
      "['be', '##mus', '##ement'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3517,  0.1883, -0.3768,  ...,  0.6694,  0.1253,  0.7816])\n",
      "bemusement\n",
      "Saved the embedding for bemusement.\n",
      "['ben', '##ev', '##ole', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0671,  0.1203, -0.0511,  ...,  0.2263,  0.1450,  0.0388])\n",
      "benevolence\n",
      "Saved the embedding for benevolence.\n",
      "['benevolent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.5525, 0.5849, 0.2870,  ..., 0.1755, 0.2028, 0.6836])\n",
      "benevolent\n",
      "Saved the embedding for benevolent.\n",
      "['ben', '##umb', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1038, -0.0620, -0.0418,  ...,  0.4280,  0.0760,  0.3388])\n",
      "benumbed\n",
      "Saved the embedding for benumbed.\n",
      "['be', '##rate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3012,  0.1452, -0.4076,  ...,  0.1933,  0.1899,  0.5839])\n",
      "berate\n",
      "Saved the embedding for berate.\n",
      "['be', '##rating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3706,  0.1647, -0.4132,  ...,  0.3170,  0.1929,  0.5263])\n",
      "berating\n",
      "Saved the embedding for berating.\n",
      "['be', '##rea', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3183,  0.1139, -0.4699,  ...,  0.2379,  0.0298,  0.4362])\n",
      "bereaved\n",
      "Saved the embedding for bereaved.\n",
      "['be', '##re', '##ft'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3067,  0.1044, -0.4624,  ...,  0.4625,  0.1181,  0.5300])\n",
      "bereft\n",
      "Saved the embedding for bereft.\n",
      "['be', '##see', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3759,  0.1503, -0.4043,  ...,  0.1325, -0.0031,  0.3943])\n",
      "beseeching\n",
      "Saved the embedding for beseeching.\n",
      "['best', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1011,  0.4131, -0.5202,  ...,  0.7498,  0.0462, -0.3912])\n",
      "bested\n",
      "Saved the embedding for bested.\n",
      "['betrayal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9936,  0.0431, -0.2966,  ..., -0.0196, -0.1559,  0.5218])\n",
      "betrayal\n",
      "Saved the embedding for betrayal.\n",
      "['betrayed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4946, -0.1240, -0.0516,  ...,  0.1426,  0.4726,  0.0556])\n",
      "betrayed\n",
      "Saved the embedding for betrayed.\n",
      "['bewildered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0399,  0.2498, -0.2276,  ..., -0.1942,  0.0662,  0.7455])\n",
      "bewildered\n",
      "Saved the embedding for bewildered.\n",
      "['be', '##wil', '##der', '##ment'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3511,  0.0652, -0.4868,  ...,  0.4498,  0.2950,  0.2537])\n",
      "bewilderment\n",
      "Saved the embedding for bewilderment.\n",
      "['bi'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0701, -0.7002, -0.1275,  ...,  0.8774,  0.0349,  0.9274])\n",
      "bi\n",
      "Saved the embedding for bi.\n",
      "['bi', '##lio', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0792, -0.8248,  0.0199,  ...,  0.4565,  0.1333,  0.8595])\n",
      "bilious\n",
      "Saved the embedding for bilious.\n",
      "['bit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8140, -0.1992, -0.3198,  ..., -0.4049, -0.0757,  0.4109])\n",
      "bit\n",
      "Saved the embedding for bit.\n",
      "['biting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4871, -0.1885, -0.2118,  ..., -0.1029,  0.2984,  0.3756])\n",
      "biting\n",
      "Saved the embedding for biting.\n",
      "['bitter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0698,  0.0980, -0.3135,  ...,  0.2954, -0.1109,  0.5912])\n",
      "bitter\n",
      "Saved the embedding for bitter.\n",
      "['bitter', '##sw', '##eet'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0138,  0.0241, -0.1793,  ...,  0.3159,  0.0591,  0.5327])\n",
      "bittersweet\n",
      "Saved the embedding for bittersweet.\n",
      "['blaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1779,  0.6029, -0.1342,  ...,  0.1500,  0.0058, -0.0706])\n",
      "blaming\n",
      "Saved the embedding for blaming.\n",
      "['bland'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1881, -0.1525, -0.1406,  ..., -0.5473, -0.0680,  0.5231])\n",
      "bland\n",
      "Saved the embedding for bland.\n",
      "['blank'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6540,  0.8063, -0.5703,  ..., -0.0268,  0.2657,  0.1948])\n",
      "blank\n",
      "Saved the embedding for blank.\n",
      "['b', '##lase'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4766,  0.2165, -0.1510,  ...,  0.0184, -0.1245,  0.1529])\n",
      "blase\n",
      "Saved the embedding for blase.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2652, -0.3125, -0.0259,  ..., -0.1631,  0.0746,  0.4862])\n",
      "blazed\n",
      "Saved the embedding for blazed.\n",
      "['bleak'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4755,  0.3233,  0.0442,  ..., -0.2899, -0.1171,  0.2193])\n",
      "bleak\n",
      "Saved the embedding for bleak.\n",
      "['b', '##lea', '##ry'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3839,  0.1876, -0.3379,  ...,  0.1590, -0.1931,  0.3375])\n",
      "bleary\n",
      "Saved the embedding for bleary.\n",
      "['blessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5355,  0.6504,  0.1743,  ..., -0.8914,  0.5753,  0.7794])\n",
      "blessed\n",
      "Saved the embedding for blessed.\n",
      "['blew'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8021, -0.0257, -0.1239,  ..., -0.0482, -0.1299, -0.3386])\n",
      "blew\n",
      "Saved the embedding for blew.\n",
      "['blinded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6044,  0.8082, -0.3499,  ..., -0.0726,  0.2953,  0.2890])\n",
      "blinded\n",
      "Saved the embedding for blinded.\n",
      "['blinds', '##ided'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3962,  0.3208, -0.6474,  ...,  0.3626,  0.1653,  0.6602])\n",
      "blindsided\n",
      "Saved the embedding for blindsided.\n",
      "['bliss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2817,  0.7083,  0.2201,  ..., -0.7395,  0.4421,  0.1996])\n",
      "bliss\n",
      "Saved the embedding for bliss.\n",
      "['bliss', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2342,  0.6414,  0.1320,  ..., -0.8986,  0.4616,  0.3495])\n",
      "blissful\n",
      "Saved the embedding for blissful.\n",
      "['bliss', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2705,  0.5696,  0.1204,  ..., -0.7520,  0.4928,  0.3005])\n",
      "blissfully\n",
      "Saved the embedding for blissfully.\n",
      "['b', '##lit', '##he'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4276,  0.1031, -0.2229,  ...,  0.2966, -0.0848, -0.1060])\n",
      "blithe\n",
      "Saved the embedding for blithe.\n",
      "['blown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9478,  0.1557, -0.1303,  ...,  0.1398, -0.6305, -0.0111])\n",
      "blown\n",
      "Saved the embedding for blown.\n",
      "['blue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0933, -0.5730, -0.3493,  ..., -0.1595, -0.0867,  0.1764])\n",
      "blue\n",
      "Saved the embedding for blue.\n",
      "['blues'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0737,  0.1757, -0.8755,  ...,  0.3683, -0.1360,  0.2172])\n",
      "blues\n",
      "Saved the embedding for blues.\n",
      "['bluff', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5942,  0.3797, -0.8636,  ..., -0.0434, -0.3518,  0.0582])\n",
      "bluffing\n",
      "Saved the embedding for bluffing.\n",
      "['blunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1967,  0.1238, -0.4279,  ...,  0.0159, -0.2201,  0.1657])\n",
      "blunt\n",
      "Saved the embedding for blunt.\n",
      "['blushing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2579,  0.1616,  0.0792,  ..., -0.8515,  0.0843,  0.4799])\n",
      "blushing\n",
      "Saved the embedding for blushing.\n",
      "['blu', '##ster', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7570, -0.2662, -0.4665,  ...,  0.2235,  0.4922,  0.0935])\n",
      "blustering\n",
      "Saved the embedding for blustering.\n",
      "['bo', '##ast', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3640,  0.3076, -0.3821,  ...,  0.2027,  0.1792,  0.4237])\n",
      "boastful\n",
      "Saved the embedding for boastful.\n",
      "['bog', '##gled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5579,  0.1518, -0.0578,  ...,  0.1861, -0.2812, -0.1717])\n",
      "boggled\n",
      "Saved the embedding for boggled.\n",
      "['boiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6233,  0.5112, -0.4056,  ...,  0.2184,  0.3110, -0.0325])\n",
      "boiling\n",
      "Saved the embedding for boiling.\n",
      "['bois', '##ter', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3821,  0.0630,  0.1971,  ...,  0.6901,  0.1644, -0.5533])\n",
      "boisterous\n",
      "Saved the embedding for boisterous.\n",
      "['bold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0709,  0.6640, -0.2912,  ...,  0.0228, -0.1312, -0.2919])\n",
      "bold\n",
      "Saved the embedding for bold.\n",
      "['bored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1226,  0.3221, -0.3618,  ...,  0.2246, -0.3312,  0.7212])\n",
      "bored\n",
      "Saved the embedding for bored.\n",
      "['boredom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3262,  0.3664,  0.2898,  ..., -0.3554, -0.0806,  0.6952])\n",
      "boredom\n",
      "Saved the embedding for boredom.\n",
      "['boring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5229,  0.2092, -0.1244,  ..., -0.0293, -0.0396,  0.5019])\n",
      "boring\n",
      "Saved the embedding for boring.\n",
      "['bothered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1385,  0.6443, -0.0546,  ...,  0.1249,  0.0721,  0.8135])\n",
      "bothered\n",
      "Saved the embedding for bothered.\n",
      "['bound', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4148, -0.5520, -0.2471,  ...,  0.8221, -0.0849,  0.5715])\n",
      "bounder\n",
      "Saved the embedding for bounder.\n",
      "['bra', '##sh', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3607,  0.5123, -0.1422,  ...,  1.3529, -0.1372, -1.1209])\n",
      "brashness\n",
      "Saved the embedding for brashness.\n",
      "['brat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1792, -0.0279,  0.1739,  ...,  0.1006, -0.8222,  0.7540])\n",
      "bratty\n",
      "Saved the embedding for bratty.\n",
      "['brave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0530,  0.7269, -0.1104,  ..., -0.1740, -0.2179,  0.2509])\n",
      "brave\n",
      "Saved the embedding for brave.\n",
      "['bright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0808,  0.3591, -0.1944,  ...,  0.0311,  0.4667,  0.6775])\n",
      "bright\n",
      "Saved the embedding for bright.\n",
      "['br', '##ist', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1294,  0.6186,  0.1509,  ..., -0.1967,  0.2699,  0.4911])\n",
      "bristling\n",
      "Saved the embedding for bristling.\n",
      "['broken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5850,  0.2722, -0.1403,  ...,  0.1010, -0.2940, -0.2003])\n",
      "broken\n",
      "Saved the embedding for broken.\n",
      "['broken', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6334,  0.3769, -0.1246,  ...,  0.3550, -0.3410,  0.0093])\n",
      "brokenhearted\n",
      "Saved the embedding for brokenhearted.\n",
      "['broken', '##hearted', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5051,  0.4132, -0.0924,  ...,  0.3784, -0.1702, -0.0398])\n",
      "brokenheartedly\n",
      "Saved the embedding for brokenheartedly.\n",
      "['brooding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3435,  1.0018,  0.1096,  ..., -0.2738, -0.1716,  0.3656])\n",
      "brooding\n",
      "Saved the embedding for brooding.\n",
      "['brood', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5744,  0.8995,  0.0882,  ..., -0.1370, -0.3161, -0.2434])\n",
      "broody\n",
      "Saved the embedding for broody.\n",
      "['bruised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0917,  0.0149, -0.3196,  ..., -0.1240, -0.1465,  0.3081])\n",
      "bruised\n",
      "Saved the embedding for bruised.\n",
      "['br', '##us', '##que'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0347,  0.6862,  0.0721,  ..., -0.0764,  0.4409,  0.3621])\n",
      "brusque\n",
      "Saved the embedding for brusque.\n",
      "['bug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2736, -0.2179, -0.3173,  ..., -0.1955, -0.2727,  0.3574])\n",
      "bug\n",
      "Saved the embedding for bug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bulging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0669,  0.1745, -0.3350,  ..., -0.1227, -0.0248,  0.1602])\n",
      "bulging\n",
      "Saved the embedding for bulging.\n",
      "['bully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4920,  0.3804, -0.4935,  ..., -0.3690, -0.2565,  0.0201])\n",
      "bully\n",
      "Saved the embedding for bully.\n",
      "['bullying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3058,  0.0328, -0.0401,  ..., -0.2273, -0.7757,  0.6153])\n",
      "bullying\n",
      "Saved the embedding for bullying.\n",
      "['bum', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1330, -0.1384, -0.2175,  ...,  0.0494, -0.6765,  0.0928])\n",
      "bummed\n",
      "Saved the embedding for bummed.\n",
      "['bu', '##oya', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1191,  0.1376, -0.1909,  ..., -0.5604,  0.0903,  0.2858])\n",
      "buoyant\n",
      "Saved the embedding for buoyant.\n",
      "['burden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1789,  0.2528, -0.0064,  ..., -0.2943, -0.2019,  0.3019])\n",
      "burdened\n",
      "Saved the embedding for burdened.\n",
      "['burn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6535, -0.5679,  0.1782,  ..., -0.1189,  0.0962, -0.4248])\n",
      "burn\n",
      "Saved the embedding for burn.\n",
      "['bursting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0447,  0.0698, -0.3384,  ..., -0.2234,  0.0637, -0.3080])\n",
      "bursting\n",
      "Saved the embedding for bursting.\n",
      "['bush', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6985,  0.3364, -0.0250,  ...,  0.0571,  0.2209,  0.5039])\n",
      "bushed\n",
      "Saved the embedding for bushed.\n",
      "['cage', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0116,  0.7512, -0.3901,  ...,  0.3119,  0.1661,  0.1439])\n",
      "cagey\n",
      "Saved the embedding for cagey.\n",
      "['ca', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3658,  0.1258,  0.1763,  ..., -0.4202, -0.0353,  0.5358])\n",
      "cagy\n",
      "Saved the embedding for cagy.\n",
      "['calculating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2114,  0.7959, -0.0444,  ...,  0.3433,  0.1985,  0.5619])\n",
      "calculating\n",
      "Saved the embedding for calculating.\n",
      "['call', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0082, -0.2038, -0.0854,  ..., -0.9946,  0.0218,  0.6505])\n",
      "callous\n",
      "Saved the embedding for callous.\n",
      "['call', '##used'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0884, -0.2914,  0.0742,  ..., -0.8631,  0.1806,  0.4873])\n",
      "callused\n",
      "Saved the embedding for callused.\n",
      "['calm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0384,  0.8325,  0.8023,  ...,  0.0118,  0.1462,  0.6176])\n",
      "calm\n",
      "Saved the embedding for calm.\n",
      "['calming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2358,  0.5603,  0.4636,  ..., -0.7332, -0.6207,  0.4315])\n",
      "calming\n",
      "Saved the embedding for calming.\n",
      "['calm', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1848,  0.9238,  0.7424,  ...,  0.2450,  0.2682,  0.7401])\n",
      "calmness\n",
      "Saved the embedding for calmness.\n",
      "['can', '##ny'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8557, -0.3506, -0.1160,  ..., -0.3981,  0.0077,  0.2962])\n",
      "canny\n",
      "Saved the embedding for canny.\n",
      "['can', '##tan', '##ker', '##ous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.7893, -0.4719,  0.0643,  ..., -0.5922,  0.1388,  0.0254])\n",
      "cantankerous\n",
      "Saved the embedding for cantankerous.\n",
      "['capable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3275,  0.2855, -0.3991,  ..., -0.1604,  0.5993,  0.0391])\n",
      "capable\n",
      "Saved the embedding for capable.\n",
      "['cap', '##ric', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5260, -0.7824,  0.1708,  ...,  0.5071,  0.2552,  0.2360])\n",
      "capricious\n",
      "Saved the embedding for capricious.\n",
      "['capt', '##ivated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6718,  0.1564,  0.2935,  ..., -0.2162,  0.2891,  0.7145])\n",
      "captivated\n",
      "Saved the embedding for captivated.\n",
      "['captive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3169, -0.1071, -0.0555,  ..., -0.1546, -0.0712, -0.1804])\n",
      "captive\n",
      "Saved the embedding for captive.\n",
      "['care', '##free'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3476,  0.0581,  0.6854,  ..., -0.3198, -0.2207,  1.0266])\n",
      "carefree\n",
      "Saved the embedding for carefree.\n",
      "['careful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1752,  0.3167, -0.2546,  ...,  0.0268,  0.0092,  0.2210])\n",
      "careful\n",
      "Saved the embedding for careful.\n",
      "['careless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2812,  0.1566, -0.0587,  ...,  0.4119,  0.0756, -0.0379])\n",
      "careless\n",
      "Saved the embedding for careless.\n",
      "['caring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2627,  0.2610,  0.5390,  ...,  0.0684, -0.2518,  1.0487])\n",
      "caring\n",
      "Saved the embedding for caring.\n",
      "['cat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6542, -0.4061,  0.1374,  ..., -0.0957, -0.2905,  0.7055])\n",
      "catty\n",
      "Saved the embedding for catty.\n",
      "['ca', '##ust', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3812,  0.2026,  0.1968,  ..., -0.2325,  0.1074,  0.6732])\n",
      "caustic\n",
      "Saved the embedding for caustic.\n",
      "['caution', '##ary'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5166,  0.2800, -0.3700,  ...,  0.4011,  0.2959, -0.3282])\n",
      "cautionary\n",
      "Saved the embedding for cautionary.\n",
      "['cautious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1681,  0.4475, -0.3790,  ..., -0.4634,  0.1744,  0.4377])\n",
      "cautious\n",
      "Saved the embedding for cautious.\n",
      "['cavalier'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3744,  0.2875,  0.1850,  ...,  0.7996,  0.5636, -0.1852])\n",
      "cavalier\n",
      "Saved the embedding for cavalier.\n",
      "['celebrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1112,  0.3683,  0.7938,  ..., -0.5769, -0.1994,  0.8189])\n",
      "celebrating\n",
      "Saved the embedding for celebrating.\n",
      "['celebration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0436,  0.4569,  0.4448,  ..., -0.1996, -0.0140,  0.4794])\n",
      "celebration\n",
      "Saved the embedding for celebration.\n",
      "['ce', '##ns', '##ure'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2097,  0.3976,  0.0521,  ..., -0.0593,  0.3758,  0.4205])\n",
      "censure\n",
      "Saved the embedding for censure.\n",
      "['centered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2727,  0.7064, -0.7189,  ..., -0.1940, -0.0418,  0.1585])\n",
      "centered\n",
      "Saved the embedding for centered.\n",
      "['certain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4197,  0.3868, -0.6781,  ..., -0.1889, -0.2931,  0.1043])\n",
      "certain\n",
      "Saved the embedding for certain.\n",
      "['cha', '##fed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2182, -0.4631, -0.8746,  ...,  0.0046, -0.1924,  0.7937])\n",
      "chafed\n",
      "Saved the embedding for chafed.\n",
      "['cha', '##grin'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1963, -0.3869, -0.9801,  ..., -0.1140, -0.0990,  0.6391])\n",
      "chagrin\n",
      "Saved the embedding for chagrin.\n",
      "['cha', '##grin', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2049, -0.4115, -0.9456,  ..., -0.0058, -0.0845,  0.6859])\n",
      "chagrined\n",
      "Saved the embedding for chagrined.\n",
      "['cha', '##grin', '##ned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1383, -0.3890, -0.9478,  ...,  0.1848, -0.2123,  0.7488])\n",
      "chagrinned\n",
      "Saved the embedding for chagrinned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['challenge'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0204, -0.2608,  0.3331,  ...,  0.1052,  0.7287,  0.6897])\n",
      "challenge\n",
      "Saved the embedding for challenge.\n",
      "['challenged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2364,  0.5663,  0.0222,  ..., -0.3951,  0.3021,  0.3892])\n",
      "challenged\n",
      "Saved the embedding for challenged.\n",
      "['challenging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0647,  0.7027, -0.2624,  ..., -0.2490, -0.0319,  0.4787])\n",
      "challenging\n",
      "Saved the embedding for challenging.\n",
      "['chaotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3906,  0.3860, -0.1002,  ...,  0.1654, -0.1062,  0.3752])\n",
      "chaotic\n",
      "Saved the embedding for chaotic.\n",
      "['charged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3493,  0.4843, -0.0217,  ...,  0.1029,  0.0098,  0.3579])\n",
      "charged\n",
      "Saved the embedding for charged.\n",
      "['charm', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3614, -0.2232,  0.4173,  ..., -0.1968,  0.7209,  0.0110])\n",
      "charmed\n",
      "Saved the embedding for charmed.\n",
      "['charming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1322,  0.3001,  0.3435,  ..., -0.4844, -0.1319,  0.2093])\n",
      "charming\n",
      "Saved the embedding for charming.\n",
      "['char', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7594, -0.8773, -0.0496,  ..., -0.1801, -0.0193, -0.1342])\n",
      "chary\n",
      "Saved the embedding for chary.\n",
      "['cheated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6258, -0.2511, -0.1060,  ..., -0.4277,  0.1904,  0.2836])\n",
      "cheated\n",
      "Saved the embedding for cheated.\n",
      "['cheek', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3180,  0.6785, -0.5231,  ...,  0.0093, -0.2696,  0.2293])\n",
      "cheeky\n",
      "Saved the embedding for cheeky.\n",
      "['cheered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2629,  0.3831,  0.1624,  ...,  0.1154, -0.0285, -0.2004])\n",
      "cheered\n",
      "Saved the embedding for cheered.\n",
      "['cheerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0809,  0.4195,  0.2400,  ..., -0.1634, -0.2156,  0.4236])\n",
      "cheerful\n",
      "Saved the embedding for cheerful.\n",
      "['cheering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3614,  0.5373, -0.3812,  ...,  0.3074, -0.2428,  0.2198])\n",
      "cheering\n",
      "Saved the embedding for cheering.\n",
      "['cheer', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2033,  0.1899,  0.0458,  ...,  0.1525, -0.2581, -0.3092])\n",
      "cheerless\n",
      "Saved the embedding for cheerless.\n",
      "['cheer', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1222,  0.3969,  0.2288,  ...,  0.0702, -0.3610, -0.3870])\n",
      "cheery\n",
      "Saved the embedding for cheery.\n",
      "['che', '##es', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1972,  0.1452, -0.1793,  ..., -0.0465,  0.1861,  0.5227])\n",
      "cheesy\n",
      "Saved the embedding for cheesy.\n",
      "['chest', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4953,  0.0713,  0.0347,  ...,  0.0467,  0.0380, -0.0660])\n",
      "chesty\n",
      "Saved the embedding for chesty.\n",
      "['chi', '##de'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6859,  0.0670, -0.0626,  ..., -0.1969,  0.2884,  0.4029])\n",
      "chide\n",
      "Saved the embedding for chide.\n",
      "['chi', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7043, -0.0071, -0.1860,  ..., -0.2160,  0.2283,  0.3603])\n",
      "chiding\n",
      "Saved the embedding for chiding.\n",
      "['childish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2213,  0.4641, -0.4309,  ..., -0.2490, -0.2195,  0.5680])\n",
      "childish\n",
      "Saved the embedding for childish.\n",
      "['childish', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1885,  0.4704, -0.2938,  ..., -0.2761, -0.0765,  0.6743])\n",
      "childishly\n",
      "Saved the embedding for childishly.\n",
      "['child', '##like'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2826, -0.0494, -0.0954,  ..., -0.2815, -0.3434, -0.1941])\n",
      "childlike\n",
      "Saved the embedding for childlike.\n",
      "['chill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9757, -0.2148, -0.1679,  ..., -0.2322,  0.3650,  0.1141])\n",
      "chill\n",
      "Saved the embedding for chill.\n",
      "['chilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.6999, 0.1768, 0.1579,  ..., 0.2615, 0.1966, 0.0973])\n",
      "chilled\n",
      "Saved the embedding for chilled.\n",
      "['chilling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3719, -0.7754, -0.2787,  ...,  0.1688,  0.3627,  0.1537])\n",
      "chilling\n",
      "Saved the embedding for chilling.\n",
      "['chip', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3360, -0.7426, -0.4465,  ...,  0.4197,  0.3920,  0.1821])\n",
      "chipper\n",
      "Saved the embedding for chipper.\n",
      "['chi', '##rp', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5301, -0.0308, -0.1594,  ...,  0.0015,  0.2436,  0.5394])\n",
      "chirpy\n",
      "Saved the embedding for chirpy.\n",
      "['cho', '##ler', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1455, -0.3479, -0.5907,  ..., -0.7522, -0.2611,  0.5724])\n",
      "choleric\n",
      "Saved the embedding for choleric.\n",
      "['cho', '##rt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0821, -0.4417, -0.4193,  ...,  0.0807, -0.0765,  0.7917])\n",
      "chortling\n",
      "Saved the embedding for chortling.\n",
      "['chuckle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.4088, 0.5878, 0.0717,  ..., 0.4709, 0.0391, 0.2285])\n",
      "chuckle\n",
      "Saved the embedding for chuckle.\n",
      "['chuck', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7769,  0.4693, -0.3940,  ...,  0.2051,  0.1962,  0.1540])\n",
      "chuckling\n",
      "Saved the embedding for chuckling.\n",
      "['chu', '##rl', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0127, -0.0222, -0.8614,  ...,  0.1677, -0.0110,  0.9271])\n",
      "churlish\n",
      "Saved the embedding for churlish.\n",
      "['ci', '##rc', '##ums', '##pe', '##ct'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.4421, -0.1540,  0.3089,  ..., -0.2917,  0.7242,  0.8527])\n",
      "circumspect\n",
      "Saved the embedding for circumspect.\n",
      "['cl', '##amo', '##rous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5224,  0.0572,  0.0676,  ..., -0.7619, -0.0054,  0.1849])\n",
      "clamorous\n",
      "Saved the embedding for clamorous.\n",
      "['clash'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7349,  0.2866, -0.2999,  ...,  0.2462,  0.3050,  0.3482])\n",
      "clash\n",
      "Saved the embedding for clash.\n",
      "['clear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1697, -0.1029, -0.0074,  ..., -0.4630,  0.2867,  0.3478])\n",
      "clear\n",
      "Saved the embedding for clear.\n",
      "['clenched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8831,  0.9172, -0.2839,  ..., -0.0993,  0.1050,  0.0860])\n",
      "clenched\n",
      "Saved the embedding for clenched.\n",
      "['clever'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5273,  0.0757,  0.1315,  ..., -0.1972,  0.3211,  0.4772])\n",
      "clever\n",
      "Saved the embedding for clever.\n",
      "['close'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1389,  0.0811, -0.0091,  ..., -0.4269,  0.1419,  0.2125])\n",
      "close\n",
      "Saved the embedding for close.\n",
      "['closed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0179, 0.1206, 0.2899,  ..., 0.1594, 0.2449, 0.2868])\n",
      "closed\n",
      "Saved the embedding for closed.\n",
      "['close', '##mouth', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2102, -0.1345, -0.0119,  ...,  0.1313,  0.2293, -0.0593])\n",
      "closemouthed\n",
      "Saved the embedding for closemouthed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cl', '##oy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3940,  0.0672,  0.1482,  ..., -0.8301, -0.3035,  0.1026])\n",
      "cloy\n",
      "Saved the embedding for cloy.\n",
      "['clue', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3537,  0.3516, -0.0855,  ...,  0.5450,  0.2079, -0.0888])\n",
      "clueless\n",
      "Saved the embedding for clueless.\n",
      "['clutched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0729,  0.3757,  0.1242,  ...,  0.0318,  0.1232, -0.1958])\n",
      "clutched\n",
      "Saved the embedding for clutched.\n",
      "['cl', '##uttered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4329, -0.2650,  0.0659,  ..., -0.8252, -0.6034,  0.2607])\n",
      "cluttered\n",
      "Saved the embedding for cluttered.\n",
      "['cock', '##eye', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.9640,  0.4649,  0.4256,  ...,  0.1946,  0.3907, -0.1313])\n",
      "cockeyed\n",
      "Saved the embedding for cockeyed.\n",
      "['cock', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0218,  0.6529,  0.5293,  ..., -0.1841,  0.2108, -0.0659])\n",
      "cockiness\n",
      "Saved the embedding for cockiness.\n",
      "['cock', '##sure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9063,  0.5592,  0.3061,  ...,  0.0214,  0.2369, -0.0344])\n",
      "cocksure\n",
      "Saved the embedding for cocksure.\n",
      "['cocky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2818,  0.6470, -0.0280,  ..., -0.0968,  0.2912,  0.1597])\n",
      "cocky\n",
      "Saved the embedding for cocky.\n",
      "['co', '##gni', '##zan', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2110, -0.1978, -0.2296,  ..., -0.2933,  0.0897,  0.4247])\n",
      "cognizant\n",
      "Saved the embedding for cognizant.\n",
      "['cold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.8619, 0.9458, 0.4009,  ..., 0.1842, 0.3472, 0.8164])\n",
      "cold\n",
      "Saved the embedding for cold.\n",
      "['collected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0791, -0.3304,  0.2481,  ...,  0.0531,  0.0144,  0.5503])\n",
      "collected\n",
      "Saved the embedding for collected.\n",
      "['col', '##lus', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0143, -0.0380, -0.1130,  ...,  0.1026,  0.4882,  0.4933])\n",
      "collusive\n",
      "Saved the embedding for collusive.\n",
      "['colon', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1698,  0.3845, -0.9710,  ..., -0.4046,  0.0264,  1.3170])\n",
      "colonized\n",
      "Saved the embedding for colonized.\n",
      "['combat', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0337,  0.9137, -0.3325,  ...,  0.1151,  0.1972, -0.1547])\n",
      "combative\n",
      "Saved the embedding for combative.\n",
      "['comedic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1208,  0.1900, -0.4619,  ..., -0.1619, -0.1144,  0.0566])\n",
      "comedic\n",
      "Saved the embedding for comedic.\n",
      "['comfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2250,  0.7160,  0.2177,  ...,  0.1600, -0.8482, -0.0719])\n",
      "comfort\n",
      "Saved the embedding for comfort.\n",
      "['comfortable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2483,  0.1339, -0.3459,  ..., -0.1284, -0.2271,  0.1990])\n",
      "comfortable\n",
      "Saved the embedding for comfortable.\n",
      "['comfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2119,  0.5942,  0.2219,  ..., -0.0854, -0.5074, -0.0678])\n",
      "comforted\n",
      "Saved the embedding for comforted.\n",
      "['comical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1697,  0.5762, -0.2386,  ..., -0.3680,  0.4251, -0.0477])\n",
      "comical\n",
      "Saved the embedding for comical.\n",
      "['commanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1612,  0.6676, -0.2520,  ...,  0.0443, -0.2634,  0.4525])\n",
      "commanding\n",
      "Saved the embedding for commanding.\n",
      "['com', '##mise', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2446, -0.6638, -0.6823,  ...,  0.4399, -0.0528,  0.3395])\n",
      "commiserating\n",
      "Saved the embedding for commiserating.\n",
      "['com', '##mise', '##rative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2771, -0.6269, -0.5475,  ...,  0.3227, -0.0339,  0.4381])\n",
      "commiserative\n",
      "Saved the embedding for commiserative.\n",
      "['com', '##mun', '##icative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2411, -0.6319, -0.5425,  ...,  0.3070,  0.1150,  0.5652])\n",
      "communicative\n",
      "Saved the embedding for communicative.\n",
      "['compassion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.3966, 0.1678, 0.1544,  ..., 0.2964, 0.3360, 0.9097])\n",
      "compassion\n",
      "Saved the embedding for compassion.\n",
      "['compassionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1069,  0.0928,  0.2089,  ..., -0.4743,  0.1310,  0.5636])\n",
      "compassionate\n",
      "Saved the embedding for compassionate.\n",
      "['competent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6294,  0.3570, -0.3904,  ..., -0.1483,  0.0029,  0.7967])\n",
      "competent\n",
      "Saved the embedding for competent.\n",
      "['competitive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0062, -0.1708, -0.4352,  ...,  0.1365,  0.2785, -0.1830])\n",
      "competitive\n",
      "Saved the embedding for competitive.\n",
      "['com', '##pl', '##ace', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2168, -0.6181, -0.5591,  ...,  0.5172, -0.1501,  0.4025])\n",
      "complacence\n",
      "Saved the embedding for complacence.\n",
      "['com', '##pl', '##ace', '##ncy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1901, -0.6599, -0.5120,  ...,  0.6083, -0.1185,  0.3824])\n",
      "complacency\n",
      "Saved the embedding for complacency.\n",
      "['com', '##pl', '##ace', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2347, -0.5673, -0.4926,  ...,  0.5317,  0.0061,  0.5160])\n",
      "complacent\n",
      "Saved the embedding for complacent.\n",
      "['com', '##pl', '##ace', '##ntly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3053, -0.6827, -0.5399,  ...,  0.6184,  0.0045,  0.4609])\n",
      "complacently\n",
      "Saved the embedding for complacently.\n",
      "['complain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4788,  0.1127,  0.4241,  ..., -0.4313,  0.0933,  0.5354])\n",
      "complain\n",
      "Saved the embedding for complain.\n",
      "['complaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2080, -0.2323,  0.2868,  ..., -0.2831, -0.3039,  0.4288])\n",
      "complaining\n",
      "Saved the embedding for complaining.\n",
      "['composed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.3009, 0.2920, 0.0312,  ..., 0.4735, 0.4022, 0.5951])\n",
      "composed\n",
      "Saved the embedding for composed.\n",
      "['comprehend', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5342,  1.1079,  0.0783,  ..., -0.0684,  0.5610,  0.9236])\n",
      "comprehending\n",
      "Saved the embedding for comprehending.\n",
      "['com', '##pu', '##ls', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1269, -0.6629, -0.5069,  ...,  0.7341,  0.2183,  0.4713])\n",
      "compulsive\n",
      "Saved the embedding for compulsive.\n",
      "['concealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1559, -0.3647, -0.4238,  ...,  0.1709, -0.3768,  0.1477])\n",
      "concealed\n",
      "Saved the embedding for concealed.\n",
      "['con', '##ced', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1899, -0.3636, -0.0160,  ..., -0.5763, -0.0699,  0.4458])\n",
      "conceding\n",
      "Saved the embedding for conceding.\n",
      "['con', '##ce', '##ited'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2360, -0.2666,  0.0116,  ..., -0.1924,  0.0645,  0.5854])\n",
      "conceited\n",
      "Saved the embedding for conceited.\n",
      "['concentrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6421,  0.3859, -0.1629,  ..., -0.2630, -0.3765,  0.3314])\n",
      "concentrated\n",
      "Saved the embedding for concentrated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concentrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2736,  0.7871, -0.5414,  ..., -0.1986, -0.5291,  0.2288])\n",
      "concentrating\n",
      "Saved the embedding for concentrating.\n",
      "['concentration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5585,  0.8898,  0.1307,  ...,  0.0498, -0.3890,  0.9829])\n",
      "concentration\n",
      "Saved the embedding for concentration.\n",
      "['concern'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0735,  1.1418, -0.2573,  ..., -0.2009, -0.3959,  0.6723])\n",
      "concern\n",
      "Saved the embedding for concern.\n",
      "['concerned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6350,  1.3573, -0.5785,  ..., -0.0888, -0.2742,  0.6826])\n",
      "concerned\n",
      "Saved the embedding for concerned.\n",
      "['con', '##ci', '##lia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2814, -0.3759,  0.0206,  ..., -0.0013,  0.1002,  0.4861])\n",
      "conciliatory\n",
      "Saved the embedding for conciliatory.\n",
      "['con', '##clusive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1940, -0.2962, -0.2050,  ..., -0.3175,  0.0452,  0.3240])\n",
      "conclusive\n",
      "Saved the embedding for conclusive.\n",
      "['condemning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3574,  0.3157,  0.6448,  ...,  0.7786,  0.5696, -0.0404])\n",
      "condemning\n",
      "Saved the embedding for condemning.\n",
      "['conde', '##sc', '##ending'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2188, -0.3196, -0.4154,  ..., -0.3413,  0.1553,  0.9666])\n",
      "condescending\n",
      "Saved the embedding for condescending.\n",
      "['condo', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1774e+00,  6.3735e-01, -4.5944e-01,  ..., -2.7190e-04,\n",
      "        -7.8045e-01,  1.6103e-01])\n",
      "condoling\n",
      "Saved the embedding for condoling.\n",
      "['confidence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4044,  0.4697, -0.1710,  ..., -0.4444, -0.1167,  0.1980])\n",
      "confidence\n",
      "Saved the embedding for confidence.\n",
      "['confident'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3117,  0.2993, -0.2954,  ..., -0.2295,  0.3211,  0.0163])\n",
      "confident\n",
      "Saved the embedding for confident.\n",
      "['confidently'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4842, -0.2981, -0.3351,  ...,  0.1416,  0.5209,  0.0321])\n",
      "confidently\n",
      "Saved the embedding for confidently.\n",
      "['conflict', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0781,  1.0368,  0.4016,  ..., -0.2122, -0.0442,  0.3474])\n",
      "conflicted\n",
      "Saved the embedding for conflicted.\n",
      "['con', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3987, -0.4390, -0.1822,  ..., -0.5670,  0.2722,  0.3750])\n",
      "confound\n",
      "Saved the embedding for confound.\n",
      "['con', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3724, -0.3446, -0.2255,  ..., -0.4466, -0.1720,  0.3421])\n",
      "confounded\n",
      "Saved the embedding for confounded.\n",
      "['confrontation', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1205,  0.7297, -0.1426,  ..., -0.0890,  0.2235,  0.4159])\n",
      "confrontational\n",
      "Saved the embedding for confrontational.\n",
      "['confused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1041,  0.6116, -0.1800,  ..., -0.4632,  0.4505,  0.7519])\n",
      "confused\n",
      "Saved the embedding for confused.\n",
      "['confusion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3478,  0.6568,  0.0245,  ..., -0.4384,  0.1986,  0.8541])\n",
      "confusion\n",
      "Saved the embedding for confusion.\n",
      "['cong', '##enia', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0634, -0.4475,  0.2027,  ..., -0.4711, -0.0778,  0.5105])\n",
      "congenial\n",
      "Saved the embedding for congenial.\n",
      "['cong', '##rat', '##ulator', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1678, -0.4196,  0.0438,  ..., -0.7217,  0.0895,  0.3917])\n",
      "congratulatory\n",
      "Saved the embedding for congratulatory.\n",
      "['con', '##ni', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3876, -0.2947, -0.2935,  ..., -0.5725, -0.1349,  0.2421])\n",
      "conniving\n",
      "Saved the embedding for conniving.\n",
      "['conscious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2085,  0.9194, -0.6077,  ..., -0.0726, -0.3520,  0.4783])\n",
      "conscious\n",
      "Saved the embedding for conscious.\n",
      "['conservative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3467,  0.0997,  0.2607,  ...,  0.2053, -0.1250,  0.4212])\n",
      "conservative\n",
      "Saved the embedding for conservative.\n",
      "['consider', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2259,  1.0456,  0.2758,  ...,  0.5024,  0.3868,  0.6822])\n",
      "considerate\n",
      "Saved the embedding for considerate.\n",
      "['considering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1164,  0.8199,  0.3338,  ...,  0.0530,  0.0203,  0.6765])\n",
      "considering\n",
      "Saved the embedding for considering.\n",
      "['con', '##sol', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3076, -0.3405, -0.2419,  ..., -0.7936, -0.2108,  0.4209])\n",
      "consoling\n",
      "Saved the embedding for consoling.\n",
      "['con', '##sp', '##ira', '##tori', '##al'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.4105, -0.2888, -0.0560,  ..., -0.2648,  0.0891,  0.3543])\n",
      "conspiratorial\n",
      "Saved the embedding for conspiratorial.\n",
      "['con', '##sp', '##iring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3748, -0.1273, -0.3335,  ..., -0.4287,  0.0088,  0.2571])\n",
      "conspiring\n",
      "Saved the embedding for conspiring.\n",
      "['con', '##ster', '##nation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2978, -0.1769, -0.2448,  ..., -0.3327, -0.1329,  0.1266])\n",
      "consternation\n",
      "Saved the embedding for consternation.\n",
      "['con', '##sti', '##pate', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3024, -0.3084, -0.1772,  ..., -0.6011,  0.2039,  0.2929])\n",
      "constipated\n",
      "Saved the embedding for constipated.\n",
      "['constrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0063,  0.3972, -0.1267,  ...,  0.3020,  0.0846,  0.4803])\n",
      "constrained\n",
      "Saved the embedding for constrained.\n",
      "['consumed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7560, -0.1653, -0.2416,  ..., -0.3787, -0.0880, -0.0672])\n",
      "consumed\n",
      "Saved the embedding for consumed.\n",
      "['consuming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7462, -0.4097, -0.1694,  ..., -0.4311, -0.2572,  0.4279])\n",
      "consuming\n",
      "Saved the embedding for consuming.\n",
      "['contained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4528, -0.1222,  0.0779,  ...,  0.7688, -0.0335,  0.5258])\n",
      "contained\n",
      "Saved the embedding for contained.\n",
      "['con', '##tem', '##plate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4129, -0.2855, -0.1553,  ..., -0.2347, -0.0251,  0.2656])\n",
      "contemplate\n",
      "Saved the embedding for contemplate.\n",
      "['contemplating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3041,  0.5663,  0.5040,  ..., -0.3495, -0.3093,  0.5611])\n",
      "contemplating\n",
      "Saved the embedding for contemplating.\n",
      "['con', '##tem', '##pl', '##ation'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4292, -0.2019, -0.0736,  ..., -0.1830,  0.0812,  0.2941])\n",
      "contemplation\n",
      "Saved the embedding for contemplation.\n",
      "['con', '##tem', '##pl', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4364, -0.2389, -0.1007,  ..., -0.2786,  0.0919,  0.4330])\n",
      "contemplative\n",
      "Saved the embedding for contemplative.\n",
      "['contempt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6247,  0.2590, -0.1418,  ..., -0.0715,  0.5273,  0.6868])\n",
      "contempt\n",
      "Saved the embedding for contempt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contempt', '##uous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4750,  0.2948, -0.2885,  ..., -0.4888,  0.3629,  0.4760])\n",
      "contemptuous\n",
      "Saved the embedding for contemptuous.\n",
      "['content'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2564, -0.0685,  0.6076,  ..., -0.1711, -0.0511,  0.1385])\n",
      "content\n",
      "Saved the embedding for content.\n",
      "['content', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1705, -0.1354,  0.5390,  ..., -0.2559,  0.0701,  0.1324])\n",
      "contented\n",
      "Saved the embedding for contented.\n",
      "['contentious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2854,  0.1342,  0.0460,  ..., -0.2448, -0.2145,  0.3199])\n",
      "contentious\n",
      "Saved the embedding for contentious.\n",
      "['content', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1278,  0.0149,  0.6229,  ..., -0.0146, -0.1392,  0.1582])\n",
      "contently\n",
      "Saved the embedding for contently.\n",
      "['content', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2486,  0.0337,  0.5555,  ..., -0.0591, -0.1683,  0.0419])\n",
      "contentment\n",
      "Saved the embedding for contentment.\n",
      "['contradictory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0565,  0.1566, -0.4670,  ...,  0.1358, -0.2470, -0.2652])\n",
      "contradictory\n",
      "Saved the embedding for contradictory.\n",
      "['contrary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2629, -0.3948, -0.1244,  ..., -0.2484,  0.1810,  0.9465])\n",
      "contrary\n",
      "Saved the embedding for contrary.\n",
      "['con', '##tri', '##te'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3726, -0.1435, -0.0704,  ..., -0.0672,  0.2333,  0.2889])\n",
      "contrite\n",
      "Saved the embedding for contrite.\n",
      "['controlled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0322,  0.2442, -0.5494,  ..., -0.4018, -0.6248,  0.6214])\n",
      "controlled\n",
      "Saved the embedding for controlled.\n",
      "['controlling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0978,  0.2366, -0.5618,  ..., -0.7782, -0.4463,  0.7138])\n",
      "controlling\n",
      "Saved the embedding for controlling.\n",
      "['controversial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0758,  0.0958,  0.5734,  ...,  0.0655, -0.4091,  0.1151])\n",
      "controversial\n",
      "Saved the embedding for controversial.\n",
      "['con', '##tum', '##acious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4002, -0.3658, -0.1848,  ..., -0.3230,  0.1202,  0.2056])\n",
      "contumacious\n",
      "Saved the embedding for contumacious.\n",
      "['convinced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0121,  0.6072, -0.4549,  ..., -0.1778,  0.3130,  0.6447])\n",
      "convinced\n",
      "Saved the embedding for convinced.\n",
      "['cool'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5450,  0.6012,  0.3509,  ...,  0.0325, -0.3664,  0.5231])\n",
      "cool\n",
      "Saved the embedding for cool.\n",
      "['cooperative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1984,  0.6263, -0.2108,  ..., -0.1464, -0.0434,  0.8748])\n",
      "cooperative\n",
      "Saved the embedding for cooperative.\n",
      "['cord', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2564, -0.3477,  0.0897,  ..., -0.3797,  0.3718, -0.1583])\n",
      "cordial\n",
      "Saved the embedding for cordial.\n",
      "['courageous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0611,  1.2115,  0.1242,  ...,  0.2552, -0.1037,  0.0617])\n",
      "courageous\n",
      "Saved the embedding for courageous.\n",
      "['covert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1619, -0.2654, -0.7546,  ..., -0.1615, -0.0241, -0.1849])\n",
      "covert\n",
      "Saved the embedding for covert.\n",
      "['coward', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4660,  0.4047, -0.2786,  ..., -0.4472, -0.4572,  0.2673])\n",
      "cowardly\n",
      "Saved the embedding for cowardly.\n",
      "['co', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2604, -0.1882, -0.3279,  ..., -0.4908,  0.2169,  0.3686])\n",
      "coy\n",
      "Saved the embedding for coy.\n",
      "['crab', '##by'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5239, -0.2178, -0.0828,  ..., -0.1064, -0.2823, -0.0903])\n",
      "crabby\n",
      "Saved the embedding for crabby.\n",
      "['craft', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9149,  0.4775, -0.7365,  ...,  0.1829,  0.3081,  0.6050])\n",
      "crafty\n",
      "Saved the embedding for crafty.\n",
      "['crank', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7079,  0.5461, -0.3568,  ..., -0.0086, -0.5617,  0.3729])\n",
      "cranky\n",
      "Saved the embedding for cranky.\n",
      "['crazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3158,  0.1587, -0.0939,  ..., -0.7009, -0.1794,  0.1483])\n",
      "crazed\n",
      "Saved the embedding for crazed.\n",
      "['crazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2139, -0.4260, -0.0632,  ..., -0.5938, -0.1858,  0.3507])\n",
      "crazy\n",
      "Saved the embedding for crazy.\n",
      "['cr', '##ed', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.6101, 0.1643, 0.0709,  ..., 0.1317, 0.6532, 0.6466])\n",
      "credulous\n",
      "Saved the embedding for credulous.\n",
      "['creepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0367,  0.2349,  0.0691,  ...,  0.1499,  0.5990,  0.2761])\n",
      "creepy\n",
      "Saved the embedding for creepy.\n",
      "['crest', '##fall', '##en'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4045, -0.2615, -0.5988,  ..., -0.1002,  0.1505,  0.1345])\n",
      "crestfallen\n",
      "Saved the embedding for crestfallen.\n",
      "['cr', '##inging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4787,  0.3898,  0.1975,  ..., -0.3598,  0.1692,  0.5946])\n",
      "cringing\n",
      "Saved the embedding for cringing.\n",
      "['critical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1152,  1.0015, -0.5327,  ...,  0.3728, -0.4088,  0.6269])\n",
      "critical\n",
      "Saved the embedding for critical.\n",
      "['cross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9064,  0.1571, -0.3739,  ...,  0.6768,  0.1640,  0.9134])\n",
      "cross\n",
      "Saved the embedding for cross.\n",
      "['crotch', '##ety'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1179,  0.3461, -0.0174,  ..., -0.1872, -0.1330, -0.0392])\n",
      "crotchety\n",
      "Saved the embedding for crotchety.\n",
      "['crude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6395, -0.0738, -0.7652,  ...,  0.0288,  0.5815, -0.0843])\n",
      "crude\n",
      "Saved the embedding for crude.\n",
      "['cruel'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5414,  0.3385, -0.1316,  ...,  0.0725, -0.1390,  0.4152])\n",
      "cruel\n",
      "Saved the embedding for cruel.\n",
      "['crushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8319,  0.1164, -0.1239,  ...,  0.1919,  0.1186, -0.1984])\n",
      "crushed\n",
      "Saved the embedding for crushed.\n",
      "['cry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0225,  0.4940, -0.3950,  ...,  0.0636,  0.1042,  0.0874])\n",
      "cry\n",
      "Saved the embedding for cry.\n",
      "['crying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2884,  0.4483, -0.0463,  ...,  0.1572,  0.0314,  0.2433])\n",
      "crying\n",
      "Saved the embedding for crying.\n",
      "['cryptic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6209, -0.2083, -0.0999,  ..., -0.1127,  0.7416, -0.0805])\n",
      "cryptic\n",
      "Saved the embedding for cryptic.\n",
      "['cu', '##lp', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0465, -0.5229, -0.4016,  ..., -0.0678,  0.0592,  0.3057])\n",
      "culpable\n",
      "Saved the embedding for culpable.\n",
      "['cunning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5974, -0.2006,  0.0293,  ..., -0.6910,  0.4237,  0.0619])\n",
      "cunning\n",
      "Saved the embedding for cunning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cu', '##rio', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0337, -0.5441, -0.4350,  ...,  0.1675,  0.3036,  0.5885])\n",
      "curios\n",
      "Saved the embedding for curios.\n",
      "['curiosity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0589,  0.4582,  0.8356,  ..., -0.2349,  0.2514,  0.9339])\n",
      "curiosity\n",
      "Saved the embedding for curiosity.\n",
      "['curious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1513,  0.2871,  0.3003,  ...,  0.1859,  0.5808,  0.7026])\n",
      "curious\n",
      "Saved the embedding for curious.\n",
      "['cutting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4853, -0.6611, -0.5175,  ...,  0.2412, -0.1532,  0.1422])\n",
      "cutting\n",
      "Saved the embedding for cutting.\n",
      "['cy', '##nic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4712,  0.5292,  0.0404,  ..., -0.2838, -0.0478,  0.5956])\n",
      "cynic\n",
      "Saved the embedding for cynic.\n",
      "['cynical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3756,  0.0982, -0.1831,  ..., -0.4696, -0.3474,  0.5433])\n",
      "cynical\n",
      "Saved the embedding for cynical.\n",
      "['cy', '##nic', '##ism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4361,  0.5211,  0.0852,  ..., -0.3412, -0.1197,  0.6216])\n",
      "cynicism\n",
      "Saved the embedding for cynicism.\n",
      "['dal', '##lian', '##ce'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5923,  0.2365, -0.1502,  ..., -0.0657,  0.1152,  0.4102])\n",
      "dalliance\n",
      "Saved the embedding for dalliance.\n",
      "['dan', '##dy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3415,  0.0786, -0.0932,  ...,  0.2523,  0.0122,  0.0051])\n",
      "dandy\n",
      "Saved the embedding for dandy.\n",
      "['dangerous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4869,  0.0713,  0.2040,  ..., -0.1588, -0.2765,  0.2009])\n",
      "dangerous\n",
      "Saved the embedding for dangerous.\n",
      "['darkly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2876, -0.0069, -0.4586,  ...,  0.7861,  0.1802,  0.6184])\n",
      "darkly\n",
      "Saved the embedding for darkly.\n",
      "['da', '##unt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0382,  0.2440, -0.2926,  ...,  0.5139,  0.1300,  0.4196])\n",
      "daunted\n",
      "Saved the embedding for daunted.\n",
      "['day', '##dre', '##am'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0415,  0.1866,  0.0271,  ...,  0.4314,  0.5995,  0.1963])\n",
      "daydream\n",
      "Saved the embedding for daydream.\n",
      "['day', '##dre', '##ami', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1467,  0.2121, -0.0494,  ...,  0.2305,  0.3992,  0.2589])\n",
      "daydreaming\n",
      "Saved the embedding for daydreaming.\n",
      "['dazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0220,  0.5706,  0.1274,  ..., -0.3443,  0.0281,  0.6775])\n",
      "dazed\n",
      "Saved the embedding for dazed.\n",
      "['da', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1178,  0.2085, -0.3134,  ...,  0.4937, -0.1915,  0.1592])\n",
      "dazzled\n",
      "Saved the embedding for dazzled.\n",
      "['deadly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5265,  0.0231,  0.1553,  ..., -0.0992, -0.0131, -0.0529])\n",
      "deadly\n",
      "Saved the embedding for deadly.\n",
      "['dead', '##pan'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3618, -0.1140,  0.0637,  ..., -0.0344,  0.4480, -0.2140])\n",
      "deadpan\n",
      "Saved the embedding for deadpan.\n",
      "['debate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4326,  0.6875, -0.0372,  ..., -0.0669, -0.0215,  0.4151])\n",
      "debate\n",
      "Saved the embedding for debate.\n",
      "['debating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4177,  0.3364, -0.0481,  ...,  0.1356,  0.2146,  0.2781])\n",
      "debating\n",
      "Saved the embedding for debating.\n",
      "['de', '##bau', '##ched'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1652, -0.2514, -0.0627,  ...,  0.2029,  0.4549,  0.5010])\n",
      "debauched\n",
      "Saved the embedding for debauched.\n",
      "['dec', '##eit', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1084,  0.4584,  0.1429,  ..., -0.6136,  0.7890,  0.5053])\n",
      "deceitful\n",
      "Saved the embedding for deceitful.\n",
      "['dec', '##ei', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1714,  0.4920,  0.2061,  ..., -0.4735,  0.7202,  0.5188])\n",
      "deceived\n",
      "Saved the embedding for deceived.\n",
      "['dec', '##ei', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0982,  0.4881,  0.1057,  ..., -0.5403,  0.7032,  0.5732])\n",
      "deceiving\n",
      "Saved the embedding for deceiving.\n",
      "['dec', '##ei', '##ving', '##ly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1697,  0.4483,  0.2523,  ..., -0.4089,  0.8180,  0.7725])\n",
      "deceivingly\n",
      "Saved the embedding for deceivingly.\n",
      "['deception'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6434,  0.0632, -0.3942,  ..., -0.1726,  0.0294,  0.3249])\n",
      "deception\n",
      "Saved the embedding for deception.\n",
      "['dec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2115,  0.4831,  0.1691,  ..., -0.4197,  0.7561,  0.7441])\n",
      "deceptive\n",
      "Saved the embedding for deceptive.\n",
      "['deciding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3205,  0.6610,  0.3663,  ..., -0.0220, -0.0110,  0.2733])\n",
      "deciding\n",
      "Saved the embedding for deciding.\n",
      "['decisive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3216,  0.6409, -0.4567,  ..., -0.1804, -0.3762,  0.4694])\n",
      "decisive\n",
      "Saved the embedding for decisive.\n",
      "['dedicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1437, 0.4438, 0.3755,  ..., 0.0563, 0.0985, 0.8960])\n",
      "dedicated\n",
      "Saved the embedding for dedicated.\n",
      "['defeat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4229,  0.1499, -0.1166,  ...,  0.5732,  0.4045,  0.0165])\n",
      "defeat\n",
      "Saved the embedding for defeat.\n",
      "['defeated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0084,  0.2105, -0.1685,  ...,  0.5059,  0.0698,  0.3737])\n",
      "defeated\n",
      "Saved the embedding for defeated.\n",
      "['defense', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0519,  1.2284, -0.6745,  ..., -0.5385,  0.4186,  0.0815])\n",
      "defenseless\n",
      "Saved the embedding for defenseless.\n",
      "['defensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0141,  0.5545, -0.3976,  ..., -0.1037,  0.4458, -0.1035])\n",
      "defensive\n",
      "Saved the embedding for defensive.\n",
      "['defiance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4549,  0.0306, -0.6215,  ..., -0.1657,  0.2183,  0.6578])\n",
      "defiance\n",
      "Saved the embedding for defiance.\n",
      "['defiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0606,  0.2535, -0.7201,  ...,  0.0946,  0.0442,  0.0402])\n",
      "defiant\n",
      "Saved the embedding for defiant.\n",
      "['def', '##lated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4723, -0.1819,  0.0553,  ...,  0.1517,  0.4118,  0.0698])\n",
      "deflated\n",
      "Saved the embedding for deflated.\n",
      "['de', '##ga', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2405, -0.3768,  0.2900,  ...,  0.2090,  0.3918,  0.4697])\n",
      "degage\n",
      "Saved the embedding for degage.\n",
      "['de', '##grad', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2675, -0.1900,  0.0917,  ...,  0.1260,  0.2276,  0.8016])\n",
      "degrading\n",
      "Saved the embedding for degrading.\n",
      "['de', '##jected'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2674, -0.3056,  0.2726,  ..., -0.0764,  0.3268,  0.6719])\n",
      "dejected\n",
      "Saved the embedding for dejected.\n",
      "['de', '##ject', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2723, -0.1100,  0.3159,  ...,  0.5469,  0.4696,  0.7186])\n",
      "dejection\n",
      "Saved the embedding for dejection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deliberate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8562,  0.4208, -0.1099,  ..., -0.7405,  0.3538,  0.1408])\n",
      "deliberate\n",
      "Saved the embedding for deliberate.\n",
      "['del', '##ibe', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1727, -0.0362, -0.1247,  ..., -0.1217,  0.6730, -0.0385])\n",
      "deliberating\n",
      "Saved the embedding for deliberating.\n",
      "['delight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0059,  0.0936,  0.1161,  ...,  0.1278,  0.1939, -0.0528])\n",
      "delight\n",
      "Saved the embedding for delight.\n",
      "['delighted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3622,  0.0283,  0.1005,  ..., -0.1933,  0.2001,  0.2265])\n",
      "delighted\n",
      "Saved the embedding for delighted.\n",
      "['delightful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2171,  0.3035,  0.2798,  ..., -0.4540, -0.2300,  0.2704])\n",
      "delightful\n",
      "Saved the embedding for delightful.\n",
      "['del', '##iri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1556, -0.2461, -0.1506,  ..., -0.2618,  0.3561,  0.0323])\n",
      "delirious\n",
      "Saved the embedding for delirious.\n",
      "['del', '##iri', '##um'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2001, -0.2631, -0.1174,  ..., -0.1149,  0.6368,  0.2382])\n",
      "delirium\n",
      "Saved the embedding for delirium.\n",
      "['del', '##ude'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0432, -0.1266, -0.0501,  ...,  0.0721,  0.6507,  0.1874])\n",
      "delude\n",
      "Saved the embedding for delude.\n",
      "['del', '##usion', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1289, -0.0736, -0.1249,  ..., -0.2261,  0.5090,  0.2184])\n",
      "delusional\n",
      "Saved the embedding for delusional.\n",
      "['demanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0339,  0.1803,  0.0911,  ...,  0.0434, -0.0730,  0.0790])\n",
      "demanding\n",
      "Saved the embedding for demanding.\n",
      "['dem', '##ean', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3279, -0.1348, -0.3112,  ...,  0.2562,  0.3912,  0.6044])\n",
      "demeaning\n",
      "Saved the embedding for demeaning.\n",
      "['dem', '##ented'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3537, -0.3118, -0.1863,  ...,  0.2041,  0.1040,  0.4901])\n",
      "demented\n",
      "Saved the embedding for demented.\n",
      "['demise', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0905,  0.3235,  0.2556,  ..., -0.1586,  0.5437, -0.0101])\n",
      "demised\n",
      "Saved the embedding for demised.\n",
      "['demo', '##ral', '##ized'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3108,  0.1495,  0.1118,  ...,  0.0764,  0.2969, -0.0675])\n",
      "demoralized\n",
      "Saved the embedding for demoralized.\n",
      "['dem', '##ure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2401, -0.0026, -0.4001,  ...,  0.2977,  0.4467,  0.7524])\n",
      "demure\n",
      "Saved the embedding for demure.\n",
      "['denied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0795, -0.5627, -0.2897,  ..., -0.6234, -0.4280,  0.4947])\n",
      "denied\n",
      "Saved the embedding for denied.\n",
      "['den', '##oun', '##cing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1701, -0.0977, -0.3461,  ...,  0.6479,  0.3434,  0.3938])\n",
      "denouncing\n",
      "Saved the embedding for denouncing.\n",
      "['depleted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1850,  0.3503, -0.3040,  ..., -0.0648, -0.2436, -0.0166])\n",
      "depleted\n",
      "Saved the embedding for depleted.\n",
      "['de', '##pl', '##ora', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2333, -0.4059,  0.2292,  ...,  0.1834,  0.3285,  0.5450])\n",
      "deplorable\n",
      "Saved the embedding for deplorable.\n",
      "['de', '##pre', '##cating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3476, -0.1672,  0.1201,  ...,  0.6682,  0.4109,  0.7089])\n",
      "deprecating\n",
      "Saved the embedding for deprecating.\n",
      "['depressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1446,  0.7267, -0.3872,  ..., -1.1322, -0.2384,  0.2479])\n",
      "depressed\n",
      "Saved the embedding for depressed.\n",
      "['depression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1682,  1.3343, -0.8089,  ..., -0.3520, -0.0868,  0.2259])\n",
      "depression\n",
      "Saved the embedding for depression.\n",
      "['deprived'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2091,  0.0268,  0.6813,  ..., -0.5396, -0.3095, -0.1161])\n",
      "deprived\n",
      "Saved the embedding for deprived.\n",
      "['der', '##ange', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0924, -0.0154, -0.8260,  ...,  0.8527, -0.1236,  0.9081])\n",
      "deranged\n",
      "Saved the embedding for deranged.\n",
      "['der', '##ision'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0045,  0.0396, -1.0421,  ...,  0.7665, -0.0253,  0.8180])\n",
      "derision\n",
      "Saved the embedding for derision.\n",
      "['der', '##isi', '##ve'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1511,  0.0067, -0.9332,  ...,  0.6144,  0.0327,  0.8780])\n",
      "derisive\n",
      "Saved the embedding for derisive.\n",
      "['der', '##oga', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0131, -0.1452, -0.9245,  ...,  0.7273, -0.0810,  1.0459])\n",
      "derogatory\n",
      "Saved the embedding for derogatory.\n",
      "['desire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0035,  0.3778, -0.0772,  ..., -0.0744, -0.2387,  0.4208])\n",
      "desire\n",
      "Saved the embedding for desire.\n",
      "['des', '##iring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0624, -0.2122, -0.4429,  ...,  0.5413,  0.6967,  0.7319])\n",
      "desiring\n",
      "Saved the embedding for desiring.\n",
      "['des', '##iro', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2638, -0.2144, -0.5309,  ...,  0.3759,  0.6119,  0.5703])\n",
      "desirous\n",
      "Saved the embedding for desirous.\n",
      "['des', '##olate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2296, -0.3442, -0.4166,  ...,  0.4438,  0.5237,  0.9683])\n",
      "desolate\n",
      "Saved the embedding for desolate.\n",
      "['despair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3811,  0.1746, -0.2035,  ...,  0.1505, -0.0506, -0.0460])\n",
      "despair\n",
      "Saved the embedding for despair.\n",
      "['despair', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3514,  0.1344, -0.1969,  ...,  0.1521,  0.1388,  0.0553])\n",
      "despaired\n",
      "Saved the embedding for despaired.\n",
      "['despair', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2570,  0.1316, -0.1933,  ...,  0.1057,  0.1848,  0.0984])\n",
      "despairing\n",
      "Saved the embedding for despairing.\n",
      "['desperate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4207,  0.1915, -0.5230,  ..., -0.5746, -0.2471,  0.0956])\n",
      "desperate\n",
      "Saved the embedding for desperate.\n",
      "['desperation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2708,  0.0712, -0.5036,  ..., -0.2801, -0.0407, -0.0348])\n",
      "desperation\n",
      "Saved the embedding for desperation.\n",
      "['des', '##pis', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3567, -0.3242, -0.3648,  ...,  0.5189,  0.6802,  0.7660])\n",
      "despise\n",
      "Saved the embedding for despise.\n",
      "['des', '##pon', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1017, -0.2779, -0.5282,  ...,  0.5238,  0.7037,  0.7576])\n",
      "despondent\n",
      "Saved the embedding for despondent.\n",
      "['des', '##ti', '##tute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0470, -0.2887, -0.5050,  ...,  0.5115,  0.8241,  0.5255])\n",
      "destitute\n",
      "Saved the embedding for destitute.\n",
      "['destroyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4223,  0.4080, -0.0801,  ...,  0.4513, -0.0294, -0.1617])\n",
      "destroyed\n",
      "Saved the embedding for destroyed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['detached'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2938, -0.3780, -0.2961,  ..., -0.5731, -0.1811,  0.8537])\n",
      "detached\n",
      "Saved the embedding for detached.\n",
      "['determination'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4880,  0.5368, -0.6584,  ..., -0.5456,  0.2716,  0.6208])\n",
      "determination\n",
      "Saved the embedding for determination.\n",
      "['determined'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1321,  0.5865, -0.4246,  ..., -0.0625,  0.3426,  0.6296])\n",
      "determined\n",
      "Saved the embedding for determined.\n",
      "['determining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3774,  1.0257, -0.5345,  ..., -0.1861, -0.2725,  0.7019])\n",
      "determining\n",
      "Saved the embedding for determining.\n",
      "['deter', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4926,  0.4516, -0.5377,  ..., -0.4418, -0.5398,  0.5830])\n",
      "deterred\n",
      "Saved the embedding for deterred.\n",
      "['det', '##est'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4693,  0.0293, -0.5380,  ...,  0.4877, -0.3158,  0.8174])\n",
      "detest\n",
      "Saved the embedding for detest.\n",
      "['det', '##est', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3627, -0.0807, -0.5197,  ...,  0.4614, -0.2874,  0.7779])\n",
      "detestable\n",
      "Saved the embedding for detestable.\n",
      "['det', '##est', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4264, -0.0216, -0.5737,  ...,  0.5011, -0.4059,  0.8304])\n",
      "detesting\n",
      "Saved the embedding for detesting.\n",
      "['det', '##rim', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4368, -0.5552, -0.3709,  ...,  0.2798, -0.3237,  0.8084])\n",
      "detriment\n",
      "Saved the embedding for detriment.\n",
      "['devastated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4710,  0.2439,  0.0504,  ..., -0.1816,  0.1210, -0.1649])\n",
      "devastated\n",
      "Saved the embedding for devastated.\n",
      "['devi', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3898, -0.2153, -0.0285,  ...,  0.1719, -0.0025,  0.9358])\n",
      "deviant\n",
      "Saved the embedding for deviant.\n",
      "['devil', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1506, -0.1439, -0.2446,  ...,  0.6562,  0.2741, -0.0559])\n",
      "devilish\n",
      "Saved the embedding for devilish.\n",
      "['devi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2713, -0.0118, -0.1137,  ...,  0.0716,  0.1176,  0.6691])\n",
      "devious\n",
      "Saved the embedding for devious.\n",
      "['devi', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4222, -0.1035,  0.0225,  ...,  0.1744,  0.2195,  0.5564])\n",
      "devising\n",
      "Saved the embedding for devising.\n",
      "['di', '##ffi', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1658, -0.3571, -0.1862,  ...,  0.0319,  0.5924,  0.8009])\n",
      "diffident\n",
      "Saved the embedding for diffident.\n",
      "['dil', '##atory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0494, -0.0199, -0.5925,  ...,  0.1119,  0.3578,  0.8027])\n",
      "dilatory\n",
      "Saved the embedding for dilatory.\n",
      "['dil', '##igen', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0428,  0.0072, -0.3785,  ...,  0.3222,  0.2130,  0.8971])\n",
      "diligent\n",
      "Saved the embedding for diligent.\n",
      "['dim', '##wi', '##tted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0203, -0.1604, -0.3597,  ..., -0.1106,  0.1612,  0.0876])\n",
      "dimwitted\n",
      "Saved the embedding for dimwitted.\n",
      "['dire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5817,  0.3846, -0.4812,  ..., -0.3225,  0.2706, -0.2485])\n",
      "dire\n",
      "Saved the embedding for dire.\n",
      "['disagree'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2777, 0.3898, 0.3049,  ..., 0.0542, 0.3400, 0.4133])\n",
      "disagree\n",
      "Saved the embedding for disagree.\n",
      "['disagree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0192,  0.5119,  0.2558,  ..., -0.0187,  0.3857,  0.3592])\n",
      "disagreeable\n",
      "Saved the embedding for disagreeable.\n",
      "['disagreement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3093,  0.3780, -0.1124,  ..., -0.3296,  0.0846,  0.4934])\n",
      "disagreement\n",
      "Saved the embedding for disagreement.\n",
      "['disappointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0834,  0.1501, -0.0280,  ..., -0.3542,  0.1064,  0.4320])\n",
      "disappointed\n",
      "Saved the embedding for disappointed.\n",
      "['disappointing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1197,  0.0622, -0.0695,  ...,  0.0520,  0.0698,  0.1302])\n",
      "disappointing\n",
      "Saved the embedding for disappointing.\n",
      "['disappointment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1868,  0.4009,  0.2962,  ..., -0.8068,  0.3479,  0.4692])\n",
      "disappointment\n",
      "Saved the embedding for disappointment.\n",
      "['disapproval'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5479,  0.1875, -0.2457,  ..., -0.4093,  0.2647,  0.3035])\n",
      "disapproval\n",
      "Saved the embedding for disapproval.\n",
      "['di', '##sa', '##pp', '##roving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1556, -0.4090, -0.0507,  ..., -0.2275,  0.2462,  0.7233])\n",
      "disapproving\n",
      "Saved the embedding for disapproving.\n",
      "['disbelief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5078,  0.7657, -0.4713,  ..., -0.4892,  0.3382,  0.5074])\n",
      "disbelief\n",
      "Saved the embedding for disbelief.\n",
      "['di', '##sb', '##eli', '##eve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2723, -0.3688, -0.2094,  ..., -0.2848,  0.5392,  0.5331])\n",
      "disbelieve\n",
      "Saved the embedding for disbelieve.\n",
      "['di', '##sb', '##eli', '##eving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2521, -0.3894, -0.1894,  ..., -0.2030,  0.3151,  0.5199])\n",
      "disbelieving\n",
      "Saved the embedding for disbelieving.\n",
      "['disc', '##ern', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1289, -0.0350, -0.3869,  ...,  0.3029,  0.2240,  0.6372])\n",
      "discerning\n",
      "Saved the embedding for discerning.\n",
      "['disco', '##mbo', '##bula', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4606, -0.2337, -0.5449,  ...,  0.2117,  0.1654,  0.3867])\n",
      "discombobulated\n",
      "Saved the embedding for discombobulated.\n",
      "['disco', '##m', '##fi', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4821, -0.1131, -0.3546,  ...,  0.2207,  0.0665,  0.1277])\n",
      "discomfited\n",
      "Saved the embedding for discomfited.\n",
      "['discomfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6378,  0.6258, -0.3610,  ..., -0.5338, -0.0611,  0.8415])\n",
      "discomfort\n",
      "Saved the embedding for discomfort.\n",
      "['discomfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6760,  0.5521, -0.2375,  ..., -0.3634,  0.2211,  0.7590])\n",
      "discomforted\n",
      "Saved the embedding for discomforted.\n",
      "['disco', '##nce', '##rted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3190, -0.2109, -0.5344,  ...,  0.0134,  0.1987,  0.2358])\n",
      "disconcerted\n",
      "Saved the embedding for disconcerted.\n",
      "['disconnected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1430,  0.1402,  0.0303,  ..., -0.4114, -0.1136,  0.3804])\n",
      "disconnected\n",
      "Saved the embedding for disconnected.\n",
      "['disco', '##ns', '##olate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4060, -0.1014, -0.3569,  ...,  0.0567,  0.0609,  0.6341])\n",
      "disconsolate\n",
      "Saved the embedding for disconsolate.\n",
      "['discontent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2927,  0.1328, -0.2911,  ...,  0.2803, -0.4250,  0.1785])\n",
      "discontent\n",
      "Saved the embedding for discontent.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discontent', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3166,  0.1076, -0.2163,  ...,  0.2748, -0.2628,  0.1450])\n",
      "discontented\n",
      "Saved the embedding for discontented.\n",
      "['discount', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4470, -0.3483, -0.0346,  ...,  0.3565,  0.3051,  0.3686])\n",
      "discounted\n",
      "Saved the embedding for discounted.\n",
      "['discouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6820,  0.0201, -0.8367,  ..., -1.0486, -0.3584,  0.5964])\n",
      "discouraged\n",
      "Saved the embedding for discouraged.\n",
      "['discovery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3987, -0.3133, -0.0142,  ..., -0.1192,  0.4577,  0.0703])\n",
      "discovery\n",
      "Saved the embedding for discovery.\n",
      "['disc', '##rim', '##inating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2959, -0.1703, -0.1225,  ...,  0.1623,  0.4603,  0.5827])\n",
      "discriminating\n",
      "Saved the embedding for discriminating.\n",
      "['discussed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0336,  0.7081,  0.2244,  ...,  0.5461,  0.1718, -0.0034])\n",
      "discussed\n",
      "Saved the embedding for discussed.\n",
      "['disdain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6693,  0.1598, -0.3678,  ...,  0.0670,  0.2525,  0.7608])\n",
      "disdain\n",
      "Saved the embedding for disdain.\n",
      "['disdain', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 5.7762e-01,  1.6288e-01, -3.8900e-01,  ..., -5.2583e-04,\n",
      "         4.6535e-01,  5.9769e-01])\n",
      "disdained\n",
      "Saved the embedding for disdained.\n",
      "['disdain', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5290,  0.2100, -0.3701,  ..., -0.0135,  0.3830,  0.6214])\n",
      "disdainful\n",
      "Saved the embedding for disdainful.\n",
      "['disdain', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5808,  0.1687, -0.3941,  ...,  0.1451,  0.3638,  0.6432])\n",
      "disdainfully\n",
      "Saved the embedding for disdainfully.\n",
      "['di', '##sen', '##chan', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1701, -0.4034, -0.1456,  ..., -0.0589,  0.2759,  0.7148])\n",
      "disenchanted\n",
      "Saved the embedding for disenchanted.\n",
      "['di', '##sen', '##ga', '##ged'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1354, -0.4514, -0.1862,  ..., -0.0858,  0.1961,  0.6417])\n",
      "disengaged\n",
      "Saved the embedding for disengaged.\n",
      "['disgrace', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6571,  0.2371,  0.0645,  ..., -0.3619,  0.2880, -0.1174])\n",
      "disgraced\n",
      "Saved the embedding for disgraced.\n",
      "['di', '##sg', '##run', '##tled'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2714, -0.4699, -0.1203,  ..., -0.1840,  0.1239,  0.5308])\n",
      "disgruntled\n",
      "Saved the embedding for disgruntled.\n",
      "['di', '##sg', '##run', '##tlement'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2861, -0.4500, -0.1595,  ..., -0.2691,  0.0461,  0.4472])\n",
      "disgruntlement\n",
      "Saved the embedding for disgruntlement.\n",
      "['disgust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9268,  0.6868, -0.1849,  ..., -0.6703,  0.3152,  0.2822])\n",
      "disgust\n",
      "Saved the embedding for disgust.\n",
      "['disgusted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9108,  0.1537, -0.4202,  ..., -0.5250, -0.1408,  0.4208])\n",
      "disgusted\n",
      "Saved the embedding for disgusted.\n",
      "['disgusted', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6278,  0.2732, -0.3832,  ..., -0.2091,  0.1415,  0.4666])\n",
      "disgustedly\n",
      "Saved the embedding for disgustedly.\n",
      "['disgusting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9093, -0.1065, -0.4685,  ..., -0.1526, -0.0250,  0.4273])\n",
      "disgusting\n",
      "Saved the embedding for disgusting.\n",
      "['dish', '##ear', '##ten', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4431, -0.6471,  0.0043,  ...,  0.2104,  0.4233,  0.4803])\n",
      "disheartened\n",
      "Saved the embedding for disheartened.\n",
      "['dish', '##ones', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3910, -0.6786,  0.0338,  ...,  0.1928,  0.1615,  0.4942])\n",
      "dishonest\n",
      "Saved the embedding for dishonest.\n",
      "['di', '##sil', '##lusion', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1345, -0.4595, -0.0063,  ..., -0.3624,  0.4149,  0.6182])\n",
      "disillusioned\n",
      "Saved the embedding for disillusioned.\n",
      "['di', '##sin', '##cl', '##ined'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1805, -0.3724, -0.1514,  ..., -0.4918, -0.0924,  0.8069])\n",
      "disinclined\n",
      "Saved the embedding for disinclined.\n",
      "['di', '##sing', '##en', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0680, -0.3850, -0.0716,  ..., -0.1218,  0.4469,  0.7225])\n",
      "disingenuous\n",
      "Saved the embedding for disingenuous.\n",
      "['di', '##sin', '##ter', '##est'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1715, -0.2736,  0.0384,  ..., -0.1512,  0.1996,  0.6682])\n",
      "disinterest\n",
      "Saved the embedding for disinterest.\n",
      "['di', '##sin', '##ter', '##ested'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1560, -0.3620,  0.1163,  ..., -0.1892,  0.0018,  0.7043])\n",
      "disinterested\n",
      "Saved the embedding for disinterested.\n",
      "['di', '##s', '##jo', '##int', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.1200, -0.3374, -0.0913,  ..., -0.0962,  0.1856,  0.5729])\n",
      "disjointed\n",
      "Saved the embedding for disjointed.\n",
      "['dislike'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8253, -0.4394, -0.0554,  ..., -0.7720, -0.0457,  0.5041])\n",
      "dislike\n",
      "Saved the embedding for dislike.\n",
      "['disliked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1803, -0.0569, -0.1054,  ..., -0.0069, -0.4090,  0.6901])\n",
      "disliked\n",
      "Saved the embedding for disliked.\n",
      "['di', '##sl', '##iki', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2803, -0.3379, -0.2455,  ..., -0.1174,  0.2813,  0.7259])\n",
      "disliking\n",
      "Saved the embedding for disliking.\n",
      "['di', '##sma', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2448, -0.2308, -0.0249,  ..., -0.3621,  0.2323,  0.4782])\n",
      "dismal\n",
      "Saved the embedding for dismal.\n",
      "['di', '##sman'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2431, -0.3655, -0.0672,  ..., -0.0284,  0.1673,  0.5889])\n",
      "disman\n",
      "Saved the embedding for disman.\n",
      "['dismay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1056,  0.1132, -0.1576,  ..., -0.8120,  0.8274,  0.3105])\n",
      "dismay\n",
      "Saved the embedding for dismay.\n",
      "['dismay', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0173,  0.1267, -0.1792,  ..., -0.5617,  0.9541,  0.3622])\n",
      "dismayed\n",
      "Saved the embedding for dismayed.\n",
      "['dismiss', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4139,  0.1130, -0.1641,  ..., -0.1813,  0.6554,  0.8519])\n",
      "dismissive\n",
      "Saved the embedding for dismissive.\n",
      "['di', '##so', '##bed', '##ient'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0772, -0.4107, -0.0214,  ...,  0.0260,  0.3379,  0.5635])\n",
      "disobedient\n",
      "Saved the embedding for disobedient.\n",
      "['disorder', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2741,  0.5025,  0.1669,  ...,  0.0186, -0.4293,  0.0492])\n",
      "disorderly\n",
      "Saved the embedding for disorderly.\n",
      "['di', '##sor', '##iente', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0614, -0.2795, -0.1439,  ..., -0.2314,  0.3173,  0.4521])\n",
      "disoriented\n",
      "Saved the embedding for disoriented.\n",
      "['di', '##sp', '##air'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1918, -0.4147, -0.2123,  ..., -0.2105,  0.3039,  0.5790])\n",
      "dispair\n",
      "Saved the embedding for dispair.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['di', '##spar', '##aging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1468, -0.3479, -0.1235,  ..., -0.1063,  0.2488,  0.6816])\n",
      "disparaging\n",
      "Saved the embedding for disparaging.\n",
      "['di', '##sp', '##ass', '##ion', '##ate'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.2805, -0.3286, -0.0962,  ..., -0.0583,  0.5164,  0.7174])\n",
      "dispassionate\n",
      "Saved the embedding for dispassionate.\n",
      "['di', '##sp', '##iri', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3227, -0.4280, -0.0614,  ..., -0.1769,  0.4249,  0.4843])\n",
      "dispirited\n",
      "Saved the embedding for dispirited.\n",
      "['di', '##sp', '##iri', '##ted', '##ness'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.3150, -0.4154, -0.0340,  ..., -0.2423,  0.3704,  0.4814])\n",
      "dispiritedness\n",
      "Saved the embedding for dispiritedness.\n",
      "['di', '##sp', '##lea', '##sed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2960, -0.3558, -0.1731,  ..., -0.1600,  0.4151,  0.4307])\n",
      "displeased\n",
      "Saved the embedding for displeased.\n",
      "['displeasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0840,  0.0440, -0.0579,  ..., -0.3070,  0.5306,  0.2421])\n",
      "displeasure\n",
      "Saved the embedding for displeasure.\n",
      "['di', '##s', '##qui', '##et'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0658, -0.4422, -0.1502,  ..., -0.0140,  0.3918,  0.5535])\n",
      "disquiet\n",
      "Saved the embedding for disquiet.\n",
      "['di', '##s', '##qui', '##ete', '##d'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0742, -0.3779, -0.1362,  ..., -0.1208,  0.3223,  0.4765])\n",
      "disquieted\n",
      "Saved the embedding for disquieted.\n",
      "['disregard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5594,  1.0977, -0.5834,  ...,  0.2379, -0.3430,  0.4321])\n",
      "disregard\n",
      "Saved the embedding for disregard.\n",
      "['di', '##sr', '##es', '##pe', '##ct', '##ful'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([ 0.1926, -0.3441, -0.0585,  ..., -0.2196,  0.2716,  0.6299])\n",
      "disrespectful\n",
      "Saved the embedding for disrespectful.\n",
      "['disrupted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8910,  0.5234,  0.1706,  ..., -0.4840, -0.0667,  0.0554])\n",
      "disrupted\n",
      "Saved the embedding for disrupted.\n",
      "['disrupt', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5235,  0.6962, -0.3040,  ..., -0.2481,  0.0998,  0.2723])\n",
      "disruptive\n",
      "Saved the embedding for disruptive.\n",
      "['dissatisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0565,  0.2820, -0.1960,  ..., -0.2584, -0.3745,  0.3429])\n",
      "dissatisfaction\n",
      "Saved the embedding for dissatisfaction.\n",
      "['dissatisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0181,  0.1612, -0.0951,  ..., -0.0946, -0.0566,  0.7378])\n",
      "dissatisfied\n",
      "Saved the embedding for dissatisfied.\n",
      "['di', '##ssa', '##tis', '##fy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1773, -0.4853, -0.0202,  ..., -0.2400,  0.5544,  0.4213])\n",
      "dissatisfy\n",
      "Saved the embedding for dissatisfy.\n",
      "['di', '##sse', '##cting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0408, -0.2423, -0.1094,  ...,  0.2095,  0.3631,  0.9231])\n",
      "dissecting\n",
      "Saved the embedding for dissecting.\n",
      "['di', '##sso', '##cia', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1197, -0.4134, -0.0689,  ..., -0.2715,  0.4106,  0.7087])\n",
      "dissociated\n",
      "Saved the embedding for dissociated.\n",
      "['di', '##sson', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1579, -0.3265, -0.0923,  ..., -0.3111,  0.0550,  0.8043])\n",
      "dissonant\n",
      "Saved the embedding for dissonant.\n",
      "['di', '##sta', '##in'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2022, -0.3312, -0.1750,  ..., -0.3994, -0.1146,  0.7571])\n",
      "distain\n",
      "Saved the embedding for distain.\n",
      "['distant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0642,  0.1288, -0.3498,  ..., -0.9123, -0.1929,  0.6733])\n",
      "distant\n",
      "Saved the embedding for distant.\n",
      "['di', '##sta', '##ste'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1176, -0.3209, -0.1906,  ..., -0.2866,  0.1884,  0.5355])\n",
      "distaste\n",
      "Saved the embedding for distaste.\n",
      "['di', '##sta', '##ste', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1163, -0.3611, -0.1551,  ..., -0.2835,  0.3288,  0.3714])\n",
      "distasteful\n",
      "Saved the embedding for distasteful.\n",
      "['distracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2688,  0.3998,  0.3395,  ..., -0.5781, -0.0082,  0.2781])\n",
      "distracted\n",
      "Saved the embedding for distracted.\n",
      "['distraught'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0674,  0.0552, -0.0668,  ..., -0.7807,  0.1875,  0.0065])\n",
      "distraught\n",
      "Saved the embedding for distraught.\n",
      "['distress'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2542,  0.5448,  0.5501,  ..., -0.0892,  0.7666,  0.2781])\n",
      "distress\n",
      "Saved the embedding for distress.\n",
      "['distressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0142, -0.1280,  0.1060,  ..., -0.2990,  0.3972,  0.3199])\n",
      "distressed\n",
      "Saved the embedding for distressed.\n",
      "['distress', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1216, 0.5208, 0.5117,  ..., 0.0857, 0.9247, 0.3340])\n",
      "distressing\n",
      "Saved the embedding for distressing.\n",
      "['distrust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4165,  0.0983, -0.2155,  ..., -0.0082, -0.0857,  0.8396])\n",
      "distrust\n",
      "Saved the embedding for distrust.\n",
      "['distrust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2831,  0.1627, -0.2124,  ...,  0.1279,  0.0608,  0.8349])\n",
      "distrustful\n",
      "Saved the embedding for distrustful.\n",
      "['distrust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2431,  0.1152, -0.1832,  ...,  0.0478,  0.1840,  0.9086])\n",
      "distrusting\n",
      "Saved the embedding for distrusting.\n",
      "['disturbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3027,  0.8352, -0.0948,  ..., -0.2436,  0.1111,  0.3571])\n",
      "disturbed\n",
      "Saved the embedding for disturbed.\n",
      "['diverted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1282,  0.3827,  0.2059,  ..., -0.4234, -0.7552,  0.2269])\n",
      "diverted\n",
      "Saved the embedding for diverted.\n",
      "['dod', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3281,  0.0162, -0.2726,  ..., -0.2016,  0.0383,  0.1542])\n",
      "dodgy\n",
      "Saved the embedding for dodgy.\n",
      "['do', '##le', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1017, -0.3065, -0.3291,  ...,  0.2811,  0.2510,  0.3332])\n",
      "doleful\n",
      "Saved the embedding for doleful.\n",
      "['do', '##lt', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3090, -0.4378, -0.2649,  ...,  0.6064, -0.0551,  0.4768])\n",
      "doltish\n",
      "Saved the embedding for doltish.\n",
      "['dominant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3934,  0.4625, -0.4491,  ..., -0.4036, -0.3195,  0.3841])\n",
      "dominant\n",
      "Saved the embedding for dominant.\n",
      "['dominating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2383,  0.6074, -0.5643,  ..., -0.2511,  0.3234,  0.1057])\n",
      "dominating\n",
      "Saved the embedding for dominating.\n",
      "['dom', '##ine', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5787,  0.1995, -0.1546,  ...,  0.2516,  0.2515,  0.4837])\n",
      "domineering\n",
      "Saved the embedding for domineering.\n",
      "['done'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8416,  0.1330, -0.3725,  ...,  0.3219, -0.3821, -0.0497])\n",
      "done\n",
      "Saved the embedding for done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doomed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4431, -0.0569, -0.1926,  ...,  0.2137, -0.0587,  0.1960])\n",
      "doomed\n",
      "Saved the embedding for doomed.\n",
      "['do', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1215, -0.2783, -0.4336,  ...,  0.3338, -0.0433,  0.2783])\n",
      "dopey\n",
      "Saved the embedding for dopey.\n",
      "['dot', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3917, -0.0688, -0.4580,  ...,  0.1827,  0.3892,  0.9523])\n",
      "doting\n",
      "Saved the embedding for doting.\n",
      "['doubt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6401, -0.2576, -0.3894,  ...,  0.0657, -0.0948,  0.2754])\n",
      "doubt\n",
      "Saved the embedding for doubt.\n",
      "['doubt', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6319, -0.2027, -0.3952,  ...,  0.1878,  0.0250,  0.3404])\n",
      "doubter\n",
      "Saved the embedding for doubter.\n",
      "['doubtful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0117, -0.1362, -0.0569,  ..., -0.4358,  0.4743,  0.2781])\n",
      "doubtful\n",
      "Saved the embedding for doubtful.\n",
      "['doubtful', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1756, -0.0707, -0.1231,  ..., -0.2649,  0.5862,  0.3162])\n",
      "doubtfully\n",
      "Saved the embedding for doubtfully.\n",
      "['doubtful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0409, -0.1168, -0.0854,  ..., -0.3171,  0.4800,  0.5138])\n",
      "doubtfulness\n",
      "Saved the embedding for doubtfulness.\n",
      "['doubt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5946, -0.1927, -0.4440,  ...,  0.0874,  0.0510,  0.3132])\n",
      "doubting\n",
      "Saved the embedding for doubting.\n",
      "['do', '##ur'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3251, -0.4466, -0.2557,  ...,  0.6953,  0.0675,  0.3341])\n",
      "dour\n",
      "Saved the embedding for dour.\n",
      "['down'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1628, -0.1509, -0.3227,  ...,  0.1434, -0.2705,  0.2139])\n",
      "down\n",
      "Saved the embedding for down.\n",
      "['down', '##cast'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2258, -0.4128, -0.2633,  ..., -0.1422, -0.1575,  0.2031])\n",
      "downcast\n",
      "Saved the embedding for downcast.\n",
      "['down', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2493, -0.2679, -0.1382,  ...,  0.2669, -0.3125,  0.1876])\n",
      "downhearted\n",
      "Saved the embedding for downhearted.\n",
      "['down', '##hearted', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2863, -0.2343, -0.1181,  ...,  0.2160, -0.1227,  0.1073])\n",
      "downheartedness\n",
      "Saved the embedding for downheartedness.\n",
      "['down', '##tro', '##dden'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1982, -0.1668, -0.2021,  ..., -0.0479, -0.1817,  0.1754])\n",
      "downtrodden\n",
      "Saved the embedding for downtrodden.\n",
      "['do', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1720, -0.0952, -0.2833,  ...,  0.2944, -0.1394,  0.4168])\n",
      "dozing\n",
      "Saved the embedding for dozing.\n",
      "['drained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7506,  0.0684,  0.3962,  ..., -0.5446,  0.2068,  0.3073])\n",
      "drained\n",
      "Saved the embedding for drained.\n",
      "['dramatic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2664,  0.7537, -0.2488,  ...,  0.1842,  0.1493,  0.2713])\n",
      "dramatic\n",
      "Saved the embedding for dramatic.\n",
      "['drawn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.8079, 0.1115, 0.0392,  ..., 0.4538, 0.0623, 0.2810])\n",
      "drawn\n",
      "Saved the embedding for drawn.\n",
      "['dread'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9422,  0.2203, -0.2002,  ..., -0.1567, -0.0508,  0.0498])\n",
      "dread\n",
      "Saved the embedding for dread.\n",
      "['dreadful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8811,  0.0078, -0.3562,  ..., -1.0718,  0.4016, -0.0526])\n",
      "dreadful\n",
      "Saved the embedding for dreadful.\n",
      "['dread', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6830,  0.1415, -0.2699,  ..., -0.0445, -0.1112,  0.3001])\n",
      "dreading\n",
      "Saved the embedding for dreading.\n",
      "['dreaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1505,  0.6034, -0.3652,  ..., -0.0699,  0.0235,  0.4516])\n",
      "dreaming\n",
      "Saved the embedding for dreaming.\n",
      "['dream', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0626,  0.4683, -0.2008,  ..., -0.0268,  0.3798,  0.4656])\n",
      "dreamy\n",
      "Saved the embedding for dreamy.\n",
      "['dr', '##ear', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0786, -0.0634,  0.2710,  ...,  0.0976,  0.6669,  0.5427])\n",
      "dreary\n",
      "Saved the embedding for dreary.\n",
      "['driven'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4259,  0.2099,  0.0324,  ..., -0.0025,  0.1031,  0.3247])\n",
      "driven\n",
      "Saved the embedding for driven.\n",
      "['dr', '##ows', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.0415, 0.0019, 0.2737,  ..., 0.1769, 0.6878, 0.4584])\n",
      "drowsy\n",
      "Saved the embedding for drowsy.\n",
      "['drugged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7284,  0.1535, -0.1599,  ..., -0.1086, -0.0729, -0.1605])\n",
      "drugged\n",
      "Saved the embedding for drugged.\n",
      "['drunk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1208,  0.6778,  0.1226,  ..., -0.4039,  0.0508, -0.3205])\n",
      "drunk\n",
      "Saved the embedding for drunk.\n",
      "['drunken', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0201,  0.5491,  0.1069,  ..., -0.6497, -0.0166, -0.0795])\n",
      "drunkenness\n",
      "Saved the embedding for drunkenness.\n",
      "['dub', '##ie', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3637,  0.1787, -0.5693,  ...,  0.1815,  0.1864,  0.0922])\n",
      "dubiety\n",
      "Saved the embedding for dubiety.\n",
      "['dubious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0920, -0.2585, -0.5447,  ..., -0.3011,  0.1063,  0.3412])\n",
      "dubious\n",
      "Saved the embedding for dubious.\n",
      "['dubious', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0813, -0.1507, -0.4067,  ..., -0.3032,  0.1675,  0.3016])\n",
      "dubiously\n",
      "Saved the embedding for dubiously.\n",
      "['dull'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2091,  0.4605, -0.1506,  ..., -0.4108, -0.1607,  0.3593])\n",
      "dull\n",
      "Saved the embedding for dull.\n",
      "['dumb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4403,  0.3462,  0.0798,  ..., -0.3118, -0.2518, -0.1715])\n",
      "dumb\n",
      "Saved the embedding for dumb.\n",
      "['dumb', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4465,  0.2758,  0.2571,  ..., -0.2336,  0.2456,  0.2380])\n",
      "dumbfound\n",
      "Saved the embedding for dumbfound.\n",
      "['dumb', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4237,  0.2555,  0.2673,  ..., -0.4849, -0.1227,  0.2242])\n",
      "dumbfounded\n",
      "Saved the embedding for dumbfounded.\n",
      "['dumb', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4003,  0.5235,  0.4256,  ..., -0.1057,  0.1421,  0.1650])\n",
      "dumbstruck\n",
      "Saved the embedding for dumbstruck.\n",
      "['du', '##m', '##founded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0769, -0.0084,  0.1197,  ...,  0.5216,  0.3723,  1.0792])\n",
      "dumfounded\n",
      "Saved the embedding for dumfounded.\n",
      "['du', '##pe'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1586,  0.2114, -0.0354,  ...,  0.9535,  0.6659,  0.7245])\n",
      "dupe\n",
      "Saved the embedding for dupe.\n",
      "['du', '##pl', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2413,  0.0204,  0.0388,  ...,  0.8937,  0.6834,  0.7198])\n",
      "duplicitous\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for duplicitous.\n",
      "['d', '##ys', '##ph', '##oric'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0143,  0.4767, -0.0647,  ..., -0.1957, -0.0123,  0.3296])\n",
      "dysphoric\n",
      "Saved the embedding for dysphoric.\n",
      "['eager'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1798, -0.0618,  0.1392,  ...,  0.0858,  0.4320,  0.0667])\n",
      "eager\n",
      "Saved the embedding for eager.\n",
      "['eager', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2770, -0.0415,  0.1982,  ...,  0.2867,  0.4079,  0.3165])\n",
      "eagerness\n",
      "Saved the embedding for eagerness.\n",
      "['earnest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1098,  0.6345,  0.1075,  ..., -0.5859,  0.7765,  0.0462])\n",
      "earnest\n",
      "Saved the embedding for earnest.\n",
      "['easy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6286, -0.1051, -0.5452,  ..., -0.0014, -0.0387,  0.7186])\n",
      "easy\n",
      "Saved the embedding for easy.\n",
      "['e', '##bu', '##llie', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0154, -0.1512, -0.1384,  ...,  0.0269, -0.3657,  0.5610])\n",
      "ebullient\n",
      "Saved the embedding for ebullient.\n",
      "['ecstasy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5745,  0.3928,  0.1523,  ..., -0.6986, -0.1942, -0.3166])\n",
      "ecstasy\n",
      "Saved the embedding for ecstasy.\n",
      "['ec', '##static'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0892,  1.0584, -0.1138,  ..., -0.0583,  0.6360,  1.2978])\n",
      "ecstatic\n",
      "Saved the embedding for ecstatic.\n",
      "['ec', '##static', '##ally'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0742,  0.9708, -0.1209,  ..., -0.0717,  0.6745,  1.3163])\n",
      "ecstatically\n",
      "Saved the embedding for ecstatically.\n",
      "['ed', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1249, -0.3518, -0.0355,  ...,  0.7569,  0.3038,  1.2398])\n",
      "edgy\n",
      "Saved the embedding for edgy.\n",
      "['eerie'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5346,  0.6480, -0.3215,  ...,  0.2683, -0.2102,  0.4929])\n",
      "eerie\n",
      "Saved the embedding for eerie.\n",
      "['e', '##ff', '##ul', '##gent'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0319, -0.3198, -0.0262,  ..., -0.2233, -0.1941,  0.5188])\n",
      "effulgent\n",
      "Saved the embedding for effulgent.\n",
      "['ego', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1639,  0.6512, -0.4563,  ..., -0.0196, -0.5467,  1.0332])\n",
      "egoistic\n",
      "Saved the embedding for egoistic.\n",
      "['ego', '##tist', '##ical'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1493,  0.6210, -0.5264,  ..., -0.4377, -0.6029,  1.1856])\n",
      "egotistical\n",
      "Saved the embedding for egotistical.\n",
      "['e', '##gre', '##gio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0786, -0.3146,  0.0206,  ..., -0.2094, -0.2229,  0.6504])\n",
      "egregious\n",
      "Saved the embedding for egregious.\n",
      "['el', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2212,  0.4634, -0.0956,  ...,  0.2574,  0.0509, -0.5276])\n",
      "elated\n",
      "Saved the embedding for elated.\n",
      "['el', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1492,  0.5569, -0.0926,  ...,  0.3078, -0.0892, -0.3879])\n",
      "elation\n",
      "Saved the embedding for elation.\n",
      "['electrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1457,  0.1831, -0.3090,  ...,  0.4270,  0.1020,  0.0587])\n",
      "electrified\n",
      "Saved the embedding for electrified.\n",
      "['elusive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3302,  0.2042,  0.3304,  ..., -0.1999,  0.0591,  0.4175])\n",
      "elusive\n",
      "Saved the embedding for elusive.\n",
      "['embarrassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3113,  0.2084, -0.3129,  ..., -0.8105, -0.0939,  0.2227])\n",
      "embarrassed\n",
      "Saved the embedding for embarrassed.\n",
      "['embarrassment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1061,  0.5472, -0.3382,  ..., -0.8915,  0.2285,  0.3549])\n",
      "embarrassment\n",
      "Saved the embedding for embarrassment.\n",
      "['em', '##bit', '##tered'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3776, -0.1381, -0.8316,  ...,  0.0111, -0.0351,  0.0869])\n",
      "embittered\n",
      "Saved the embedding for embittered.\n",
      "['em', '##body'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4206, -0.1495, -0.8686,  ...,  0.0870, -0.1943,  0.0054])\n",
      "embody\n",
      "Saved the embedding for embody.\n",
      "['emotional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0766,  0.8023, -0.0091,  ..., -0.5137, -0.4096,  0.4196])\n",
      "emotional\n",
      "Saved the embedding for emotional.\n",
      "['emotion', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3059,  0.8541,  0.7355,  ..., -0.1641, -0.1387,  0.7846])\n",
      "emotionless\n",
      "Saved the embedding for emotionless.\n",
      "['em', '##path', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3419, -0.2088, -0.6796,  ..., -0.2037,  0.0376,  0.5161])\n",
      "empathetic\n",
      "Saved the embedding for empathetic.\n",
      "['em', '##pathic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3673, -0.1408, -0.8025,  ..., -0.4519, -0.1690, -0.0451])\n",
      "empathic\n",
      "Saved the embedding for empathic.\n",
      "['empathy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4850,  0.6867, -0.0288,  ..., -0.1450, -0.0809,  0.6644])\n",
      "empathy\n",
      "Saved the embedding for empathy.\n",
      "['emptiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5356,  0.3800,  0.1716,  ..., -0.1432, -0.0160,  0.5737])\n",
      "emptiness\n",
      "Saved the embedding for emptiness.\n",
      "['empty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6305,  0.3813,  0.0830,  ..., -0.1230, -0.2153,  0.3451])\n",
      "empty\n",
      "Saved the embedding for empty.\n",
      "['en', '##amo', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5152, -0.3022, -0.5849,  ...,  0.0577,  0.2104,  0.2766])\n",
      "enamored\n",
      "Saved the embedding for enamored.\n",
      "['enchanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4190,  0.3614, -0.2378,  ..., -0.1654,  0.5999, -0.0689])\n",
      "enchanted\n",
      "Saved the embedding for enchanted.\n",
      "['encouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0185,  0.0393, -0.4338,  ..., -0.6000, -0.1126,  0.3451])\n",
      "encouraged\n",
      "Saved the embedding for encouraged.\n",
      "['encouragement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1429,  0.2794, -0.3357,  ..., -0.4450,  0.0770,  0.6124])\n",
      "encouragement\n",
      "Saved the embedding for encouragement.\n",
      "['encouraging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3448, -0.0250, -0.1461,  ..., -0.6228,  0.1402,  0.5429])\n",
      "encouraging\n",
      "Saved the embedding for encouraging.\n",
      "['end', '##ear', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5327, -0.3467, -0.0613,  ...,  0.0278,  0.0036, -0.0164])\n",
      "endeared\n",
      "Saved the embedding for endeared.\n",
      "['end', '##earing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5005, -0.3561,  0.0253,  ..., -0.1361, -0.1781,  0.1911])\n",
      "endearing\n",
      "Saved the embedding for endearing.\n",
      "['enduring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6391,  0.4519, -0.1154,  ..., -0.2629, -0.3745,  0.5192])\n",
      "enduring\n",
      "Saved the embedding for enduring.\n",
      "['energetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1918,  0.8905, -0.0778,  ..., -0.0361,  0.2173,  0.0327])\n",
      "energetic\n",
      "Saved the embedding for energetic.\n",
      "['en', '##er', '##gi', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4362, -0.3240, -0.6344,  ...,  0.2986,  0.3410,  0.4052])\n",
      "energized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for energized.\n",
      "['engaged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2886,  0.9410, -0.2154,  ..., -0.9590, -0.4393, -0.1185])\n",
      "engaged\n",
      "Saved the embedding for engaged.\n",
      "['eng', '##ross', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1748,  0.4167, -0.3022,  ...,  0.1660,  0.4460,  1.0606])\n",
      "engrossed\n",
      "Saved the embedding for engrossed.\n",
      "['eng', '##ross', '##ment'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2296,  0.3986, -0.3508,  ...,  0.1479,  0.5014,  1.0224])\n",
      "engrossment\n",
      "Saved the embedding for engrossment.\n",
      "['enigma', '##tic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.9478, 0.8079, 0.3330,  ..., 0.3836, 0.2270, 0.9118])\n",
      "enigmatic\n",
      "Saved the embedding for enigmatic.\n",
      "['enjoy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1463, -0.2680,  0.9499,  ..., -0.0420, -0.0379,  0.2170])\n",
      "enjoy\n",
      "Saved the embedding for enjoy.\n",
      "['enjoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1058, -0.1068,  0.6262,  ...,  0.0413, -0.0784,  0.3474])\n",
      "enjoying\n",
      "Saved the embedding for enjoying.\n",
      "['enjoyment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1326,  0.3244,  0.5978,  ..., -0.5318, -0.2564,  0.1608])\n",
      "enjoyment\n",
      "Saved the embedding for enjoyment.\n",
      "['en', '##light', '##ened'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4414, -0.2857, -0.5848,  ...,  0.3495,  0.3205,  0.3189])\n",
      "enlightened\n",
      "Saved the embedding for enlightened.\n",
      "['en', '##mity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4995, -0.3762, -0.7163,  ...,  0.2995,  0.3363,  0.3273])\n",
      "enmity\n",
      "Saved the embedding for enmity.\n",
      "['en', '##nu', '##i'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2973, -0.1831, -0.5733,  ...,  0.4166,  0.2021,  0.3980])\n",
      "ennui\n",
      "Saved the embedding for ennui.\n",
      "['enraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4133,  0.5940, -0.8363,  ..., -0.3976, -0.0548, -0.0693])\n",
      "enraged\n",
      "Saved the embedding for enraged.\n",
      "['en', '##rag', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3956, -0.3772, -0.5701,  ...,  0.2687,  0.0463,  0.4448])\n",
      "enraging\n",
      "Saved the embedding for enraging.\n",
      "['en', '##ra', '##pt', '##ured'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6033, -0.4049, -0.6003,  ..., -0.0718,  0.2278,  0.4877])\n",
      "enraptured\n",
      "Saved the embedding for enraptured.\n",
      "['entertained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5701,  0.4452,  0.1553,  ..., -0.3054,  0.4538,  0.2333])\n",
      "entertained\n",
      "Saved the embedding for entertained.\n",
      "['en', '##th', '##ral', '##led'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5671, -0.2763, -0.4951,  ...,  0.1089,  0.1457,  0.2938])\n",
      "enthralled\n",
      "Saved the embedding for enthralled.\n",
      "['en', '##thus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4686, -0.3115, -0.5677,  ...,  0.0934,  0.4084,  0.1749])\n",
      "enthused\n",
      "Saved the embedding for enthused.\n",
      "['enthusiasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1084,  0.4674,  0.0094,  ..., -0.3039,  0.0175,  0.5948])\n",
      "enthusiasm\n",
      "Saved the embedding for enthusiasm.\n",
      "['enthusiastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0113,  0.2005, -0.0185,  ...,  0.1226,  0.2198,  0.1934])\n",
      "enthusiastic\n",
      "Saved the embedding for enthusiastic.\n",
      "['en', '##tic', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5335, -0.2745, -0.5094,  ...,  0.4180,  0.4400,  0.4044])\n",
      "enticed\n",
      "Saved the embedding for enticed.\n",
      "['entrance', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0534,  0.2588, -0.6833,  ..., -0.1381, -0.0487, -0.0961])\n",
      "entranced\n",
      "Saved the embedding for entranced.\n",
      "['en', '##vious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4430, -0.3440, -0.6243,  ...,  0.3750,  0.3571,  0.3421])\n",
      "envious\n",
      "Saved the embedding for envious.\n",
      "['envy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2248, 0.3743, 0.1954,  ..., 0.4976, 0.3183, 0.6182])\n",
      "envy\n",
      "Saved the embedding for envy.\n",
      "['erotic', '##ally'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0318, -0.1140, -0.0431,  ...,  0.0707, -0.1750,  0.2636])\n",
      "erotically\n",
      "Saved the embedding for erotically.\n",
      "['estranged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2480, -0.2934, -0.2793,  ..., -0.2418, -0.2897,  0.2632])\n",
      "estranged\n",
      "Saved the embedding for estranged.\n",
      "['etched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9634,  0.5916, -0.0954,  ...,  0.9531,  0.8306,  0.4000])\n",
      "etched\n",
      "Saved the embedding for etched.\n",
      "['eu', '##ph', '##oric'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2564,  0.3020,  0.5383,  ...,  0.1562,  0.0323,  0.4371])\n",
      "euphoric\n",
      "Saved the embedding for euphoric.\n",
      "['evaluating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3090,  0.3480, -0.3276,  ...,  0.0328,  0.0495,  0.6844])\n",
      "evaluating\n",
      "Saved the embedding for evaluating.\n",
      "['eva', '##sive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6726,  0.0924, -0.4359,  ..., -0.3269, -0.3486, -0.2846])\n",
      "evasive\n",
      "Saved the embedding for evasive.\n",
      "['evil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1942,  0.4787, -0.3564,  ..., -0.0072,  0.1726,  0.0418])\n",
      "evil\n",
      "Saved the embedding for evil.\n",
      "['ev', '##oke'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0254, -0.1533, -0.6909,  ..., -0.1411,  0.0398,  0.3750])\n",
      "evoke\n",
      "Saved the embedding for evoke.\n",
      "['ex', '##ace', '##rba', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5098, -0.4616,  0.4509,  ..., -0.6414,  0.0869,  0.3021])\n",
      "exacerbated\n",
      "Saved the embedding for exacerbated.\n",
      "['ex', '##al', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5089, -0.3981,  0.3936,  ..., -0.6135,  0.3172,  0.4383])\n",
      "exalted\n",
      "Saved the embedding for exalted.\n",
      "['examining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0684,  0.1668, -0.2496,  ...,  0.0870,  0.4584,  0.6239])\n",
      "examining\n",
      "Saved the embedding for examining.\n",
      "['ex', '##as', '##per', '##ate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4890, -0.4500,  0.3900,  ..., -0.7334,  0.4332,  0.7121])\n",
      "exasperate\n",
      "Saved the embedding for exasperate.\n",
      "['exasperated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0380,  0.2998, -0.2650,  ..., -0.2757, -0.0209,  0.6406])\n",
      "exasperated\n",
      "Saved the embedding for exasperated.\n",
      "['ex', '##as', '##peration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4005, -0.5155,  0.4224,  ..., -0.6784,  0.2897,  0.3806])\n",
      "exasperation\n",
      "Saved the embedding for exasperation.\n",
      "['excited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2157,  0.4097, -0.3861,  ...,  0.0420,  0.0128,  0.1265])\n",
      "excited\n",
      "Saved the embedding for excited.\n",
      "['excitedly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0350,  0.0247,  0.0689,  ..., -0.0775,  0.2375, -0.0553])\n",
      "excitedly\n",
      "Saved the embedding for excitedly.\n",
      "['excitement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0367,  0.5735,  0.0776,  ..., -0.3958,  0.2930,  0.4368])\n",
      "excitement\n",
      "Saved the embedding for excitement.\n",
      "['ex', '##cl', '##ama', '##tion'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4486, -0.5171,  0.2812,  ..., -0.8542,  0.0707,  0.5768])\n",
      "exclamation\n",
      "Saved the embedding for exclamation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ex', '##cl', '##ama', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4919, -0.6570,  0.3935,  ..., -0.8711,  0.2260,  0.3995])\n",
      "exclamatory\n",
      "Saved the embedding for exclamatory.\n",
      "['exhausted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0528,  0.1054, -0.4832,  ..., -0.2470, -0.0791, -0.1748])\n",
      "exhausted\n",
      "Saved the embedding for exhausted.\n",
      "['exhaustion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1942, -0.0943, -0.2555,  ..., -0.1647, -0.1238,  0.1015])\n",
      "exhaustion\n",
      "Saved the embedding for exhaustion.\n",
      "['exhaust', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2761,  0.1334, -0.6596,  ..., -0.2392, -0.2967, -0.0298])\n",
      "exhaustive\n",
      "Saved the embedding for exhaustive.\n",
      "['ex', '##hila', '##rated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4906, -0.5937,  0.3160,  ..., -0.9157,  0.2252,  0.5287])\n",
      "exhilarated\n",
      "Saved the embedding for exhilarated.\n",
      "['ex', '##hila', '##ration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5020, -0.5228,  0.3796,  ..., -0.7392,  0.1706,  0.4635])\n",
      "exhilaration\n",
      "Saved the embedding for exhilaration.\n",
      "['exited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4232, -0.0241, -0.2544,  ...,  0.0548,  0.3565,  0.3131])\n",
      "exited\n",
      "Saved the embedding for exited.\n",
      "['expect', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2523,  0.2475, -0.1335,  ...,  0.1485,  0.5738,  0.1616])\n",
      "expectant\n",
      "Saved the embedding for expectant.\n",
      "['expectation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1482,  0.4072, -0.4112,  ...,  0.6330,  0.0853,  0.4449])\n",
      "expectation\n",
      "Saved the embedding for expectation.\n",
      "['expecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2896,  0.3053, -0.1233,  ..., -0.3238,  0.4763,  0.2331])\n",
      "expecting\n",
      "Saved the embedding for expecting.\n",
      "['explain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.3272, 0.8493, 0.0882,  ..., 0.2590, 0.0969, 0.8194])\n",
      "explain\n",
      "Saved the embedding for explain.\n",
      "['explaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1094,  0.6942, -0.4262,  ...,  0.3825, -0.0816,  0.4930])\n",
      "explaining\n",
      "Saved the embedding for explaining.\n",
      "['exploit', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1939,  0.4639, -1.0306,  ..., -0.0945, -0.0510, -0.0497])\n",
      "exploitive\n",
      "Saved the embedding for exploitive.\n",
      "['explosive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6541,  0.5587, -0.2378,  ..., -0.3400, -0.4463, -0.5521])\n",
      "explosive\n",
      "Saved the embedding for explosive.\n",
      "['exposure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3845,  0.6922, -1.1436,  ..., -0.8992, -0.3804,  0.2339])\n",
      "exposure\n",
      "Saved the embedding for exposure.\n",
      "['expressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1044,  0.9832,  0.2149,  ...,  0.4672, -0.2212, -0.0483])\n",
      "expressive\n",
      "Saved the embedding for expressive.\n",
      "['ex', '##uber', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5335, -0.5872,  0.3397,  ..., -0.7960,  0.1254,  0.5556])\n",
      "exuberant\n",
      "Saved the embedding for exuberant.\n",
      "['ex', '##ult', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5145, -0.6434,  0.3378,  ..., -0.9382,  0.2528,  0.8979])\n",
      "exultant\n",
      "Saved the embedding for exultant.\n",
      "['ex', '##ult', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4472, -0.5956,  0.3357,  ..., -0.7657,  0.2993,  0.7027])\n",
      "exulted\n",
      "Saved the embedding for exulted.\n",
      "['eye'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6052,  0.4839, -0.1708,  ...,  0.0458,  0.2726,  0.5176])\n",
      "eye\n",
      "Saved the embedding for eye.\n",
      "['eyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1623, -0.0764,  0.0149,  ..., -0.2319,  0.5513,  0.4600])\n",
      "eyed\n",
      "Saved the embedding for eyed.\n",
      "['faced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0257,  0.6214, -0.3890,  ...,  0.2505,  0.2349,  0.4284])\n",
      "faced\n",
      "Saved the embedding for faced.\n",
      "['face', '##tious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3999,  0.4062, -0.2899,  ..., -0.0547,  0.1507,  0.5490])\n",
      "facetious\n",
      "Saved the embedding for facetious.\n",
      "['failure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0147,  1.0393, -0.8765,  ...,  0.0595, -0.1090, -0.3506])\n",
      "failure\n",
      "Saved the embedding for failure.\n",
      "['faint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4712,  0.0350, -0.0877,  ...,  0.3879,  0.5082, -0.1251])\n",
      "faint\n",
      "Saved the embedding for faint.\n",
      "['fair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3260,  0.8357,  0.0214,  ...,  0.3477,  0.2526, -0.1894])\n",
      "fair\n",
      "Saved the embedding for fair.\n",
      "['fake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8795, -0.7576, -0.3112,  ...,  0.0138, -0.1840, -0.4398])\n",
      "fake\n",
      "Saved the embedding for fake.\n",
      "['fa', '##king'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3475, -0.1491, -0.5636,  ...,  0.6066,  0.1156,  0.5228])\n",
      "faking\n",
      "Saved the embedding for faking.\n",
      "['fa', '##lter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2120, -0.2050, -0.4842,  ...,  0.3348,  0.2540,  0.6946])\n",
      "falter\n",
      "Saved the embedding for falter.\n",
      "['fa', '##mis', '##hed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2950, -0.2845, -0.5435,  ...,  0.4932,  0.2209,  0.2051])\n",
      "famished\n",
      "Saved the embedding for famished.\n",
      "['fan', '##atic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1099, -0.7291,  0.0374,  ..., -0.4073, -0.0634,  0.3274])\n",
      "fanatic\n",
      "Saved the embedding for fanatic.\n",
      "['fan', '##ciful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0934, -0.7715, -0.1253,  ..., -0.4106,  0.4405,  0.4066])\n",
      "fanciful\n",
      "Saved the embedding for fanciful.\n",
      "['far', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1916,  0.2737, -0.1830,  ..., -0.2111,  0.1531,  0.2670])\n",
      "fart\n",
      "Saved the embedding for fart.\n",
      "['fascinated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2210,  0.4048, -0.1644,  ...,  0.4660,  0.2136,  1.0968])\n",
      "fascinated\n",
      "Saved the embedding for fascinated.\n",
      "['fast', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1567, -0.7425,  0.2523,  ..., -0.1985,  0.4428,  0.1801])\n",
      "fastidious\n",
      "Saved the embedding for fastidious.\n",
      "['fatigue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4254,  0.2258, -0.5486,  ...,  0.3357,  0.4873, -0.4542])\n",
      "fatigue\n",
      "Saved the embedding for fatigue.\n",
      "['fatigue', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4549,  0.3135, -0.3421,  ...,  0.3572,  0.4580, -0.3477])\n",
      "fatigued\n",
      "Saved the embedding for fatigued.\n",
      "['fault', '##fin', '##ding'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4591,  0.4068,  0.2081,  ..., -0.7022,  0.1044,  0.9531])\n",
      "faultfinding\n",
      "Saved the embedding for faultfinding.\n",
      "['favorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1709,  0.7491, -0.7896,  ..., -0.0296, -0.0818,  0.1171])\n",
      "favorable\n",
      "Saved the embedding for favorable.\n",
      "['fa', '##wn', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1763, -0.2716, -0.5749,  ...,  0.5633,  0.3057,  0.7866])\n",
      "fawning\n",
      "Saved the embedding for fawning.\n",
      "['fa', '##zed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2942,  0.0137, -0.6087,  ...,  0.5911,  0.1668,  0.4347])\n",
      "fazed\n",
      "Saved the embedding for fazed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2452,  0.6029, -0.0857,  ...,  0.2375, -0.1638,  0.3226])\n",
      "fear\n",
      "Saved the embedding for fear.\n",
      "['feared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2403,  0.4179, -0.4202,  ..., -0.0637,  0.0877, -0.0051])\n",
      "feared\n",
      "Saved the embedding for feared.\n",
      "['fearful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1797,  0.3532, -0.3933,  ..., -0.0917,  0.0640,  0.4447])\n",
      "fearful\n",
      "Saved the embedding for fearful.\n",
      "['fearing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1652,  0.4260, -0.3647,  ...,  0.1443,  0.0216,  0.2843])\n",
      "fearing\n",
      "Saved the embedding for fearing.\n",
      "['fearless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0620, -0.0822, -0.1728,  ...,  0.0148,  0.3252,  0.0297])\n",
      "fearless\n",
      "Saved the embedding for fearless.\n",
      "['fears', '##ome'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1938,  0.4239, -0.2533,  ..., -0.2081,  0.2630,  0.4685])\n",
      "fearsome\n",
      "Saved the embedding for fearsome.\n",
      "['fe', '##ckle', '##ss'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1877,  0.6477, -0.2792,  ...,  0.4016,  0.6039,  0.6316])\n",
      "feckless\n",
      "Saved the embedding for feckless.\n",
      "['fed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8951,  0.2441, -0.5548,  ..., -0.1051, -0.5579,  0.6732])\n",
      "fed\n",
      "Saved the embedding for fed.\n",
      "['fee', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1081, -0.4488, -0.3159,  ...,  0.2722,  0.5693,  0.4956])\n",
      "feeble\n",
      "Saved the embedding for feeble.\n",
      "['fei', '##gn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4360,  0.4832, -0.3172,  ...,  0.2477, -0.0320,  0.4494])\n",
      "feign\n",
      "Saved the embedding for feign.\n",
      "['fe', '##lic', '##ito', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1986,  0.4742, -0.2050,  ..., -0.1732,  0.4265,  0.5587])\n",
      "felicitous\n",
      "Saved the embedding for felicitous.\n",
      "['ferocious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2801,  0.3534, -0.3474,  ..., -0.2787,  0.0350,  0.5814])\n",
      "ferocious\n",
      "Saved the embedding for ferocious.\n",
      "['fe', '##rocity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1922,  0.5853, -0.3943,  ..., -0.0818,  0.2845,  0.6549])\n",
      "ferocity\n",
      "Saved the embedding for ferocity.\n",
      "['fest', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5597,  0.6101,  0.5888,  ...,  0.4045,  0.5753,  0.3327])\n",
      "festive\n",
      "Saved the embedding for festive.\n",
      "['fi', '##dget', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2504, -0.2575, -0.1225,  ...,  0.0085,  0.1633,  0.2232])\n",
      "fidgety\n",
      "Saved the embedding for fidgety.\n",
      "['fi', '##end', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0506, -0.3184, -0.1881,  ...,  0.1783,  0.1127,  0.6494])\n",
      "fiendish\n",
      "Saved the embedding for fiendish.\n",
      "['fierce'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3119,  0.3304,  0.0594,  ..., -0.2717, -0.0826,  0.4572])\n",
      "fierce\n",
      "Saved the embedding for fierce.\n",
      "['fiery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6365,  0.1062, -0.0816,  ..., -0.3103,  0.2982,  0.0290])\n",
      "fiery\n",
      "Saved the embedding for fiery.\n",
      "['fighting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3443,  0.6501, -0.4012,  ...,  0.5136,  0.3658,  0.3852])\n",
      "fighting\n",
      "Saved the embedding for fighting.\n",
      "['fine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6822, -0.0080,  0.1829,  ..., -0.0197, -0.0068,  0.3446])\n",
      "fine\n",
      "Saved the embedding for fine.\n",
      "['finished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8929,  0.2099,  0.3464,  ...,  0.3470,  0.1349, -0.1633])\n",
      "finished\n",
      "Saved the embedding for finished.\n",
      "['firm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3836,  0.5817, -0.1052,  ..., -0.4682,  0.1876,  0.4674])\n",
      "firm\n",
      "Saved the embedding for firm.\n",
      "['fish', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4027,  0.0410, -0.2728,  ...,  0.0299, -0.0553, -0.3031])\n",
      "fishy\n",
      "Saved the embedding for fishy.\n",
      "['fix', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1261, -0.2515,  0.0875,  ...,  0.0341,  0.4357,  1.0334])\n",
      "fixated\n",
      "Saved the embedding for fixated.\n",
      "['fixed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1381, -0.0627, -0.1516,  ..., -0.0258, -0.4676,  0.4066])\n",
      "fixed\n",
      "Saved the embedding for fixed.\n",
      "['fl', '##ab', '##berg', '##ast', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([0.5765, 0.2245, 0.0113,  ..., 0.4124, 0.5188, 0.1238])\n",
      "flabbergasted\n",
      "Saved the embedding for flabbergasted.\n",
      "['flaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8563,  0.6036, -0.2116,  ..., -0.6059, -0.3017,  0.5250])\n",
      "flaming\n",
      "Saved the embedding for flaming.\n",
      "['flat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2590,  0.1654, -0.5103,  ...,  0.1614, -0.4103,  0.3064])\n",
      "flat\n",
      "Saved the embedding for flat.\n",
      "['fl', '##au', '##nting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6622,  0.3424,  0.0140,  ...,  0.3038,  0.2762, -0.0461])\n",
      "flaunting\n",
      "Saved the embedding for flaunting.\n",
      "['flight', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5297,  0.7065,  0.2168,  ...,  0.2538,  0.8004, -0.3839])\n",
      "flighty\n",
      "Saved the embedding for flighty.\n",
      "['flip', '##pan', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1352, -0.1021, -0.3391,  ...,  0.4696,  0.3871, -0.1311])\n",
      "flippant\n",
      "Saved the embedding for flippant.\n",
      "['flipped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1326,  0.2188, -0.2747,  ..., -0.4850, -0.1425,  0.2750])\n",
      "flipped\n",
      "Saved the embedding for flipped.\n",
      "['flirt', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0259, -0.1081,  0.5338,  ..., -0.6120,  0.4446,  0.1149])\n",
      "flirtation\n",
      "Saved the embedding for flirtation.\n",
      "['flirt', '##ati', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0567, -0.2177,  0.5375,  ..., -0.6300,  0.2925,  0.3225])\n",
      "flirtatious\n",
      "Saved the embedding for flirtatious.\n",
      "['flirt', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0119, -0.1463,  0.5143,  ..., -0.4883,  0.1809,  0.2378])\n",
      "flirty\n",
      "Saved the embedding for flirty.\n",
      "['floor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6226,  0.4672, -0.2527,  ...,  0.9057,  0.0523, -0.1215])\n",
      "floored\n",
      "Saved the embedding for floored.\n",
      "['flu', '##mm', '##ox', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 1.0770,  0.4164,  0.1930,  ..., -0.2262,  0.2247,  1.0312])\n",
      "flummoxed\n",
      "Saved the embedding for flummoxed.\n",
      "['flu', '##stered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8289,  0.3437,  0.2917,  ..., -0.2585,  0.3806,  0.8394])\n",
      "flustered\n",
      "Saved the embedding for flustered.\n",
      "['focus'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0914,  0.4389,  0.1844,  ..., -0.0785, -0.6082,  0.4726])\n",
      "focus\n",
      "Saved the embedding for focus.\n",
      "['focused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2955,  0.4789, -0.1990,  ..., -0.0037, -0.2522,  0.4785])\n",
      "focused\n",
      "Saved the embedding for focused.\n",
      "['focusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4977,  1.0537, -0.3775,  ..., -0.2808, -0.8744,  0.0966])\n",
      "focusing\n",
      "Saved the embedding for focusing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foil', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5514,  0.2605, -0.7877,  ...,  0.3268,  0.2366,  0.4914])\n",
      "foiled\n",
      "Saved the embedding for foiled.\n",
      "['foolish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4449,  0.4786, -0.2532,  ..., -0.2759,  0.0371,  0.2724])\n",
      "foolish\n",
      "Saved the embedding for foolish.\n",
      "['for', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0688,  0.1661, -0.3011,  ...,  0.0129,  0.1739,  0.1552])\n",
      "forbearing\n",
      "Saved the embedding for forbearing.\n",
      "['forbid', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3827, -0.4935, -0.6576,  ..., -0.0187,  0.2286,  0.4612])\n",
      "forbidding\n",
      "Saved the embedding for forbidding.\n",
      "['forced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0917,  0.1033, -0.1248,  ..., -0.1484,  0.0104, -0.1050])\n",
      "forced\n",
      "Saved the embedding for forced.\n",
      "['forceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0942,  0.8285, -0.3631,  ..., -0.2725, -0.0525,  0.3299])\n",
      "forceful\n",
      "Saved the embedding for forceful.\n",
      "['for', '##feit', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0458,  0.0938, -0.1278,  ..., -0.3706, -0.0114,  0.0564])\n",
      "forfeited\n",
      "Saved the embedding for forfeited.\n",
      "['for', '##lor', '##n'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0078,  0.1398, -0.2134,  ..., -0.0930,  0.1155,  0.2319])\n",
      "forlorn\n",
      "Saved the embedding for forlorn.\n",
      "['fortunate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0384,  0.3194,  0.0094,  ..., -0.7109,  0.3349,  0.1752])\n",
      "fortunate\n",
      "Saved the embedding for fortunate.\n",
      "['forward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2487,  0.9281, -0.5316,  ..., -0.2127,  0.0682,  0.2833])\n",
      "forward\n",
      "Saved the embedding for forward.\n",
      "['foul'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6068,  0.1917,  0.0709,  ...,  0.1514, -0.1123, -0.6430])\n",
      "foul\n",
      "Saved the embedding for foul.\n",
      "['fra', '##ct', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.6941, 0.4473, 0.2611,  ..., 0.1719, 0.4248, 0.5981])\n",
      "fractious\n",
      "Saved the embedding for fractious.\n",
      "['fragile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4462,  0.0223,  0.3080,  ..., -0.3240,  0.0470,  0.6462])\n",
      "fragile\n",
      "Saved the embedding for fragile.\n",
      "['frantic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0804, -0.1400, -0.3070,  ..., -0.4179, -0.1317,  0.1337])\n",
      "frantic\n",
      "Saved the embedding for frantic.\n",
      "['fraudulent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3128, -0.2750,  0.0451,  ..., -0.2730,  0.2902, -0.5497])\n",
      "fraudulent\n",
      "Saved the embedding for fraudulent.\n",
      "['fra', '##ught'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5404,  0.4659,  0.1984,  ..., -0.0401,  0.1797,  0.4742])\n",
      "fraught\n",
      "Saved the embedding for fraught.\n",
      "['fra', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.5597, 0.4258, 0.1345,  ..., 0.1892, 0.0956, 0.4554])\n",
      "frazzled\n",
      "Saved the embedding for frazzled.\n",
      "['freaked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1380,  0.4587, -0.5595,  ..., -0.2368, -0.1389,  0.0898])\n",
      "freaked\n",
      "Saved the embedding for freaked.\n",
      "['fr', '##en', '##zie', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([0.3073, 0.0265, 0.0740,  ..., 0.3894, 0.3644, 0.7430])\n",
      "frenzied\n",
      "Saved the embedding for frenzied.\n",
      "['fr', '##et', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5519, -0.0243,  0.1328,  ...,  0.5738,  0.4117,  0.4235])\n",
      "fretful\n",
      "Saved the embedding for fretful.\n",
      "['friend', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0967, -0.1772,  0.3055,  ..., -0.3007, -0.1003,  0.5474])\n",
      "friendliness\n",
      "Saved the embedding for friendliness.\n",
      "['friendly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0265, -0.0021,  0.4372,  ..., -0.0882, -0.1913,  0.9931])\n",
      "friendly\n",
      "Saved the embedding for friendly.\n",
      "['fright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1849,  0.5870, -0.2415,  ...,  0.0215,  0.6603,  0.2011])\n",
      "fright\n",
      "Saved the embedding for fright.\n",
      "['frightened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3259,  0.2142, -0.3300,  ..., -0.0891,  0.2430,  0.1329])\n",
      "frightened\n",
      "Saved the embedding for frightened.\n",
      "['frightening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5470,  0.4612, -0.0628,  ..., -0.2865,  0.1621,  0.3806])\n",
      "frightening\n",
      "Saved the embedding for frightening.\n",
      "['fr', '##ig', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5474, -0.0442,  0.1737,  ..., -0.0094,  0.4117,  0.6252])\n",
      "frigid\n",
      "Saved the embedding for frigid.\n",
      "['fr', '##isk', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3978, 0.0573, 0.0480,  ..., 0.1522, 0.3999, 0.5575])\n",
      "frisky\n",
      "Saved the embedding for frisky.\n",
      "['fr', '##olic', '##ker'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4590, -0.0602,  0.0947,  ...,  0.3651,  0.2104,  0.6071])\n",
      "frolicker\n",
      "Saved the embedding for frolicker.\n",
      "['frown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0556,  0.3082,  0.2660,  ..., -0.4542,  0.4469,  1.0342])\n",
      "frown\n",
      "Saved the embedding for frown.\n",
      "['frowning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0816,  0.5544,  0.1001,  ..., -0.3914,  0.1893,  0.7073])\n",
      "frowning\n",
      "Saved the embedding for frowning.\n",
      "['frozen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3341,  0.5044, -0.2466,  ..., -0.5679,  0.3088,  0.8461])\n",
      "frozen\n",
      "Saved the embedding for frozen.\n",
      "['fr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3315, 0.0014, 0.0724,  ..., 0.1999, 0.3113, 0.5167])\n",
      "frumpy\n",
      "Saved the embedding for frumpy.\n",
      "['frustrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5496,  0.2548, -0.4111,  ..., -0.1336, -0.1131,  0.9148])\n",
      "frustrated\n",
      "Saved the embedding for frustrated.\n",
      "['frustration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2279,  0.4781, -0.5423,  ..., -0.4542, -0.1696,  0.5583])\n",
      "frustration\n",
      "Saved the embedding for frustration.\n",
      "['fulfilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8112,  0.3558,  0.0309,  ..., -0.5629,  0.4934,  0.1161])\n",
      "fulfilled\n",
      "Saved the embedding for fulfilled.\n",
      "['fu', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2524,  0.1772, -0.9019,  ..., -0.1335, -0.5191,  0.3634])\n",
      "fumed\n",
      "Saved the embedding for fumed.\n",
      "['fu', '##ming'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2260,  0.3277, -1.0640,  ..., -0.1239, -0.2954,  0.3902])\n",
      "fuming\n",
      "Saved the embedding for fuming.\n",
      "['fun'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0340,  0.2595,  0.5346,  ..., -0.2214,  0.0616,  0.4322])\n",
      "fun\n",
      "Saved the embedding for fun.\n",
      "['funny'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3374,  0.8584,  0.0024,  ..., -0.0564,  0.2538,  0.5143])\n",
      "funny\n",
      "Saved the embedding for funny.\n",
      "['furious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3989,  0.2784, -0.4449,  ..., -0.1530,  0.2327,  0.3181])\n",
      "furious\n",
      "Saved the embedding for furious.\n",
      "['furiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0777, -0.1257, -0.3195,  ..., -0.2711,  0.2558,  0.3620])\n",
      "furiously\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for furiously.\n",
      "['furious', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3378,  0.3463, -0.4172,  ..., -0.0222,  0.2270,  0.3938])\n",
      "furiousness\n",
      "Saved the embedding for furiousness.\n",
      "['furrowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4799,  0.3043,  0.1316,  ..., -0.5064,  0.1892,  0.8059])\n",
      "furrowed\n",
      "Saved the embedding for furrowed.\n",
      "['fur', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1522e+00, -3.8490e-02,  7.4933e-02,  ...,  6.0025e-01,\n",
      "         2.8969e-02, -5.6099e-05])\n",
      "furtive\n",
      "Saved the embedding for furtive.\n",
      "['fury'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6815,  0.7525, -0.1880,  ...,  0.0153,  0.0677,  1.0174])\n",
      "fury\n",
      "Saved the embedding for fury.\n",
      "['fuss', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0290,  0.5835, -0.1452,  ...,  0.3695, -0.1096,  1.1882])\n",
      "fussy\n",
      "Saved the embedding for fussy.\n",
      "['gall', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0160, -0.2789, -0.4476,  ...,  0.3312,  0.1360,  0.5700])\n",
      "galled\n",
      "Saved the embedding for galled.\n",
      "['gall', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0493, -0.2327, -0.4776,  ...,  0.4001,  0.0382,  0.6380])\n",
      "galling\n",
      "Saved the embedding for galling.\n",
      "['gasp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2148,  0.1107,  0.3736,  ..., -0.6732,  0.4162,  0.3669])\n",
      "gasp\n",
      "Saved the embedding for gasp.\n",
      "['gasped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4227,  0.1528, -0.0437,  ..., -0.2309,  0.1761,  0.3120])\n",
      "gasped\n",
      "Saved the embedding for gasped.\n",
      "['gasping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0477,  0.3304, -0.0319,  ..., -0.5844,  0.2199,  0.1969])\n",
      "gasping\n",
      "Saved the embedding for gasping.\n",
      "['gay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8027,  0.3926,  0.3719,  ..., -0.0125, -0.7220,  0.1700])\n",
      "gay\n",
      "Saved the embedding for gay.\n",
      "['gazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2713,  0.6695,  0.3546,  ..., -0.1870,  0.1427,  0.5786])\n",
      "gazing\n",
      "Saved the embedding for gazing.\n",
      "['gen', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5638, -0.3119,  0.0206,  ...,  0.0938,  0.5907,  0.3876])\n",
      "genial\n",
      "Saved the embedding for genial.\n",
      "['gentle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1376,  0.4419, -0.0114,  ...,  0.1815, -0.1255,  0.5271])\n",
      "gentle\n",
      "Saved the embedding for gentle.\n",
      "['genuine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6930,  0.2301,  0.4825,  ...,  0.0658, -0.0131,  0.0163])\n",
      "genuine\n",
      "Saved the embedding for genuine.\n",
      "['g', '##has', '##tly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2218, -0.2859,  0.2305,  ..., -0.6015, -0.4605,  1.0709])\n",
      "ghastly\n",
      "Saved the embedding for ghastly.\n",
      "['gi', '##ddy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2210, -0.2355, -0.9559,  ...,  0.3443, -0.0400,  0.0339])\n",
      "giddy\n",
      "Saved the embedding for giddy.\n",
      "['giggle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1702,  0.6083,  0.4510,  ...,  0.0132, -0.0485, -0.4697])\n",
      "giggle\n",
      "Saved the embedding for giggle.\n",
      "['giggling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4943,  0.2038,  0.3302,  ..., -0.1803, -0.2865, -0.0255])\n",
      "giggling\n",
      "Saved the embedding for giggling.\n",
      "['glad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2420,  0.4339,  0.2895,  ..., -0.4899,  0.1571,  0.7110])\n",
      "glad\n",
      "Saved the embedding for glad.\n",
      "['glad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2695,  0.3772,  0.2610,  ..., -0.4291,  0.3004,  0.8431])\n",
      "gladdened\n",
      "Saved the embedding for gladdened.\n",
      "['glad', '##iol', '##a'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.1051, 0.4142, 0.1471,  ..., 0.0392, 0.3730, 0.8204])\n",
      "gladiola\n",
      "Saved the embedding for gladiola.\n",
      "['glad', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2318,  0.4789,  0.3168,  ..., -0.3439,  0.1744,  0.7819])\n",
      "gladness\n",
      "Saved the embedding for gladness.\n",
      "['glad', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2340,  0.4253,  0.1265,  ..., -0.4372,  0.2170,  0.9263])\n",
      "gladsome\n",
      "Saved the embedding for gladsome.\n",
      "['glare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2917,  0.3695,  0.0493,  ..., -0.3671,  0.2417,  0.5683])\n",
      "glare\n",
      "Saved the embedding for glare.\n",
      "['glaring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2081,  0.6386, -0.0722,  ..., -0.3075,  0.3346,  0.4643])\n",
      "glaring\n",
      "Saved the embedding for glaring.\n",
      "['glazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2679, 0.0075, 0.1908,  ..., 0.4384, 0.0328, 1.0126])\n",
      "glazed\n",
      "Saved the embedding for glazed.\n",
      "['glee'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1151, -0.1436, -0.3472,  ...,  0.8165,  0.2088, -0.2670])\n",
      "glee\n",
      "Saved the embedding for glee.\n",
      "['glee', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0407, -0.0741, -0.3701,  ...,  0.7281,  0.3059, -0.2462])\n",
      "gleeful\n",
      "Saved the embedding for gleeful.\n",
      "['glee', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0949, -0.1566, -0.4125,  ...,  0.7485,  0.4045, -0.2922])\n",
      "gleefully\n",
      "Saved the embedding for gleefully.\n",
      "['g', '##lib'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2750, -0.2062,  0.1578,  ...,  0.3378, -0.1067,  0.7346])\n",
      "glib\n",
      "Saved the embedding for glib.\n",
      "['g', '##lo', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0792, -0.1942,  0.0862,  ..., -0.2654, -0.2680,  0.7540])\n",
      "gloating\n",
      "Saved the embedding for gloating.\n",
      "['gloom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3998,  1.1092, -0.3912,  ..., -0.2905,  0.1411,  0.7850])\n",
      "gloom\n",
      "Saved the embedding for gloom.\n",
      "['gloom', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2257,  1.1348, -0.3202,  ..., -0.1453,  0.2969,  0.7289])\n",
      "gloomy\n",
      "Saved the embedding for gloomy.\n",
      "['glow', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9475,  0.9081,  0.0870,  ...,  0.2712, -0.1540,  0.4145])\n",
      "glowering\n",
      "Saved the embedding for glowering.\n",
      "['glowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8857,  0.2013, -0.0216,  ...,  0.2229,  0.2682,  0.1988])\n",
      "glowing\n",
      "Saved the embedding for glowing.\n",
      "['g', '##lum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1638, -0.3338,  0.2942,  ..., -0.1121, -0.3415,  0.7578])\n",
      "glum\n",
      "Saved the embedding for glum.\n",
      "['g', '##nar', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1605, -0.1823,  0.3323,  ..., -0.2811, -0.5272,  0.7070])\n",
      "gnarl\n",
      "Saved the embedding for gnarl.\n",
      "['go', '##bs', '##mack', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2585, -0.5578, -0.5243,  ...,  0.4615,  0.0950,  0.3617])\n",
      "gobsmacked\n",
      "Saved the embedding for gobsmacked.\n",
      "['good'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1730,  0.4880, -0.3174,  ...,  0.0177, -0.7639, -0.2080])\n",
      "good\n",
      "Saved the embedding for good.\n",
      "['goofy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1723,  0.4563, -0.3255,  ..., -0.1356,  0.4477,  0.9793])\n",
      "goofy\n",
      "Saved the embedding for goofy.\n",
      "['gossip', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4510,  0.1183,  0.5029,  ...,  0.2023, -0.0060, -0.6531])\n",
      "gossipy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for gossipy.\n",
      "['grand', '##ios', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0383,  0.2587,  0.0788,  ...,  0.1125,  0.7770, -0.1776])\n",
      "grandiose\n",
      "Saved the embedding for grandiose.\n",
      "['grateful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1822, -0.0873, -0.1045,  ..., -0.1729,  0.0530,  0.2081])\n",
      "grateful\n",
      "Saved the embedding for grateful.\n",
      "['gr', '##ati', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1211,  0.6361, -0.0200,  ...,  0.0045,  0.6254,  0.2492])\n",
      "gratified\n",
      "Saved the embedding for gratified.\n",
      "['grave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8479,  0.9344,  0.8660,  ...,  0.9750, -0.0179,  0.2429])\n",
      "grave\n",
      "Saved the embedding for grave.\n",
      "['great'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7490,  0.4810, -0.2799,  ..., -0.5230, -0.2337,  0.3300])\n",
      "great\n",
      "Saved the embedding for great.\n",
      "['greedy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2809,  0.1601, -0.2285,  ...,  0.2986,  0.1510,  0.7739])\n",
      "greedy\n",
      "Saved the embedding for greedy.\n",
      "['greeting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1423,  0.3986,  0.1131,  ..., -0.0397, -0.0651,  0.9816])\n",
      "greeting\n",
      "Saved the embedding for greeting.\n",
      "['grief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4611,  0.7912,  0.2194,  ..., -0.1800, -0.1143,  0.2550])\n",
      "grief\n",
      "Saved the embedding for grief.\n",
      "['gr', '##ie', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0793,  0.7478, -0.1580,  ...,  0.0572,  0.5785,  0.5012])\n",
      "grieved\n",
      "Saved the embedding for grieved.\n",
      "['gr', '##ieving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2279,  0.6242,  0.0176,  ..., -0.3105,  0.3046,  0.4014])\n",
      "grieving\n",
      "Saved the embedding for grieving.\n",
      "['grim'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1192, -0.0551,  1.0220,  ..., -0.0912,  0.3657,  0.2591])\n",
      "grim\n",
      "Saved the embedding for grim.\n",
      "['grimace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0318,  0.6464, -0.0874,  ..., -0.3481,  0.2857,  0.7305])\n",
      "grimace\n",
      "Saved the embedding for grimace.\n",
      "['grim', '##acing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9988, -0.0272,  0.9611,  ...,  0.1490,  0.3031,  0.3266])\n",
      "grimacing\n",
      "Saved the embedding for grimacing.\n",
      "['grin'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1067, 0.4287, 0.1999,  ..., 0.1201, 0.5746, 0.6553])\n",
      "grin\n",
      "Saved the embedding for grin.\n",
      "['grinning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1543,  0.6291,  0.0950,  ..., -0.1281,  0.1601,  0.4729])\n",
      "grinning\n",
      "Saved the embedding for grinning.\n",
      "['grip', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5474,  0.7968, -0.1274,  ..., -0.2019,  0.1446,  0.4951])\n",
      "griping\n",
      "Saved the embedding for griping.\n",
      "['gross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0974,  0.0585, -0.4142,  ..., -0.0979,  0.5690,  0.3947])\n",
      "gross\n",
      "Saved the embedding for gross.\n",
      "['grossed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6624, -0.3850, -0.4840,  ...,  0.1258,  0.3405, -0.3785])\n",
      "grossed\n",
      "Saved the embedding for grossed.\n",
      "['gr', '##ou', '##chy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2079,  0.5627, -0.2265,  ..., -0.0406,  0.4108,  0.2294])\n",
      "grouchy\n",
      "Saved the embedding for grouchy.\n",
      "['growl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3000,  0.3465, -0.0515,  ..., -0.1812,  0.1061,  0.1228])\n",
      "growl\n",
      "Saved the embedding for growl.\n",
      "['growling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1671,  0.1940, -0.3676,  ..., -0.3071,  0.0945,  0.2276])\n",
      "growling\n",
      "Saved the embedding for growling.\n",
      "['gr', '##udge'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2456,  0.5193, -0.1346,  ..., -0.0736,  0.4693,  0.4565])\n",
      "grudge\n",
      "Saved the embedding for grudge.\n",
      "['gr', '##ud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2046,  0.5432, -0.1893,  ...,  0.1328,  0.5253,  0.7036])\n",
      "grudging\n",
      "Saved the embedding for grudging.\n",
      "['gruff'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3391, -0.1830, -0.0425,  ..., -0.1480,  0.1237,  0.4801])\n",
      "gruff\n",
      "Saved the embedding for gruff.\n",
      "['gr', '##umb', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1554,  0.4983, -0.0863,  ..., -0.0169,  0.3097,  0.5469])\n",
      "grumbling\n",
      "Saved the embedding for grumbling.\n",
      "['gr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0024,  0.5423, -0.1749,  ...,  0.1088,  0.5585,  0.5617])\n",
      "grumpy\n",
      "Saved the embedding for grumpy.\n",
      "['grunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1684,  0.5805, -0.5926,  ..., -0.0872,  0.2745,  0.2575])\n",
      "grunt\n",
      "Saved the embedding for grunt.\n",
      "['grunt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0536,  0.5046, -0.5773,  ..., -0.0331,  0.2881,  0.2496])\n",
      "grunting\n",
      "Saved the embedding for grunting.\n",
      "['guarded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3096, -0.5624, -0.0709,  ...,  0.0406,  0.3209,  0.7325])\n",
      "guarded\n",
      "Saved the embedding for guarded.\n",
      "['guilty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0073, -0.0284,  0.1447,  ...,  0.4885, -0.0542,  0.1980])\n",
      "guilty\n",
      "Saved the embedding for guilty.\n",
      "['gulp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1464,  0.0399,  0.1073,  ..., -0.4257,  0.0061,  0.4543])\n",
      "gulp\n",
      "Saved the embedding for gulp.\n",
      "['haggard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1018, -0.1094, -0.1320,  ..., -0.3737,  0.1333, -0.5142])\n",
      "haggard\n",
      "Saved the embedding for haggard.\n",
      "['half', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4671, -0.7684,  0.0157,  ...,  0.4476,  0.1491,  0.0774])\n",
      "halfhearted\n",
      "Saved the embedding for halfhearted.\n",
      "['halted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5408,  0.4736, -0.0045,  ..., -0.0417,  0.2028,  0.6045])\n",
      "halted\n",
      "Saved the embedding for halted.\n",
      "['ha', '##ples', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3651,  0.1450, -0.2042,  ...,  0.6310,  0.1995,  0.7047])\n",
      "hapless\n",
      "Saved the embedding for hapless.\n",
      "['happiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1055,  0.6758,  0.4964,  ...,  0.3333, -0.0135, -0.1052])\n",
      "happiness\n",
      "Saved the embedding for happiness.\n",
      "['happy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0994,  0.1530,  0.2959,  ..., -0.4343, -0.1237,  0.1017])\n",
      "happy\n",
      "Saved the embedding for happy.\n",
      "['harassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0491, -0.0735,  0.1362,  ..., -0.6747, -0.4064,  0.0557])\n",
      "harassed\n",
      "Saved the embedding for harassed.\n",
      "['hard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3510,  0.1737, -1.0415,  ..., -0.4218,  0.0232,  0.3398])\n",
      "hard\n",
      "Saved the embedding for hard.\n",
      "['hardened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3121,  0.4969,  0.1218,  ...,  0.0347,  0.1159, -0.0156])\n",
      "hardened\n",
      "Saved the embedding for hardened.\n",
      "['harmful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1031,  0.4030,  0.0837,  ..., -0.5793, -0.7739,  0.2191])\n",
      "harmful\n",
      "Saved the embedding for harmful.\n",
      "['ha', '##rrie', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3381,  0.2329, -0.1851,  ...,  0.5196, -0.1550,  0.5209])\n",
      "harried\n",
      "Saved the embedding for harried.\n",
      "['harsh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2747,  0.2842, -0.4022,  ..., -0.0969, -0.0698,  0.4317])\n",
      "harsh\n",
      "Saved the embedding for harsh.\n",
      "['hate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9027, -0.2999,  0.3711,  ..., -0.0368, -0.2031,  0.4605])\n",
      "hate\n",
      "Saved the embedding for hate.\n",
      "['hate', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7968, -0.2704,  0.3350,  ...,  0.0441, -0.0605,  0.4968])\n",
      "hateful\n",
      "Saved the embedding for hateful.\n",
      "['hating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8412, -0.0999,  0.0242,  ..., -0.1772, -0.4065,  0.3038])\n",
      "hating\n",
      "Saved the embedding for hating.\n",
      "['hatred'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9902,  0.5283,  0.4363,  ..., -0.0203, -0.2860,  0.7534])\n",
      "hatred\n",
      "Saved the embedding for hatred.\n",
      "['ha', '##ught', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3065,  0.2383, -0.3077,  ...,  0.7853,  0.2130,  0.6482])\n",
      "haughty\n",
      "Saved the embedding for haughty.\n",
      "['haunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3521,  0.3354,  0.0289,  ..., -0.2416,  0.1316, -0.0194])\n",
      "haunted\n",
      "Saved the embedding for haunted.\n",
      "['hazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6202,  0.4018,  0.0057,  ..., -0.5488,  0.5263,  0.8008])\n",
      "hazy\n",
      "Saved the embedding for hazy.\n",
      "['heads', '##hak', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5598,  0.5948, -0.4451,  ..., -0.2004, -0.0413,  0.3593])\n",
      "headshake\n",
      "Saved the embedding for headshake.\n",
      "['heart', '##ache'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5750,  0.1361, -0.2916,  ..., -0.3413, -0.2501,  0.3000])\n",
      "heartache\n",
      "Saved the embedding for heartache.\n",
      "['heart', '##broken'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6089, -0.3030,  0.0041,  ..., -0.0670,  0.1589,  0.1481])\n",
      "heartbroken\n",
      "Saved the embedding for heartbroken.\n",
      "['hearted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5996, -0.0862,  0.2474,  ...,  0.3455, -0.0505,  0.4998])\n",
      "hearted\n",
      "Saved the embedding for hearted.\n",
      "['hearts', '##ick'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5623, -0.1715,  0.4443,  ...,  0.0979,  0.4209,  0.5454])\n",
      "heartsick\n",
      "Saved the embedding for heartsick.\n",
      "['heated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5782,  0.6011,  0.1395,  ..., -0.0862, -0.0369, -0.3260])\n",
      "heated\n",
      "Saved the embedding for heated.\n",
      "['heavy', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2372,  0.4673, -0.3934,  ..., -0.2872, -0.0491, -0.0175])\n",
      "heavyhearted\n",
      "Saved the embedding for heavyhearted.\n",
      "['heck', '##le'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8941,  0.6882, -0.2920,  ..., -0.3020, -0.5334,  0.0717])\n",
      "heckle\n",
      "Saved the embedding for heckle.\n",
      "['hee', '##df', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.0127,  0.8016, -0.3348,  ...,  0.5126,  0.6421,  0.2713])\n",
      "heedful\n",
      "Saved the embedding for heedful.\n",
      "['he', '##ino', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2415,  0.4433, -0.0705,  ...,  0.5851,  0.1966,  0.5584])\n",
      "heinous\n",
      "Saved the embedding for heinous.\n",
      "['helpful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1810,  0.2472,  0.1209,  ..., -0.3252, -0.0650,  0.8554])\n",
      "helpful\n",
      "Saved the embedding for helpful.\n",
      "['helpless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6075,  0.6476, -0.1304,  ..., -0.0238,  0.1426,  0.2749])\n",
      "helpless\n",
      "Saved the embedding for helpless.\n",
      "['hesitant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1470,  0.1878, -0.4593,  ..., -0.1528,  0.1576,  0.7233])\n",
      "hesitant\n",
      "Saved the embedding for hesitant.\n",
      "['hesitantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2865,  0.1533, -0.1276,  ..., -0.2684,  0.6507,  0.3880])\n",
      "hesitantly\n",
      "Saved the embedding for hesitantly.\n",
      "['he', '##sit', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.2633, 0.3596, 0.0657,  ..., 0.4857, 0.1232, 0.4695])\n",
      "hesitating\n",
      "Saved the embedding for hesitating.\n",
      "['hesitation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0248,  0.4960, -0.2160,  ..., -0.1169,  0.3871,  0.5779])\n",
      "hesitation\n",
      "Saved the embedding for hesitation.\n",
      "['high'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1027,  0.1009, -0.2754,  ..., -0.2236, -0.1384,  0.0279])\n",
      "high\n",
      "Saved the embedding for high.\n",
      "['ho', '##ller', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2042,  0.1261, -0.1367,  ...,  0.5388, -0.2487,  0.1860])\n",
      "hollering\n",
      "Saved the embedding for hollering.\n",
      "['ho', '##mic', '##idal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2928,  0.1453, -0.2346,  ...,  0.3727, -0.1092,  0.1159])\n",
      "homicidal\n",
      "Saved the embedding for homicidal.\n",
      "['honest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7938,  0.3465, -0.0586,  ..., -0.5273,  0.3422, -0.1648])\n",
      "honest\n",
      "Saved the embedding for honest.\n",
      "['honorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0517,  1.0305,  0.0468,  ..., -0.0017,  0.0518,  0.2918])\n",
      "honorable\n",
      "Saved the embedding for honorable.\n",
      "['hope'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1944,  0.3094,  0.0477,  ..., -0.3337,  0.1660,  0.2133])\n",
      "hope\n",
      "Saved the embedding for hope.\n",
      "['hopeful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4789,  0.4896,  0.0603,  ..., -0.4715,  0.1281,  0.2620])\n",
      "hopeful\n",
      "Saved the embedding for hopeful.\n",
      "['hopeful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4645,  0.5911,  0.0161,  ..., -0.2878,  0.2191,  0.3124])\n",
      "hopefulness\n",
      "Saved the embedding for hopefulness.\n",
      "['hopeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4086,  0.1622, -0.2446,  ..., -0.5383, -0.1597,  0.2075])\n",
      "hopeless\n",
      "Saved the embedding for hopeless.\n",
      "['hoping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1165,  0.1232, -0.1737,  ..., -0.2592, -0.0429,  0.6881])\n",
      "hoping\n",
      "Saved the embedding for hoping.\n",
      "['horn', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4515, -0.1993,  0.2863,  ..., -0.0978, -0.0773, -0.0542])\n",
      "horny\n",
      "Saved the embedding for horny.\n",
      "['horrible'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4332,  0.0971, -0.3916,  ..., -0.3281, -0.0146,  0.1839])\n",
      "horrible\n",
      "Saved the embedding for horrible.\n",
      "['horrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2858,  0.2971, -0.8216,  ..., -0.0824,  0.2180,  0.2601])\n",
      "horrified\n",
      "Saved the embedding for horrified.\n",
      "['ho', '##rri', '##fy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0743, -0.0205, -0.1365,  ...,  0.5143, -0.4078, -0.0877])\n",
      "horrify\n",
      "Saved the embedding for horrify.\n",
      "['ho', '##rri', '##fying'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2251,  0.0016, -0.2395,  ...,  0.4512, -0.4719, -0.0693])\n",
      "horrifying\n",
      "Saved the embedding for horrifying.\n",
      "['horror'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4366,  0.6220, -0.6284,  ...,  0.3222,  0.5225,  0.1053])\n",
      "horror\n",
      "Saved the embedding for horror.\n",
      "['hostile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0794,  0.6644, -0.4309,  ..., -0.2114, -0.6093,  0.6630])\n",
      "hostile\n",
      "Saved the embedding for hostile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hostility'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0895,  0.6521,  0.3080,  ..., -0.1003, -0.2476,  0.8552])\n",
      "hostility\n",
      "Saved the embedding for hostility.\n",
      "['hot'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2074,  0.7575,  0.2572,  ...,  0.2020, -0.0610, -0.3649])\n",
      "hot\n",
      "Saved the embedding for hot.\n",
      "['hot', '##shot'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2155,  0.5019,  0.1216,  ..., -0.0714, -0.0617, -0.0248])\n",
      "hotshot\n",
      "Saved the embedding for hotshot.\n",
      "['huff', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0021,  0.1788,  0.1279,  ..., -0.3272,  0.2685,  0.5619])\n",
      "huffiness\n",
      "Saved the embedding for huffiness.\n",
      "['huff', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1684,  0.2632,  0.0286,  ..., -0.2182,  0.1577,  0.4711])\n",
      "huffy\n",
      "Saved the embedding for huffy.\n",
      "['humble'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5720,  0.4187,  0.1628,  ..., -0.3899,  0.7688,  0.2525])\n",
      "humble\n",
      "Saved the embedding for humble.\n",
      "['humble', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5176,  0.4546,  0.2182,  ..., -0.5824,  0.8725,  0.4675])\n",
      "humbled\n",
      "Saved the embedding for humbled.\n",
      "['hum', '##drum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4720, -0.6872,  0.3319,  ...,  0.2911,  0.2259,  0.3016])\n",
      "humdrum\n",
      "Saved the embedding for humdrum.\n",
      "['humiliated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1063,  0.5661, -0.1651,  ..., -0.0727,  0.0211,  0.0581])\n",
      "humiliated\n",
      "Saved the embedding for humiliated.\n",
      "['hum', '##ility'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6144, -0.6294,  0.3242,  ...,  0.0339,  0.2151,  0.2423])\n",
      "humility\n",
      "Saved the embedding for humility.\n",
      "['humming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4629, -0.3499, -0.1174,  ...,  0.0518, -0.0890, -0.4557])\n",
      "humming\n",
      "Saved the embedding for humming.\n",
      "['humor'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0017,  0.8577,  0.3444,  ...,  0.1476, -0.3910,  0.8044])\n",
      "humor\n",
      "Saved the embedding for humor.\n",
      "['humor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1228,  0.7100,  0.3412,  ...,  0.0595, -0.1931,  0.7880])\n",
      "humored\n",
      "Saved the embedding for humored.\n",
      "['humorous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0604,  0.2486,  0.2056,  ..., -0.5057, -0.1341,  0.4760])\n",
      "humorous\n",
      "Saved the embedding for humorous.\n",
      "['hunger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4290,  0.1904, -0.0918,  ...,  0.3103, -0.2492, -0.0048])\n",
      "hunger\n",
      "Saved the embedding for hunger.\n",
      "['hungry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0436, 0.2257, 0.4171,  ..., 0.0022, 0.2296, 0.0644])\n",
      "hungry\n",
      "Saved the embedding for hungry.\n",
      "['hunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8736, -0.0060,  0.1850,  ..., -0.3300, -0.0724, -0.2660])\n",
      "hunted\n",
      "Saved the embedding for hunted.\n",
      "['hurt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2814,  0.4537,  0.3137,  ...,  0.1712, -0.2852,  0.2889])\n",
      "hurt\n",
      "Saved the embedding for hurt.\n",
      "['hurt', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1435, 0.4345, 0.2633,  ..., 0.0688, 0.0765, 0.4021])\n",
      "hurtful\n",
      "Saved the embedding for hurtful.\n",
      "['hurting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3409,  0.3217,  0.0921,  ...,  0.0616, -0.2303,  0.2163])\n",
      "hurting\n",
      "Saved the embedding for hurting.\n",
      "['hush'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.8145, 0.1836, 0.1895,  ..., 0.1550, 0.4210, 0.2613])\n",
      "hush\n",
      "Saved the embedding for hush.\n",
      "['hushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5404, -0.3212, -0.0588,  ..., -0.4964,  0.3888,  0.6203])\n",
      "hushed\n",
      "Saved the embedding for hushed.\n",
      "['hyper'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0703, -0.0343,  0.4634,  ..., -0.1142,  0.2696,  0.7138])\n",
      "hyper\n",
      "Saved the embedding for hyper.\n",
      "['hyper', '##active'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0285, -0.1615,  0.5115,  ..., -0.2809,  0.1208,  0.9100])\n",
      "hyperactive\n",
      "Saved the embedding for hyperactive.\n",
      "['h', '##yp', '##not', '##ized'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2859,  0.0028,  0.0387,  ..., -0.2492,  0.0835,  0.4774])\n",
      "hypnotized\n",
      "Saved the embedding for hypnotized.\n",
      "['h', '##yp', '##oc', '##rit', '##ical'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.3379, -0.1002,  0.0738,  ..., -0.3703,  0.0664,  0.5332])\n",
      "hypocritical\n",
      "Saved the embedding for hypocritical.\n",
      "['hysteria'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1719, -0.0376, -0.3847,  ..., -0.0913,  0.2272,  0.0301])\n",
      "hysteria\n",
      "Saved the embedding for hysteria.\n",
      "['hysterical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2151,  0.5560, -0.1165,  ..., -0.0115,  0.0313,  0.3670])\n",
      "hysterical\n",
      "Saved the embedding for hysterical.\n",
      "['idiot', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1423,  0.5095, -0.2768,  ...,  0.2107, -0.1469,  0.4076])\n",
      "idiotic\n",
      "Saved the embedding for idiotic.\n",
      "['ignorant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4830,  0.6567, -0.1824,  ..., -0.1784,  0.1325,  0.0708])\n",
      "ignorant\n",
      "Saved the embedding for ignorant.\n",
      "['ignoring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0209,  0.4713,  0.3153,  ..., -0.5984, -0.1241,  0.6071])\n",
      "ignoring\n",
      "Saved the embedding for ignoring.\n",
      "['ill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1503, -0.1520, -0.0345,  ..., -0.6591,  0.0752,  0.6983])\n",
      "ill\n",
      "Saved the embedding for ill.\n",
      "['imaginative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2093,  0.8012, -0.1535,  ...,  0.7074,  0.0534,  0.4285])\n",
      "imaginative\n",
      "Saved the embedding for imaginative.\n",
      "['immature'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1199,  0.6466,  0.0274,  ..., -0.7677, -0.1662, -0.2562])\n",
      "immature\n",
      "Saved the embedding for immature.\n",
      "['immersed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0517,  0.0384, -0.0784,  ..., -0.1880, -0.1033,  0.2832])\n",
      "immersed\n",
      "Saved the embedding for immersed.\n",
      "['impacted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3594,  0.8163, -0.4212,  ..., -0.5412, -0.6558,  0.1522])\n",
      "impacted\n",
      "Saved the embedding for impacted.\n",
      "['imp', '##art', '##ial'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1154, -0.5089,  0.0577,  ..., -0.3317,  0.8490,  0.2774])\n",
      "impartial\n",
      "Saved the embedding for impartial.\n",
      "['imp', '##ass', '##ioned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0060, -0.6034, -0.2260,  ..., -0.1821,  0.6468,  0.2909])\n",
      "impassioned\n",
      "Saved the embedding for impassioned.\n",
      "['imp', '##ass', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1325, -0.4317, -0.2525,  ..., -0.4009,  0.7789,  0.3269])\n",
      "impassive\n",
      "Saved the embedding for impassive.\n",
      "['impatience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4251,  0.4889, -0.0188,  ...,  0.0383,  0.2114,  0.6654])\n",
      "impatience\n",
      "Saved the embedding for impatience.\n",
      "['impatient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1946,  0.4249, -0.0139,  ..., -0.0624,  0.1718,  0.4616])\n",
      "impatient\n",
      "Saved the embedding for impatient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imp', '##eri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0290, -0.7077, -0.2537,  ..., -0.5293,  0.9145,  0.2232])\n",
      "imperious\n",
      "Saved the embedding for imperious.\n",
      "['imp', '##erson', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0750, -0.5264,  0.0288,  ..., -0.0569,  0.5741,  0.4571])\n",
      "impersonal\n",
      "Saved the embedding for impersonal.\n",
      "['imp', '##ert', '##inen', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1078, -0.4653,  0.0110,  ..., -0.1923,  0.9028,  0.4740])\n",
      "impertinent\n",
      "Saved the embedding for impertinent.\n",
      "['imp', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0254, -0.5142, -0.2901,  ...,  0.2822,  0.8012,  0.2197])\n",
      "impish\n",
      "Saved the embedding for impish.\n",
      "['implicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2077,  0.5269, -0.2716,  ..., -0.1222, -0.0974,  0.1683])\n",
      "implicated\n",
      "Saved the embedding for implicated.\n",
      "['imp', '##lor', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0580, -0.5069, -0.0896,  ..., -0.3127,  0.7130,  0.2622])\n",
      "imploring\n",
      "Saved the embedding for imploring.\n",
      "['important'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1102,  0.7517,  0.3415,  ..., -0.2987, -0.5302, -0.2429])\n",
      "important\n",
      "Saved the embedding for important.\n",
      "['impressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2760,  0.5493, -0.3508,  ...,  0.6504,  0.3545,  0.7106])\n",
      "impressed\n",
      "Saved the embedding for impressed.\n",
      "['imp', '##ulsive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1388, -0.4880, -0.1223,  ..., -0.2328,  0.7009,  0.2056])\n",
      "impulsive\n",
      "Saved the embedding for impulsive.\n",
      "['inactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3594,  0.3537,  0.0815,  ..., -0.4946,  0.4316, -0.0917])\n",
      "inactive\n",
      "Saved the embedding for inactive.\n",
      "['inadequate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2567,  0.5288, -0.5485,  ..., -0.2360, -0.3846,  0.2981])\n",
      "inadequate\n",
      "Saved the embedding for inadequate.\n",
      "['ina', '##rti', '##cula', '##te'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1870, -0.2402, -0.2213,  ..., -0.5280,  0.2511,  0.7904])\n",
      "inarticulate\n",
      "Saved the embedding for inarticulate.\n",
      "['ina', '##tten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2814, -0.0767, -0.3007,  ..., -0.2701,  0.4019,  0.6791])\n",
      "inattentive\n",
      "Saved the embedding for inattentive.\n",
      "['ina', '##udi', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0813, -0.3991, -0.4498,  ..., -0.7104,  0.4875,  0.7135])\n",
      "inaudible\n",
      "Saved the embedding for inaudible.\n",
      "['ina', '##uth', '##ent', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2820, -0.2434, -0.2866,  ..., -0.5540,  0.1299,  0.9172])\n",
      "inauthentic\n",
      "Saved the embedding for inauthentic.\n",
      "['incapable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0405,  0.4384, -0.5311,  ..., -0.2154,  0.2704,  0.1069])\n",
      "incapable\n",
      "Saved the embedding for incapable.\n",
      "['incense', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.0930, 0.1489, 0.2733,  ..., 0.2898, 0.7285, 0.2916])\n",
      "incensed\n",
      "Saved the embedding for incensed.\n",
      "['inc', '##ert', '##ain'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3450, -0.0381, -0.1055,  ..., -0.4331,  0.4641,  0.9124])\n",
      "incertain\n",
      "Saved the embedding for incertain.\n",
      "['inc', '##ert', '##itude'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3162,  0.1314, -0.1134,  ..., -0.7031,  0.3285,  1.1442])\n",
      "incertitude\n",
      "Saved the embedding for incertitude.\n",
      "['inc', '##ited'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2278, -0.1870, -0.2438,  ..., -0.4767,  0.5565,  1.0658])\n",
      "incited\n",
      "Saved the embedding for incited.\n",
      "['inc', '##omp', '##re', '##hen', '##sible'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.3667, -0.1034, -0.3271,  ..., -0.2522,  0.3015,  0.9306])\n",
      "incomprehensible\n",
      "Saved the embedding for incomprehensible.\n",
      "['inc', '##ons', '##pic', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3297, -0.2711, -0.2597,  ..., -0.3737,  0.5399,  0.9690])\n",
      "inconspicuous\n",
      "Saved the embedding for inconspicuous.\n",
      "['inc', '##red', '##uli', '##ty'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3667, -0.2446, -0.1635,  ..., -0.4518,  0.5605,  0.9067])\n",
      "incredulity\n",
      "Saved the embedding for incredulity.\n",
      "['inc', '##red', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2384, -0.2346, -0.2283,  ..., -0.3939,  0.5933,  1.0733])\n",
      "incredulous\n",
      "Saved the embedding for incredulous.\n",
      "['inc', '##red', '##ulously'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1476, -0.2975, -0.2895,  ..., -0.5586,  0.5506,  0.9669])\n",
      "incredulously\n",
      "Saved the embedding for incredulously.\n",
      "['inc', '##ul', '##pate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3413, -0.1716, -0.1734,  ..., -0.4460,  0.4395,  0.8214])\n",
      "inculpate\n",
      "Saved the embedding for inculpate.\n",
      "['inc', '##uri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4706, -0.1892, -0.4634,  ..., -0.5833,  0.3482,  1.0253])\n",
      "incurious\n",
      "Saved the embedding for incurious.\n",
      "['ind', '##ec', '##ip', '##her', '##able'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0044, -0.4806, -0.5601,  ..., -0.1109, -0.0722,  0.7488])\n",
      "indecipherable\n",
      "Saved the embedding for indecipherable.\n",
      "['ind', '##ec', '##ision'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0150, -0.3345, -0.6389,  ..., -0.1708, -0.0401,  0.7839])\n",
      "indecision\n",
      "Saved the embedding for indecision.\n",
      "['ind', '##ec', '##isi', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0145, -0.4413, -0.5928,  ..., -0.3651, -0.0265,  0.8456])\n",
      "indecisive\n",
      "Saved the embedding for indecisive.\n",
      "['indifferent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1036,  0.7105, -0.4254,  ...,  0.0578,  0.4160,  0.5856])\n",
      "indifferent\n",
      "Saved the embedding for indifferent.\n",
      "['indifferent', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0474,  0.5852, -0.4254,  ..., -0.0302,  0.6409,  0.5658])\n",
      "indifferently\n",
      "Saved the embedding for indifferently.\n",
      "['ind', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1621, -0.5247, -0.6383,  ..., -0.2926, -0.1755,  0.7600])\n",
      "indignant\n",
      "Saved the embedding for indignant.\n",
      "['indo', '##lent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3526, -0.0218, -0.2179,  ...,  0.0744, -0.1657,  0.9695])\n",
      "indolent\n",
      "Saved the embedding for indolent.\n",
      "['in', '##eb', '##riated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1079,  0.1354,  0.0017,  ..., -0.4602,  0.1149,  0.4722])\n",
      "inebriated\n",
      "Saved the embedding for inebriated.\n",
      "['in', '##ert'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2038,  0.2060, -0.1084,  ..., -0.1357,  0.2497,  0.5683])\n",
      "inert\n",
      "Saved the embedding for inert.\n",
      "['in', '##fat', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1499,  0.2402, -0.1922,  ..., -0.6687, -0.1231,  0.3194])\n",
      "infatuating\n",
      "Saved the embedding for infatuating.\n",
      "['inferior'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1539,  0.0211, -0.2632,  ..., -0.1406, -0.3579,  0.4391])\n",
      "inferior\n",
      "Saved the embedding for inferior.\n",
      "['inferior', '##ity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1348,  0.2185, -0.1920,  ..., -0.1003, -0.3064,  0.6496])\n",
      "inferiority\n",
      "Saved the embedding for inferiority.\n",
      "['in', '##fl', '##ame', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1032,  0.2138, -0.2047,  ..., -0.4607,  0.2318,  0.3050])\n",
      "inflamed\n",
      "Saved the embedding for inflamed.\n",
      "['informal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1791,  0.3097, -0.3757,  ..., -0.3587, -0.4306,  0.5497])\n",
      "informal\n",
      "Saved the embedding for informal.\n",
      "['informing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6437,  0.6986,  0.3009,  ..., -0.1465,  0.4077,  0.4383])\n",
      "informing\n",
      "Saved the embedding for informing.\n",
      "['in', '##fur', '##iated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1376,  0.1891, -0.0154,  ..., -0.4405, -0.0213,  0.4322])\n",
      "infuriated\n",
      "Saved the embedding for infuriated.\n",
      "['inhibit', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0178,  0.4239, -0.3896,  ...,  0.0408,  0.1119,  0.2528])\n",
      "inhibited\n",
      "Saved the embedding for inhibited.\n",
      "['inhibit', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0627,  0.4725, -0.4404,  ...,  0.0447,  0.0123,  0.2384])\n",
      "inhibiting\n",
      "Saved the embedding for inhibiting.\n",
      "['in', '##imi', '##cal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1365,  0.1421, -0.2479,  ..., -0.4643,  0.1561,  0.3701])\n",
      "inimical\n",
      "Saved the embedding for inimical.\n",
      "['injured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1195,  0.1268,  0.0161,  ...,  0.3494, -0.1450,  0.2364])\n",
      "injured\n",
      "Saved the embedding for injured.\n",
      "['innocent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2485,  0.1397,  0.2161,  ...,  0.0170,  0.3906, -0.0144])\n",
      "innocent\n",
      "Saved the embedding for innocent.\n",
      "['in', '##patient'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1212,  0.0749, -0.1277,  ..., -0.6668, -0.2694,  0.5151])\n",
      "inpatient\n",
      "Saved the embedding for inpatient.\n",
      "['in', '##qui', '##ring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1928,  0.1051, -0.3611,  ..., -0.5741, -0.0060,  0.5262])\n",
      "inquiring\n",
      "Saved the embedding for inquiring.\n",
      "['in', '##qui', '##sit', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1812,  0.2105, -0.3779,  ..., -0.6165, -0.0033,  0.6320])\n",
      "inquisitive\n",
      "Saved the embedding for inquisitive.\n",
      "['insane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 4.0943e-01,  2.3462e-01, -6.9492e-05,  ..., -3.9262e-02,\n",
      "        -8.4834e-02,  3.6888e-01])\n",
      "insane\n",
      "Saved the embedding for insane.\n",
      "['ins', '##cr', '##utable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5569, -0.0729, -0.4187,  ..., -0.1541,  0.3098,  0.4722])\n",
      "inscrutable\n",
      "Saved the embedding for inscrutable.\n",
      "['ins', '##ecure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4679, -0.0853, -0.2387,  ..., -0.3289, -0.0354,  0.4320])\n",
      "insecure\n",
      "Saved the embedding for insecure.\n",
      "['ins', '##ec', '##urity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5151,  0.1869, -0.2373,  ..., -0.1440,  0.1586,  0.5849])\n",
      "insecurity\n",
      "Saved the embedding for insecurity.\n",
      "['ins', '##ens', '##itive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6179,  0.0217, -0.3464,  ..., -0.1325,  0.1758,  0.4554])\n",
      "insensitive\n",
      "Saved the embedding for insensitive.\n",
      "['ins', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6288,  0.0545, -0.3500,  ..., -0.1638,  0.2877,  0.6366])\n",
      "insidious\n",
      "Saved the embedding for insidious.\n",
      "['ins', '##in', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6420,  0.1660, -0.2470,  ..., -0.2001,  0.1947,  0.3909])\n",
      "insinuating\n",
      "Saved the embedding for insinuating.\n",
      "['insistence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5186, -0.2931, -0.7549,  ..., -0.6077, -0.0020,  0.7063])\n",
      "insistence\n",
      "Saved the embedding for insistence.\n",
      "['insistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8084,  0.3439, -0.5735,  ..., -0.7054, -0.2014,  0.8121])\n",
      "insistent\n",
      "Saved the embedding for insistent.\n",
      "['insisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0345,  0.4199, -0.7322,  ..., -0.0706,  0.0851,  0.8465])\n",
      "insisting\n",
      "Saved the embedding for insisting.\n",
      "['ins', '##ole', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4663,  0.3071, -0.5279,  ..., -0.1497,  0.1464,  0.6949])\n",
      "insolent\n",
      "Saved the embedding for insolent.\n",
      "['ins', '##ou', '##cian', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7118,  0.0665, -0.4794,  ...,  0.0432,  0.2034,  0.4868])\n",
      "insouciance\n",
      "Saved the embedding for insouciance.\n",
      "['ins', '##ou', '##cian', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6643,  0.0770, -0.3950,  ...,  0.2304,  0.3446,  0.4485])\n",
      "insouciant\n",
      "Saved the embedding for insouciant.\n",
      "['inspired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1932,  0.4808, -0.3948,  ...,  0.3029,  0.1975,  0.8222])\n",
      "inspired\n",
      "Saved the embedding for inspired.\n",
      "['inspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5285,  0.4039, -0.0345,  ...,  0.1320, -0.0842,  0.9954])\n",
      "inspiring\n",
      "Saved the embedding for inspiring.\n",
      "['ins', '##ti', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5463, -0.0070, -0.4233,  ..., -0.1670,  0.2748,  0.3604])\n",
      "instigating\n",
      "Saved the embedding for instigating.\n",
      "['ins', '##tructing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4227,  0.0265, -0.4792,  ..., -0.1035,  0.3707,  0.4144])\n",
      "instructing\n",
      "Saved the embedding for instructing.\n",
      "['ins', '##ub', '##ord', '##inate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6869, -0.1530, -0.3440,  ..., -0.0812,  0.4910,  0.6297])\n",
      "insubordinate\n",
      "Saved the embedding for insubordinate.\n",
      "['ins', '##ular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5261, -0.1423, -0.3408,  ...,  0.1165,  0.5342,  0.7131])\n",
      "insular\n",
      "Saved the embedding for insular.\n",
      "['insulted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.6923, 0.3792, 0.3514,  ..., 0.1492, 0.3087, 0.2781])\n",
      "insulted\n",
      "Saved the embedding for insulted.\n",
      "['insulting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6710,  0.1631,  0.3741,  ..., -0.2004, -0.2672,  0.1570])\n",
      "insulting\n",
      "Saved the embedding for insulting.\n",
      "['intelligence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0978,  0.7226, -0.1184,  ...,  0.4523,  0.1885,  0.1506])\n",
      "intelligence\n",
      "Saved the embedding for intelligence.\n",
      "['intense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0262,  0.5223,  0.0080,  ..., -0.2298,  0.2521,  0.6404])\n",
      "intense\n",
      "Saved the embedding for intense.\n",
      "['intensely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1313, -0.0296, -0.2658,  ..., -0.4016,  0.5074,  0.5446])\n",
      "intensely\n",
      "Saved the embedding for intensely.\n",
      "['intensity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3084,  0.7179, -0.0634,  ..., -0.0650,  0.9553,  0.2790])\n",
      "intensity\n",
      "Saved the embedding for intensity.\n",
      "['intensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0517,  0.4366, -0.2280,  ..., -0.3052,  0.1415,  0.4602])\n",
      "intensive\n",
      "Saved the embedding for intensive.\n",
      "['intent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3470,  0.0290,  0.2146,  ..., -0.2368,  0.1883,  0.8187])\n",
      "intent\n",
      "Saved the embedding for intent.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intentional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1615,  0.4315, -0.4196,  ..., -0.6789, -0.4150,  0.4007])\n",
      "intentional\n",
      "Saved the embedding for intentional.\n",
      "['interacting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2600,  0.8846, -0.1628,  ...,  0.1640, -0.5290,  0.6244])\n",
      "interacting\n",
      "Saved the embedding for interacting.\n",
      "['interest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3102,  0.6932,  0.0425,  ..., -0.5996,  0.1604,  0.2487])\n",
      "interest\n",
      "Saved the embedding for interest.\n",
      "['interested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4841,  0.8182,  0.3977,  ...,  0.1230,  0.3180,  0.4607])\n",
      "interested\n",
      "Saved the embedding for interested.\n",
      "['inter', '##ject', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2382, -0.2433, -0.3429,  ..., -0.5755,  0.3374,  0.9885])\n",
      "interjecting\n",
      "Saved the embedding for interjecting.\n",
      "['internal', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3109,  0.7479, -0.8284,  ..., -0.1408, -0.4648,  0.5369])\n",
      "internalizing\n",
      "Saved the embedding for internalizing.\n",
      "['inter', '##ro', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0874, -0.3554, -0.4998,  ..., -0.5858,  0.1146,  0.8989])\n",
      "interrogating\n",
      "Saved the embedding for interrogating.\n",
      "['interrupting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3221,  0.7850, -0.2029,  ..., -0.0598, -0.1395,  0.4748])\n",
      "interrupting\n",
      "Saved the embedding for interrupting.\n",
      "['intimidated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5836,  0.7121, -0.1642,  ..., -0.4581,  0.0538,  0.4928])\n",
      "intimidated\n",
      "Saved the embedding for intimidated.\n",
      "['intimidating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1816,  0.4343, -0.5614,  ..., -0.5386, -0.1684,  0.4644])\n",
      "intimidating\n",
      "Saved the embedding for intimidating.\n",
      "['into', '##ler', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0607, -0.0550,  0.0268,  ..., -0.3530,  0.1075,  0.7277])\n",
      "intolerant\n",
      "Saved the embedding for intolerant.\n",
      "['into', '##xi', '##cated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1677,  0.0718,  0.0580,  ..., -0.7342,  0.0557,  0.7411])\n",
      "intoxicated\n",
      "Saved the embedding for intoxicated.\n",
      "['int', '##rigue'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3848,  0.0668, -0.4788,  ..., -0.3891, -0.3128,  0.6348])\n",
      "intrigue\n",
      "Saved the embedding for intrigue.\n",
      "['intrigued'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1062,  0.3669,  0.1620,  ..., -0.0682,  0.3085,  0.8723])\n",
      "intrigued\n",
      "Saved the embedding for intrigued.\n",
      "['intriguing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1259,  0.3882,  0.2473,  ..., -0.3125, -0.1194,  0.4122])\n",
      "intriguing\n",
      "Saved the embedding for intriguing.\n",
      "['intro', '##sp', '##ect', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0898,  0.2312, -0.2324,  ..., -0.4361, -0.1777,  0.6747])\n",
      "introspective\n",
      "Saved the embedding for introspective.\n",
      "['invested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0971,  0.4418, -0.1472,  ..., -0.0812,  0.0684,  0.8001])\n",
      "invested\n",
      "Saved the embedding for invested.\n",
      "['investigate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0010, -0.0689, -0.1743,  ..., -0.1345,  0.2478,  0.1478])\n",
      "investigate\n",
      "Saved the embedding for investigate.\n",
      "['investigative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2505,  0.1747, -0.3528,  ...,  0.1183,  0.0899,  0.1277])\n",
      "investigative\n",
      "Saved the embedding for investigative.\n",
      "['investigator', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3274,  0.9006,  0.6097,  ...,  0.0551,  0.1886,  0.7490])\n",
      "investigatory\n",
      "Saved the embedding for investigatory.\n",
      "['in', '##vi', '##gor', '##ated'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1601,  0.1660, -0.1771,  ..., -0.0864,  0.1558,  0.4061])\n",
      "invigorated\n",
      "Saved the embedding for invigorated.\n",
      "['involved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2101,  0.6640, -0.6085,  ..., -0.5860, -0.0690,  0.5680])\n",
      "involved\n",
      "Saved the embedding for involved.\n",
      "['ira', '##sc', '##ible'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3054,  0.4956, -0.8076,  ..., -0.5448,  0.4328,  0.1680])\n",
      "irascible\n",
      "Saved the embedding for irascible.\n",
      "['ira', '##te'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2875,  0.5763, -0.6912,  ..., -0.5129,  0.1033,  0.0894])\n",
      "irate\n",
      "Saved the embedding for irate.\n",
      "['ir', '##e'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0856,  0.3596, -0.0817,  ..., -0.0341,  0.3873,  0.6448])\n",
      "ire\n",
      "Saved the embedding for ire.\n",
      "['ir', '##ef', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0312,  0.0446, -0.0643,  ..., -0.1099,  0.3994,  1.0237])\n",
      "ireful\n",
      "Saved the embedding for ireful.\n",
      "['ir', '##ked'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0261,  0.2613, -0.1935,  ..., -0.0865,  0.0633,  0.6417])\n",
      "irked\n",
      "Saved the embedding for irked.\n",
      "['ironic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3112,  0.7663,  0.1731,  ..., -0.3428, -0.1657,  0.6701])\n",
      "ironic\n",
      "Saved the embedding for ironic.\n",
      "['irony'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8368,  0.7533,  0.3445,  ..., -0.1579, -0.0350,  0.3789])\n",
      "irony\n",
      "Saved the embedding for irony.\n",
      "['ir', '##res', '##ol', '##ute'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1310,  0.3696,  0.0069,  ..., -0.3345,  0.0579,  0.9210])\n",
      "irresolute\n",
      "Saved the embedding for irresolute.\n",
      "['ir', '##rita', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0435,  0.2575, -0.0635,  ..., -0.3635,  0.2512,  0.6953])\n",
      "irritable\n",
      "Saved the embedding for irritable.\n",
      "['ir', '##rita', '##bly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0697,  0.1630, -0.0133,  ..., -0.1683,  0.3027,  0.8174])\n",
      "irritably\n",
      "Saved the embedding for irritably.\n",
      "['irritated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2436,  0.2482, -0.2128,  ..., -0.1087,  0.0915,  0.9609])\n",
      "irritated\n",
      "Saved the embedding for irritated.\n",
      "['irritation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0967,  0.5078, -0.1857,  ..., -0.4288, -0.0683,  0.7108])\n",
      "irritation\n",
      "Saved the embedding for irritation.\n",
      "['isolated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5067,  0.4896, -0.5630,  ..., -0.1668,  0.0250,  0.4672])\n",
      "isolated\n",
      "Saved the embedding for isolated.\n",
      "['ja', '##bbed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4543, -0.6535, -0.7452,  ...,  0.2731,  0.1499, -0.0645])\n",
      "jabbed\n",
      "Saved the embedding for jabbed.\n",
      "['jade', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1844, -0.1815,  0.1961,  ..., -0.2766,  0.2391, -0.1053])\n",
      "jaded\n",
      "Saved the embedding for jaded.\n",
      "['jar', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9986,  0.2311,  0.1312,  ..., -0.0267,  0.4066, -0.1434])\n",
      "jarred\n",
      "Saved the embedding for jarred.\n",
      "['jar', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8902,  0.2811,  0.0266,  ..., -0.1588,  0.2704, -0.0861])\n",
      "jarring\n",
      "Saved the embedding for jarring.\n",
      "['ja', '##unt', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1593, -0.5226, -0.6656,  ...,  0.4851,  0.3387,  0.0455])\n",
      "jaunty\n",
      "Saved the embedding for jaunty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jaw', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7195,  0.5620, -0.4159,  ..., -0.1774,  0.2825,  0.4160])\n",
      "jawed\n",
      "Saved the embedding for jawed.\n",
      "['jealous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6075,  0.3273, -0.1386,  ..., -1.2928, -0.0568, -0.0300])\n",
      "jealous\n",
      "Saved the embedding for jealous.\n",
      "['je', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4695, -0.3845, -0.3876,  ...,  0.5425,  0.2888,  0.0381])\n",
      "jeering\n",
      "Saved the embedding for jeering.\n",
      "['je', '##sti', '##ng'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4082, -0.3387, -0.3067,  ...,  0.7558,  0.1073,  0.0127])\n",
      "jesting\n",
      "Saved the embedding for jesting.\n",
      "['ji', '##lt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1360, -0.1692, -0.5378,  ..., -0.0190, -0.0608,  0.2691])\n",
      "jilted\n",
      "Saved the embedding for jilted.\n",
      "['ji', '##tter', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0404,  0.0062, -0.4481,  ..., -0.0911, -0.2364,  0.0742])\n",
      "jittery\n",
      "Saved the embedding for jittery.\n",
      "['jo', '##cular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3330, -0.7762, -0.7717,  ...,  0.1710,  0.1510,  0.2679])\n",
      "jocular\n",
      "Saved the embedding for jocular.\n",
      "['joking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2940, -0.0739, -0.3561,  ..., -0.0312, -0.1344,  0.6583])\n",
      "joking\n",
      "Saved the embedding for joking.\n",
      "['jolly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5985,  0.6680,  0.4785,  ...,  0.5900, -0.6887, -0.4618])\n",
      "jolly\n",
      "Saved the embedding for jolly.\n",
      "['jolted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2656,  0.5062,  0.0008,  ..., -0.5312,  0.1163,  0.3953])\n",
      "jolted\n",
      "Saved the embedding for jolted.\n",
      "['jo', '##vial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3984, -0.8425, -0.7666,  ...,  0.0214,  0.0844,  0.4131])\n",
      "jovial\n",
      "Saved the embedding for jovial.\n",
      "['joy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2158,  0.3172,  0.3443,  ..., -0.0231,  0.4541,  0.0805])\n",
      "joy\n",
      "Saved the embedding for joy.\n",
      "['joy', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1700,  0.2954,  0.3085,  ..., -0.1764,  0.3982,  0.1273])\n",
      "joyful\n",
      "Saved the embedding for joyful.\n",
      "['joy', '##fulness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1854,  0.3323,  0.2096,  ..., -0.1471,  0.2365,  0.3074])\n",
      "joyfulness\n",
      "Saved the embedding for joyfulness.\n",
      "['joy', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1532,  0.3045,  0.3058,  ..., -0.2898,  0.2778,  0.1596])\n",
      "joyless\n",
      "Saved the embedding for joyless.\n",
      "['joy', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1116,  0.3862,  0.3083,  ..., -0.3114,  0.3074,  0.2091])\n",
      "joyous\n",
      "Saved the embedding for joyous.\n",
      "['ju', '##bil', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2109, -0.4253, -0.8754,  ...,  0.2174,  0.3609,  0.2642])\n",
      "jubilant\n",
      "Saved the embedding for jubilant.\n",
      "['ju', '##bil', '##ation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2128, -0.3626, -0.8503,  ...,  0.1160,  0.3868,  0.2086])\n",
      "jubilation\n",
      "Saved the embedding for jubilation.\n",
      "['judgement', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1833,  0.7167,  0.4986,  ..., -0.1984,  0.5446,  0.3538])\n",
      "judgemental\n",
      "Saved the embedding for judgemental.\n",
      "['judging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7343,  0.2711,  0.0554,  ..., -0.1193, -0.0047,  0.0186])\n",
      "judging\n",
      "Saved the embedding for judging.\n",
      "['judgment', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1205,  1.0080,  0.3249,  ..., -0.2182,  0.8485,  0.6956])\n",
      "judgmental\n",
      "Saved the embedding for judgmental.\n",
      "['ju', '##dic', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1035, -0.4270, -0.9064,  ...,  0.2308,  0.3646,  0.0291])\n",
      "judicious\n",
      "Saved the embedding for judicious.\n",
      "['jump', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1286,  0.7342, -0.4445,  ...,  0.4888,  0.6139, -0.2648])\n",
      "jumpy\n",
      "Saved the embedding for jumpy.\n",
      "['justified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2913,  0.3494, -0.3116,  ..., -0.2665,  0.1213,  0.4194])\n",
      "justified\n",
      "Saved the embedding for justified.\n",
      "['keen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1901, -0.2118,  0.1941,  ..., -0.2431,  0.2736,  0.4866])\n",
      "keen\n",
      "Saved the embedding for keen.\n",
      "['kind'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0978, -0.3243, -0.0422,  ..., -0.3136,  0.0600,  0.1423])\n",
      "kind\n",
      "Saved the embedding for kind.\n",
      "['kind', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0440, -0.3606,  0.1887,  ..., -0.3491, -0.1329,  0.2228])\n",
      "kindhearted\n",
      "Saved the embedding for kindhearted.\n",
      "['kiss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2959,  0.0504,  0.2765,  ...,  0.0741,  0.3368, -0.2262])\n",
      "kiss\n",
      "Saved the embedding for kiss.\n",
      "['knowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2668,  0.3332, -0.2668,  ..., -0.0729, -0.2271,  0.3951])\n",
      "knowing\n",
      "Saved the embedding for knowing.\n",
      "['know', '##led', '##ga', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.7470, -0.2148,  0.2463,  ...,  0.3379,  0.2443,  0.2919])\n",
      "knowledgable\n",
      "Saved the embedding for knowledgable.\n",
      "['knowledge', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2207,  1.0101,  0.2420,  ...,  0.1689, -0.7472,  0.5133])\n",
      "knowledgeable\n",
      "Saved the embedding for knowledgeable.\n",
      "['ko', '##sher'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0890, -0.0982, -0.6689,  ...,  0.0145, -0.0378,  0.9968])\n",
      "kosher\n",
      "Saved the embedding for kosher.\n",
      "['lack', '##ada', '##isi', '##cal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4411, -0.0129, -0.4027,  ...,  0.0335,  0.4553,  0.4428])\n",
      "lackadaisical\n",
      "Saved the embedding for lackadaisical.\n",
      "['lack', '##lus', '##ter'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4560, -0.0279, -0.2086,  ...,  0.0540,  0.6201,  0.3026])\n",
      "lackluster\n",
      "Saved the embedding for lackluster.\n",
      "['lac', '##onic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6379, -0.2603,  0.0263,  ...,  0.1289,  0.2930,  0.6081])\n",
      "laconic\n",
      "Saved the embedding for laconic.\n",
      "['lamb', '##ast', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6549,  0.3947, -0.1621,  ...,  0.4252, -0.1696, -0.0817])\n",
      "lambaste\n",
      "Saved the embedding for lambaste.\n",
      "['lame', '##nta', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3147, -0.6710,  0.4518,  ...,  0.2128,  0.0548,  0.2353])\n",
      "lamentable\n",
      "Saved the embedding for lamentable.\n",
      "['lame', '##nting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5501, -0.5312,  0.4568,  ...,  0.3135, -0.0656,  0.2393])\n",
      "lamenting\n",
      "Saved the embedding for lamenting.\n",
      "['las', '##ci', '##vious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4739,  0.0418,  0.0135,  ...,  0.5210,  0.4507, -0.3804])\n",
      "lascivious\n",
      "Saved the embedding for lascivious.\n",
      "['laugh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1623,  0.3447,  0.3919,  ...,  0.1381,  0.0782, -0.0966])\n",
      "laugh\n",
      "Saved the embedding for laugh.\n",
      "['laughing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2096,  0.6113,  0.4240,  ..., -0.0757, -0.0552, -0.0877])\n",
      "laughing\n",
      "Saved the embedding for laughing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['laughter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1382,  0.8906,  0.1930,  ...,  0.0436, -0.0291,  0.3775])\n",
      "laughter\n",
      "Saved the embedding for laughter.\n",
      "['lazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0948,  0.4938, -0.4840,  ...,  0.0551, -0.1624,  0.9168])\n",
      "lazy\n",
      "Saved the embedding for lazy.\n",
      "['leaving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3882, -0.4447, -0.0862,  ...,  0.3898,  0.3494, -0.0062])\n",
      "leaving\n",
      "Saved the embedding for leaving.\n",
      "['le', '##cher', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2661, -0.0326, -0.0825,  ...,  0.8955,  0.5646,  0.3913])\n",
      "lecherous\n",
      "Saved the embedding for lecherous.\n",
      "['le', '##cturing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3441, -0.0849,  0.1715,  ...,  0.8347,  0.3704,  0.3738])\n",
      "lecturing\n",
      "Saved the embedding for lecturing.\n",
      "['lee', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6022,  0.2441, -0.5466,  ...,  0.1943,  0.0385,  0.5774])\n",
      "leering\n",
      "Saved the embedding for leering.\n",
      "['lee', '##ry'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5135,  0.2422, -0.5651,  ...,  0.4134,  0.0444,  0.4120])\n",
      "leery\n",
      "Saved the embedding for leery.\n",
      "['let', '##down'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2102,  0.3386, -0.0559,  ...,  0.6249, -0.0514,  0.8366])\n",
      "letdown\n",
      "Saved the embedding for letdown.\n",
      "['let', '##har', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3698,  0.3047,  0.0833,  ...,  0.8698, -0.1562,  0.2978])\n",
      "lethargic\n",
      "Saved the embedding for lethargic.\n",
      "['level', '##head', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 3.5021e-01, -1.6764e-01, -2.2109e-01,  ...,  4.0086e-04,\n",
      "        -1.1540e-01,  4.3759e-01])\n",
      "levelheaded\n",
      "Saved the embedding for levelheaded.\n",
      "['lew', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1793,  0.4631, -0.3544,  ...,  0.1871,  0.0487,  0.0395])\n",
      "lewd\n",
      "Saved the embedding for lewd.\n",
      "['li', '##bid', '##ino', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2430, -0.2764, -0.0991,  ...,  0.2936,  0.5524,  0.3659])\n",
      "libidinous\n",
      "Saved the embedding for libidinous.\n",
      "['lifeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5228,  0.0194,  0.2919,  ..., -0.2427,  0.2777,  0.0996])\n",
      "lifeless\n",
      "Saved the embedding for lifeless.\n",
      "['light', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2125,  0.7077,  0.3842,  ...,  0.2527,  0.2158, -0.0716])\n",
      "lighthearted\n",
      "Saved the embedding for lighthearted.\n",
      "['lip', '##ped'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8834, -0.4730, -0.6887,  ..., -0.2647, -0.2209,  0.6214])\n",
      "lipped\n",
      "Saved the embedding for lipped.\n",
      "['listening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1471,  0.5612, -0.3675,  ..., -0.3625, -0.4880, -0.0255])\n",
      "listening\n",
      "Saved the embedding for listening.\n",
      "['list', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1994, -0.5538,  0.4586,  ...,  0.3061,  0.4173, -0.1433])\n",
      "listless\n",
      "Saved the embedding for listless.\n",
      "['lively'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1417, 0.1805, 0.3503,  ..., 0.1130, 0.3808, 0.2272])\n",
      "lively\n",
      "Saved the embedding for lively.\n",
      "['liv', '##id'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2363, -0.0994, -0.6806,  ...,  0.8112,  0.2497,  0.9016])\n",
      "livid\n",
      "Saved the embedding for livid.\n",
      "['loaded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3335,  0.1964, -0.3029,  ...,  0.2307, -0.1390, -0.2359])\n",
      "loaded\n",
      "Saved the embedding for loaded.\n",
      "['lo', '##ath'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3813, -0.6920, -0.3921,  ..., -0.0934,  0.4938,  0.2516])\n",
      "loath\n",
      "Saved the embedding for loath.\n",
      "['lo', '##ath', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2602, -0.5398, -0.3350,  ...,  0.3694,  0.6136,  0.2453])\n",
      "loathe\n",
      "Saved the embedding for loathe.\n",
      "['lo', '##athing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3078, -0.6391, -0.3177,  ..., -0.0550,  0.3385,  0.1980])\n",
      "loathing\n",
      "Saved the embedding for loathing.\n",
      "['lo', '##ath', '##some'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3418, -0.6700, -0.4975,  ...,  0.0952,  0.2853,  0.3396])\n",
      "loathsome\n",
      "Saved the embedding for loathsome.\n",
      "['locked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3831,  0.4116, -0.4126,  ..., -0.0303, -0.1192,  0.2514])\n",
      "locked\n",
      "Saved the embedding for locked.\n",
      "['loneliness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2400,  0.2786,  0.3074,  ..., -0.5810, -0.4785,  0.9859])\n",
      "loneliness\n",
      "Saved the embedding for loneliness.\n",
      "['lonely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0447,  0.1156,  0.0810,  ..., -0.2960, -0.2023,  0.3460])\n",
      "lonely\n",
      "Saved the embedding for lonely.\n",
      "['longing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6213, -0.0718,  0.2090,  ..., -0.3134, -0.1899,  0.0944])\n",
      "longing\n",
      "Saved the embedding for longing.\n",
      "['looking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8520,  0.4513, -0.4601,  ...,  0.0945,  0.4348,  0.3254])\n",
      "looking\n",
      "Saved the embedding for looking.\n",
      "['lo', '##ony'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3669, -0.5881, -0.3605,  ...,  0.2431,  0.3774,  0.1464])\n",
      "loony\n",
      "Saved the embedding for loony.\n",
      "['loss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4895,  0.5089,  0.0014,  ..., -0.0611,  0.4745,  0.3615])\n",
      "loss\n",
      "Saved the embedding for loss.\n",
      "['lost'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2275, -0.0973,  0.0109,  ..., -0.0044,  0.2064,  0.0898])\n",
      "lost\n",
      "Saved the embedding for lost.\n",
      "['loud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2676,  0.2286, -0.6470,  ...,  0.5639,  0.2581, -0.6288])\n",
      "loud\n",
      "Saved the embedding for loud.\n",
      "['lou', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0404, -0.2322,  0.0464,  ...,  0.2066,  0.1248,  0.4753])\n",
      "lousy\n",
      "Saved the embedding for lousy.\n",
      "['love'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1868,  0.2470,  0.1403,  ...,  0.1181, -0.3040, -0.4204])\n",
      "love\n",
      "Saved the embedding for love.\n",
      "['loving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8438,  0.2505,  0.2378,  ..., -0.0466, -0.2092, -0.0899])\n",
      "loving\n",
      "Saved the embedding for loving.\n",
      "['low', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0310,  0.1710, -0.2483,  ..., -0.4364, -0.4102, -0.1223])\n",
      "lowliness\n",
      "Saved the embedding for lowliness.\n",
      "['lu', '##rid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4130, -0.7530, -0.5877,  ...,  0.1114,  0.2468,  0.1002])\n",
      "lurid\n",
      "Saved the embedding for lurid.\n",
      "['lust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.5157, 0.6576, 0.2386,  ..., 0.1162, 0.0264, 0.1292])\n",
      "lustful\n",
      "Saved the embedding for lustful.\n",
      "['lust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4672,  0.6784,  0.2106,  ...,  0.1283, -0.0947,  0.1610])\n",
      "lusting\n",
      "Saved the embedding for lusting.\n",
      "['lust', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3585,  0.7473,  0.2979,  ...,  0.2697, -0.1495,  0.0484])\n",
      "lusty\n",
      "Saved the embedding for lusty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0748,  0.3907, -0.0999,  ...,  0.6169, -0.2985, -0.0864])\n",
      "lying\n",
      "Saved the embedding for lying.\n",
      "['mad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0438,  0.4377,  0.1243,  ..., -0.0119,  0.0104,  0.5819])\n",
      "mad\n",
      "Saved the embedding for mad.\n",
      "['madden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1222, -0.1420, -0.3225,  ..., -0.4062,  0.5032,  0.5225])\n",
      "maddened\n",
      "Saved the embedding for maddened.\n",
      "['madness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7415, -0.0390, -0.2906,  ..., -0.0780,  0.0876,  0.4792])\n",
      "madness\n",
      "Saved the embedding for madness.\n",
      "['mal', '##con', '##ten', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.7811,  0.2633, -0.5221,  ..., -0.0103, -0.2486,  0.0994])\n",
      "malcontent\n",
      "Saved the embedding for malcontent.\n",
      "['male', '##fi', '##cent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3047,  0.0559, -0.2149,  ..., -0.4219,  0.1527, -0.0199])\n",
      "maleficent\n",
      "Saved the embedding for maleficent.\n",
      "['male', '##vo', '##lent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2152,  0.0299, -0.3803,  ..., -0.4710,  0.0731,  0.1184])\n",
      "malevolent\n",
      "Saved the embedding for malevolent.\n",
      "['malice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6932, -0.0761, -0.1243,  ..., -0.1137,  0.9209,  0.8119])\n",
      "malice\n",
      "Saved the embedding for malice.\n",
      "['malicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5455, -0.2985,  0.0435,  ..., -0.8246, -0.2139,  0.7346])\n",
      "malicious\n",
      "Saved the embedding for malicious.\n",
      "['mali', '##gnant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5736,  0.2468, -0.1293,  ..., -0.5153, -0.1344, -0.0157])\n",
      "malignant\n",
      "Saved the embedding for malignant.\n",
      "['mania', '##cal'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5931, -0.0419, -0.0747,  ...,  0.3084,  0.6802,  0.4067])\n",
      "maniacal\n",
      "Saved the embedding for maniacal.\n",
      "['mani', '##pu', '##lative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2133, -0.4470, -0.3499,  ..., -0.1546,  0.1250,  0.6739])\n",
      "manipulative\n",
      "Saved the embedding for manipulative.\n",
      "['marvel', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3445,  0.8204, -0.6757,  ...,  0.2404,  0.4589, -0.4263])\n",
      "marveled\n",
      "Saved the embedding for marveled.\n",
      "['master'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.4024,  0.0768, -0.1429,  ...,  0.2077,  0.2274,  0.3063])\n",
      "master\n",
      "Saved the embedding for master.\n",
      "['mean'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.4212, 0.0473, 0.0853,  ..., 0.7255, 0.2023, 1.0622])\n",
      "mean\n",
      "Saved the embedding for mean.\n",
      "['meaningful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4039,  0.9382, -0.6142,  ..., -0.5753, -0.8556,  0.1051])\n",
      "meaningful\n",
      "Saved the embedding for meaningful.\n",
      "['med', '##itative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2100, -0.9559, -0.3333,  ..., -0.3370, -0.4896,  0.5421])\n",
      "meditative\n",
      "Saved the embedding for meditative.\n",
      "['meek'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4768,  0.5715, -0.0537,  ..., -0.0725,  0.1743,  0.2326])\n",
      "meek\n",
      "Saved the embedding for meek.\n",
      "['mel', '##an', '##cho', '##lic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6856,  0.1602,  0.2938,  ..., -0.1001, -0.0274,  0.1000])\n",
      "melancholic\n",
      "Saved the embedding for melancholic.\n",
      "['melancholy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0566,  0.0072,  0.7941,  ...,  0.0264,  0.1497,  0.1482])\n",
      "melancholy\n",
      "Saved the embedding for melancholy.\n",
      "['mel', '##low'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7583,  0.1625, -0.0520,  ..., -0.1660, -0.1292, -0.1261])\n",
      "mellow\n",
      "Saved the embedding for mellow.\n",
      "['menace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2359, 0.6056, 0.3643,  ..., 0.3965, 0.5987, 0.5286])\n",
      "menace\n",
      "Saved the embedding for menace.\n",
      "['menacing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4425,  0.7510, -0.0978,  ..., -0.3350, -0.0525,  0.2089])\n",
      "menacing\n",
      "Saved the embedding for menacing.\n",
      "['mental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6470,  1.1035, -0.7887,  ..., -0.3902, -0.1827,  0.5850])\n",
      "mental\n",
      "Saved the embedding for mental.\n",
      "['mer', '##rily'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4609, -0.4581, -0.2434,  ...,  0.1912, -0.0448,  0.5231])\n",
      "merrily\n",
      "Saved the embedding for merrily.\n",
      "['merry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0235, 0.1575, 0.5481,  ..., 0.1083, 0.5901, 0.2241])\n",
      "merry\n",
      "Saved the embedding for merry.\n",
      "['me', '##sm', '##eri', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3184,  0.2160, -0.6254,  ...,  0.2517,  0.0119,  0.3370])\n",
      "mesmerized\n",
      "Saved the embedding for mesmerized.\n",
      "['mi', '##ffed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3978, -0.0582, -0.0527,  ..., -0.1932,  0.1218,  0.7932])\n",
      "miffed\n",
      "Saved the embedding for miffed.\n",
      "['mild'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0968,  0.5484, -0.4040,  ..., -0.4489, -0.3927,  0.0624])\n",
      "mild\n",
      "Saved the embedding for mild.\n",
      "['min', '##cing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2644, -0.0474, -0.2256,  ...,  0.3208, -0.3348,  0.6107])\n",
      "mincing\n",
      "Saved the embedding for mincing.\n",
      "['mind', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3151,  0.8207, -0.0938,  ...,  0.4242,  0.0762,  0.1638])\n",
      "mindful\n",
      "Saved the embedding for mindful.\n",
      "['mind', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3191,  0.7571, -0.1917,  ...,  0.4214, -0.0774,  0.3271])\n",
      "mindless\n",
      "Saved the embedding for mindless.\n",
      "['mo', '##urn', '##fulness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2030,  0.5504, -0.5682,  ...,  0.3492, -0.3064,  0.1812])\n",
      "mournfulness\n",
      "Saved the embedding for mournfulness.\n",
      "['mourning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.6227, 0.4383, 0.1769,  ..., 0.2115, 0.5749, 0.0415])\n",
      "mourning\n",
      "Saved the embedding for mourning.\n",
      "['mouthed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.0152,  0.0630,  0.1403,  ..., -0.0348, -0.1582,  0.5228])\n",
      "mouthed\n",
      "Saved the embedding for mouthed.\n",
      "['moved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5941,  0.4321, -0.0068,  ..., -0.3677, -0.2738,  0.6199])\n",
      "moved\n",
      "Saved the embedding for moved.\n",
      "['mud', '##dled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4114, -0.1823, -0.2770,  ..., -0.2872, -0.3525,  0.2483])\n",
      "muddled\n",
      "Saved the embedding for muddled.\n",
      "['mum'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6426, -0.1959, -0.5458,  ...,  0.1451,  0.0385,  0.0736])\n",
      "mum\n",
      "Saved the embedding for mum.\n",
      "['murderous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7442,  0.8387,  0.0412,  ..., -0.0303, -0.3388, -0.0085])\n",
      "murderous\n",
      "Saved the embedding for murderous.\n",
      "['musical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3767,  0.0994, -0.1610,  ..., -0.1598, -0.2641,  0.4289])\n",
      "musical\n",
      "Saved the embedding for musical.\n",
      "['mu', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1559,  0.5035, -0.6271,  ...,  0.3849,  0.0621,  0.4684])\n",
      "musing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for musing.\n",
      "['muster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9586,  0.1123, -0.2081,  ..., -0.4346,  0.2927, -0.0714])\n",
      "muster\n",
      "Saved the embedding for muster.\n",
      "['mute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3308, -0.5543, -0.6141,  ..., -0.4294, -0.1583,  0.0776])\n",
      "mute\n",
      "Saved the embedding for mute.\n",
      "['muted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2849,  0.3311, -0.4252,  ...,  0.1261, -0.3527,  0.3089])\n",
      "muted\n",
      "Saved the embedding for muted.\n",
      "['muttering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8662,  0.1653,  0.0413,  ..., -0.1038, -0.0553,  0.0615])\n",
      "muttering\n",
      "Saved the embedding for muttering.\n",
      "['mysterious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1698, -0.0312,  0.1336,  ..., -0.3727,  0.2685,  0.3178])\n",
      "mysterious\n",
      "Saved the embedding for mysterious.\n",
      "['mystical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2040,  0.2975,  0.1494,  ..., -0.1473,  0.1290,  0.5407])\n",
      "mystical\n",
      "Saved the embedding for mystical.\n",
      "['my', '##sti', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3548,  0.2037, -0.6451,  ..., -0.1468,  0.0098,  0.1972])\n",
      "mystified\n",
      "Saved the embedding for mystified.\n",
      "['naive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3083,  0.6524, -0.0253,  ...,  0.8669, -0.1475,  0.1689])\n",
      "naive\n",
      "Saved the embedding for naive.\n",
      "['nap', '##ping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0351,  0.0548, -0.4270,  ..., -0.4633, -0.6130,  0.1562])\n",
      "napping\n",
      "Saved the embedding for napping.\n",
      "['narrow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1567, -0.1732, -0.6262,  ...,  0.3578,  0.0096, -0.2033])\n",
      "narrow\n",
      "Saved the embedding for narrow.\n",
      "['nasty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7575, -0.3314, -0.1710,  ..., -0.1158, -0.0318,  0.1974])\n",
      "nasty\n",
      "Saved the embedding for nasty.\n",
      "['natural'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4133,  0.3982,  0.2457,  ..., -0.6082,  0.0567,  0.0819])\n",
      "natural\n",
      "Saved the embedding for natural.\n",
      "['nature', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.4961, 0.4765, 0.3567,  ..., 0.4856, 0.0148, 0.4575])\n",
      "natured\n",
      "Saved the embedding for natured.\n",
      "['naughty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0622,  0.2497,  0.4950,  ...,  0.7564,  0.5349, -0.3131])\n",
      "naughty\n",
      "Saved the embedding for naughty.\n",
      "['nausea'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1903,  0.5801, -0.5646,  ..., -0.4109, -0.0932,  0.6461])\n",
      "nausea\n",
      "Saved the embedding for nausea.\n",
      "['nausea', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1059,  0.5913, -0.5124,  ..., -0.2429,  0.0667,  0.5267])\n",
      "nauseated\n",
      "Saved the embedding for nauseated.\n",
      "['na', '##use', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1976,  0.1335, -0.4915,  ...,  0.3005, -0.2266,  0.7080])\n",
      "nauseous\n",
      "Saved the embedding for nauseous.\n",
      "['needy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-6.0980e-01, -6.2795e-04,  7.5777e-01,  ..., -3.2152e-01,\n",
      "         1.8843e-01, -2.2400e-01])\n",
      "needy\n",
      "Saved the embedding for needy.\n",
      "['ne', '##far', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2416, -0.1231, -0.6237,  ...,  0.1907, -0.0606,  0.7658])\n",
      "nefarious\n",
      "Saved the embedding for nefarious.\n",
      "['ne', '##gating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2254, -0.0251, -0.6519,  ...,  0.0920, -0.1396,  0.6019])\n",
      "negating\n",
      "Saved the embedding for negating.\n",
      "['negative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6318,  0.4941, -0.6690,  ..., -0.0613, -0.5341,  0.1774])\n",
      "negative\n",
      "Saved the embedding for negative.\n",
      "['ne', '##gat', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2225, -0.1617, -0.5526,  ...,  0.0424, -0.2450,  0.5320])\n",
      "negativity\n",
      "Saved the embedding for negativity.\n",
      "['neglected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1393,  0.7026, -0.0529,  ...,  0.7428, -0.1731,  0.4616])\n",
      "neglected\n",
      "Saved the embedding for neglected.\n",
      "['ne', '##rdy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1976,  0.1193, -0.6553,  ...,  0.4721, -0.0527,  0.8466])\n",
      "nerdy\n",
      "Saved the embedding for nerdy.\n",
      "['nerve', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5423,  0.7520,  0.0775,  ..., -0.1215, -0.4735,  0.6744])\n",
      "nerved\n",
      "Saved the embedding for nerved.\n",
      "['nerves'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2302,  0.3551, -0.2089,  ..., -0.0470, -0.0730,  0.6769])\n",
      "nerves\n",
      "Saved the embedding for nerves.\n",
      "['nervous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5682,  0.4541, -0.2261,  ..., -0.1688, -0.2854,  0.2944])\n",
      "nervous\n",
      "Saved the embedding for nervous.\n",
      "['nervously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1117, -0.4080, -0.2826,  ..., -0.6100,  0.0148,  0.1579])\n",
      "nervously\n",
      "Saved the embedding for nervously.\n",
      "['nervous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4957,  0.5428, -0.0989,  ..., -0.1708, -0.3996,  0.2707])\n",
      "nervousness\n",
      "Saved the embedding for nervousness.\n",
      "['nes', '##cie', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4863, -0.6172, -0.4935,  ...,  1.3741, -0.0458,  0.3737])\n",
      "nescient\n",
      "Saved the embedding for nescient.\n",
      "['net', '##tled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1633, -1.4291, -0.1974,  ...,  0.4179,  0.2679,  1.1354])\n",
      "nettled\n",
      "Saved the embedding for nettled.\n",
      "['neutral'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1769,  0.6898,  0.0217,  ..., -0.5282, -0.4625,  0.0472])\n",
      "neutral\n",
      "Saved the embedding for neutral.\n",
      "['neutrality'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1747, -0.0918, -0.3376,  ..., -0.5582, -0.1843,  0.4518])\n",
      "neutrality\n",
      "Saved the embedding for neutrality.\n",
      "['nice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2468, 0.3628, 0.4772,  ..., 0.5649, 0.1279, 0.0644])\n",
      "nice\n",
      "Saved the embedding for nice.\n",
      "['noisy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4179,  0.3867, -0.2570,  ..., -0.4056, -0.1547, -0.2237])\n",
      "noisy\n",
      "Saved the embedding for noisy.\n",
      "['non', '##bel', '##ie', '##f'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1759, -0.2357,  0.2112,  ...,  0.2036,  0.0912,  0.9359])\n",
      "nonbelief\n",
      "Saved the embedding for nonbelief.\n",
      "['non', '##chal', '##ance'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2111, -0.4224,  0.2102,  ...,  0.0765,  0.1423,  1.1313])\n",
      "nonchalance\n",
      "Saved the embedding for nonchalance.\n",
      "['non', '##chal', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1829, -0.4232,  0.2509,  ...,  0.0549,  0.1314,  1.2115])\n",
      "nonchalant\n",
      "Saved the embedding for nonchalant.\n",
      "['non', '##com', '##mit', '##tal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1463, -0.4659,  0.2569,  ..., -0.0990, -0.0715,  0.9775])\n",
      "noncommittal\n",
      "Saved the embedding for noncommittal.\n",
      "['non', '##com', '##pl', '##ian', '##t'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.1727, -0.4120,  0.2679,  ...,  0.2272,  0.0052,  1.0095])\n",
      "noncompliant\n",
      "Saved the embedding for noncompliant.\n",
      "['non', '##pl', '##uss', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1253, -0.4832,  0.2588,  ...,  0.1058,  0.0920,  0.9613])\n",
      "nonplussed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for nonplussed.\n",
      "['non', '##sen', '##sic', '##al'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1973, -0.3265,  0.3079,  ...,  0.1393,  0.1082,  1.0119])\n",
      "nonsensical\n",
      "Saved the embedding for nonsensical.\n",
      "['normal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3529,  0.4992, -0.4382,  ..., -0.5344, -0.5981, -0.1805])\n",
      "normal\n",
      "Saved the embedding for normal.\n",
      "['nose', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0123,  0.3035, -0.3556,  ..., -0.1469, -0.5449,  0.3188])\n",
      "nosey\n",
      "Saved the embedding for nosey.\n",
      "['nos', '##tal', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.1617, 0.0359, 0.3540,  ..., 0.8199, 0.1464, 0.6509])\n",
      "nostalgic\n",
      "Saved the embedding for nostalgic.\n",
      "['nos', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.0593, 0.1326, 0.2221,  ..., 0.8368, 0.3220, 0.5941])\n",
      "nosy\n",
      "Saved the embedding for nosy.\n",
      "['numb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2130, -0.1803, -0.5192,  ..., -0.1037, -0.3052,  0.6747])\n",
      "numb\n",
      "Saved the embedding for numb.\n",
      "['obe', '##die', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2770,  0.8953, -0.0890,  ...,  0.1177,  0.2623, -0.0460])\n",
      "obedient\n",
      "Saved the embedding for obedient.\n",
      "['object', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0584,  0.5389,  0.1178,  ...,  0.0807, -0.1959,  1.0113])\n",
      "objecting\n",
      "Saved the embedding for objecting.\n",
      "['objection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6888,  0.0024,  0.2230,  ..., -0.2115,  0.5545,  0.2086])\n",
      "objection\n",
      "Saved the embedding for objection.\n",
      "['objective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4271,  0.5445, -0.7583,  ..., -0.1749,  0.0312,  0.9173])\n",
      "objective\n",
      "Saved the embedding for objective.\n",
      "['obliged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3097, -0.2491, -0.2923,  ..., -0.7688,  0.2701,  0.4287])\n",
      "obliged\n",
      "Saved the embedding for obliged.\n",
      "['ob', '##li', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0683,  0.0359, -0.8510,  ..., -0.5009,  0.3027, -0.0049])\n",
      "obliging\n",
      "Saved the embedding for obliging.\n",
      "['oblivious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4301,  0.4232, -0.0294,  ..., -0.4258, -0.4328,  0.2659])\n",
      "oblivious\n",
      "Saved the embedding for oblivious.\n",
      "['ob', '##ser', '##vant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 4.8976e-04,  1.1067e-01, -5.4313e-01,  ..., -2.3360e-01,\n",
      "         3.2435e-01,  1.6133e-01])\n",
      "observant\n",
      "Saved the embedding for observant.\n",
      "['observing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0658,  1.1678, -0.3498,  ...,  0.5681,  0.7201,  0.3639])\n",
      "observing\n",
      "Saved the embedding for observing.\n",
      "['obsessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5490, -0.1833, -0.5513,  ..., -0.5360, -0.1934,  0.2839])\n",
      "obsessed\n",
      "Saved the embedding for obsessed.\n",
      "['ob', '##sti', '##nate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0234, -0.0088, -0.8034,  ..., -0.3631,  0.4514,  0.1498])\n",
      "obstinate\n",
      "Saved the embedding for obstinate.\n",
      "['occupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9003,  0.4231, -0.0669,  ..., -0.0417, -0.6922,  0.5365])\n",
      "occupied\n",
      "Saved the embedding for occupied.\n",
      "['odd'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1883, -0.1999, -0.2326,  ...,  0.3134,  0.0716,  0.7218])\n",
      "odd\n",
      "Saved the embedding for odd.\n",
      "['odi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7142, -0.4777, -0.3506,  ...,  0.0098,  0.0593, -0.3055])\n",
      "odious\n",
      "Saved the embedding for odious.\n",
      "['off'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1801, -0.7669,  0.1558,  ...,  0.1176,  0.1020, -0.1887])\n",
      "off\n",
      "Saved the embedding for off.\n",
      "['offended'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0969,  0.6642,  0.1171,  ...,  0.1377, -0.0389,  0.6258])\n",
      "offended\n",
      "Saved the embedding for offended.\n",
      "['offensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3752,  1.0277, -0.2748,  ...,  0.2046,  0.0480, -0.1527])\n",
      "offensive\n",
      "Saved the embedding for offensive.\n",
      "['og', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7505,  0.7113, -0.0087,  ..., -0.1313, -0.2191,  0.8907])\n",
      "ogling\n",
      "Saved the embedding for ogling.\n",
      "['okay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2494,  0.1198, -0.3700,  ..., -0.0513, -0.4687,  0.3414])\n",
      "okay\n",
      "Saved the embedding for okay.\n",
      "['on'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0538,  0.2371, -0.3895,  ..., -0.0641, -0.1174,  0.1514])\n",
      "on\n",
      "Saved the embedding for on.\n",
      "['open'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0045,  0.1596,  0.2159,  ...,  1.1481,  0.3327,  0.4576])\n",
      "open\n",
      "Saved the embedding for open.\n",
      "['open', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1082,  0.1211,  0.1756,  ...,  1.1884,  0.3579,  0.5272])\n",
      "openness\n",
      "Saved the embedding for openness.\n",
      "['opposed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3608,  0.1416, -0.4212,  ...,  0.1192, -0.2179,  0.9410])\n",
      "opposed\n",
      "Saved the embedding for opposed.\n",
      "['opposition', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4759,  0.4569, -0.0431,  ...,  0.1376,  0.1823,  0.3256])\n",
      "oppositional\n",
      "Saved the embedding for oppositional.\n",
      "['op', '##pressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3148,  0.6562, -0.2006,  ...,  1.1643,  0.3129,  0.2328])\n",
      "oppressed\n",
      "Saved the embedding for oppressed.\n",
      "['optimism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3191,  0.9052,  0.0142,  ...,  0.2080, -0.2229,  0.3905])\n",
      "optimism\n",
      "Saved the embedding for optimism.\n",
      "['optimistic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2219,  0.3404, -0.3961,  ...,  0.0910, -0.0910, -0.0039])\n",
      "optimistic\n",
      "Saved the embedding for optimistic.\n",
      "['ordering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5150, -0.0777, -0.3454,  ...,  0.1255,  0.0904,  0.2863])\n",
      "ordering\n",
      "Saved the embedding for ordering.\n",
      "['orgasm', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2798,  0.7906, -0.0737,  ..., -0.6806,  0.0683,  0.0844])\n",
      "orgasmic\n",
      "Saved the embedding for orgasmic.\n",
      "['or', '##nery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2658,  0.4287, -0.2299,  ..., -0.6399, -0.3807, -0.0426])\n",
      "ornery\n",
      "Saved the embedding for ornery.\n",
      "['ou', '##ch'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0307,  0.0872, -0.1688,  ...,  0.5925, -0.1543,  0.2943])\n",
      "ouch\n",
      "Saved the embedding for ouch.\n",
      "['out'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2075, -0.1315,  0.0361,  ...,  0.6839, -0.1174,  0.1198])\n",
      "out\n",
      "Saved the embedding for out.\n",
      "['outburst'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2065,  0.7274,  0.1215,  ..., -0.0610,  0.3066, -0.1163])\n",
      "outburst\n",
      "Saved the embedding for outburst.\n",
      "['out', '##cr', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0816, -0.1361, -0.2537,  ...,  0.3897,  0.0020,  0.3879])\n",
      "outcry\n",
      "Saved the embedding for outcry.\n",
      "['out', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1031, -0.2548, -0.0779,  ...,  0.7008, -0.0755,  0.0294])\n",
      "outed\n",
      "Saved the embedding for outed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['out', '##land', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2334, -0.2680, -0.0446,  ...,  0.3290, -0.0056,  0.5121])\n",
      "outlandish\n",
      "Saved the embedding for outlandish.\n",
      "['outrage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2590,  0.7965, -0.5729,  ...,  0.3096,  0.1675,  0.1394])\n",
      "outrage\n",
      "Saved the embedding for outrage.\n",
      "['outraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4489,  0.6013, -0.6594,  ...,  0.0011, -0.0030, -0.1122])\n",
      "outraged\n",
      "Saved the embedding for outraged.\n",
      "['outspoken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1734,  0.3273,  0.3024,  ..., -0.3535, -0.1921, -0.0766])\n",
      "outspoken\n",
      "Saved the embedding for outspoken.\n",
      "['over', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4418, -0.1120, -0.0943,  ..., -0.1714, -0.2104,  0.5628])\n",
      "overbearing\n",
      "Saved the embedding for overbearing.\n",
      "['over', '##ex', '##cite', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3554, -0.1836, -0.0233,  ..., -0.2578, -0.1617,  0.6490])\n",
      "overexcited\n",
      "Saved the embedding for overexcited.\n",
      "['over', '##joy', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4441, -0.2455, -0.0750,  ..., -0.1693, -0.1159,  0.6275])\n",
      "overjoyed\n",
      "Saved the embedding for overjoyed.\n",
      "['overshadowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2030,  0.1421,  0.1082,  ..., -0.4048,  0.2492,  0.2188])\n",
      "overshadowed\n",
      "Saved the embedding for overshadowed.\n",
      "['overs', '##tr', '##ung'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1837, -0.8764, -0.2432,  ...,  0.3336,  0.1151,  0.4806])\n",
      "overstrung\n",
      "Saved the embedding for overstrung.\n",
      "['overwhelmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0468,  0.1241, -0.2273,  ..., -0.2828,  0.1574,  0.5067])\n",
      "overwhelmed\n",
      "Saved the embedding for overwhelmed.\n",
      "['over', '##work', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4700, -0.1326, -0.0557,  ..., -0.0255, -0.3654,  0.4446])\n",
      "overworked\n",
      "Saved the embedding for overworked.\n",
      "['over', '##wr', '##ough', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4780, -0.3422, -0.0067,  ...,  0.0634, -0.2716,  0.5518])\n",
      "overwrought\n",
      "Saved the embedding for overwrought.\n",
      "['pain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2188,  0.8144,  0.0335,  ...,  0.1221, -0.0815,  0.4458])\n",
      "pain\n",
      "Saved the embedding for pain.\n",
      "['pained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6743,  0.0553, -0.5677,  ..., -0.1661,  0.3894,  0.4777])\n",
      "pained\n",
      "Saved the embedding for pained.\n",
      "['painful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2161,  0.1228, -0.7238,  ...,  0.1261,  0.0894,  0.1724])\n",
      "painful\n",
      "Saved the embedding for painful.\n",
      "['painfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1837,  0.0284, -0.4641,  ..., -0.5520,  0.1419,  0.5227])\n",
      "painfully\n",
      "Saved the embedding for painfully.\n",
      "['panic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0279,  0.2350, -0.2224,  ..., -0.1646,  0.0348,  0.2564])\n",
      "panic\n",
      "Saved the embedding for panic.\n",
      "['panicked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0956,  0.2201, -0.1622,  ..., -0.4086, -0.1919,  0.2787])\n",
      "panicked\n",
      "Saved the embedding for panicked.\n",
      "['panic', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0412,  0.2718, -0.0897,  ..., -0.0775,  0.0901,  0.2001])\n",
      "panicky\n",
      "Saved the embedding for panicky.\n",
      "['paralyzed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4176,  0.6005, -0.6512,  ..., -0.4358, -0.1847,  0.2673])\n",
      "paralyzed\n",
      "Saved the embedding for paralyzed.\n",
      "['paranoid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3417,  0.1873, -0.4881,  ..., -0.0732, -0.3714,  0.5115])\n",
      "paranoid\n",
      "Saved the embedding for paranoid.\n",
      "['passionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4385,  0.0336,  0.3843,  ..., -0.0924,  0.2862,  0.3127])\n",
      "passionate\n",
      "Saved the embedding for passionate.\n",
      "['passive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7117,  0.6878, -0.6100,  ...,  0.4536, -0.5091,  0.3124])\n",
      "passive\n",
      "Saved the embedding for passive.\n",
      "['patience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1074,  0.5145,  0.3381,  ...,  0.1193,  0.2095,  1.0932])\n",
      "patience\n",
      "Saved the embedding for patience.\n",
      "['patient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2802, -0.0486,  0.3616,  ..., -0.1722,  0.0437,  0.4289])\n",
      "patient\n",
      "Saved the embedding for patient.\n",
      "['patron', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2144,  0.5183,  1.1206,  ..., -0.1777, -0.0844,  0.7812])\n",
      "patronizing\n",
      "Saved the embedding for patronizing.\n",
      "['pause'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3938,  0.6173,  0.4031,  ..., -0.2602, -0.2693,  0.0543])\n",
      "pause\n",
      "Saved the embedding for pause.\n",
      "['pausing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0898, 0.1724, 0.1015,  ..., 0.2362, 0.1036, 0.5219])\n",
      "pausing\n",
      "Saved the embedding for pausing.\n",
      "['peaceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1170,  0.6998,  0.3780,  ..., -0.4631, -0.1206, -0.0166])\n",
      "peaceful\n",
      "Saved the embedding for peaceful.\n",
      "['peculiar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0626,  0.0539, -0.2595,  ..., -0.7201,  0.1512,  0.4811])\n",
      "peculiar\n",
      "Saved the embedding for peculiar.\n",
      "['peering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1516,  0.3481, -0.3065,  ..., -0.5319,  0.2956,  0.5167])\n",
      "peering\n",
      "Saved the embedding for peering.\n",
      "['pee', '##ved'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9948,  0.0488, -0.2597,  ...,  0.2907, -0.2680, -0.2692])\n",
      "peeved\n",
      "Saved the embedding for peeved.\n",
      "['pee', '##vish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9048, -0.1169, -0.3401,  ...,  0.2348, -0.3844, -0.4427])\n",
      "peevish\n",
      "Saved the embedding for peevish.\n",
      "['pens', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0777,  0.4973,  0.0701,  ..., -0.1220,  0.4515,  0.8329])\n",
      "pensive\n",
      "Saved the embedding for pensive.\n",
      "['pep', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6498, -0.0486,  0.2913,  ..., -0.4501, -0.3968,  0.1203])\n",
      "peppy\n",
      "Saved the embedding for peppy.\n",
      "['per', '##ceptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3958,  0.1898, -0.4301,  ..., -0.2571,  0.3993,  0.1729])\n",
      "perceptive\n",
      "Saved the embedding for perceptive.\n",
      "['per', '##fi', '##dio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3625,  0.1308, -0.3712,  ..., -0.1182,  1.0518,  0.3343])\n",
      "perfidious\n",
      "Saved the embedding for perfidious.\n",
      "['per', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5140,  0.3303, -0.3966,  ..., -0.1399,  0.4579, -0.1022])\n",
      "perky\n",
      "Saved the embedding for perky.\n",
      "['per', '##plex', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4758,  0.0801, -0.4773,  ..., -0.1502,  0.5066,  0.3551])\n",
      "perplexed\n",
      "Saved the embedding for perplexed.\n",
      "['per', '##plex', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4705,  0.0888, -0.5633,  ..., -0.0794,  0.4237,  0.3202])\n",
      "perplexing\n",
      "Saved the embedding for perplexing.\n",
      "['persistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4532,  0.2624,  0.0880,  ..., -0.9505, -0.0405,  0.8132])\n",
      "persistent\n",
      "Saved the embedding for persistent.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['persona', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2759,  0.1128, -0.1462,  ..., -0.2898,  0.5211,  0.1132])\n",
      "personable\n",
      "Saved the embedding for personable.\n",
      "['per', '##tur', '##bed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3997,  0.1081, -0.3668,  ..., -0.3496,  0.4613,  0.3961])\n",
      "perturbed\n",
      "Saved the embedding for perturbed.\n",
      "['per', '##verse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4128,  0.0224, -0.3874,  ..., -0.1934,  0.5164,  0.1428])\n",
      "perverse\n",
      "Saved the embedding for perverse.\n",
      "['pe', '##sky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2723,  0.1761, -0.7887,  ...,  0.3089, -0.3488, -0.0271])\n",
      "pesky\n",
      "Saved the embedding for pesky.\n",
      "['pe', '##ssi', '##mism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2421, -0.0604, -0.5625,  ...,  0.0710,  0.3449, -0.1649])\n",
      "pessimism\n",
      "Saved the embedding for pessimism.\n",
      "['pe', '##ssi', '##mist', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2474, -0.0722, -0.6220,  ...,  0.1767,  0.0210,  0.0118])\n",
      "pessimistic\n",
      "Saved the embedding for pessimistic.\n",
      "['pest', '##ered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5918,  0.3914,  0.4585,  ..., -0.6230,  0.0495, -0.1463])\n",
      "pestered\n",
      "Saved the embedding for pestered.\n",
      "['petition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4493, -0.3451,  0.3390,  ..., -0.5954,  0.6040,  0.8375])\n",
      "petitioning\n",
      "Saved the embedding for petitioning.\n",
      "['pet', '##rified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8410, -0.0067,  0.5410,  ...,  0.3304,  0.4156,  0.7307])\n",
      "petrified\n",
      "Saved the embedding for petrified.\n",
      "['petty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6658,  0.1319, -0.1396,  ..., -0.3580, -0.5999,  0.1596])\n",
      "petty\n",
      "Saved the embedding for petty.\n",
      "['pet', '##ula', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.6803, 0.0983, 0.5859,  ..., 0.1699, 0.6336, 0.5735])\n",
      "petulant\n",
      "Saved the embedding for petulant.\n",
      "['picked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0496, -0.5882,  0.1842,  ..., -0.0660,  0.0683, -0.3815])\n",
      "picked\n",
      "Saved the embedding for picked.\n",
      "['piercing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1680,  0.1580, -0.4175,  ...,  0.0064, -0.1212, -0.0263])\n",
      "piercing\n",
      "Saved the embedding for piercing.\n",
      "['pinched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1330, -0.1490, -0.1037,  ..., -0.1871,  0.1961,  0.2864])\n",
      "pinched\n",
      "Saved the embedding for pinched.\n",
      "['pious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3686, -0.0903,  0.2036,  ..., -0.0460,  0.4940,  0.8815])\n",
      "pious\n",
      "Saved the embedding for pious.\n",
      "['pi', '##que', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4878,  0.1254, -0.2379,  ...,  0.2776, -0.5220,  0.4603])\n",
      "piqued\n",
      "Saved the embedding for piqued.\n",
      "['pissed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9128,  0.3747,  0.2889,  ..., -0.0927, -0.1703, -0.0368])\n",
      "pissed\n",
      "Saved the embedding for pissed.\n",
      "['pit', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4491, -0.0586, -0.4758,  ...,  0.5971, -0.4329, -0.2010])\n",
      "pitiable\n",
      "Saved the embedding for pitiable.\n",
      "['pit', '##iful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5528, -0.1673, -0.5342,  ...,  0.2853, -0.3784, -0.0917])\n",
      "pitiful\n",
      "Saved the embedding for pitiful.\n",
      "['pity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9366,  0.7436,  0.8048,  ..., -0.6050,  0.4844,  0.6294])\n",
      "pity\n",
      "Saved the embedding for pity.\n",
      "['pity', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8022,  0.6062,  0.6277,  ..., -0.4342,  0.4546,  0.6397])\n",
      "pitying\n",
      "Saved the embedding for pitying.\n",
      "['pl', '##aca', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3383, -0.4752,  0.3102,  ...,  0.2154,  0.7436,  0.5090])\n",
      "placated\n",
      "Saved the embedding for placated.\n",
      "['pl', '##aca', '##tion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3060, -0.4679,  0.3907,  ...,  0.1370,  0.6810,  0.5502])\n",
      "placation\n",
      "Saved the embedding for placation.\n",
      "['pl', '##ac', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2744, -0.5821,  0.5262,  ..., -0.0749,  0.7377,  0.7208])\n",
      "placid\n",
      "Saved the embedding for placid.\n",
      "['plain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5337,  0.0458, -0.4401,  ...,  0.3730,  0.1592,  0.0293])\n",
      "plain\n",
      "Saved the embedding for plain.\n",
      "['plain', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5986,  0.0691, -0.0867,  ...,  0.2038,  0.1501, -0.1552])\n",
      "plaintive\n",
      "Saved the embedding for plaintive.\n",
      "['planning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4578,  0.3600, -0.0361,  ..., -0.1627, -0.6631,  0.0804])\n",
      "planning\n",
      "Saved the embedding for planning.\n",
      "['playful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2481,  0.5766,  0.2194,  ..., -0.2443, -0.1072,  0.7394])\n",
      "playful\n",
      "Saved the embedding for playful.\n",
      "['playfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2910,  0.2352,  0.0589,  ..., -0.4157, -0.1981,  0.4662])\n",
      "playfully\n",
      "Saved the embedding for playfully.\n",
      "['pleading'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1323, -0.2069, -0.2512,  ...,  0.3595,  0.9360,  0.2713])\n",
      "pleading\n",
      "Saved the embedding for pleading.\n",
      "['pleasant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3533,  0.6608,  0.2229,  ..., -0.3696,  0.1092,  0.2741])\n",
      "pleasant\n",
      "Saved the embedding for pleasant.\n",
      "['pleased'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0089,  0.1889,  0.0495,  ..., -0.0483, -0.0835,  0.5721])\n",
      "pleased\n",
      "Saved the embedding for pleased.\n",
      "['pleasing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2650,  0.6364, -0.0663,  ..., -0.6763, -0.2985, -0.0739])\n",
      "pleasing\n",
      "Saved the embedding for pleasing.\n",
      "['pleas', '##urable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5050, -0.0945,  0.5475,  ..., -0.5143,  0.3111,  0.5122])\n",
      "pleasurable\n",
      "Saved the embedding for pleasurable.\n",
      "['pleasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2199,  0.5453,  0.3508,  ..., -1.1199, -0.3431,  0.3749])\n",
      "pleasure\n",
      "Saved the embedding for pleasure.\n",
      "['pleasure', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1587,  0.4725,  0.3832,  ..., -1.0991, -0.2200,  0.3337])\n",
      "pleasured\n",
      "Saved the embedding for pleasured.\n",
      "['pl', '##ian', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1991, -0.2473,  0.5294,  ...,  0.2760,  0.6691,  0.5233])\n",
      "pliant\n",
      "Saved the embedding for pliant.\n",
      "['plotting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4091,  0.8651,  0.0806,  ...,  0.6389, -0.0605,  0.2717])\n",
      "plotting\n",
      "Saved the embedding for plotting.\n",
      "['po', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1981,  0.2114, -0.4980,  ..., -0.1171,  0.0927,  0.9986])\n",
      "poignant\n",
      "Saved the embedding for poignant.\n",
      "['pointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1808, 0.0301, 0.0250,  ..., 0.2121, 0.0890, 0.3989])\n",
      "pointed\n",
      "Saved the embedding for pointed.\n",
      "['poised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4797,  0.7763, -0.0110,  ..., -0.0041,  0.2103,  0.3733])\n",
      "poised\n",
      "Saved the embedding for poised.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polite'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1785,  0.4174, -0.3249,  ..., -0.4270, -0.0143,  0.8588])\n",
      "polite\n",
      "Saved the embedding for polite.\n",
      "['po', '##mp', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2711,  0.3297, -0.6411,  ..., -0.1427,  0.1291,  0.7437])\n",
      "pompous\n",
      "Saved the embedding for pompous.\n",
      "['ponder'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5642,  0.5386,  0.4570,  ..., -0.2422,  0.3581,  0.4724])\n",
      "ponder\n",
      "Saved the embedding for ponder.\n",
      "['ponder', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3983,  0.4869,  0.3603,  ..., -0.4694,  0.6233,  0.3477])\n",
      "pondering\n",
      "Saved the embedding for pondering.\n",
      "['po', '##oping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2244,  0.4079, -0.6606,  ..., -0.2461, -0.5050,  0.8045])\n",
      "pooping\n",
      "Saved the embedding for pooping.\n",
      "['pop'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0623, -0.0658,  0.0443,  ..., -0.3599,  0.1927,  0.3080])\n",
      "pop\n",
      "Saved the embedding for pop.\n",
      "['posing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5727, -0.1260,  0.1137,  ...,  0.0774,  0.3978, -0.2016])\n",
      "posing\n",
      "Saved the embedding for posing.\n",
      "['positive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2732,  0.3786, -0.4528,  ...,  0.2538, -0.3193, -0.0075])\n",
      "positive\n",
      "Saved the embedding for positive.\n",
      "['po', '##sit', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2989,  0.3173, -0.4785,  ..., -0.2504,  0.0797,  0.7116])\n",
      "positivity\n",
      "Saved the embedding for positivity.\n",
      "['possibly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4105,  0.5393, -0.2719,  ..., -0.2601,  0.1603, -0.4377])\n",
      "possibly\n",
      "Saved the embedding for possibly.\n",
      "['po', '##ut'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3870,  0.3837, -0.5990,  ...,  0.1414, -0.1982,  0.8364])\n",
      "pout\n",
      "Saved the embedding for pout.\n",
      "['po', '##uting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2276,  0.3509, -0.5254,  ..., -0.1127, -0.2528,  0.7629])\n",
      "pouting\n",
      "Saved the embedding for pouting.\n",
      "['po', '##ut', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4274,  0.4059, -0.6050,  ...,  0.2047, -0.1241,  0.7938])\n",
      "pouty\n",
      "Saved the embedding for pouty.\n",
      "['powerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3587,  0.3336, -0.1758,  ..., -0.4228, -0.1642,  0.0376])\n",
      "powerful\n",
      "Saved the embedding for powerful.\n",
      "['powerless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0670,  0.8999, -0.5412,  ...,  0.1518,  0.2594,  0.0917])\n",
      "powerless\n",
      "Saved the embedding for powerless.\n",
      "['prank', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5356, -0.2318, -0.0789,  ..., -0.3529, -0.1079,  0.1824])\n",
      "pranking\n",
      "Saved the embedding for pranking.\n",
      "['pre', '##car', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4245, -0.1000, -0.2341,  ..., -1.0380, -0.1338,  0.3705])\n",
      "precarious\n",
      "Saved the embedding for precarious.\n",
      "['predatory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2876, -0.2689, -0.0536,  ..., -0.3134,  0.2305,  0.2167])\n",
      "predatory\n",
      "Saved the embedding for predatory.\n",
      "['prejudice', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1192,  0.9156, -0.2419,  ..., -0.9834,  0.0237,  0.8002])\n",
      "prejudiced\n",
      "Saved the embedding for prejudiced.\n",
      "['preoccupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3524,  1.0476,  0.0622,  ..., -0.0248,  0.2033,  0.3207])\n",
      "preoccupied\n",
      "Saved the embedding for preoccupied.\n",
      "['prepared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4177,  0.3896, -0.7738,  ..., -0.1061,  0.1582, -0.2296])\n",
      "prepared\n",
      "Saved the embedding for prepared.\n",
      "['preparing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4371,  0.3611, -0.3145,  ..., -0.3197,  0.1444,  0.1274])\n",
      "preparing\n",
      "Saved the embedding for preparing.\n",
      "['pretending'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2203,  0.1988, -0.2061,  ..., -0.6719, -0.1670,  0.5470])\n",
      "pretending\n",
      "Saved the embedding for pretending.\n",
      "['pre', '##ten', '##tious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4809, -0.1123, -0.0898,  ..., -0.9392,  0.1306,  0.2574])\n",
      "pretentious\n",
      "Saved the embedding for pretentious.\n",
      "['pride', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0743,  0.3088, -0.0424,  ...,  0.2724, -0.1989,  0.0739])\n",
      "prideful\n",
      "Saved the embedding for prideful.\n",
      "['pri', '##gg', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1656, -0.1169, -0.3490,  ...,  0.1922,  0.1258,  0.4400])\n",
      "priggish\n",
      "Saved the embedding for priggish.\n",
      "['prime', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1451,  0.3576, -0.5149,  ...,  0.8428,  0.7151,  0.4922])\n",
      "primed\n",
      "Saved the embedding for primed.\n",
      "['private'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2861, -0.2592,  0.1875,  ...,  0.0876,  0.3581, -0.4170])\n",
      "private\n",
      "Saved the embedding for private.\n",
      "['processing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3056,  0.5585,  0.1748,  ..., -0.2495, -0.6315,  0.2700])\n",
      "processing\n",
      "Saved the embedding for processing.\n",
      "['proposition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.2018, 0.8026, 0.1695,  ..., 0.4605, 0.2972, 0.5524])\n",
      "propositioning\n",
      "Saved the embedding for propositioning.\n",
      "['proud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3447,  0.3454,  0.0945,  ...,  0.5524, -0.0492, -0.0858])\n",
      "proud\n",
      "Saved the embedding for proud.\n",
      "['provocative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1925,  0.4906,  0.2510,  ...,  0.4072,  0.0307,  0.3081])\n",
      "provocative\n",
      "Saved the embedding for provocative.\n",
      "['provoke'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0888,  0.4062, -0.1264,  ...,  0.4642,  0.1284,  0.6284])\n",
      "provoke\n",
      "Saved the embedding for provoke.\n",
      "['provoked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2865, -0.0247, -0.0024,  ...,  0.1708,  0.3064,  0.5551])\n",
      "provoked\n",
      "Saved the embedding for provoked.\n",
      "['pro', '##voking'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1150, -0.1937, -0.4025,  ...,  0.4539,  0.0090,  0.2629])\n",
      "provoking\n",
      "Saved the embedding for provoking.\n",
      "['pry', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1742,  0.1645, -0.2240,  ...,  0.3365, -0.2001,  0.2977])\n",
      "prying\n",
      "Saved the embedding for prying.\n",
      "['psycho'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1209,  0.9483, -0.3341,  ..., -0.4436, -0.3496,  0.2651])\n",
      "psycho\n",
      "Saved the embedding for psycho.\n",
      "['psychotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0529,  0.5761, -0.1089,  ..., -0.1939, -0.3324,  0.3524])\n",
      "psychotic\n",
      "Saved the embedding for psychotic.\n",
      "['puck', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0948, -0.2514, -0.0957,  ...,  0.0376,  0.1744, -0.3383])\n",
      "puckish\n",
      "Saved the embedding for puckish.\n",
      "['pu', '##eri', '##le'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0806,  0.0832, -0.1987,  ..., -0.3949,  0.2497,  0.2947])\n",
      "puerile\n",
      "Saved the embedding for puerile.\n",
      "['pu', '##gna', '##cious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1184,  0.2134, -0.2534,  ..., -0.2685,  0.1924,  0.3236])\n",
      "pugnacious\n",
      "Saved the embedding for pugnacious.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['punished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2467,  0.2137, -0.4076,  ...,  0.0979,  0.4396,  0.0455])\n",
      "punished\n",
      "Saved the embedding for punished.\n",
      "['punish', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1025, -0.0499, -0.3159,  ...,  0.3229,  0.3798,  0.4320])\n",
      "punishing\n",
      "Saved the embedding for punishing.\n",
      "['pun', '##itive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1760, -0.0548, -0.3208,  ..., -0.2206, -0.3533, -0.0361])\n",
      "punitive\n",
      "Saved the embedding for punitive.\n",
      "['punk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3872,  0.6341, -0.6864,  ...,  0.1003, -0.5454,  0.0649])\n",
      "punk\n",
      "Saved the embedding for punk.\n",
      "['puppy', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2406, -0.2310,  0.3293,  ...,  0.2664,  0.3756,  0.9249])\n",
      "puppyish\n",
      "Saved the embedding for puppyish.\n",
      "['purpose', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9265, -0.1977,  0.0204,  ..., -0.3104,  0.2437,  0.3034])\n",
      "purposeful\n",
      "Saved the embedding for purposeful.\n",
      "['pursed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1792,  0.0964,  0.1591,  ..., -0.6637,  0.0810,  0.4050])\n",
      "pursed\n",
      "Saved the embedding for pursed.\n",
      "['put'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2856, -0.1264, -0.3124,  ...,  0.5410,  0.4328, -0.0464])\n",
      "put\n",
      "Saved the embedding for put.\n",
      "['putting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1498, -0.0745, -0.3485,  ...,  0.3483,  0.0860, -0.0678])\n",
      "putting\n",
      "Saved the embedding for putting.\n",
      "['puzzled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1398,  0.4188, -0.0891,  ..., -0.3874,  0.3953,  1.3391])\n",
      "puzzled\n",
      "Saved the embedding for puzzled.\n",
      "['puzzle', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2731,  0.0454, -0.3143,  ...,  0.1977,  0.3459,  0.5012])\n",
      "puzzlement\n",
      "Saved the embedding for puzzlement.\n",
      "['qu', '##al', '##ms'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2862, -0.5369,  0.2971,  ...,  0.3829,  0.6267,  0.6122])\n",
      "qualms\n",
      "Saved the embedding for qualms.\n",
      "['quarrel', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3434,  0.2401,  0.0030,  ..., -0.8594,  0.4644,  0.2991])\n",
      "quarrelsome\n",
      "Saved the embedding for quarrelsome.\n",
      "['que', '##as', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3146, -0.1973, -0.1517,  ...,  0.1035,  0.1091,  0.3718])\n",
      "queasy\n",
      "Saved the embedding for queasy.\n",
      "['que', '##nched'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4038, -0.3050, -0.4110,  ..., -0.0057,  0.2436,  0.3853])\n",
      "quenched\n",
      "Saved the embedding for quenched.\n",
      "['questionable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4014, -0.2470, -0.3394,  ..., -0.1970, -0.0993,  0.0755])\n",
      "questionable\n",
      "Saved the embedding for questionable.\n",
      "['questioning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1179,  0.3540, -0.0728,  ..., -0.1266, -0.2796,  0.3729])\n",
      "questioning\n",
      "Saved the embedding for questioning.\n",
      "['questioning', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1602,  0.5391,  0.1258,  ...,  0.0067,  0.0355,  0.7439])\n",
      "questioningly\n",
      "Saved the embedding for questioningly.\n",
      "['quiet'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1113,  0.7020,  0.2008,  ..., -0.2861, -0.1064,  0.3754])\n",
      "quiet\n",
      "Saved the embedding for quiet.\n",
      "['quiet', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2484,  0.7249,  0.2572,  ..., -0.4249, -0.0473,  0.3345])\n",
      "quietness\n",
      "Saved the embedding for quietness.\n",
      "['quilt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6744,  0.2242, -0.4159,  ...,  0.6895, -0.1808,  0.2350])\n",
      "quilt\n",
      "Saved the embedding for quilt.\n",
      "['qui', '##rky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1910, -0.9014, -0.0658,  ...,  0.3884,  0.3452,  0.0033])\n",
      "quirky\n",
      "Saved the embedding for quirky.\n",
      "['quiz', '##zic', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4270, -0.1297,  0.6049,  ..., -0.3693,  0.2491,  0.3320])\n",
      "quizzical\n",
      "Saved the embedding for quizzical.\n",
      "['ra', '##bid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6683, -0.0983, -0.0533,  ..., -0.0435, -0.0092,  0.1874])\n",
      "rabid\n",
      "Saved the embedding for rabid.\n",
      "['rack', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6703,  0.2761,  0.0623,  ...,  0.0634, -0.2251, -0.1626])\n",
      "racked\n",
      "Saved the embedding for racked.\n",
      "['radiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3521,  0.6829,  0.0875,  ..., -0.6189,  0.5980,  0.5806])\n",
      "radiant\n",
      "Saved the embedding for radiant.\n",
      "['rage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.9553, 0.7274, 0.2771,  ..., 0.1039, 0.1928, 0.6517])\n",
      "rage\n",
      "Saved the embedding for rage.\n",
      "['raged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8764,  0.1056, -0.6591,  ..., -0.1332, -0.3484,  0.4436])\n",
      "raged\n",
      "Saved the embedding for raged.\n",
      "['ragged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 7.9177e-01, -7.9791e-02, -8.7314e-01,  ..., -2.9405e-02,\n",
      "        -2.8297e-04,  1.2606e-01])\n",
      "ragged\n",
      "Saved the embedding for ragged.\n",
      "['raging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5897,  0.9265, -0.3087,  ..., -0.2427, -0.3916,  0.4673])\n",
      "raging\n",
      "Saved the embedding for raging.\n",
      "['ran', '##cor', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5158, -1.1178, -0.3953,  ...,  0.2108, -0.1370,  0.4053])\n",
      "rancorous\n",
      "Saved the embedding for rancorous.\n",
      "['randy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6759, -0.3925, -0.2456,  ..., -0.0510,  0.0029,  0.0939])\n",
      "randy\n",
      "Saved the embedding for randy.\n",
      "['rap', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7073, -0.0109, -0.6010,  ...,  0.9696,  0.3446, -0.3259])\n",
      "rapt\n",
      "Saved the embedding for rapt.\n",
      "['rattled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4762,  0.1548, -0.1024,  ..., -0.8686, -0.2574, -0.0096])\n",
      "rattled\n",
      "Saved the embedding for rattled.\n",
      "['ravi', '##ng'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0362,  0.0226, -0.1620,  ...,  0.5574,  0.8169,  0.2732])\n",
      "raving\n",
      "Saved the embedding for raving.\n",
      "['reactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0424,  1.5757, -0.1483,  ..., -0.6359, -1.0983,  0.3552])\n",
      "reactive\n",
      "Saved the embedding for reactive.\n",
      "['ready'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6661,  0.2328, -0.2430,  ...,  0.2309,  0.4452, -0.2782])\n",
      "ready\n",
      "Saved the embedding for ready.\n",
      "['realization'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.9831,  0.9711,  0.2830,  ..., -0.4739,  0.1821,  0.4615])\n",
      "realization\n",
      "Saved the embedding for realization.\n",
      "['reassured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5417,  0.3447,  0.0741,  ..., -0.2206,  0.6141,  0.3422])\n",
      "reassured\n",
      "Saved the embedding for reassured.\n",
      "['rebellious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2980,  0.7168,  0.0034,  ..., -0.0031, -0.0823,  0.0102])\n",
      "rebellious\n",
      "Saved the embedding for rebellious.\n",
      "['re', '##bu', '##ke'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3771, -0.5029, -0.1517,  ...,  0.2377,  0.1217,  0.2755])\n",
      "rebuke\n",
      "Saved the embedding for rebuke.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recalling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1709, 0.8338, 0.0508,  ..., 0.0672, 0.2810, 0.2729])\n",
      "recalling\n",
      "Saved the embedding for recalling.\n",
      "['rec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0342, -0.0182,  0.1114,  ..., -0.3687,  0.0820,  0.3293])\n",
      "receptive\n",
      "Saved the embedding for receptive.\n",
      "['reckless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1823,  0.3304, -0.6604,  ..., -0.5077, -0.3635,  0.0955])\n",
      "reckless\n",
      "Saved the embedding for reckless.\n",
      "['recoil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5120,  1.0294,  0.0611,  ..., -0.0231, -0.3080, -0.0841])\n",
      "recoil\n",
      "Saved the embedding for recoil.\n",
      "['recoil', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3490,  1.1179,  0.0558,  ..., -0.0735, -0.1288, -0.0122])\n",
      "recoiling\n",
      "Saved the embedding for recoiling.\n",
      "['reflecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4301,  0.9080, -0.0270,  ..., -0.4767, -0.3097,  0.5166])\n",
      "reflecting\n",
      "Saved the embedding for reflecting.\n",
      "['reflection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8670,  0.6184,  0.2131,  ...,  0.0485, -0.0994,  0.5211])\n",
      "reflection\n",
      "Saved the embedding for reflection.\n",
      "['reflective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3815,  1.0177,  0.0231,  ..., -0.4307, -0.2727,  0.3819])\n",
      "reflective\n",
      "Saved the embedding for reflective.\n",
      "['ref', '##ul', '##gent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4559,  0.8034,  0.2174,  ..., -0.1219,  0.2903,  0.4510])\n",
      "refulgent\n",
      "Saved the embedding for refulgent.\n",
      "['refusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4409, -0.2228, -0.5404,  ..., -0.4443, -0.3967,  0.1629])\n",
      "refusing\n",
      "Saved the embedding for refusing.\n",
      "['regret'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3708,  0.1158,  0.6935,  ..., -0.0027,  0.3225,  0.5082])\n",
      "regret\n",
      "Saved the embedding for regret.\n",
      "['regret', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.2243, 0.1587, 0.6989,  ..., 0.1769, 0.4515, 0.4810])\n",
      "regretful\n",
      "Saved the embedding for regretful.\n",
      "['rejected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2834, -0.0146, -0.4819,  ..., -0.2001,  0.4037,  0.3365])\n",
      "rejected\n",
      "Saved the embedding for rejected.\n",
      "['rejecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1658,  0.0508, -0.6478,  ...,  0.1039,  0.1254,  0.2420])\n",
      "rejecting\n",
      "Saved the embedding for rejecting.\n",
      "['rejection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3564,  0.3204, -0.2374,  ..., -0.2373, -0.3159,  0.2223])\n",
      "rejection\n",
      "Saved the embedding for rejection.\n",
      "['re', '##jo', '##icing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3579, -0.4275, -0.0699,  ...,  0.2202,  0.1585,  0.3138])\n",
      "rejoicing\n",
      "Saved the embedding for rejoicing.\n",
      "['relaxation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0912,  0.4595,  0.5216,  ..., -0.1075, -0.5541,  0.7870])\n",
      "relaxation\n",
      "Saved the embedding for relaxation.\n",
      "['relaxed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4423,  0.8427,  0.0219,  ...,  0.1242,  0.1706,  0.7061])\n",
      "relaxed\n",
      "Saved the embedding for relaxed.\n",
      "['relentless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0826,  0.4094, -0.0104,  ..., -0.7138, -0.1749,  0.8330])\n",
      "relentless\n",
      "Saved the embedding for relentless.\n",
      "['relief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1945,  0.6236,  0.1792,  ...,  0.3266, -0.0984,  0.8506])\n",
      "relief\n",
      "Saved the embedding for relief.\n",
      "['relieved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0592,  0.4778,  0.1975,  ..., -0.0437, -0.1199,  0.5111])\n",
      "relieved\n",
      "Saved the embedding for relieved.\n",
      "['re', '##li', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2401, -0.4878,  0.0240,  ...,  0.2187,  0.0438,  0.2436])\n",
      "relived\n",
      "Saved the embedding for relived.\n",
      "['reluctant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3723,  0.0901, -0.6287,  ..., -0.3027,  0.1184,  0.6028])\n",
      "reluctant\n",
      "Saved the embedding for reluctant.\n",
      "['reluctantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3809, -0.3862, -0.2415,  ..., -0.4838,  0.7700,  0.7051])\n",
      "reluctantly\n",
      "Saved the embedding for reluctantly.\n",
      "['remorse'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.6098, 0.8678, 0.1902,  ..., 0.1399, 0.4625, 0.1346])\n",
      "remorse\n",
      "Saved the embedding for remorse.\n",
      "['remorse', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.4632, 0.8746, 0.2361,  ..., 0.1357, 0.6936, 0.2774])\n",
      "remorseful\n",
      "Saved the embedding for remorseful.\n",
      "['rep', '##elled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1611, -0.0384, -0.1162,  ..., -0.3807,  0.0631,  0.4603])\n",
      "repelled\n",
      "Saved the embedding for repelled.\n",
      "['rep', '##ressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0406,  0.0204, -0.1900,  ..., -0.2118,  0.1518,  0.6599])\n",
      "repressed\n",
      "Saved the embedding for repressed.\n",
      "['rep', '##ro', '##ach'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1226, -0.1519, -0.0129,  ..., -0.2928,  0.0149,  0.3426])\n",
      "reproach\n",
      "Saved the embedding for reproach.\n",
      "['rep', '##ro', '##ach', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0436, -0.1490, -0.0426,  ..., -0.1661,  0.2416,  0.3896])\n",
      "reproachful\n",
      "Saved the embedding for reproachful.\n",
      "['rep', '##ug', '##nan', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0479, -0.0863,  0.1543,  ..., -0.2321,  0.1520,  0.7316])\n",
      "repugnance\n",
      "Saved the embedding for repugnance.\n",
      "['rep', '##ug', '##nant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0531, -0.0586,  0.2013,  ..., -0.2176,  0.2277,  0.6268])\n",
      "repugnant\n",
      "Saved the embedding for repugnant.\n",
      "['repulsed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0662,  0.9870, -0.8955,  ..., -0.2129, -0.4484,  0.9746])\n",
      "repulsed\n",
      "Saved the embedding for repulsed.\n",
      "['rep', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1328, -0.0354,  0.1035,  ..., -0.3578,  0.0980,  0.7617])\n",
      "repulsion\n",
      "Saved the embedding for repulsion.\n",
      "['res', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5509, -0.1113,  0.2833,  ...,  0.0631,  0.4468,  1.1730])\n",
      "resent\n",
      "Saved the embedding for resent.\n",
      "['res', '##ent', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5472, -0.1868,  0.2167,  ...,  0.1003,  0.6041,  0.8275])\n",
      "resentful\n",
      "Saved the embedding for resentful.\n",
      "['res', '##enting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7634, -0.1955,  0.2125,  ...,  0.3708,  0.3354,  0.9382])\n",
      "resenting\n",
      "Saved the embedding for resenting.\n",
      "['resentment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2798,  0.5204, -0.3809,  ..., -0.5367, -0.3166,  0.8937])\n",
      "resentment\n",
      "Saved the embedding for resentment.\n",
      "['reserved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3112, -0.6122, -0.3223,  ..., -0.3669, -0.2883,  0.0318])\n",
      "reserved\n",
      "Saved the embedding for reserved.\n",
      "['resignation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0914, -0.0200,  0.5546,  ..., -0.3076,  0.3573,  0.4941])\n",
      "resignation\n",
      "Saved the embedding for resignation.\n",
      "['resigned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2730, -0.4893,  0.2343,  ..., -0.4023,  0.3405,  0.4506])\n",
      "resigned\n",
      "Saved the embedding for resigned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['res', '##ili', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5423, -0.1000,  0.3036,  ...,  0.0665,  0.4009,  0.9513])\n",
      "resilience\n",
      "Saved the embedding for resilience.\n",
      "['resistance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0683,  0.5221, -0.3828,  ...,  0.5187, -0.4422,  0.4062])\n",
      "resistance\n",
      "Saved the embedding for resistance.\n",
      "['resistant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2178,  0.1862, -0.6540,  ..., -0.8682, -0.2249,  0.0070])\n",
      "resistant\n",
      "Saved the embedding for resistant.\n",
      "['resist', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1988,  0.9181, -0.3333,  ..., -0.3997, -0.3588,  1.0457])\n",
      "resistent\n",
      "Saved the embedding for resistent.\n",
      "['resisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1237,  0.9236, -0.4994,  ..., -0.1897, -0.5881,  0.8405])\n",
      "resisting\n",
      "Saved the embedding for resisting.\n",
      "['res', '##ol', '##ute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4574,  0.1458,  0.1819,  ..., -0.5236, -0.0013,  1.2572])\n",
      "resolute\n",
      "Saved the embedding for resolute.\n",
      "['resolved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0457,  0.6682, -0.0675,  ...,  0.2008,  0.5874,  0.1046])\n",
      "resolved\n",
      "Saved the embedding for resolved.\n",
      "['responsive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1138,  0.5835, -0.0629,  ..., -0.5638, -0.2397,  0.3023])\n",
      "responsive\n",
      "Saved the embedding for responsive.\n",
      "['rest', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1141, -0.1756,  0.3894,  ...,  0.4032,  0.2120,  0.1522])\n",
      "restful\n",
      "Saved the embedding for restful.\n",
      "['resting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0571, -0.3077,  0.2405,  ...,  0.3345,  0.0914, -0.1516])\n",
      "resting\n",
      "Saved the embedding for resting.\n",
      "['restless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2781,  0.4193,  0.0572,  ..., -0.0063,  0.2350,  0.3116])\n",
      "restless\n",
      "Saved the embedding for restless.\n",
      "['restless', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1586,  0.4334,  0.1266,  ..., -0.0143,  0.3575,  0.2146])\n",
      "restlessness\n",
      "Saved the embedding for restlessness.\n",
      "['restrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0801,  0.3170, -0.2545,  ...,  0.8772, -0.2821,  0.2160])\n",
      "restrained\n",
      "Saved the embedding for restrained.\n",
      "['restraint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1032,  0.7894, -0.2661,  ...,  0.2974,  0.2421,  0.3759])\n",
      "restraint\n",
      "Saved the embedding for restraint.\n",
      "['re', '##tal', '##iating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3327, -0.2935,  0.0202,  ...,  0.0602,  0.0249,  0.5605])\n",
      "retaliating\n",
      "Saved the embedding for retaliating.\n",
      "['re', '##tal', '##ia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3119, -0.4215,  0.1623,  ...,  0.1322,  0.0437,  0.1011])\n",
      "retaliatory\n",
      "Saved the embedding for retaliatory.\n",
      "['re', '##thi', '##nk', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3662, -0.4179, -0.1168,  ...,  0.2119,  0.0300,  0.3959])\n",
      "rethinking\n",
      "Saved the embedding for rethinking.\n",
      "['re', '##tic', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3590, -0.3167,  0.0838,  ...,  0.1769,  0.0110,  0.4540])\n",
      "reticence\n",
      "Saved the embedding for reticence.\n",
      "['re', '##tic', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4342, -0.3614,  0.1138,  ...,  0.0922, -0.0018,  0.6801])\n",
      "reticent\n",
      "Saved the embedding for reticent.\n",
      "['revenge', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0980,  0.3569,  0.0415,  ...,  0.1232, -0.0399, -0.3758])\n",
      "revengeful\n",
      "Saved the embedding for revengeful.\n",
      "['rev', '##ere', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2166, -0.0521,  0.1273,  ...,  0.2026,  0.6473,  0.1277])\n",
      "reverent\n",
      "Saved the embedding for reverent.\n",
      "['revolt', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3376,  0.8271,  0.0424,  ...,  0.0203, -0.1597,  0.4403])\n",
      "revolted\n",
      "Saved the embedding for revolted.\n",
      "['rev', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2372, -0.1445,  0.0323,  ..., -0.8141,  0.1551,  0.2369])\n",
      "revulsion\n",
      "Saved the embedding for revulsion.\n",
      "['righteous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8022,  0.8027,  0.4337,  ..., -0.3331,  0.6200,  0.6638])\n",
      "righteous\n",
      "Saved the embedding for righteous.\n",
      "['rigid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3574,  0.5329, -0.2468,  ...,  0.1582,  0.2722,  0.2312])\n",
      "rigid\n",
      "Saved the embedding for rigid.\n",
      "['ri', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2929, -0.0802, -0.1346,  ...,  0.0267,  0.2203,  0.3676])\n",
      "riled\n",
      "Saved the embedding for riled.\n",
      "['riot', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7690,  0.4557, -0.1763,  ...,  0.4582, -0.1456, -0.7597])\n",
      "riotous\n",
      "Saved the embedding for riotous.\n",
      "['ri', '##vet', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3953, -0.0832, -0.0144,  ...,  0.1802,  0.3786,  0.2145])\n",
      "riveted\n",
      "Saved the embedding for riveted.\n",
      "['roar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8361,  0.2249, -0.6403,  ...,  0.1304,  0.1960,  0.3199])\n",
      "roar\n",
      "Saved the embedding for roar.\n",
      "['ro', '##gui', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1227, -0.1917,  0.1175,  ...,  0.0409, -0.1183, -0.4000])\n",
      "roguish\n",
      "Saved the embedding for roguish.\n",
      "['roi', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4721, -0.2301, -0.1771,  ..., -0.6797,  0.6842, -0.0307])\n",
      "roiled\n",
      "Saved the embedding for roiled.\n",
      "['rough'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5027, -0.3245, -0.2720,  ...,  0.1697,  0.2255,  0.2040])\n",
      "rough\n",
      "Saved the embedding for rough.\n",
      "['rouse', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0308,  0.4611,  0.0184,  ...,  0.3460,  0.6575, -0.2398])\n",
      "roused\n",
      "Saved the embedding for roused.\n",
      "['rude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5364,  0.7360,  0.0221,  ..., -0.1575,  0.0305,  0.2032])\n",
      "rude\n",
      "Saved the embedding for rude.\n",
      "['rue', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0966, -0.1730,  0.0262,  ...,  0.8406,  0.6693, -0.2415])\n",
      "rueful\n",
      "Saved the embedding for rueful.\n",
      "['ru', '##ffled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0899, -1.2474,  0.0554,  ..., -0.0950, -0.3828,  0.0335])\n",
      "ruffled\n",
      "Saved the embedding for ruffled.\n",
      "['rum', '##inating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5127, -0.3610, -0.6984,  ..., -0.0557, -0.3198,  0.1849])\n",
      "ruminating\n",
      "Saved the embedding for ruminating.\n",
      "['rust', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4414, -0.3206, -0.2130,  ...,  0.2137,  0.1243,  0.0215])\n",
      "rustled\n",
      "Saved the embedding for rustled.\n",
      "['ruthless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7107,  0.3795, -0.1572,  ..., -0.2274,  0.0474, -0.0545])\n",
      "ruthless\n",
      "Saved the embedding for ruthless.\n",
      "['sad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0343, 0.6701, 0.3316,  ..., 0.6157, 0.4716, 0.6837])\n",
      "sad\n",
      "Saved the embedding for sad.\n",
      "['sad', '##den'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0511,  0.6997,  0.2665,  ...,  0.0853,  0.2051,  0.7104])\n",
      "sadden\n",
      "Saved the embedding for sadden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0262,  0.6265,  0.3351,  ...,  0.2080,  0.3951,  0.7532])\n",
      "saddened\n",
      "Saved the embedding for saddened.\n",
      "['sad', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0138,  0.6451,  0.3946,  ...,  0.3908,  0.2973,  0.7125])\n",
      "sadistic\n",
      "Saved the embedding for sadistic.\n",
      "['sadness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0093,  0.3940,  0.5799,  ...,  0.0998,  0.2555,  0.4305])\n",
      "sadness\n",
      "Saved the embedding for sadness.\n",
      "['sal', '##acious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.2297, 0.3295, 0.0739,  ..., 0.6823, 0.0734, 0.3116])\n",
      "salacious\n",
      "Saved the embedding for salacious.\n",
      "['saliva', '##ting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6350,  0.2834,  0.0767,  ..., -0.5616,  0.2566,  0.2964])\n",
      "salivating\n",
      "Saved the embedding for salivating.\n",
      "['san', '##ct', '##imo', '##nio', '##us'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0915, -0.3861, -0.2523,  ..., -0.4426,  0.6111,  0.3098])\n",
      "sanctimonious\n",
      "Saved the embedding for sanctimonious.\n",
      "['sane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1104,  0.6853,  0.2084,  ..., -0.0281, -0.0947,  1.1238])\n",
      "sane\n",
      "Saved the embedding for sane.\n",
      "['sang', '##uin', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1300, -0.6633, -0.0449,  ...,  0.2297,  0.6441, -0.1168])\n",
      "sanguine\n",
      "Saved the embedding for sanguine.\n",
      "['sap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8565, -0.4522,  0.0392,  ..., -0.4937,  0.0272, -0.1060])\n",
      "sappy\n",
      "Saved the embedding for sappy.\n",
      "['sarcasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7095,  0.3625, -0.1841,  ...,  0.2060,  0.0700,  0.6480])\n",
      "sarcasm\n",
      "Saved the embedding for sarcasm.\n",
      "['sarcastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5457,  0.0671,  0.0677,  ...,  0.0046, -0.0044,  0.4612])\n",
      "sarcastic\n",
      "Saved the embedding for sarcastic.\n",
      "['sar', '##don', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.5453, 0.0561, 0.2616,  ..., 0.2176, 0.0546, 0.2206])\n",
      "sardonic\n",
      "Saved the embedding for sardonic.\n",
      "['sas', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4469,  0.0965,  0.2522,  ...,  0.2854,  0.0554,  0.1634])\n",
      "sassy\n",
      "Saved the embedding for sassy.\n",
      "['sat', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-4.9031e-01, -1.9448e-04,  6.2425e-02,  ...,  1.6255e-01,\n",
      "         7.4177e-01,  1.3141e-01])\n",
      "sated\n",
      "Saved the embedding for sated.\n",
      "['sat', '##iated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4762,  0.1097,  0.2739,  ...,  0.2509,  0.4940,  0.1978])\n",
      "satiated\n",
      "Saved the embedding for satiated.\n",
      "['satirical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2715, -0.2208,  0.0343,  ..., -0.0900,  0.2271,  0.1119])\n",
      "satirical\n",
      "Saved the embedding for satirical.\n",
      "['satisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2855,  0.5410,  0.2307,  ..., -0.7906,  0.0439,  0.6699])\n",
      "satisfaction\n",
      "Saved the embedding for satisfaction.\n",
      "['satisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2018, 0.4965, 0.1381,  ..., 0.0673, 0.4546, 1.3348])\n",
      "satisfied\n",
      "Saved the embedding for satisfied.\n",
      "['satisfy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2168,  0.6410,  0.1420,  ...,  0.5937,  0.1645,  1.3517])\n",
      "satisfy\n",
      "Saved the embedding for satisfy.\n",
      "['saturn', '##ine'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6388,  0.8296, -0.4414,  ..., -0.2342,  0.7088, -0.8236])\n",
      "saturnine\n",
      "Saved the embedding for saturnine.\n",
      "['sa', '##uc', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3274,  0.6253, -0.3317,  ...,  0.2758,  0.2998,  0.4335])\n",
      "saucy\n",
      "Saved the embedding for saucy.\n",
      "['savage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3825,  0.5119, -0.5838,  ...,  0.4065, -0.2526,  0.1376])\n",
      "savage\n",
      "Saved the embedding for savage.\n",
      "['scandal', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0832,  0.1616,  0.1932,  ..., -0.2351,  0.0078,  0.2244])\n",
      "scandalized\n",
      "Saved the embedding for scandalized.\n",
      "['scare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 4.6072e-01, -2.7288e-02, -6.7400e-02,  ..., -1.7404e-01,\n",
      "         3.8122e-01,  9.4157e-05])\n",
      "scare\n",
      "Saved the embedding for scare.\n",
      "['scared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2460, -0.0434,  0.0508,  ..., -0.2105,  0.1605,  0.4104])\n",
      "scared\n",
      "Saved the embedding for scared.\n",
      "['scary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0157,  0.0847,  0.0325,  ...,  0.4873,  0.5538,  0.5289])\n",
      "scary\n",
      "Saved the embedding for scary.\n",
      "['scattered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1030, -0.3125,  0.0007,  ...,  0.0274, -0.2195,  0.4029])\n",
      "scattered\n",
      "Saved the embedding for scattered.\n",
      "['sc', '##had', '##en', '##fr', '##eu', '##de'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([-0.2502, -0.2728, -0.2420,  ...,  0.4860,  0.5508,  0.5217])\n",
      "schadenfreude\n",
      "Saved the embedding for schadenfreude.\n",
      "['sc', '##hem', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1029, -0.0133, -0.3778,  ...,  0.3043,  0.3194,  0.5781])\n",
      "scheming\n",
      "Saved the embedding for scheming.\n",
      "['sc', '##off', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2021, -0.0661, -0.2836,  ...,  0.6570,  0.5054,  0.5324])\n",
      "scoffer\n",
      "Saved the embedding for scoffer.\n",
      "['sc', '##off', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1242, -0.0671, -0.3366,  ...,  0.4201,  0.3651,  0.5638])\n",
      "scoffing\n",
      "Saved the embedding for scoffing.\n",
      "['sc', '##orn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1114,  0.0154, -0.2913,  ...,  0.4370,  0.4701,  0.5590])\n",
      "scorn\n",
      "Saved the embedding for scorn.\n",
      "['sc', '##orne', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1613, -0.1346, -0.2748,  ...,  0.3022,  0.4059,  0.6172])\n",
      "scorned\n",
      "Saved the embedding for scorned.\n",
      "['sc', '##orn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1060, -0.0627, -0.2881,  ...,  0.5693,  0.4710,  0.4577])\n",
      "scornful\n",
      "Saved the embedding for scornful.\n",
      "['scowl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0103,  0.5732,  0.0792,  ..., -0.9884,  0.1221,  0.6781])\n",
      "scowl\n",
      "Saved the embedding for scowl.\n",
      "['scowl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0966,  0.4652,  0.0312,  ..., -0.5971,  0.1345,  0.6572])\n",
      "scowling\n",
      "Saved the embedding for scowling.\n",
      "['scream'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5367,  0.2372, -0.6359,  ..., -0.0321, -0.2074, -0.1989])\n",
      "scream\n",
      "Saved the embedding for scream.\n",
      "['screaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3697,  0.0832, -0.6286,  ..., -0.1218, -0.3735, -0.1018])\n",
      "screaming\n",
      "Saved the embedding for screaming.\n",
      "['sc', '##rut', '##ini', '##zing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1066,  0.0051, -0.2358,  ...,  0.5308,  0.3158,  0.7766])\n",
      "scrutinizing\n",
      "Saved the embedding for scrutinizing.\n",
      "['sealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8009, -0.3524, -0.3364,  ...,  0.6742,  0.1307,  0.1048])\n",
      "sealed\n",
      "Saved the embedding for sealed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['searching'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1335,  0.0057,  0.0112,  ..., -0.2778,  0.4279,  0.5411])\n",
      "searching\n",
      "Saved the embedding for searching.\n",
      "['secretive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3127, -0.3362, -0.1284,  ..., -0.2578,  0.2150,  0.1860])\n",
      "secretive\n",
      "Saved the embedding for secretive.\n",
      "['secretive', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1245, -0.0758,  0.0838,  ..., -0.0996,  0.3222,  0.4213])\n",
      "secretively\n",
      "Saved the embedding for secretively.\n",
      "['secure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0189,  0.0635, -0.0660,  ..., -0.3796,  0.3496,  0.7913])\n",
      "secure\n",
      "Saved the embedding for secure.\n",
      "['se', '##date'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0122, -0.3124, -0.4727,  ...,  0.0544,  0.1101,  0.8792])\n",
      "sedate\n",
      "Saved the embedding for sedate.\n",
      "['seduction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5691,  0.2915, -0.0435,  ..., -0.1007, -0.2729, -0.0321])\n",
      "seduction\n",
      "Saved the embedding for seduction.\n",
      "['seductive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4869, -0.1673,  0.0655,  ..., -0.2458, -0.6536, -0.5166])\n",
      "seductive\n",
      "Saved the embedding for seductive.\n",
      "['see', '##thing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1952, 0.3862, 0.1259,  ..., 0.4629, 0.2420, 0.3801])\n",
      "seething\n",
      "Saved the embedding for seething.\n",
      "['self'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0167,  0.3306, -0.4990,  ..., -0.6709, -0.4332,  0.4664])\n",
      "self\n",
      "Saved the embedding for self.\n",
      "['sensual'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1468, -0.0123,  0.1597,  ..., -0.3228, -0.2266,  0.1312])\n",
      "sensual\n",
      "Saved the embedding for sensual.\n",
      "['sentimental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1705,  0.5658,  0.5085,  ...,  0.2664, -0.2467, -0.0617])\n",
      "sentimental\n",
      "Saved the embedding for sentimental.\n",
      "['serene'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0448, 0.4975, 0.7354,  ..., 0.6010, 0.6258, 0.5950])\n",
      "serene\n",
      "Saved the embedding for serene.\n",
      "['serious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0741,  0.5502,  0.0254,  ..., -0.4909, -0.0894,  0.2910])\n",
      "serious\n",
      "Saved the embedding for serious.\n",
      "['seriousness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2382,  0.6343,  0.2959,  ..., -0.0501,  0.5861,  0.4174])\n",
      "seriousness\n",
      "Saved the embedding for seriousness.\n",
      "['ser', '##vil', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4802,  0.2424,  0.2318,  ..., -0.2304,  0.9621,  0.3586])\n",
      "servile\n",
      "Saved the embedding for servile.\n",
      "['set'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3608,  0.0636, -0.0736,  ...,  0.5792, -0.0089, -0.1291])\n",
      "set\n",
      "Saved the embedding for set.\n",
      "['severe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0980,  0.5093, -0.1309,  ..., -0.5424, -0.1840, -0.1299])\n",
      "severe\n",
      "Saved the embedding for severe.\n",
      "['sha', '##bby'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4490, -0.1535, -0.5789,  ...,  0.1970, -0.0466,  0.1502])\n",
      "shabby\n",
      "Saved the embedding for shabby.\n",
      "['shady'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1713,  0.1910, -0.3234,  ...,  0.0458,  0.2908,  0.2126])\n",
      "shady\n",
      "Saved the embedding for shady.\n",
      "['shaken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2639,  0.6653, -0.0732,  ..., -0.1411, -0.1820,  0.6111])\n",
      "shaken\n",
      "Saved the embedding for shaken.\n",
      "['shaky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4259, -0.3512, -0.1276,  ..., -0.4973,  0.0904,  0.4460])\n",
      "shaky\n",
      "Saved the embedding for shaky.\n",
      "['shame'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2800,  0.2839,  0.2931,  ..., -0.4038, -0.2286,  0.0314])\n",
      "shame\n",
      "Saved the embedding for shame.\n",
      "['shame', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1209,  0.3611,  0.4296,  ..., -0.3005, -0.1032,  0.1024])\n",
      "shamed\n",
      "Saved the embedding for shamed.\n",
      "['shame', '##face', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2551,  0.3302,  0.3942,  ..., -0.1749, -0.1065,  0.0796])\n",
      "shamefaced\n",
      "Saved the embedding for shamefaced.\n",
      "['shame', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1904,  0.2698,  0.2625,  ..., -0.2079, -0.1143, -0.0251])\n",
      "shameful\n",
      "Saved the embedding for shameful.\n",
      "['shame', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1466,  0.2326,  0.2436,  ..., -0.3079, -0.2036,  0.0673])\n",
      "shameless\n",
      "Saved the embedding for shameless.\n",
      "['sharp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0175,  0.0163, -0.1447,  ..., -0.3195, -0.0366,  0.3507])\n",
      "sharp\n",
      "Saved the embedding for sharp.\n",
      "['sheep', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4803, -0.2756,  0.0268,  ...,  0.3040,  0.2395,  0.2281])\n",
      "sheepish\n",
      "Saved the embedding for sheepish.\n",
      "['sheep', '##ish', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4334, -0.2476,  0.0861,  ...,  0.2697,  0.3274,  0.2792])\n",
      "sheepishness\n",
      "Saved the embedding for sheepishness.\n",
      "['shell', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.3222,  0.2577, -0.3516,  ...,  0.0704, -0.3422,  0.5637])\n",
      "shelled\n",
      "Saved the embedding for shelled.\n",
      "['shift', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1592,  0.7648, -0.3471,  ..., -0.5027, -0.0309,  0.3053])\n",
      "shifty\n",
      "Saved the embedding for shifty.\n",
      "['shock'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6363,  1.3433, -0.2144,  ..., -0.4253,  0.1065,  0.4886])\n",
      "shock\n",
      "Saved the embedding for shock.\n",
      "['shocked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4090,  0.3816, -0.2250,  ..., -0.1012,  0.6880,  0.3523])\n",
      "shocked\n",
      "Saved the embedding for shocked.\n",
      "['shocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3019,  0.2323, -0.0100,  ..., -0.1960,  0.3429,  0.3348])\n",
      "shocking\n",
      "Saved the embedding for shocking.\n",
      "['shocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2095,  0.3344,  0.0638,  ..., -0.0085,  0.4391,  0.4667])\n",
      "shockingly\n",
      "Saved the embedding for shockingly.\n",
      "['shook'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6804,  0.0780, -0.1150,  ..., -0.3183, -0.0713,  0.4015])\n",
      "shook\n",
      "Saved the embedding for shook.\n",
      "['shout'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2741,  0.1530, -0.4557,  ...,  0.0076, -0.0538, -0.1024])\n",
      "shout\n",
      "Saved the embedding for shout.\n",
      "['shouting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7631,  0.4995, -0.9595,  ..., -0.0133, -0.5634, -0.0175])\n",
      "shouting\n",
      "Saved the embedding for shouting.\n",
      "['sh', '##rew', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.5821, 0.0298, 0.3617,  ..., 0.4437, 0.2991, 0.6148])\n",
      "shrewd\n",
      "Saved the embedding for shrewd.\n",
      "['shy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3639, -0.3051,  0.0830,  ..., -0.2900, -0.0016,  0.1397])\n",
      "shy\n",
      "Saved the embedding for shy.\n",
      "['shy', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3618, -0.2199,  0.1025,  ..., -0.1852, -0.0586,  0.0660])\n",
      "shyness\n",
      "Saved the embedding for shyness.\n",
      "['sick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1454,  0.5810,  0.2551,  ..., -0.3238, -0.0322, -0.0596])\n",
      "sick\n",
      "Saved the embedding for sick.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sick', '##en'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2728,  0.5179,  0.2745,  ..., -0.4409,  0.1305, -0.0965])\n",
      "sicken\n",
      "Saved the embedding for sicken.\n",
      "['sick', '##ened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1323,  0.5583,  0.1762,  ..., -0.2202,  0.1342, -0.0661])\n",
      "sickened\n",
      "Saved the embedding for sickened.\n",
      "['sigh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0406,  0.4564,  0.6383,  ..., -0.2941, -0.2850,  0.2434])\n",
      "sigh\n",
      "Saved the embedding for sigh.\n",
      "['silenced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5748,  0.8378, -0.5147,  ...,  0.0403, -0.0738,  0.2835])\n",
      "silenced\n",
      "Saved the embedding for silenced.\n",
      "['silent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7121,  0.5796, -0.3927,  ..., -0.1244,  0.2935,  0.1680])\n",
      "silent\n",
      "Saved the embedding for silent.\n",
      "['si', '##llin', '##ess'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3659,  0.5124,  0.0289,  ..., -0.4077,  0.4373,  0.5481])\n",
      "silliness\n",
      "Saved the embedding for silliness.\n",
      "['silly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0041,  0.2656, -0.0147,  ..., -0.0828,  0.2330,  0.4439])\n",
      "silly\n",
      "Saved the embedding for silly.\n",
      "['sim', '##mering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1680, -0.4668, -0.2693,  ..., -0.4755, -0.4922,  0.7060])\n",
      "simmering\n",
      "Saved the embedding for simmering.\n",
      "['sim', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0775, -0.3943, -0.2247,  ..., -0.3366, -0.4288,  0.6519])\n",
      "simper\n",
      "Saved the embedding for simper.\n",
      "['sim', '##per', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0821, -0.4936, -0.2471,  ..., -0.7844, -0.3925,  0.7147])\n",
      "simpering\n",
      "Saved the embedding for simpering.\n",
      "['simple'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5519,  0.3739, -0.4931,  ...,  0.2996, -0.3059,  0.3787])\n",
      "simple\n",
      "Saved the embedding for simple.\n",
      "['simplicity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6921,  0.7885, -0.0632,  ..., -0.2777, -0.1339,  0.4537])\n",
      "simplicity\n",
      "Saved the embedding for simplicity.\n",
      "['sincere'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4840,  0.4071,  0.5496,  ..., -0.4513,  0.6790,  0.3276])\n",
      "sincere\n",
      "Saved the embedding for sincere.\n",
      "['sin', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5852, -0.1485, -0.0793,  ..., -0.1133,  0.0840,  0.5487])\n",
      "sinful\n",
      "Saved the embedding for sinful.\n",
      "['singing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0226, -0.6056,  0.0128,  ..., -0.1981, -0.2610, -0.2545])\n",
      "singing\n",
      "Saved the embedding for singing.\n",
      "['sinister'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5053,  0.5417, -0.3490,  ...,  0.0933,  0.2231, -0.2935])\n",
      "sinister\n",
      "Saved the embedding for sinister.\n",
      "['sinister', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2988,  0.5349, -0.0521,  ...,  0.2599,  0.3948,  0.1078])\n",
      "sinisterly\n",
      "Saved the embedding for sinisterly.\n",
      "['si', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3142,  0.8205, -0.0508,  ..., -0.3879,  0.0746,  0.5063])\n",
      "sizing\n",
      "Saved the embedding for sizing.\n",
      "['sk', '##ept', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.9818, -0.0674, -0.0068,  ...,  0.4471, -0.0379,  0.3751])\n",
      "skeptic\n",
      "Saved the embedding for skeptic.\n",
      "['skeptical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0990,  0.4927, -0.4420,  ...,  0.2539,  0.1198,  0.4667])\n",
      "skeptical\n",
      "Saved the embedding for skeptical.\n",
      "['skeptical', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0281,  0.6981, -0.3105,  ...,  0.4298,  0.3855,  0.5874])\n",
      "skeptically\n",
      "Saved the embedding for skeptically.\n",
      "['skepticism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1751,  0.3155, -0.4157,  ...,  0.1418,  0.0489,  0.7469])\n",
      "skepticism\n",
      "Saved the embedding for skepticism.\n",
      "['sketch', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7075,  0.0988, -0.0267,  ...,  0.7946, -0.1075,  0.4967])\n",
      "sketchy\n",
      "Saved the embedding for sketchy.\n",
      "['ski', '##tti', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6190, -0.3136, -0.0569,  ...,  0.6292,  0.1678, -0.3606])\n",
      "skittish\n",
      "Saved the embedding for skittish.\n",
      "['slack'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2777,  0.5159, -0.1455,  ..., -0.1831, -0.2279,  0.0100])\n",
      "slack\n",
      "Saved the embedding for slack.\n",
      "['sl', '##ea', '##zy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8656,  0.1706, -0.0698,  ...,  0.0132, -0.1202,  0.3538])\n",
      "sleazy\n",
      "Saved the embedding for sleazy.\n",
      "['sleepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6765, -0.0029,  0.1408,  ...,  0.1088,  0.4208,  0.3721])\n",
      "sleepy\n",
      "Saved the embedding for sleepy.\n",
      "['slick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6459,  0.2054, -0.4906,  ..., -0.4982, -0.2678, -0.3408])\n",
      "slick\n",
      "Saved the embedding for slick.\n",
      "['slot', '##h', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2512, -0.3107, -0.5150,  ..., -0.1095, -0.1194,  0.8387])\n",
      "slothful\n",
      "Saved the embedding for slothful.\n",
      "['slow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0585, -0.0897,  0.0526,  ...,  0.0777,  0.2670, -0.0876])\n",
      "slow\n",
      "Saved the embedding for slow.\n",
      "['slug', '##gis', '##h'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([1.0663, 0.2844, 0.0158,  ..., 0.3132, 0.1650, 0.6128])\n",
      "sluggish\n",
      "Saved the embedding for sluggish.\n",
      "['sly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2771, -0.2612, -0.0565,  ...,  0.3600,  0.1853,  0.5885])\n",
      "sly\n",
      "Saved the embedding for sly.\n",
      "['sm', '##arm', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.0612, 0.1930, 0.2788,  ..., 0.1958, 0.3724, 0.0026])\n",
      "smarmy\n",
      "Saved the embedding for smarmy.\n",
      "['smart'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2195,  0.0376,  0.0429,  ..., -0.3438, -0.2300, -0.1240])\n",
      "smart\n",
      "Saved the embedding for smart.\n",
      "['smashed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3842,  0.1318, -0.2256,  ...,  0.0102, -0.1989, -0.3889])\n",
      "smashed\n",
      "Saved the embedding for smashed.\n",
      "['smile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1844,  0.3270,  0.3783,  ...,  0.3255,  0.6533,  0.2591])\n",
      "smile\n",
      "Saved the embedding for smile.\n",
      "['smiley'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4294, -0.4049, -0.2362,  ..., -0.0899,  0.7759,  0.5184])\n",
      "smiley\n",
      "Saved the embedding for smiley.\n",
      "['smiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5796,  0.6186,  0.2492,  ..., -0.0702,  0.2456,  0.3143])\n",
      "smiling\n",
      "Saved the embedding for smiling.\n",
      "['smirk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0371,  0.3533,  0.3129,  ..., -0.3733,  0.3340,  0.4552])\n",
      "smirk\n",
      "Saved the embedding for smirk.\n",
      "['smirk', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0975,  0.2809,  0.2187,  ..., -0.0877,  0.4255,  0.6249])\n",
      "smirking\n",
      "Saved the embedding for smirking.\n",
      "['sm', '##old', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.0928, 0.1171, 0.2549,  ..., 0.2074, 0.3631, 0.0779])\n",
      "smoldering\n",
      "Saved the embedding for smoldering.\n",
      "['sm', '##oo', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0247,  0.0517,  0.0967,  ..., -0.0085,  0.0004,  0.0823])\n",
      "smooching\n",
      "Saved the embedding for smooching.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smooth'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2714, -0.0560, -0.0799,  ...,  0.0659,  0.1826, -0.1712])\n",
      "smooth\n",
      "Saved the embedding for smooth.\n",
      "['smug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3021, -0.0421,  0.4123,  ...,  0.1663,  0.0923,  0.2920])\n",
      "smug\n",
      "Saved the embedding for smug.\n",
      "['smug', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.2697, 0.0788, 0.4565,  ..., 0.2410, 0.1085, 0.6001])\n",
      "smugness\n",
      "Saved the embedding for smugness.\n",
      "['snake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8965,  0.0487, -0.0098,  ...,  0.4522,  0.3907, -0.2765])\n",
      "snake\n",
      "Saved the embedding for snake.\n",
      "['snap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4640, -0.6222,  0.2072,  ...,  0.3994,  0.4374, -0.4563])\n",
      "snappy\n",
      "Saved the embedding for snappy.\n",
      "['s', '##nar', '##ky'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3473, -0.0371,  0.0170,  ...,  0.0572, -0.0234,  0.6104])\n",
      "snarky\n",
      "Saved the embedding for snarky.\n",
      "['snarl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8624, -0.1224, -0.0160,  ..., -0.0144,  0.0616,  0.4825])\n",
      "snarl\n",
      "Saved the embedding for snarl.\n",
      "['snarled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.1762, -0.4892,  0.1552,  ...,  0.0589, -0.0567,  0.3730])\n",
      "snarled\n",
      "Saved the embedding for snarled.\n",
      "['snarl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6573, -0.1205, -0.0914,  ...,  0.0099,  0.2122,  0.3828])\n",
      "snarling\n",
      "Saved the embedding for snarling.\n",
      "['snarl', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5795, -0.0844, -0.0663,  ..., -0.0245,  0.1268,  0.2773])\n",
      "snarly\n",
      "Saved the embedding for snarly.\n",
      "['sneak', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7767, -0.1721, -0.5998,  ..., -0.0242, -0.0054, -0.1113])\n",
      "sneaky\n",
      "Saved the embedding for sneaky.\n",
      "['s', '##neer'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2621, -0.2187, -0.0027,  ..., -0.0968, -0.0377,  0.6952])\n",
      "sneer\n",
      "Saved the embedding for sneer.\n",
      "['s', '##neer', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2272, -0.2087, -0.0276,  ..., -0.0381, -0.0116,  0.7402])\n",
      "sneering\n",
      "Saved the embedding for sneering.\n",
      "['s', '##nee', '##ze'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3296, -0.1601, -0.1179,  ...,  0.1251, -0.1251,  0.4761])\n",
      "sneeze\n",
      "Saved the embedding for sneeze.\n",
      "['s', '##nee', '##zing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2722, -0.1283, -0.0918,  ...,  0.0645, -0.1059,  0.6438])\n",
      "sneezing\n",
      "Saved the embedding for sneezing.\n",
      "['s', '##nick', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3725, -0.0891, -0.0420,  ...,  0.3264,  0.0995,  0.5143])\n",
      "snicker\n",
      "Saved the embedding for snicker.\n",
      "['s', '##nick', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3937, -0.2291,  0.0054,  ..., -0.2527, -0.1292,  0.7429])\n",
      "snickering\n",
      "Saved the embedding for snickering.\n",
      "['s', '##ni', '##de'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3465, -0.1621, -0.0301,  ...,  0.1922, -0.0187,  0.5947])\n",
      "snide\n",
      "Saved the embedding for snide.\n",
      "['s', '##nig', '##ger', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3074, -0.1155, -0.0612,  ...,  0.0633, -0.0412,  0.6136])\n",
      "sniggering\n",
      "Saved the embedding for sniggering.\n",
      "['s', '##ni', '##vel', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2085, -0.2253, -0.0832,  ...,  0.1393, -0.3166,  0.7131])\n",
      "sniveling\n",
      "Saved the embedding for sniveling.\n",
      "['s', '##nob', '##bis', '##h'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4025, -0.1223,  0.0252,  ...,  0.1440, -0.0569,  0.6115])\n",
      "snobbish\n",
      "Saved the embedding for snobbish.\n",
      "['s', '##nob', '##by'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2361, -0.1264, -0.0241,  ..., -0.2881, -0.2287,  0.5265])\n",
      "snobby\n",
      "Saved the embedding for snobby.\n",
      "['s', '##no', '##ot', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2668, -0.0531, -0.1082,  ...,  0.2798, -0.1015,  0.3909])\n",
      "snooty\n",
      "Saved the embedding for snooty.\n",
      "['s', '##not', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4268, -0.1096,  0.0727,  ...,  0.0608, -0.2442,  0.6138])\n",
      "snotty\n",
      "Saved the embedding for snotty.\n",
      "['soc', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2671, -0.1374, -0.1301,  ...,  0.8277,  0.5804,  0.5366])\n",
      "sociable\n",
      "Saved the embedding for sociable.\n",
      "['soft'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2983,  0.5344, -0.0808,  ..., -0.3172,  0.3139, -0.0685])\n",
      "soft\n",
      "Saved the embedding for soft.\n",
      "['solemn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1962,  0.4816,  0.7245,  ..., -0.3025,  1.3862,  0.7164])\n",
      "solemn\n",
      "Saved the embedding for solemn.\n",
      "['sol', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0982, -0.1256,  0.3462,  ...,  0.3437,  0.3925,  0.4909])\n",
      "solicitous\n",
      "Saved the embedding for solicitous.\n",
      "['solitary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3723, -0.1264,  0.2786,  ..., -0.1572, -0.3320,  0.1841])\n",
      "solitary\n",
      "Saved the embedding for solitary.\n",
      "['solitude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3038,  0.6694,  0.2365,  ..., -0.1575, -0.3048,  0.7261])\n",
      "solitude\n",
      "Saved the embedding for solitude.\n",
      "['somber'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6922,  0.5399,  0.2730,  ..., -0.1212,  0.4101,  0.2077])\n",
      "somber\n",
      "Saved the embedding for somber.\n",
      "['somber', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.4972, 0.4747, 0.3327,  ..., 0.0194, 0.3826, 0.4249])\n",
      "somberly\n",
      "Saved the embedding for somberly.\n",
      "['so', '##m', '##no', '##lent'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0963,  0.5022,  0.1413,  ...,  0.0617,  0.0457,  0.7192])\n",
      "somnolent\n",
      "Saved the embedding for somnolent.\n",
      "['soothe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2954,  0.4863,  0.4881,  ..., -0.1804, -0.0484,  0.6028])\n",
      "soothed\n",
      "Saved the embedding for soothed.\n",
      "['sore'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8859, -0.1404, -0.3069,  ..., -0.0606, -0.0719,  0.1749])\n",
      "sore\n",
      "Saved the embedding for sore.\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Set up input and output paths.\n",
    "vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "layer_combining_function = cat_first_four\n",
    "embeddings_file = os.path.join('/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab', layer_combining_function.__name__ + '.txt')\n",
    "if os.path.exists(embeddings_file):\n",
    "    os.remove(embeddings_file)\n",
    "\n",
    "# Create a list of vocabulary words we want embeddings for.\n",
    "vocab = make_vocab(vocab_file)\n",
    "\n",
    "# Tokenize the vocabulary and look up the BERT token indices.\n",
    "tokenized_text, indexed_tokens = tokenize_text(vocab)\n",
    "\n",
    "# Generate segment IDs for each token.\n",
    "segments_IDs = generate_segments_IDs(tokenized_text)\n",
    "\n",
    "# Generate and write out the contextual embeddings for the vocabulary words.\n",
    "# Embeddings are saved in a standard format that can be used for calcualting\n",
    "# the cosine distances between word vectors.\n",
    "for i in range(len(tokenized_text)):\n",
    "    # Convert indexed tokens and segments to tensors.\n",
    "    # Create a BERT model for the tokens.\n",
    "    # Get the encoded model layers and reshape them.\n",
    "    token_embeddings = generate_embeddings(indexed_tokens[i], segments_IDs[i])\n",
    "    print(f'{tokenized_text[i]} has a token embedding of size {token_embeddings.size()}')\n",
    "\n",
    "    # Extract the contextual embedding for a token.\n",
    "    contextual_embedding = layer_combining_function(token_embeddings)\n",
    "\n",
    "    # Write the embedding to a text file, with the vocabulary word prepended.\n",
    "    vocab_word = reconstruct_tokens(tokenized_text[i])\n",
    "    # Make sure we've got the correct vocabulary word.\n",
    "    assert vocab[i] == vocab_word\n",
    "    write_embedding(embeddings_file, vocab[i], contextual_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
