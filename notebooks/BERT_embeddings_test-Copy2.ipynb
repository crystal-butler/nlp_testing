{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Notebooks/crystal/NLP/nlp_testing'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgusted'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]\n",
    "list(tokenizer.vocab.keys())[17733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"disgusted\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreate vocabulary words from their tokenized representations.\n",
    "for t in tokenized_text:\n",
    "    this_word = ''\n",
    "    for token in t:\n",
    "        this_word += token.strip('#')\n",
    "#     print(this_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mark each of the tokens as belonging to sentence \"0\" or \"1\".\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text[3])\n",
    "# segments_ids = [0,0,0]\n",
    "print (segments_ids)\n",
    "print(indexed_tokens)\n",
    "print(tokenized_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens[3]])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 1\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For our token, select its feature values from layer 5.\n",
    "token_i = 1\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# print(vec)\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 1 x 3072\n",
      "tensor([-0.2373,  0.8259, -0.6190,  ..., -0.3836, -0.5039,  0.6153])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_last = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "print(token_vecs_cat_last[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 1 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_last = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_last.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_last), len(token_vecs_sum_last[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the first 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the first 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:4], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_first.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_first), len(token_vecs_sum_first[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[4:8], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle1.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle1), len(token_vecs_sum_middle1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the middle 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[8:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle2.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle2), len(token_vecs_sum_middle2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate all hidden layers to create word embeddings.\n",
    "token_vecs_cat_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3], token[4], token[5], token[6], token[7], token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_all.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_all), len(token_vecs_cat_all[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum all hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_all.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_all), len(token_vecs_sum_all[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a single vector to represent the pair of sentences by averaging across tokens.\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "sentences_vec = []\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "for s in sentence_embedding:\n",
    "    sentences_vec.append(s)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "print(sentence_embedding[767])\n",
    "print(sentence_embedding[-1])\n",
    "print(f'Shape of sentences vector is: {len(sentences_vec)}')\n",
    "print(sentences_vec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# Test the similarity of a word with itself.\n",
    "# For words trained contextually, self-synonymy is less than 1.\n",
    "similarity = 1 - cosine(token_vecs_cat[0], token_vecs_cat[0])\n",
    "print(f'Similarity of {tokenized_text[8]} and {tokenized_text[8]} in token_vecs_cat is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum[4], token_vecs_sum[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_first[4], token_vecs_cat_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_first[4], token_vecs_sum_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle1[4], token_vecs_cat_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle1[4], token_vecs_sum_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle2[4], token_vecs_cat_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle2[4], token_vecs_sum_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_all[4], token_vecs_cat_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_all is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_all[4], token_vecs_sum_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_all is: {similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "############## BEGIN TESTING STATIC CONTEXTUAL EMBEDDING CREATION ####################\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(vocab_file):\n",
    "    # start = timer()\n",
    "    vocab = []\n",
    "    # vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "    with open(vocab_file, 'r') as v:\n",
    "        vocab = v.read().splitlines()\n",
    "    # end = timer()\n",
    "    # run_time = end - start\n",
    "#     print(f'There are {len(vocab)} words in the vocabulary.\\n')\n",
    "#     print(f'It took {run_time} seconds to read the vocabulary file into memory.')\n",
    "#     print(f'Test word is {vocab[2]}.')\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(vocab):\n",
    "    tokenized_text = []\n",
    "    indexed_tokens = []\n",
    "    for word in vocab:\n",
    "        # Add the special tokens.\n",
    "    #     marked_text = \"[CLS] \" + word + \" [SEP]\"\n",
    "        marked_text = word\n",
    "\n",
    "        # Split the sentence into tokens.\n",
    "        # tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        tokenized_text.append(tokenizer.tokenize(marked_text))\n",
    "#         print(f'Added {tokenized_text[-1]} to the tokenized_text array.')\n",
    "\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens.append(tokenizer.convert_tokens_to_ids(tokenized_text[-1]))\n",
    "\n",
    "        # Display the words with their indeces.\n",
    "    #     print(f'The word {tokenized_text[-1][1]} is at index {indexed_tokens[-1]}.')\n",
    "#         for tup in zip(tokenized_text[-1], indexed_tokens[-1]):\n",
    "#             print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "    return tokenized_text, indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_segments_IDs(tokenized_text):\n",
    "    # Create segment IDs for sentence 1 (there can be a sentence 0 to compare to\n",
    "    # sentence 1, but we're not doing that).\n",
    "    # Check that indices and token indices look correct.\n",
    "    segments_IDs = []\n",
    "    for i in range(len(tokenized_text)):\n",
    "        segments_IDs.append([1] * len(tokenized_text[i]))\n",
    "#     for i in range(len(segments_IDs)):\n",
    "#         print (segments_IDs[i])\n",
    "#         print(tokenized_text[i])\n",
    "    return segments_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(indexed_tokens, segments_IDs):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_IDs])\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "#         print('Type of encoded_layers: ', type(encoded_layers))\n",
    "        # Each layer in the list is a torch tensor.\n",
    "#         print('Tensor shape for each layer: ', encoded_layers[0].size())\n",
    "\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "#     print(token_embeddings.size())\n",
    "    \n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_last_four(token_embeddings): \n",
    "    # Concatenate the last 4 hidden layers to create contextual embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_last = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "    print(token_vecs_cat_last[0])\n",
    "    \n",
    "    return token_vecs_cat_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_middle_four2(token_embeddings):\n",
    "    # Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_middle2 = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "    print(token_vecs_cat_middle2[0])\n",
    "    \n",
    "    return token_vecs_cat_middle2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_middle_four1(token_embeddings):\n",
    "    # Concatenate the middle 4 hidden layers to create word embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_middle1 = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "    print(token_vecs_cat_middle1[0])\n",
    "    \n",
    "    return token_vecs_cat_middle1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_first_four(token_embeddings):\n",
    "    token_vecs_cat_first = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "    print(token_vecs_cat_first[0])\n",
    "    \n",
    "    return token_vecs_cat_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_embedding(token_embeddings):\n",
    "    mean_embedding = sum(token_embeddings) / len(token_embeddings)\n",
    "    print(mean_embedding)\n",
    "    \n",
    "    return mean_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_tokens(tokenized_text):\n",
    "    vocab_word = ''\n",
    "    for i in tokenized_text:\n",
    "        vocab_word += i.strip('#')\n",
    "    print(vocab_word)\n",
    "\n",
    "    return vocab_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_embedding(embeddings_file, vocab_word, contextual_embedding):\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(vocab_word)\n",
    "            for value in contextual_embedding[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {vocab_word}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aback'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0913,  1.4276,  0.4738,  ..., -0.4144,  0.0285, -0.0063])\n",
      "aback\n",
      "Saved the embedding for aback.\n",
      "['aba', '##shed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0985, -0.3056, -0.0392,  ...,  0.3008, -0.5077,  0.2036])\n",
      "abashed\n",
      "Saved the embedding for abashed.\n",
      "['ab', '##hor'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4193,  0.4612,  0.7739,  ..., -0.1391,  0.0203,  0.4971])\n",
      "abhor\n",
      "Saved the embedding for abhor.\n",
      "['ab', '##hor', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0553,  0.5331,  0.3810,  ..., -0.1551, -0.0535,  0.1270])\n",
      "abhorred\n",
      "Saved the embedding for abhorred.\n",
      "['ab', '##hor', '##rence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1730, -0.8257,  0.6310,  ..., -0.2092,  0.0052,  0.4344])\n",
      "abhorrence\n",
      "Saved the embedding for abhorrence.\n",
      "['ab', '##hor', '##rent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2501,  0.2684,  0.6867,  ...,  0.2825,  0.1190,  0.2267])\n",
      "abhorrent\n",
      "Saved the embedding for abhorrent.\n",
      "['ab', '##omi', '##nable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3768,  0.8105,  0.7886,  ..., -0.0150,  0.1574,  0.0335])\n",
      "abominable\n",
      "Saved the embedding for abominable.\n",
      "['ab', '##ound'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0598,  0.3475,  0.6817,  ...,  0.3657,  0.2086,  0.4488])\n",
      "abound\n",
      "Saved the embedding for abound.\n",
      "['absent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5728,  0.4880, -0.3794,  ..., -0.0235,  0.8883, -0.6919])\n",
      "absent\n",
      "Saved the embedding for absent.\n",
      "['absorbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1602,  0.4887, -1.3217,  ...,  0.4390,  0.6063,  0.1899])\n",
      "absorbed\n",
      "Saved the embedding for absorbed.\n",
      "['acceptance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0977,  0.5486, -0.0480,  ...,  0.4522,  0.4067,  0.1717])\n",
      "acceptance\n",
      "Saved the embedding for acceptance.\n",
      "['accepted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1796,  0.6632, -1.2526,  ...,  0.2225,  0.3352,  0.0464])\n",
      "accepted\n",
      "Saved the embedding for accepted.\n",
      "['accepting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9470,  0.1649, -0.3838,  ...,  0.3469,  0.0574,  0.1892])\n",
      "accepting\n",
      "Saved the embedding for accepting.\n",
      "['acc', '##om', '##mo', '##dating'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6271,  0.7516,  0.7186,  ..., -0.4962,  0.1347,  0.1132])\n",
      "accommodating\n",
      "Saved the embedding for accommodating.\n",
      "['accomplished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9889,  0.8307, -0.9110,  ..., -0.7357,  0.7470, -0.8813])\n",
      "accomplished\n",
      "Saved the embedding for accomplished.\n",
      "['accord', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1907,  0.6879, -0.4728,  ..., -0.2228,  0.8634,  0.1719])\n",
      "accordant\n",
      "Saved the embedding for accordant.\n",
      "['acc', '##urse', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4923,  0.9484,  0.4677,  ..., -0.1204,  0.7370, -0.3748])\n",
      "accursed\n",
      "Saved the embedding for accursed.\n",
      "['acc', '##usa', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5718,  0.8579,  0.6197,  ..., -0.6872,  0.3313, -0.0542])\n",
      "accusatory\n",
      "Saved the embedding for accusatory.\n",
      "['accused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1654, 1.1252, 0.8130,  ..., 0.0786, 0.0498, 0.2217])\n",
      "accused\n",
      "Saved the embedding for accused.\n",
      "['accusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2950,  0.2680,  0.1777,  ...,  0.6360,  0.2421, -0.0859])\n",
      "accusing\n",
      "Saved the embedding for accusing.\n",
      "['ace', '##rb', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2748,  0.6753,  0.0892,  ..., -0.4101,  0.6429, -0.0838])\n",
      "acerbic\n",
      "Saved the embedding for acerbic.\n",
      "['acidic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8088, -0.0612, -0.3304,  ..., -0.1832, -0.3729,  0.2952])\n",
      "acidic\n",
      "Saved the embedding for acidic.\n",
      "['active'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9228,  1.7193, -0.6858,  ...,  0.1258,  0.4865,  0.9182])\n",
      "active\n",
      "Saved the embedding for active.\n",
      "['acute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6730,  1.2322, -0.9058,  ...,  0.3908,  0.2125,  0.4771])\n",
      "acute\n",
      "Saved the embedding for acute.\n",
      "['adamant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2574, -0.0649,  0.1573,  ...,  1.0801,  0.8033,  0.7831])\n",
      "adamant\n",
      "Saved the embedding for adamant.\n",
      "['add', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8520,  0.7012,  0.5629,  ..., -0.2235, -0.0176,  0.4496])\n",
      "addled\n",
      "Saved the embedding for addled.\n",
      "['admiration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5608,  1.3212,  0.2524,  ..., -0.7511,  0.2802,  0.0149])\n",
      "admiration\n",
      "Saved the embedding for admiration.\n",
      "['admit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6534,  0.7623,  0.4996,  ...,  0.7534, -0.0027,  0.3720])\n",
      "admit\n",
      "Saved the embedding for admit.\n",
      "['ad', '##oration'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6475,  0.2562,  0.5421,  ..., -0.2495,  0.0749,  0.1494])\n",
      "adoration\n",
      "Saved the embedding for adoration.\n",
      "['ad', '##orin', '##g'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5783,  0.8137,  0.0051,  ..., -0.1199,  0.3531,  0.1441])\n",
      "adoring\n",
      "Saved the embedding for adoring.\n",
      "['ad', '##rift'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1045, -0.4924,  1.4953,  ...,  0.0702, -0.0436, -0.1758])\n",
      "adrift\n",
      "Saved the embedding for adrift.\n",
      "['ad', '##vers', '##aria', '##l'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([0.2969, 0.2227, 0.4645,  ..., 0.0908, 0.1111, 0.3406])\n",
      "adversarial\n",
      "Saved the embedding for adversarial.\n",
      "['af', '##fa', '##bility'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1782,  0.0902,  0.2527,  ..., -0.0936,  0.2158,  0.3101])\n",
      "affability\n",
      "Saved the embedding for affability.\n",
      "['affected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1398,  0.5211,  0.0284,  ..., -0.3178,  0.1124,  0.1215])\n",
      "affected\n",
      "Saved the embedding for affected.\n",
      "['affection', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1806,  1.1956, -0.2073,  ..., -0.6195,  0.3466,  0.2681])\n",
      "affectionate\n",
      "Saved the embedding for affectionate.\n",
      "['af', '##flict', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2228,  0.3535,  0.1423,  ...,  0.2585,  0.5777, -0.0295])\n",
      "afflicted\n",
      "Saved the embedding for afflicted.\n",
      "['af', '##front', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0427,  0.2527,  0.5031,  ...,  0.3853,  0.0341, -0.0492])\n",
      "affronted\n",
      "Saved the embedding for affronted.\n",
      "['afl', '##utter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0649,  0.1700, -0.4434,  ...,  0.2978,  0.6779, -0.0464])\n",
      "aflutter\n",
      "Saved the embedding for aflutter.\n",
      "['afraid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1638,  0.9193, -0.8702,  ..., -0.0736,  0.0256,  0.0998])\n",
      "afraid\n",
      "Saved the embedding for afraid.\n",
      "['ag', '##ape'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2035,  0.9035,  0.7794,  ..., -0.2227, -0.2579, -0.0676])\n",
      "agape\n",
      "Saved the embedding for agape.\n",
      "['aggravated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1127,  0.8328,  0.3436,  ..., -0.3349,  0.9999, -0.3482])\n",
      "aggravated\n",
      "Saved the embedding for aggravated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ag', '##gra', '##vation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0653,  0.8995,  0.5749,  ...,  0.1177,  0.1458, -0.2573])\n",
      "aggravation\n",
      "Saved the embedding for aggravation.\n",
      "['aggression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5144,  1.0312, -0.6284,  ...,  0.3372, -0.1049, -0.3468])\n",
      "aggression\n",
      "Saved the embedding for aggression.\n",
      "['aggressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1463,  0.5762, -0.7487,  ...,  0.3911, -0.5970, -0.5397])\n",
      "aggressive\n",
      "Saved the embedding for aggressive.\n",
      "['ag', '##gr', '##ie', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0470,  0.4448,  0.8178,  ...,  0.1632,  0.1066, -0.7245])\n",
      "aggrieve\n",
      "Saved the embedding for aggrieve.\n",
      "['ag', '##gr', '##ie', '##ved'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4535,  0.2086,  1.0646,  ..., -0.2953,  0.2312, -1.1458])\n",
      "aggrieved\n",
      "Saved the embedding for aggrieved.\n",
      "['ag', '##has', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8259,  0.4242,  0.9308,  ..., -0.6090, -0.2172, -0.3989])\n",
      "aghast\n",
      "Saved the embedding for aghast.\n",
      "['agitated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0462,  1.1250, -1.3211,  ..., -0.5198,  0.8435, -0.8239])\n",
      "agitated\n",
      "Saved the embedding for agitated.\n",
      "['ago', '##g'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0692,  0.5495, -0.1335,  ..., -0.2444,  0.4792,  0.1906])\n",
      "agog\n",
      "Saved the embedding for agog.\n",
      "['ago', '##ni', '##zed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1554,  0.6603,  0.8444,  ..., -0.3687,  0.1003, -0.0365])\n",
      "agonized\n",
      "Saved the embedding for agonized.\n",
      "['agree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9773,  0.0798,  0.2140,  ..., -0.2835, -0.1230,  0.3720])\n",
      "agreeable\n",
      "Saved the embedding for agreeable.\n",
      "['ag', '##ress', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0987,  0.9103,  0.6120,  ...,  0.4485,  0.0485, -0.0694])\n",
      "agressive\n",
      "Saved the embedding for agressive.\n",
      "['air', '##head'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1712,  0.8001,  1.3446,  ...,  0.9609,  0.3456, -0.0365])\n",
      "airhead\n",
      "Saved the embedding for airhead.\n",
      "['alarm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4934,  1.0503,  0.2450,  ..., -0.1339,  0.2481,  0.0900])\n",
      "alarm\n",
      "Saved the embedding for alarm.\n",
      "['alarmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7243,  0.6994, -0.3094,  ...,  0.1924,  0.1901, -0.0207])\n",
      "alarmed\n",
      "Saved the embedding for alarmed.\n",
      "['alarm', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4042,  0.5862, -0.0110,  ...,  0.2609,  0.3089, -0.0433])\n",
      "alarming\n",
      "Saved the embedding for alarming.\n",
      "['alert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0376,  0.5752, -0.3386,  ...,  0.3681,  0.0917, -0.1004])\n",
      "alert\n",
      "Saved the embedding for alert.\n",
      "['alerted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1754,  1.4500,  0.2846,  ...,  0.2284,  0.5294, -1.0150])\n",
      "alerted\n",
      "Saved the embedding for alerted.\n",
      "['alien', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1072,  0.0818, -0.2743,  ...,  0.2439,  0.0855,  0.1824])\n",
      "alienated\n",
      "Saved the embedding for alienated.\n",
      "['allergic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9593, -0.2071,  0.2752,  ...,  0.6123,  0.0474,  0.7155])\n",
      "allergic\n",
      "Saved the embedding for allergic.\n",
      "['alleviate', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.3348,  0.5154,  0.6424,  ...,  0.3783, -0.2703,  0.1470])\n",
      "alleviated\n",
      "Saved the embedding for alleviated.\n",
      "['all', '##uring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4625,  0.6259, -0.3021,  ...,  0.8111,  0.1583, -0.1419])\n",
      "alluring\n",
      "Saved the embedding for alluring.\n",
      "['al', '##oof'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1892, -0.6859,  0.0731,  ...,  0.4077,  0.6193,  0.4150])\n",
      "aloof\n",
      "Saved the embedding for aloof.\n",
      "['ama', '##tory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2390,  0.1873,  0.1877,  ...,  0.7184, -0.3640,  0.3935])\n",
      "amatory\n",
      "Saved the embedding for amatory.\n",
      "['amazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3501,  0.6341, -1.0874,  ...,  0.4531,  0.8848, -0.5217])\n",
      "amazed\n",
      "Saved the embedding for amazed.\n",
      "['amazement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0056,  0.7288, -1.7160,  ...,  0.2620,  0.5702, -0.5220])\n",
      "amazement\n",
      "Saved the embedding for amazement.\n",
      "['amazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6134,  0.3455, -0.4014,  ...,  0.8803,  0.4834, -0.4337])\n",
      "amazing\n",
      "Saved the embedding for amazing.\n",
      "['ambition'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2123,  0.8543, -0.9672,  ..., -0.0118, -0.0655, -0.1112])\n",
      "ambition\n",
      "Saved the embedding for ambition.\n",
      "['ambitious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5613,  1.3753, -0.2080,  ..., -0.9670,  0.5192, -0.5078])\n",
      "ambitious\n",
      "Saved the embedding for ambitious.\n",
      "['am', '##bi', '##vale', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2083, -0.0656,  1.0819,  ..., -0.5477,  0.2458,  0.4411])\n",
      "ambivalence\n",
      "Saved the embedding for ambivalence.\n",
      "['am', '##bi', '##valent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0793,  0.6255,  0.1493,  ...,  0.4983,  0.5740,  0.7034])\n",
      "ambivalent\n",
      "Saved the embedding for ambivalent.\n",
      "['am', '##ena', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0251, -0.2618,  0.6971,  ...,  0.4259,  0.3014,  0.2012])\n",
      "amenable\n",
      "Saved the embedding for amenable.\n",
      "['ami', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2400,  1.0145,  0.0406,  ...,  0.7251,  0.7200,  0.5611])\n",
      "amiable\n",
      "Saved the embedding for amiable.\n",
      "['ami', '##cable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.3386, 0.6467, 0.5607,  ..., 0.2630, 0.1720, 0.1007])\n",
      "amicable\n",
      "Saved the embedding for amicable.\n",
      "['amused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4722,  1.0482,  0.2020,  ..., -0.6268,  0.6612, -1.0389])\n",
      "amused\n",
      "Saved the embedding for amused.\n",
      "['amusement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1378,  0.8677, -0.6926,  ..., -0.3753,  0.2546,  0.4859])\n",
      "amusement\n",
      "Saved the embedding for amusement.\n",
      "['analytical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3713,  1.1056,  0.2744,  ...,  0.0578,  0.5247,  0.8130])\n",
      "analytical\n",
      "Saved the embedding for analytical.\n",
      "['analyzing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0382,  0.6447,  0.3296,  ...,  1.1145,  0.2247,  0.3099])\n",
      "analyzing\n",
      "Saved the embedding for analyzing.\n",
      "['anger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2612,  0.8367, -1.3040,  ...,  0.5496,  0.6782, -0.3922])\n",
      "anger\n",
      "Saved the embedding for anger.\n",
      "['angered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3018,  0.1926,  0.6460,  ...,  0.1853,  0.4121, -0.3993])\n",
      "angered\n",
      "Saved the embedding for angered.\n",
      "['angrily'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2747, -0.3113,  0.1366,  ...,  0.3323,  0.2059, -0.4576])\n",
      "angrily\n",
      "Saved the embedding for angrily.\n",
      "['angry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3770,  0.8160, -0.3892,  ...,  0.3806, -0.1034, -0.0659])\n",
      "angry\n",
      "Saved the embedding for angry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ang', '##st'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1915,  0.0732,  0.7304,  ...,  0.6035,  0.2142, -0.1650])\n",
      "angst\n",
      "Saved the embedding for angst.\n",
      "['anguish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0282,  1.4766,  0.3311,  ..., -0.4970,  0.7294, -0.4133])\n",
      "anguish\n",
      "Saved the embedding for anguish.\n",
      "['anguish', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5110,  1.3244,  0.2221,  ..., -0.1738,  0.5002, -0.0183])\n",
      "anguished\n",
      "Saved the embedding for anguished.\n",
      "['animated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4838,  0.6223,  0.4137,  ...,  0.0671,  0.9273, -0.0550])\n",
      "animated\n",
      "Saved the embedding for animated.\n",
      "['an', '##imo', '##sity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7939,  0.5979,  0.1296,  ..., -0.5694, -0.1118,  0.1823])\n",
      "animosity\n",
      "Saved the embedding for animosity.\n",
      "['annoyance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4259,  1.2728, -1.7084,  ...,  0.0374,  0.0618,  0.0302])\n",
      "annoyance\n",
      "Saved the embedding for annoyance.\n",
      "['annoyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5996,  0.8740, -0.5281,  ..., -0.3861, -0.0701, -0.4730])\n",
      "annoyed\n",
      "Saved the embedding for annoyed.\n",
      "['annoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0222,  1.1670, -1.4098,  ..., -0.2423,  0.8083, -0.2859])\n",
      "annoying\n",
      "Saved the embedding for annoying.\n",
      "['antagonist', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1373,  2.0773, -0.1946,  ..., -0.4707, -0.0192,  0.0717])\n",
      "antagonistic\n",
      "Saved the embedding for antagonistic.\n",
      "['ant', '##ago', '##ni', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6235,  0.6688, -0.5019,  ...,  0.4496,  0.2008,  0.4158])\n",
      "antagonized\n",
      "Saved the embedding for antagonized.\n",
      "['anticipated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6200,  1.4631, -1.0204,  ...,  0.1257, -0.4170, -0.5138])\n",
      "anticipated\n",
      "Saved the embedding for anticipated.\n",
      "['anticipating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8721,  0.6280, -0.6332,  ...,  0.0958,  0.1263, -0.1350])\n",
      "anticipating\n",
      "Saved the embedding for anticipating.\n",
      "['anticipation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1078,  1.3446, -1.2386,  ..., -0.1908,  1.0739, -0.4104])\n",
      "anticipation\n",
      "Saved the embedding for anticipation.\n",
      "['anti', '##ci', '##pati', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3646,  0.5224,  0.3582,  ..., -0.4036,  0.7493, -0.3271])\n",
      "anticipative\n",
      "Saved the embedding for anticipative.\n",
      "['anti', '##ci', '##pa', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0612,  0.1353,  0.9441,  ..., -0.3160,  0.2779,  0.1585])\n",
      "anticipatory\n",
      "Saved the embedding for anticipatory.\n",
      "['anti', '##pathy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0861,  0.5849,  1.3780,  ..., -0.3813,  0.1371,  0.1764])\n",
      "antipathy\n",
      "Saved the embedding for antipathy.\n",
      "['ants', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0354,  1.7478, -1.1954,  ...,  0.0137, -0.3332, -0.5035])\n",
      "antsy\n",
      "Saved the embedding for antsy.\n",
      "['anxiety'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3084,  0.2598, -0.5114,  ...,  0.9129,  1.1275,  0.5036])\n",
      "anxiety\n",
      "Saved the embedding for anxiety.\n",
      "['anxious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9296,  1.8467, -0.6421,  ...,  0.0091, -0.1045, -0.2569])\n",
      "anxious\n",
      "Saved the embedding for anxious.\n",
      "['anxiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4459,  0.6800, -0.6032,  ..., -0.2089, -0.0794, -0.0954])\n",
      "anxiously\n",
      "Saved the embedding for anxiously.\n",
      "['ap', '##ath', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3274,  0.8394, -0.7810,  ..., -0.1884,  0.0357,  0.3912])\n",
      "apathetic\n",
      "Saved the embedding for apathetic.\n",
      "['ap', '##athy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0027,  0.7724, -0.2928,  ..., -0.0690, -0.1770,  0.5712])\n",
      "apathy\n",
      "Saved the embedding for apathy.\n",
      "['apologetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3921,  1.7524, -0.4414,  ...,  0.0289,  0.4074, -0.7754])\n",
      "apologetic\n",
      "Saved the embedding for apologetic.\n",
      "['appalled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5430,  1.1221, -0.0331,  ..., -0.2299,  0.0651,  0.0407])\n",
      "appalled\n",
      "Saved the embedding for appalled.\n",
      "['app', '##all', '##ingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0188,  0.1876,  0.6718,  ..., -0.1774,  0.4522, -0.0306])\n",
      "appallingly\n",
      "Saved the embedding for appallingly.\n",
      "['app', '##eased'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2076,  0.5193,  1.7282,  ..., -0.1975,  0.2840, -0.2135])\n",
      "appeased\n",
      "Saved the embedding for appeased.\n",
      "['app', '##ea', '##sing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0748,  0.3170,  1.2421,  ..., -0.3931,  0.1241, -0.2824])\n",
      "appeasing\n",
      "Saved the embedding for appeasing.\n",
      "['app', '##re', '##cia', '##tive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1150, -0.1089,  0.8722,  ..., -0.1554, -0.0622, -0.3469])\n",
      "appreciative\n",
      "Saved the embedding for appreciative.\n",
      "['apprehension'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0851,  0.7217, -1.1519,  ..., -0.5724,  0.5147,  0.1485])\n",
      "apprehension\n",
      "Saved the embedding for apprehension.\n",
      "['app', '##re', '##hen', '##sive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2902,  0.2259,  0.3716,  ..., -0.2560,  0.1766,  0.1412])\n",
      "apprehensive\n",
      "Saved the embedding for apprehensive.\n",
      "['approve'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6528,  0.3915, -0.3197,  ...,  0.6924,  1.1459, -0.4324])\n",
      "approve\n",
      "Saved the embedding for approve.\n",
      "['approved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7397,  0.5531, -0.3094,  ...,  0.2626,  0.9175,  0.7047])\n",
      "approved\n",
      "Saved the embedding for approved.\n",
      "['app', '##roving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2183,  0.0199,  1.3619,  ..., -0.4558,  0.1567, -0.1642])\n",
      "approving\n",
      "Saved the embedding for approving.\n",
      "['argue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6932,  0.8903, -0.0259,  ..., -0.1952,  0.3816, -0.0379])\n",
      "argue\n",
      "Saved the embedding for argue.\n",
      "['argument', '##ative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5130,  2.4027,  1.1726,  ..., -0.8719,  0.4137, -0.7467])\n",
      "argumentative\n",
      "Saved the embedding for argumentative.\n",
      "['aroused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1055,  0.8731,  1.0452,  ..., -0.1518,  0.8761,  0.0874])\n",
      "aroused\n",
      "Saved the embedding for aroused.\n",
      "['arrogance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2368,  0.5427, -0.1292,  ...,  0.0597,  0.2009,  0.6841])\n",
      "arrogance\n",
      "Saved the embedding for arrogance.\n",
      "['arrogant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6136,  0.3441,  0.0425,  ...,  0.4262, -0.2127, -0.2073])\n",
      "arrogant\n",
      "Saved the embedding for arrogant.\n",
      "['arrogant', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6682,  1.5504,  0.5720,  ...,  0.3536, -0.1071, -0.0095])\n",
      "arrogantly\n",
      "Saved the embedding for arrogantly.\n",
      "['artificial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0534,  0.2960,  0.4287,  ..., -0.3341, -0.8985,  0.7907])\n",
      "artificial\n",
      "Saved the embedding for artificial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ashamed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8249,  0.6267, -0.9373,  ...,  1.0249,  0.1462, -0.2750])\n",
      "ashamed\n",
      "Saved the embedding for ashamed.\n",
      "['aspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0652,  0.2626, -0.0492,  ...,  0.3584, -0.1985,  0.6254])\n",
      "aspiring\n",
      "Saved the embedding for aspiring.\n",
      "['assert', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5699,  0.8623,  0.2104,  ...,  0.1907,  0.5752, -0.1986])\n",
      "assertive\n",
      "Saved the embedding for assertive.\n",
      "['assert', '##ively'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8104,  0.8994,  0.6644,  ..., -0.6660,  0.9689, -0.9693])\n",
      "assertively\n",
      "Saved the embedding for assertively.\n",
      "['assessing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1620,  0.6290, -0.2597,  ...,  0.4135,  0.6680, -0.0492])\n",
      "assessing\n",
      "Saved the embedding for assessing.\n",
      "['assured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8942, -0.0990, -0.4736,  ..., -0.6817,  0.2658, -0.3059])\n",
      "assured\n",
      "Saved the embedding for assured.\n",
      "['astonished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1121,  0.5909, -0.7246,  ...,  0.5361,  0.7758, -0.0023])\n",
      "astonished\n",
      "Saved the embedding for astonished.\n",
      "['astonishment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6131,  0.9189,  0.4401,  ..., -0.6502,  0.6491, -0.4032])\n",
      "astonishment\n",
      "Saved the embedding for astonishment.\n",
      "['as', '##tou', '##nded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4041,  0.2105,  0.7780,  ..., -0.7668,  0.3064,  0.1071])\n",
      "astounded\n",
      "Saved the embedding for astounded.\n",
      "['attempting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4641,  0.7011, -0.8087,  ...,  0.2200,  0.6686, -0.1981])\n",
      "attempting\n",
      "Saved the embedding for attempting.\n",
      "['at', '##ten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2027,  0.8723,  0.0349,  ..., -0.4444, -0.6196,  0.5210])\n",
      "attentive\n",
      "Saved the embedding for attentive.\n",
      "['at', '##ten', '##tive', '##ness'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0705, -0.2605,  0.4633,  ..., -0.2330, -0.1297,  0.9656])\n",
      "attentiveness\n",
      "Saved the embedding for attentiveness.\n",
      "['attracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1727,  0.4344,  0.6362,  ...,  0.5399, -0.4368, -0.7263])\n",
      "attracted\n",
      "Saved the embedding for attracted.\n",
      "['ave', '##nging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2939,  0.4179,  0.1496,  ..., -0.4680, -0.1617, -0.1200])\n",
      "avenging\n",
      "Saved the embedding for avenging.\n",
      "['ave', '##rse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4775,  0.0853,  0.2742,  ..., -0.3860, -0.1548,  0.3080])\n",
      "averse\n",
      "Saved the embedding for averse.\n",
      "['ave', '##rs', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0752,  0.0115, -0.0996,  ..., -0.4247, -0.1836,  0.3145])\n",
      "aversion\n",
      "Saved the embedding for aversion.\n",
      "['ave', '##rs', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3874, -0.1452,  0.1608,  ..., -0.1613, -0.2256,  0.4965])\n",
      "aversive\n",
      "Saved the embedding for aversive.\n",
      "['avid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0284,  0.3820, -0.7857,  ...,  0.9331, -0.0593, -0.3212])\n",
      "avid\n",
      "Saved the embedding for avid.\n",
      "['avoiding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6813,  0.4438, -0.1220,  ...,  0.4377,  1.2556, -0.0629])\n",
      "avoiding\n",
      "Saved the embedding for avoiding.\n",
      "['awaiting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1826,  0.8030, -0.0235,  ...,  0.3998,  0.0937, -0.5201])\n",
      "awaiting\n",
      "Saved the embedding for awaiting.\n",
      "['awakened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9937,  0.5085, -0.7092,  ..., -0.2262,  0.1655,  0.3204])\n",
      "awakened\n",
      "Saved the embedding for awakened.\n",
      "['aware'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.8641,  0.5884, -0.1469,  ...,  0.0426,  0.4774,  1.0921])\n",
      "aware\n",
      "Saved the embedding for aware.\n",
      "['awareness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4822,  0.6863,  0.5383,  ..., -0.3675,  0.0218,  0.2195])\n",
      "awareness\n",
      "Saved the embedding for awareness.\n",
      "['awe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2818,  0.3335, -0.6560,  ...,  0.5962,  0.4199, -0.3713])\n",
      "awe\n",
      "Saved the embedding for awe.\n",
      "['awe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4442,  0.2183, -0.3682,  ...,  0.7638,  0.3494, -0.3533])\n",
      "awed\n",
      "Saved the embedding for awed.\n",
      "['awe', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0228,  0.4636,  0.5727,  ..., -0.1554,  0.2146, -0.1190])\n",
      "awestruck\n",
      "Saved the embedding for awestruck.\n",
      "['awful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3417,  1.0631, -0.7464,  ..., -0.4942,  0.7165, -0.3169])\n",
      "awful\n",
      "Saved the embedding for awful.\n",
      "['awkward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1260,  0.6951, -1.2465,  ...,  0.0075,  0.5972, -0.1531])\n",
      "awkward\n",
      "Saved the embedding for awkward.\n",
      "['awkward', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.3028, 0.7243, 0.1865,  ..., 0.2468, 0.4259, 0.3132])\n",
      "awkwardness\n",
      "Saved the embedding for awkwardness.\n",
      "['axe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0576,  0.4408,  0.0621,  ..., -0.1920, -0.5824, -0.2265])\n",
      "axed\n",
      "Saved the embedding for axed.\n",
      "['back', '##hand', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5461,  1.8491, -0.4037,  ..., -0.7406,  0.7364, -0.2932])\n",
      "backhanded\n",
      "Saved the embedding for backhanded.\n",
      "['badly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3318,  0.6115, -0.1927,  ...,  0.3614,  0.2594,  0.0085])\n",
      "badly\n",
      "Saved the embedding for badly.\n",
      "['ba', '##ffle'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3847, -0.0739,  0.4411,  ...,  0.3360, -0.3631,  0.0141])\n",
      "baffle\n",
      "Saved the embedding for baffle.\n",
      "['baffled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4908,  0.5028, -0.9572,  ...,  0.5386,  0.9311, -0.1793])\n",
      "baffled\n",
      "Saved the embedding for baffled.\n",
      "['ba', '##ff', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2390,  0.5198, -0.2203,  ...,  0.3853,  0.1137,  0.3687])\n",
      "baffling\n",
      "Saved the embedding for baffling.\n",
      "['baked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0588,  0.7518, -0.5329,  ...,  0.5214,  0.2068, -0.4568])\n",
      "baked\n",
      "Saved the embedding for baked.\n",
      "['ban', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0626, -0.0459,  0.3694,  ...,  0.1442,  0.1076,  0.1630])\n",
      "banal\n",
      "Saved the embedding for banal.\n",
      "['barking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3132,  1.2175, -1.3188,  ...,  0.4721,  1.1026,  0.1717])\n",
      "barking\n",
      "Saved the embedding for barking.\n",
      "['bash', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4816, -0.0236, -0.0079,  ..., -0.2358,  0.6761, -0.2627])\n",
      "bashful\n",
      "Saved the embedding for bashful.\n",
      "['beaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0676,  0.6103, -0.8613,  ...,  0.1770,  1.0439, -1.0340])\n",
      "beaming\n",
      "Saved the embedding for beaming.\n",
      "['bear', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0317,  0.1022, -0.1041,  ...,  1.0720,  0.8018, -0.0995])\n",
      "bearish\n",
      "Saved the embedding for bearish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1441,  1.2114, -0.7565,  ...,  0.5628,  1.0945,  0.3002])\n",
      "beat\n",
      "Saved the embedding for beat.\n",
      "['beaten'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2069,  0.8025, -0.1612,  ..., -0.1613,  0.3740, -0.8912])\n",
      "beaten\n",
      "Saved the embedding for beaten.\n",
      "['bed', '##ev', '##iled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0442,  0.1295,  0.6587,  ..., -0.0631,  0.0515,  0.0749])\n",
      "bedeviled\n",
      "Saved the embedding for bedeviled.\n",
      "['be', '##fu', '##ddled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0779,  0.1986,  0.8141,  ...,  0.0695,  0.0980, -0.0476])\n",
      "befuddled\n",
      "Saved the embedding for befuddled.\n",
      "['begging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1176,  1.5832, -1.7210,  ...,  0.7771,  1.2993,  0.1483])\n",
      "begging\n",
      "Saved the embedding for begging.\n",
      "['beg', '##rud', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3738,  0.1801,  0.4756,  ...,  0.1562,  0.0066,  0.4544])\n",
      "begrudge\n",
      "Saved the embedding for begrudge.\n",
      "['beg', '##rud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1624, -0.0823, -0.3831,  ..., -0.0911,  0.0398,  0.3617])\n",
      "begrudging\n",
      "Saved the embedding for begrudging.\n",
      "['beg', '##rud', '##gingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3357,  0.7489,  0.2979,  ..., -0.0960, -0.0950, -0.4637])\n",
      "begrudgingly\n",
      "Saved the embedding for begrudgingly.\n",
      "['beg', '##uil', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4104,  0.1923,  0.2870,  ..., -0.1498, -0.0053,  0.0977])\n",
      "beguiled\n",
      "Saved the embedding for beguiled.\n",
      "['bela', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5074,  0.7203,  0.7454,  ..., -0.3202,  0.6068,  0.4310])\n",
      "belated\n",
      "Saved the embedding for belated.\n",
      "['bel', '##itt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3771, 0.4319, 0.1336,  ..., 0.0780, 0.0553, 0.1951])\n",
      "belittling\n",
      "Saved the embedding for belittling.\n",
      "['bell', '##iger', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3814, -0.0317,  0.3914,  ...,  0.3805,  0.1383,  0.6589])\n",
      "belligerence\n",
      "Saved the embedding for belligerence.\n",
      "['bell', '##iger', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0565,  0.1888,  0.1200,  ...,  0.3290, -0.1301,  0.0756])\n",
      "belligerent\n",
      "Saved the embedding for belligerent.\n",
      "['belonging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7060,  1.2461, -0.5692,  ..., -0.0943,  0.0234, -0.1801])\n",
      "belonging\n",
      "Saved the embedding for belonging.\n",
      "['be', '##mus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2189,  0.3247,  0.4730,  ..., -0.5022,  0.6846,  0.2109])\n",
      "bemused\n",
      "Saved the embedding for bemused.\n",
      "['be', '##mus', '##ement'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4159, -0.4609,  0.5928,  ..., -0.2872,  0.0808,  0.5475])\n",
      "bemusement\n",
      "Saved the embedding for bemusement.\n",
      "['ben', '##ev', '##ole', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1252,  0.0673,  0.5266,  ...,  0.0565, -0.0957, -0.0786])\n",
      "benevolence\n",
      "Saved the embedding for benevolence.\n",
      "['benevolent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2031,  0.5518,  0.0337,  ...,  0.0899, -0.7762,  0.3434])\n",
      "benevolent\n",
      "Saved the embedding for benevolent.\n",
      "['ben', '##umb', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-2.1518e-01, -2.0923e-04,  4.9878e-01,  ..., -2.1015e-01,\n",
      "         2.0726e-01,  9.3064e-02])\n",
      "benumbed\n",
      "Saved the embedding for benumbed.\n",
      "['be', '##rate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2678,  0.1243,  0.1129,  ...,  0.3659, -0.7786, -0.3076])\n",
      "berate\n",
      "Saved the embedding for berate.\n",
      "['be', '##rating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1963, 0.1827, 0.3733,  ..., 0.9528, 0.5729, 1.0477])\n",
      "berating\n",
      "Saved the embedding for berating.\n",
      "['be', '##rea', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0990, -0.0404,  0.0363,  ..., -0.3471,  0.3276,  0.3085])\n",
      "bereaved\n",
      "Saved the embedding for bereaved.\n",
      "['be', '##re', '##ft'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0827, -0.2488,  0.8383,  ..., -0.1519,  0.0701, -0.1724])\n",
      "bereft\n",
      "Saved the embedding for bereft.\n",
      "['be', '##see', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0511,  0.1934,  0.2760,  ..., -0.0659, -0.1024,  0.0717])\n",
      "beseeching\n",
      "Saved the embedding for beseeching.\n",
      "['best', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2193,  0.7707,  0.5377,  ..., -0.5873,  0.2072, -0.3317])\n",
      "bested\n",
      "Saved the embedding for bested.\n",
      "['betrayal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0638,  0.3854, -0.4922,  ...,  0.2053,  0.1731, -0.8226])\n",
      "betrayal\n",
      "Saved the embedding for betrayal.\n",
      "['betrayed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1085, 0.6864, 0.2213,  ..., 0.1368, 0.1585, 0.5657])\n",
      "betrayed\n",
      "Saved the embedding for betrayed.\n",
      "['bewildered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8112,  1.3062, -1.7108,  ...,  0.1621,  0.4475, -0.1844])\n",
      "bewildered\n",
      "Saved the embedding for bewildered.\n",
      "['be', '##wil', '##der', '##ment'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4730,  0.0356,  0.5797,  ..., -0.5610,  0.2092,  0.3411])\n",
      "bewilderment\n",
      "Saved the embedding for bewilderment.\n",
      "['bi'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3391,  1.2183,  0.3735,  ..., -0.8657, -0.0088, -0.5936])\n",
      "bi\n",
      "Saved the embedding for bi.\n",
      "['bi', '##lio', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0997,  0.3532,  0.6187,  ..., -0.0190,  0.3339,  0.0568])\n",
      "bilious\n",
      "Saved the embedding for bilious.\n",
      "['bit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4391,  0.3657,  0.5968,  ..., -0.2327, -0.0976,  0.6036])\n",
      "bit\n",
      "Saved the embedding for bit.\n",
      "['biting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3041,  1.7307, -1.5811,  ...,  0.1200,  0.8335,  0.2241])\n",
      "biting\n",
      "Saved the embedding for biting.\n",
      "['bitter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9163,  0.7726, -1.0458,  ...,  0.4722,  0.9244, -0.3626])\n",
      "bitter\n",
      "Saved the embedding for bitter.\n",
      "['bitter', '##sw', '##eet'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0018,  1.1003, -0.2432,  ..., -0.1282,  0.4291,  0.5007])\n",
      "bittersweet\n",
      "Saved the embedding for bittersweet.\n",
      "['blaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4080,  0.5695,  0.7930,  ...,  0.3166,  0.4158, -0.0803])\n",
      "blaming\n",
      "Saved the embedding for blaming.\n",
      "['bland'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5587,  0.8375, -0.5846,  ..., -0.3929,  0.3896, -0.9239])\n",
      "bland\n",
      "Saved the embedding for bland.\n",
      "['blank'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8144,  1.1382, -0.9271,  ...,  0.2921,  1.0462,  0.3342])\n",
      "blank\n",
      "Saved the embedding for blank.\n",
      "['b', '##lase'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0470,  0.0735,  0.1552,  ...,  0.6758,  0.5335,  0.2218])\n",
      "blase\n",
      "Saved the embedding for blase.\n",
      "['blazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7519,  1.1775, -1.2730,  ...,  0.6583,  0.8971,  0.5592])\n",
      "blazed\n",
      "Saved the embedding for blazed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bleak'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3195,  0.9115,  0.2979,  ..., -0.5004,  0.2403,  0.1353])\n",
      "bleak\n",
      "Saved the embedding for bleak.\n",
      "['b', '##lea', '##ry'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0228,  0.2114,  0.4803,  ...,  0.6304,  0.3375, -0.0791])\n",
      "bleary\n",
      "Saved the embedding for bleary.\n",
      "['blessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1708,  1.1632,  0.6687,  ..., -0.1502, -0.0342,  0.2539])\n",
      "blessed\n",
      "Saved the embedding for blessed.\n",
      "['blew'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4961,  0.2048,  0.1556,  ...,  0.7316,  0.6114, -0.0876])\n",
      "blew\n",
      "Saved the embedding for blew.\n",
      "['blinded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2569,  0.9436, -1.4358,  ...,  0.8699,  0.7966, -0.1648])\n",
      "blinded\n",
      "Saved the embedding for blinded.\n",
      "['blinds', '##ided'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1498,  0.7298, -0.1657,  ..., -0.0099,  0.8395, -0.5412])\n",
      "blindsided\n",
      "Saved the embedding for blindsided.\n",
      "['bliss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7797,  0.1400, -0.1432,  ..., -0.0753,  0.6017,  0.1805])\n",
      "bliss\n",
      "Saved the embedding for bliss.\n",
      "['bliss', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5228,  0.7588,  0.0698,  ..., -0.4663,  0.3159,  0.6847])\n",
      "blissful\n",
      "Saved the embedding for blissful.\n",
      "['bliss', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4502,  0.7330, -0.0652,  ..., -0.3558,  0.3186,  0.3781])\n",
      "blissfully\n",
      "Saved the embedding for blissfully.\n",
      "['b', '##lit', '##he'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3108,  0.1499,  0.2986,  ...,  0.1055,  0.4132,  0.6018])\n",
      "blithe\n",
      "Saved the embedding for blithe.\n",
      "['blown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1697,  0.8592, -0.0142,  ..., -0.0910,  0.4719, -0.2576])\n",
      "blown\n",
      "Saved the embedding for blown.\n",
      "['blue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0445,  0.6905, -0.3088,  ...,  0.6268,  0.0498,  0.5006])\n",
      "blue\n",
      "Saved the embedding for blue.\n",
      "['blues'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1453,  1.6742,  0.0200,  ..., -0.4057,  0.4207, -0.2562])\n",
      "blues\n",
      "Saved the embedding for blues.\n",
      "['bluff', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5003,  1.1055, -0.0048,  ...,  0.0256,  0.2270,  0.4499])\n",
      "bluffing\n",
      "Saved the embedding for bluffing.\n",
      "['blunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3459,  0.2688,  0.2269,  ..., -0.1176, -0.1855, -0.3409])\n",
      "blunt\n",
      "Saved the embedding for blunt.\n",
      "['blushing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0015,  1.2442, -0.3624,  ...,  0.4317, -0.1921,  0.3248])\n",
      "blushing\n",
      "Saved the embedding for blushing.\n",
      "['blu', '##ster', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0852,  0.4650, -0.3356,  ...,  0.4769,  0.0543,  0.5361])\n",
      "blustering\n",
      "Saved the embedding for blustering.\n",
      "['bo', '##ast', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5170,  1.1798,  0.8088,  ..., -0.3102, -0.1859,  0.2248])\n",
      "boastful\n",
      "Saved the embedding for boastful.\n",
      "['bog', '##gled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5050,  0.1374,  0.3050,  ...,  0.0732,  0.5370,  0.0331])\n",
      "boggled\n",
      "Saved the embedding for boggled.\n",
      "['boiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2824,  0.5099, -0.4703,  ...,  1.3756,  0.3351,  0.8462])\n",
      "boiling\n",
      "Saved the embedding for boiling.\n",
      "['bois', '##ter', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8478,  0.1978,  0.6936,  ...,  0.0951, -0.0321,  0.6002])\n",
      "boisterous\n",
      "Saved the embedding for boisterous.\n",
      "['bold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3319,  0.1998,  0.1634,  ...,  0.6559, -0.2710, -0.4237])\n",
      "bold\n",
      "Saved the embedding for bold.\n",
      "['bored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1512,  1.2812, -0.6718,  ..., -0.3088,  0.4412, -0.2555])\n",
      "bored\n",
      "Saved the embedding for bored.\n",
      "['boredom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2513,  0.8918, -1.3842,  ..., -0.1771,  0.3132, -0.9354])\n",
      "boredom\n",
      "Saved the embedding for boredom.\n",
      "['boring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3788,  0.3831, -0.8364,  ...,  0.2253,  0.4881, -0.5696])\n",
      "boring\n",
      "Saved the embedding for boring.\n",
      "['bothered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2407,  0.1779, -0.5171,  ..., -0.3911,  0.0125, -0.1638])\n",
      "bothered\n",
      "Saved the embedding for bothered.\n",
      "['bound', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4396,  1.2705, -0.2051,  ..., -0.3839,  0.4134, -0.8590])\n",
      "bounder\n",
      "Saved the embedding for bounder.\n",
      "['bra', '##sh', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0842,  0.8752,  0.0398,  ..., -0.2713, -0.0879, -0.3879])\n",
      "brashness\n",
      "Saved the embedding for brashness.\n",
      "['brat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5531,  0.8678, -0.5193,  ...,  0.4186,  0.4699, -0.1332])\n",
      "bratty\n",
      "Saved the embedding for bratty.\n",
      "['brave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2558,  0.2728,  0.2237,  ...,  0.3862, -0.0875,  0.0677])\n",
      "brave\n",
      "Saved the embedding for brave.\n",
      "['bright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2156,  1.7012, -0.5549,  ...,  0.0555,  0.2726, -0.4622])\n",
      "bright\n",
      "Saved the embedding for bright.\n",
      "['br', '##ist', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6715,  0.3066, -0.5149,  ...,  0.0824,  0.5266,  0.3592])\n",
      "bristling\n",
      "Saved the embedding for bristling.\n",
      "['broken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1645,  0.8080, -1.1704,  ...,  0.0240,  0.5289, -0.9649])\n",
      "broken\n",
      "Saved the embedding for broken.\n",
      "['broken', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3774,  0.4434,  0.2274,  ...,  0.1321, -0.0365,  0.4347])\n",
      "brokenhearted\n",
      "Saved the embedding for brokenhearted.\n",
      "['broken', '##hearted', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6141,  0.3515,  0.3641,  ..., -0.1427, -0.0718,  0.1499])\n",
      "brokenheartedly\n",
      "Saved the embedding for brokenheartedly.\n",
      "['brooding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1307,  0.5445, -0.9054,  ..., -0.4874,  0.5720, -0.5227])\n",
      "brooding\n",
      "Saved the embedding for brooding.\n",
      "['brood', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6897,  0.9732, -0.1439,  ..., -0.2269, -0.0524, -0.2379])\n",
      "broody\n",
      "Saved the embedding for broody.\n",
      "['bruised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3714,  0.9391, -0.8867,  ..., -0.0991,  0.1034, -0.3162])\n",
      "bruised\n",
      "Saved the embedding for bruised.\n",
      "['br', '##us', '##que'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.4087,  0.5883,  0.0934,  ..., -0.2383,  0.3113,  0.5859])\n",
      "brusque\n",
      "Saved the embedding for brusque.\n",
      "['bug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1859,  0.1242,  0.2072,  ..., -0.6768, -0.2059,  0.0681])\n",
      "bug\n",
      "Saved the embedding for bug.\n",
      "['bulging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5899,  1.0004, -0.9234,  ..., -0.2976,  0.6867, -0.5155])\n",
      "bulging\n",
      "Saved the embedding for bulging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6445,  0.6519, -0.5022,  ...,  0.0869, -0.1163, -0.8137])\n",
      "bully\n",
      "Saved the embedding for bully.\n",
      "['bullying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1923,  0.1629,  0.6417,  ...,  0.4834,  0.3485, -0.0838])\n",
      "bullying\n",
      "Saved the embedding for bullying.\n",
      "['bum', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7655,  0.1802,  0.4196,  ...,  0.2805, -0.0769,  0.0932])\n",
      "bummed\n",
      "Saved the embedding for bummed.\n",
      "['bu', '##oya', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2820,  0.5009,  0.3915,  ...,  0.1794, -0.1943,  0.1084])\n",
      "buoyant\n",
      "Saved the embedding for buoyant.\n",
      "['burden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3671,  0.9289, -0.2373,  ...,  0.2780,  0.4175,  0.2597])\n",
      "burdened\n",
      "Saved the embedding for burdened.\n",
      "['burn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5557, -0.4154,  1.0058,  ..., -0.8330,  0.1395,  0.4172])\n",
      "burn\n",
      "Saved the embedding for burn.\n",
      "['bursting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0353,  0.0177,  0.0019,  ...,  0.0615,  0.1709, -0.1029])\n",
      "bursting\n",
      "Saved the embedding for bursting.\n",
      "['bush', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2180,  1.1403, -1.0681,  ..., -0.1103,  0.6290, -0.2962])\n",
      "bushed\n",
      "Saved the embedding for bushed.\n",
      "['cage', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0926,  1.4366, -0.2754,  ...,  0.7197,  0.1333,  0.0018])\n",
      "cagey\n",
      "Saved the embedding for cagey.\n",
      "['ca', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0667,  0.4672, -0.6245,  ...,  0.6289,  0.9538, -0.0706])\n",
      "cagy\n",
      "Saved the embedding for cagy.\n",
      "['calculating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6291,  1.2932,  0.3371,  ...,  0.1196,  0.5679,  0.1586])\n",
      "calculating\n",
      "Saved the embedding for calculating.\n",
      "['call', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3481,  0.7085,  0.4646,  ..., -0.3030, -0.0746,  0.3186])\n",
      "callous\n",
      "Saved the embedding for callous.\n",
      "['call', '##used'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1322,  0.6307,  0.4919,  ..., -0.3746, -0.1405,  0.2667])\n",
      "callused\n",
      "Saved the embedding for callused.\n",
      "['calm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5109,  0.5728, -1.1138,  ...,  0.3050,  0.9180, -0.1699])\n",
      "calm\n",
      "Saved the embedding for calm.\n",
      "['calming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2523,  1.3841, -0.5693,  ..., -0.2082,  0.0461,  0.4916])\n",
      "calming\n",
      "Saved the embedding for calming.\n",
      "['calm', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0656,  0.4176,  0.3133,  ..., -0.2085,  0.0689,  0.2107])\n",
      "calmness\n",
      "Saved the embedding for calmness.\n",
      "['can', '##ny'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2891, -0.5258,  0.1790,  ...,  0.8178,  0.9274,  0.3348])\n",
      "canny\n",
      "Saved the embedding for canny.\n",
      "['can', '##tan', '##ker', '##ous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.7286,  0.2449,  0.0620,  ...,  0.0896,  0.0523, -0.4442])\n",
      "cantankerous\n",
      "Saved the embedding for cantankerous.\n",
      "['capable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4563,  1.3866,  0.7591,  ..., -0.1839,  0.4396,  0.5389])\n",
      "capable\n",
      "Saved the embedding for capable.\n",
      "['cap', '##ric', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3748,  0.2582, -0.1227,  ...,  0.2338, -0.3709, -0.0795])\n",
      "capricious\n",
      "Saved the embedding for capricious.\n",
      "['capt', '##ivated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1422, -0.5457, -0.0015,  ...,  0.2703,  0.2593,  0.3212])\n",
      "captivated\n",
      "Saved the embedding for captivated.\n",
      "['captive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1283,  0.8248,  0.0100,  ..., -0.0949,  0.8492, -0.0724])\n",
      "captive\n",
      "Saved the embedding for captive.\n",
      "['care', '##free'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1555,  0.4331,  0.1420,  ...,  0.6299, -0.2690, -0.1371])\n",
      "carefree\n",
      "Saved the embedding for carefree.\n",
      "['careful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2067,  0.7704, -1.0420,  ..., -0.0858,  0.5298, -0.2205])\n",
      "careful\n",
      "Saved the embedding for careful.\n",
      "['careless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2671,  1.2889,  0.4189,  ...,  0.2433, -0.0285,  0.3151])\n",
      "careless\n",
      "Saved the embedding for careless.\n",
      "['caring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9033,  0.8703,  0.6536,  ...,  0.5239, -0.1807,  0.7774])\n",
      "caring\n",
      "Saved the embedding for caring.\n",
      "['cat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3816,  0.4068, -0.4524,  ...,  0.7115,  0.5196,  0.6569])\n",
      "catty\n",
      "Saved the embedding for catty.\n",
      "['ca', '##ust', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1447,  1.1595, -0.0051,  ...,  0.0758,  0.5298,  0.0802])\n",
      "caustic\n",
      "Saved the embedding for caustic.\n",
      "['caution', '##ary'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1553,  0.4004,  0.1037,  ..., -0.4684,  0.5000, -0.3215])\n",
      "cautionary\n",
      "Saved the embedding for cautionary.\n",
      "['cautious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7877,  0.7286,  0.4271,  ..., -0.9663,  0.9830, -0.2801])\n",
      "cautious\n",
      "Saved the embedding for cautious.\n",
      "['cavalier'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1779,  0.2240, -0.1772,  ...,  0.1714,  0.2186,  0.6058])\n",
      "cavalier\n",
      "Saved the embedding for cavalier.\n",
      "['celebrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4930,  1.7304, -0.0141,  ...,  0.6429, -0.1369, -0.5246])\n",
      "celebrating\n",
      "Saved the embedding for celebrating.\n",
      "['celebration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4523,  1.3691,  0.1683,  ...,  0.9805, -0.0563,  0.1095])\n",
      "celebration\n",
      "Saved the embedding for celebration.\n",
      "['ce', '##ns', '##ure'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.1462, 0.7300, 0.4975,  ..., 0.2666, 0.0325, 0.1772])\n",
      "censure\n",
      "Saved the embedding for censure.\n",
      "['centered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2358,  0.2226, -0.7723,  ...,  0.8295, -0.6313, -0.0233])\n",
      "centered\n",
      "Saved the embedding for centered.\n",
      "['certain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6178,  0.2750, -1.3048,  ...,  0.2899,  0.4003, -0.4150])\n",
      "certain\n",
      "Saved the embedding for certain.\n",
      "['cha', '##fed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1081,  0.3192,  0.0401,  ..., -0.0103, -0.1959,  0.2940])\n",
      "chafed\n",
      "Saved the embedding for chafed.\n",
      "['cha', '##grin'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2111, -0.0321,  0.2191,  ..., -0.2206, -0.1352,  0.7642])\n",
      "chagrin\n",
      "Saved the embedding for chagrin.\n",
      "['cha', '##grin', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2505,  1.0434,  0.2847,  ..., -0.3257,  0.5341,  0.2154])\n",
      "chagrined\n",
      "Saved the embedding for chagrined.\n",
      "['cha', '##grin', '##ned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3809,  0.9789,  0.3485,  ..., -0.4924,  0.3214,  0.1826])\n",
      "chagrinned\n",
      "Saved the embedding for chagrinned.\n",
      "['challenge'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4493,  0.3854,  0.5386,  ..., -0.0886,  0.1550,  0.7136])\n",
      "challenge\n",
      "Saved the embedding for challenge.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['challenged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4743,  0.8378,  0.8892,  ..., -0.7966,  0.0898,  0.3938])\n",
      "challenged\n",
      "Saved the embedding for challenged.\n",
      "['challenging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.6186,  0.9499, -0.0335,  ...,  0.2596,  0.0946,  0.8002])\n",
      "challenging\n",
      "Saved the embedding for challenging.\n",
      "['chaotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4627,  0.6195, -1.1992,  ...,  0.2740, -0.1896,  0.1575])\n",
      "chaotic\n",
      "Saved the embedding for chaotic.\n",
      "['charged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2144, 0.7838, 0.1377,  ..., 0.6658, 1.6130, 0.2878])\n",
      "charged\n",
      "Saved the embedding for charged.\n",
      "['charm', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1085,  0.1037,  0.3298,  ..., -0.4108,  0.1351,  0.0092])\n",
      "charmed\n",
      "Saved the embedding for charmed.\n",
      "['charming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4031,  1.0677,  1.0014,  ..., -0.2204, -0.0932,  0.4028])\n",
      "charming\n",
      "Saved the embedding for charming.\n",
      "['char', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1073,  0.6179, -0.2262,  ...,  0.2896,  0.2353,  0.7549])\n",
      "chary\n",
      "Saved the embedding for chary.\n",
      "['cheated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5933,  0.6598,  0.2219,  ...,  0.0426, -0.5329, -0.7632])\n",
      "cheated\n",
      "Saved the embedding for cheated.\n",
      "['cheek', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1378,  0.9535, -0.1859,  ...,  0.6722,  0.4862,  0.0638])\n",
      "cheeky\n",
      "Saved the embedding for cheeky.\n",
      "['cheered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5706,  0.1910,  0.3991,  ...,  0.4309,  0.4813, -0.8656])\n",
      "cheered\n",
      "Saved the embedding for cheered.\n",
      "['cheerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7526,  0.8498,  0.0947,  ...,  0.0742,  0.1785, -0.3198])\n",
      "cheerful\n",
      "Saved the embedding for cheerful.\n",
      "['cheering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0693,  1.1658,  0.5470,  ...,  0.3852, -0.0412,  0.0229])\n",
      "cheering\n",
      "Saved the embedding for cheering.\n",
      "['cheer', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0014,  1.2452,  0.8210,  ...,  0.1596, -0.0022,  0.1699])\n",
      "cheerless\n",
      "Saved the embedding for cheerless.\n",
      "['cheer', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0463,  1.1055,  0.1083,  ...,  0.6152, -0.0630,  0.0981])\n",
      "cheery\n",
      "Saved the embedding for cheery.\n",
      "['che', '##es', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4363,  0.4993, -0.0339,  ..., -0.1129,  0.2217,  0.2780])\n",
      "cheesy\n",
      "Saved the embedding for cheesy.\n",
      "['chest', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2745,  0.4364, -0.3060,  ...,  0.0382,  0.2604,  0.4950])\n",
      "chesty\n",
      "Saved the embedding for chesty.\n",
      "['chi', '##de'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1818,  0.9036, -0.7055,  ...,  0.6598,  0.7007, -0.4017])\n",
      "chide\n",
      "Saved the embedding for chide.\n",
      "['chi', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6472,  0.8909, -0.1426,  ...,  0.6668,  0.6746, -0.4108])\n",
      "chiding\n",
      "Saved the embedding for chiding.\n",
      "['childish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4677,  0.3410, -0.5191,  ..., -0.0312, -0.0616, -0.2449])\n",
      "childish\n",
      "Saved the embedding for childish.\n",
      "['childish', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6660,  0.5584,  0.5430,  ...,  0.3223, -0.3179,  0.1913])\n",
      "childishly\n",
      "Saved the embedding for childishly.\n",
      "['child', '##like'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4114,  0.7337,  0.0470,  ...,  0.1873,  0.0722, -0.0999])\n",
      "childlike\n",
      "Saved the embedding for childlike.\n",
      "['chill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7145, -0.6666, -1.0540,  ..., -0.1034,  0.1209,  0.1413])\n",
      "chill\n",
      "Saved the embedding for chill.\n",
      "['chilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1761,  0.9167, -0.3563,  ..., -0.5824,  0.8565, -0.6235])\n",
      "chilled\n",
      "Saved the embedding for chilled.\n",
      "['chilling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6723,  1.1741, -0.2893,  ..., -0.6521,  0.5768, -0.7312])\n",
      "chilling\n",
      "Saved the embedding for chilling.\n",
      "['chip', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.2065,  0.5404,  0.2020,  ...,  0.1515,  0.0094,  0.6924])\n",
      "chipper\n",
      "Saved the embedding for chipper.\n",
      "['chi', '##rp', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2717,  1.3230, -0.6965,  ...,  0.1711,  0.1504, -0.2566])\n",
      "chirpy\n",
      "Saved the embedding for chirpy.\n",
      "['cho', '##ler', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3029,  0.4407,  0.0699,  ..., -0.2991,  0.3594,  0.5250])\n",
      "choleric\n",
      "Saved the embedding for choleric.\n",
      "['cho', '##rt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7457, -0.3802, -0.1798,  ...,  0.3286,  0.7861,  0.2208])\n",
      "chortling\n",
      "Saved the embedding for chortling.\n",
      "['chuckle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0593,  0.5011, -1.3814,  ..., -0.1855, -0.1754, -0.3455])\n",
      "chuckle\n",
      "Saved the embedding for chuckle.\n",
      "['chuck', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5475,  0.9632, -0.3097,  ...,  0.5754,  0.8153,  0.2973])\n",
      "chuckling\n",
      "Saved the embedding for chuckling.\n",
      "['chu', '##rl', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5599,  0.2658,  0.7702,  ...,  0.0916,  0.0992,  0.4231])\n",
      "churlish\n",
      "Saved the embedding for churlish.\n",
      "['ci', '##rc', '##ums', '##pe', '##ct'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([0.5657, 0.0831, 0.7344,  ..., 0.0540, 0.1211, 0.3352])\n",
      "circumspect\n",
      "Saved the embedding for circumspect.\n",
      "['cl', '##amo', '##rous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0830,  0.0176, -0.1634,  ..., -0.7012,  0.3933,  0.0634])\n",
      "clamorous\n",
      "Saved the embedding for clamorous.\n",
      "['clash'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0486,  0.5577, -0.7411,  ...,  0.0963,  0.5418, -0.2661])\n",
      "clash\n",
      "Saved the embedding for clash.\n",
      "['clear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7053,  0.9294, -0.6890,  ..., -0.1686,  0.6938,  0.0321])\n",
      "clear\n",
      "Saved the embedding for clear.\n",
      "['clenched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0479,  0.7613, -0.6126,  ...,  0.3953,  0.5522,  0.1562])\n",
      "clenched\n",
      "Saved the embedding for clenched.\n",
      "['clever'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6347,  0.9951,  0.3800,  ..., -0.4019,  0.2220,  0.2338])\n",
      "clever\n",
      "Saved the embedding for clever.\n",
      "['close'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3027,  0.7393, -0.6887,  ...,  0.7475,  0.5837,  0.0702])\n",
      "close\n",
      "Saved the embedding for close.\n",
      "['closed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0334,  1.5844, -0.9113,  ..., -0.4511,  0.8442, -0.0648])\n",
      "closed\n",
      "Saved the embedding for closed.\n",
      "['close', '##mouth', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3003,  0.7104,  0.6496,  ..., -0.4398,  0.0994,  0.1305])\n",
      "closemouthed\n",
      "Saved the embedding for closemouthed.\n",
      "['cl', '##oy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.2105,  0.1216, -0.2469,  ...,  0.6019,  0.6454, -0.3639])\n",
      "cloy\n",
      "Saved the embedding for cloy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clue', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5456, -0.2245,  0.0973,  ...,  0.2026,  0.0098,  0.1088])\n",
      "clueless\n",
      "Saved the embedding for clueless.\n",
      "['clutched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8435,  0.4977, -1.5067,  ...,  0.4988,  1.3342, -0.3034])\n",
      "clutched\n",
      "Saved the embedding for clutched.\n",
      "['cl', '##uttered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5600,  0.2962, -0.1853,  ..., -0.4170,  0.2542, -0.0473])\n",
      "cluttered\n",
      "Saved the embedding for cluttered.\n",
      "['cock', '##eye', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2508,  0.7483, -0.3578,  ..., -0.1509, -0.0876, -0.1811])\n",
      "cockeyed\n",
      "Saved the embedding for cockeyed.\n",
      "['cock', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2752,  0.3661,  0.4629,  ..., -0.3333,  0.0814,  0.6261])\n",
      "cockiness\n",
      "Saved the embedding for cockiness.\n",
      "['cock', '##sure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0517,  0.5716, -0.2563,  ...,  0.5741,  0.0422,  0.4161])\n",
      "cocksure\n",
      "Saved the embedding for cocksure.\n",
      "['cocky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6198,  0.9731, -0.2214,  ...,  0.2000, -0.2483, -0.2613])\n",
      "cocky\n",
      "Saved the embedding for cocky.\n",
      "['co', '##gni', '##zan', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3774, -0.3409,  0.7707,  ...,  0.2568,  0.0790,  0.4670])\n",
      "cognizant\n",
      "Saved the embedding for cognizant.\n",
      "['cold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.7196,  0.8156, -1.1615,  ...,  0.7191,  0.6020, -0.1244])\n",
      "cold\n",
      "Saved the embedding for cold.\n",
      "['collected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9795,  0.7794,  0.0807,  ...,  0.9037, -0.2920,  0.0695])\n",
      "collected\n",
      "Saved the embedding for collected.\n",
      "['col', '##lus', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4625,  0.0037, -0.0625,  ..., -0.0740,  0.5446,  0.2080])\n",
      "collusive\n",
      "Saved the embedding for collusive.\n",
      "['colon', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8427,  0.6655, -0.3474,  ..., -0.2996,  0.0031,  0.9325])\n",
      "colonized\n",
      "Saved the embedding for colonized.\n",
      "['combat', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6980,  1.0126,  0.8096,  ...,  0.0896,  0.2086,  0.2380])\n",
      "combative\n",
      "Saved the embedding for combative.\n",
      "['comedic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3866,  0.3600, -0.6774,  ...,  0.3717,  0.5127, -0.3381])\n",
      "comedic\n",
      "Saved the embedding for comedic.\n",
      "['comfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3458,  0.9364,  0.3008,  ..., -0.6934, -0.4207, -0.2283])\n",
      "comfort\n",
      "Saved the embedding for comfort.\n",
      "['comfortable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3083,  0.4867, -0.9203,  ...,  0.2407, -0.0128,  0.1097])\n",
      "comfortable\n",
      "Saved the embedding for comfortable.\n",
      "['comfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3556,  0.7828,  0.2885,  ..., -0.3158,  0.0353, -0.2816])\n",
      "comforted\n",
      "Saved the embedding for comforted.\n",
      "['comical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5252,  1.5117, -0.5811,  ...,  0.2870,  0.2322,  0.1085])\n",
      "comical\n",
      "Saved the embedding for comical.\n",
      "['commanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2695,  1.1658, -1.1571,  ...,  0.3783, -0.4668, -0.5347])\n",
      "commanding\n",
      "Saved the embedding for commanding.\n",
      "['com', '##mise', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8293, -0.1152,  0.8194,  ..., -0.2991,  0.7159,  0.5879])\n",
      "commiserating\n",
      "Saved the embedding for commiserating.\n",
      "['com', '##mise', '##rative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6961, -0.1768,  0.0181,  ...,  0.3201,  0.4730,  0.6918])\n",
      "commiserative\n",
      "Saved the embedding for commiserative.\n",
      "['com', '##mun', '##icative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4368, -0.5095, -0.0039,  ..., -0.3234,  0.5797,  0.7791])\n",
      "communicative\n",
      "Saved the embedding for communicative.\n",
      "['compassion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0421,  1.1208, -0.3535,  ...,  0.2958,  0.0345,  0.4423])\n",
      "compassion\n",
      "Saved the embedding for compassion.\n",
      "['compassionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4396,  0.5783, -0.6190,  ...,  0.4506,  0.2891,  0.0302])\n",
      "compassionate\n",
      "Saved the embedding for compassionate.\n",
      "['competent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1036,  1.2323, -0.5382,  ..., -0.0054,  0.0951, -0.1342])\n",
      "competent\n",
      "Saved the embedding for competent.\n",
      "['competitive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2972,  0.4555, -0.1544,  ..., -0.1544,  0.5334,  0.5924])\n",
      "competitive\n",
      "Saved the embedding for competitive.\n",
      "['com', '##pl', '##ace', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5500, -0.5406,  0.1004,  ...,  0.7054,  0.8214,  1.0163])\n",
      "complacence\n",
      "Saved the embedding for complacence.\n",
      "['com', '##pl', '##ace', '##ncy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4091, -0.0207,  0.3886,  ...,  0.1484,  0.7368,  0.6761])\n",
      "complacency\n",
      "Saved the embedding for complacency.\n",
      "['com', '##pl', '##ace', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3786,  0.0029,  0.3525,  ...,  0.1939,  0.5686,  1.1100])\n",
      "complacent\n",
      "Saved the embedding for complacent.\n",
      "['com', '##pl', '##ace', '##ntly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4191, -0.4103,  0.4224,  ..., -0.1132,  1.1929,  0.6526])\n",
      "complacently\n",
      "Saved the embedding for complacently.\n",
      "['complain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1107,  0.9280,  0.8325,  ..., -0.3318,  0.3785,  0.5346])\n",
      "complain\n",
      "Saved the embedding for complain.\n",
      "['complaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1142,  0.9290, -1.1979,  ...,  0.9442,  0.6298, -0.0936])\n",
      "complaining\n",
      "Saved the embedding for complaining.\n",
      "['composed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0698,  0.6397, -1.5115,  ...,  0.5836,  0.1043, -0.3477])\n",
      "composed\n",
      "Saved the embedding for composed.\n",
      "['comprehend', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4923,  1.1302, -0.0026,  ...,  0.2684,  0.4512,  0.4534])\n",
      "comprehending\n",
      "Saved the embedding for comprehending.\n",
      "['com', '##pu', '##ls', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3009,  0.0685,  0.2188,  ..., -0.0303,  0.0771,  0.4319])\n",
      "compulsive\n",
      "Saved the embedding for compulsive.\n",
      "['concealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1004,  0.2469, -0.2948,  ...,  0.3972,  0.6533, -0.1727])\n",
      "concealed\n",
      "Saved the embedding for concealed.\n",
      "['con', '##ced', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8854,  0.3085,  0.6946,  ...,  0.0614, -0.0109,  0.4817])\n",
      "conceding\n",
      "Saved the embedding for conceding.\n",
      "['con', '##ce', '##ited'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0809,  0.1590,  0.6563,  ..., -0.0185,  0.2095,  0.7213])\n",
      "conceited\n",
      "Saved the embedding for conceited.\n",
      "['concentrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2768,  0.6559, -1.3963,  ..., -0.1511,  1.0662, -0.0500])\n",
      "concentrated\n",
      "Saved the embedding for concentrated.\n",
      "['concentrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6776, -0.0455, -0.7318,  ...,  0.8021,  0.3062,  0.0171])\n",
      "concentrating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for concentrating.\n",
      "['concentration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1136,  1.2601,  0.7379,  ..., -0.5347,  0.4327, -0.1867])\n",
      "concentration\n",
      "Saved the embedding for concentration.\n",
      "['concern'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6477,  0.6747,  0.4007,  ..., -0.1915,  0.0203,  0.0810])\n",
      "concern\n",
      "Saved the embedding for concern.\n",
      "['concerned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3162,  1.2216,  0.3536,  ...,  0.0479, -0.0382,  0.0238])\n",
      "concerned\n",
      "Saved the embedding for concerned.\n",
      "['con', '##ci', '##lia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6146,  0.1092,  0.6218,  ...,  0.1498, -0.0593,  0.7261])\n",
      "conciliatory\n",
      "Saved the embedding for conciliatory.\n",
      "['con', '##clusive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5662,  0.8234,  0.6196,  ...,  0.2247,  0.1693,  1.0915])\n",
      "conclusive\n",
      "Saved the embedding for conclusive.\n",
      "['condemning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0856,  0.9473,  0.6625,  ..., -0.4802,  0.3651, -0.0702])\n",
      "condemning\n",
      "Saved the embedding for condemning.\n",
      "['conde', '##sc', '##ending'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0655,  1.0417, -0.6946,  ..., -0.5080,  0.5340, -0.6377])\n",
      "condescending\n",
      "Saved the embedding for condescending.\n",
      "['condo', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1423,  1.7032, -0.0951,  ..., -0.3513,  0.5207,  0.0578])\n",
      "condoling\n",
      "Saved the embedding for condoling.\n",
      "['confidence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2076,  0.5963, -0.0353,  ...,  0.5459,  0.2302,  0.1153])\n",
      "confidence\n",
      "Saved the embedding for confidence.\n",
      "['confident'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8217,  0.5457,  0.2017,  ..., -0.0457,  0.3127, -0.3881])\n",
      "confident\n",
      "Saved the embedding for confident.\n",
      "['confidently'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7150,  0.1275, -0.4315,  ..., -0.4638,  0.4629, -0.3597])\n",
      "confidently\n",
      "Saved the embedding for confidently.\n",
      "['conflict', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2294,  0.6220,  0.4688,  ...,  0.2411,  0.3719,  0.5997])\n",
      "conflicted\n",
      "Saved the embedding for conflicted.\n",
      "['con', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0714,  0.6483,  0.8939,  ...,  0.3820,  0.1949,  0.5298])\n",
      "confound\n",
      "Saved the embedding for confound.\n",
      "['con', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1616,  0.8504,  0.3653,  ..., -0.2414,  0.1257,  0.1990])\n",
      "confounded\n",
      "Saved the embedding for confounded.\n",
      "['confrontation', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4359,  1.3563, -0.3679,  ..., -0.0148,  0.0700,  0.1891])\n",
      "confrontational\n",
      "Saved the embedding for confrontational.\n",
      "['confused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0864,  1.8922, -1.5779,  ...,  0.3296, -0.1929, -0.3156])\n",
      "confused\n",
      "Saved the embedding for confused.\n",
      "['confusion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0023,  0.7967, -0.8280,  ..., -0.3112,  0.8892, -0.3829])\n",
      "confusion\n",
      "Saved the embedding for confusion.\n",
      "['cong', '##enia', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6667,  1.1571, -0.6487,  ..., -0.1635,  0.6647,  0.4078])\n",
      "congenial\n",
      "Saved the embedding for congenial.\n",
      "['cong', '##rat', '##ulator', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3410,  0.9482, -0.0980,  ..., -0.0573,  0.0110,  0.6516])\n",
      "congratulatory\n",
      "Saved the embedding for congratulatory.\n",
      "['con', '##ni', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6339,  1.1156,  0.0638,  ...,  0.2424,  0.2351,  0.1012])\n",
      "conniving\n",
      "Saved the embedding for conniving.\n",
      "['conscious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1834,  1.5917, -0.1519,  ...,  0.0563,  0.7034, -0.1926])\n",
      "conscious\n",
      "Saved the embedding for conscious.\n",
      "['conservative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1520,  1.9494,  0.3859,  ...,  0.3905, -0.3231, -0.1498])\n",
      "conservative\n",
      "Saved the embedding for conservative.\n",
      "['consider', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1672,  0.6873,  0.1818,  ...,  0.3646,  0.5253,  0.6187])\n",
      "considerate\n",
      "Saved the embedding for considerate.\n",
      "['considering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5122,  0.7198, -1.0816,  ...,  0.2493,  0.4306, -0.2555])\n",
      "considering\n",
      "Saved the embedding for considering.\n",
      "['con', '##sol', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2299,  1.0590,  0.1813,  ...,  0.1331, -0.1673, -0.0426])\n",
      "consoling\n",
      "Saved the embedding for consoling.\n",
      "['con', '##sp', '##ira', '##tori', '##al'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2598,  0.0824,  0.4972,  ...,  0.0463, -0.1055,  0.3614])\n",
      "conspiratorial\n",
      "Saved the embedding for conspiratorial.\n",
      "['con', '##sp', '##iring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2201,  0.5690,  0.7273,  ..., -0.2306, -0.5073, -0.0258])\n",
      "conspiring\n",
      "Saved the embedding for conspiring.\n",
      "['con', '##ster', '##nation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1763,  1.1959,  0.6092,  ...,  0.3658,  0.0619,  0.6229])\n",
      "consternation\n",
      "Saved the embedding for consternation.\n",
      "['con', '##sti', '##pate', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2969,  0.6749,  0.5516,  ..., -0.2161,  0.2646,  0.4885])\n",
      "constipated\n",
      "Saved the embedding for constipated.\n",
      "['constrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0777,  0.7588,  0.5362,  ..., -0.4981,  0.0155,  0.1742])\n",
      "constrained\n",
      "Saved the embedding for constrained.\n",
      "['consumed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2942,  1.1376, -1.9842,  ...,  0.3380,  1.2951, -0.4111])\n",
      "consumed\n",
      "Saved the embedding for consumed.\n",
      "['consuming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9831,  0.7451, -0.9368,  ...,  0.5416,  0.7150, -0.5676])\n",
      "consuming\n",
      "Saved the embedding for consuming.\n",
      "['contained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6801,  0.7493, -1.8937,  ...,  1.0701,  0.3841, -0.1869])\n",
      "contained\n",
      "Saved the embedding for contained.\n",
      "['con', '##tem', '##plate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7685,  0.7230,  0.6536,  ...,  0.3444, -0.0541,  0.6986])\n",
      "contemplate\n",
      "Saved the embedding for contemplate.\n",
      "['contemplating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1809,  0.8526, -0.6040,  ..., -0.3989,  0.2098, -0.4388])\n",
      "contemplating\n",
      "Saved the embedding for contemplating.\n",
      "['con', '##tem', '##pl', '##ation'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5367,  0.7282, -0.1173,  ..., -0.0721, -0.1912, -0.5861])\n",
      "contemplation\n",
      "Saved the embedding for contemplation.\n",
      "['con', '##tem', '##pl', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6880,  0.8288,  0.4524,  ..., -0.2446, -0.1479,  0.0976])\n",
      "contemplative\n",
      "Saved the embedding for contemplative.\n",
      "['contempt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1193,  0.5861,  0.6070,  ..., -0.0491,  0.2604,  0.0776])\n",
      "contempt\n",
      "Saved the embedding for contempt.\n",
      "['contempt', '##uous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1753,  1.4606,  0.8583,  ..., -0.4706,  0.1454,  0.8201])\n",
      "contemptuous\n",
      "Saved the embedding for contemptuous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2950, 0.7161, 0.3305,  ..., 0.0113, 0.0264, 0.5069])\n",
      "content\n",
      "Saved the embedding for content.\n",
      "['content', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0065,  0.3377,  0.4948,  ...,  0.0506,  0.1250,  0.4780])\n",
      "contented\n",
      "Saved the embedding for contented.\n",
      "['contentious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1645,  1.1819, -0.9429,  ...,  0.0278,  0.0344, -0.6342])\n",
      "contentious\n",
      "Saved the embedding for contentious.\n",
      "['content', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1971,  0.9866,  0.4541,  ..., -0.2194, -0.0935,  0.1753])\n",
      "contently\n",
      "Saved the embedding for contently.\n",
      "['content', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1748,  0.4974,  0.4697,  ...,  0.0829,  0.2005,  0.4189])\n",
      "contentment\n",
      "Saved the embedding for contentment.\n",
      "['contradictory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8307,  1.1851, -0.3662,  ...,  0.1271,  0.4276, -0.6303])\n",
      "contradictory\n",
      "Saved the embedding for contradictory.\n",
      "['contrary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6375, -0.0178, -0.1515,  ...,  0.4113,  0.1962,  0.4810])\n",
      "contrary\n",
      "Saved the embedding for contrary.\n",
      "['con', '##tri', '##te'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6782,  0.5017,  0.6273,  ...,  0.2705,  0.2653,  0.4810])\n",
      "contrite\n",
      "Saved the embedding for contrite.\n",
      "['controlled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5820,  1.0976, -0.0418,  ...,  0.1576,  0.3300,  0.3098])\n",
      "controlled\n",
      "Saved the embedding for controlled.\n",
      "['controlling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7732,  0.0130, -0.6431,  ...,  0.6364,  0.9937,  0.5975])\n",
      "controlling\n",
      "Saved the embedding for controlling.\n",
      "['controversial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7438,  1.7973, -0.7079,  ..., -0.7648,  0.0490, -1.1788])\n",
      "controversial\n",
      "Saved the embedding for controversial.\n",
      "['con', '##tum', '##acious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4695,  0.7718,  0.3156,  ..., -0.3979, -0.0968,  0.2927])\n",
      "contumacious\n",
      "Saved the embedding for contumacious.\n",
      "['convinced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8741,  1.2328, -0.6174,  ...,  0.4164,  0.4209,  0.2491])\n",
      "convinced\n",
      "Saved the embedding for convinced.\n",
      "['cool'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7497,  0.8094, -0.2911,  ...,  0.3823,  0.0127,  0.3514])\n",
      "cool\n",
      "Saved the embedding for cool.\n",
      "['cooperative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9454,  0.8296, -0.3148,  ..., -0.1737,  0.6546,  0.0619])\n",
      "cooperative\n",
      "Saved the embedding for cooperative.\n",
      "['cord', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0828,  0.5557, -1.0392,  ...,  0.1233,  0.3806, -0.0846])\n",
      "cordial\n",
      "Saved the embedding for cordial.\n",
      "['courageous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9039, -0.0121, -0.2776,  ...,  0.3610, -0.1650,  0.5995])\n",
      "courageous\n",
      "Saved the embedding for courageous.\n",
      "['covert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0783,  1.3529, -1.0452,  ..., -0.1879,  1.0364, -0.2747])\n",
      "covert\n",
      "Saved the embedding for covert.\n",
      "['coward', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0180,  0.7963,  1.1809,  ..., -0.5750,  0.0061,  0.0791])\n",
      "cowardly\n",
      "Saved the embedding for cowardly.\n",
      "['co', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2861,  0.3284,  0.1857,  ..., -0.2969,  0.1322, -0.1587])\n",
      "coy\n",
      "Saved the embedding for coy.\n",
      "['crab', '##by'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3499,  0.2146,  0.3146,  ...,  0.1730,  0.7594, -0.0443])\n",
      "crabby\n",
      "Saved the embedding for crabby.\n",
      "['craft', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5340, -0.0389, -0.6031,  ...,  0.5943,  0.4436,  0.4475])\n",
      "crafty\n",
      "Saved the embedding for crafty.\n",
      "['crank', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4094,  1.2339,  0.2122,  ..., -0.1740, -1.0299, -0.3937])\n",
      "cranky\n",
      "Saved the embedding for cranky.\n",
      "['crazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5355,  0.8649, -0.9131,  ..., -0.0558,  0.4002, -0.3065])\n",
      "crazed\n",
      "Saved the embedding for crazed.\n",
      "['crazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5441,  1.2077, -0.8403,  ..., -0.0974,  0.7224, -0.2689])\n",
      "crazy\n",
      "Saved the embedding for crazy.\n",
      "['cr', '##ed', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2574,  0.5326,  0.5974,  ...,  0.3674,  0.1148,  0.7151])\n",
      "credulous\n",
      "Saved the embedding for credulous.\n",
      "['creepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2784,  1.5134, -0.7305,  ..., -0.2381,  0.7940, -0.2220])\n",
      "creepy\n",
      "Saved the embedding for creepy.\n",
      "['crest', '##fall', '##en'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2202, -0.1850,  0.9420,  ..., -0.3118, -0.0754,  0.1313])\n",
      "crestfallen\n",
      "Saved the embedding for crestfallen.\n",
      "['cr', '##inging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2613,  1.0096,  0.9486,  ..., -0.0754, -0.3031,  0.4120])\n",
      "cringing\n",
      "Saved the embedding for cringing.\n",
      "['critical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0408,  1.0453,  1.0302,  ..., -0.2456,  0.1638,  0.0544])\n",
      "critical\n",
      "Saved the embedding for critical.\n",
      "['cross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1018,  1.3873,  0.3671,  ..., -0.1416, -0.7411, -0.2840])\n",
      "cross\n",
      "Saved the embedding for cross.\n",
      "['crotch', '##ety'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5933,  0.8397,  0.0374,  ...,  0.1843,  0.4785,  0.1204])\n",
      "crotchety\n",
      "Saved the embedding for crotchety.\n",
      "['crude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5724,  1.1951, -1.0596,  ...,  0.0532,  0.5008,  0.0165])\n",
      "crude\n",
      "Saved the embedding for crude.\n",
      "['cruel'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8439,  1.2445, -0.7294,  ...,  0.8808,  0.2565, -0.1944])\n",
      "cruel\n",
      "Saved the embedding for cruel.\n",
      "['crushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9477,  0.6961, -1.5149,  ...,  0.2139,  0.8524, -0.7321])\n",
      "crushed\n",
      "Saved the embedding for crushed.\n",
      "['cry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6504,  0.0191, -0.6517,  ...,  0.4728,  1.0550,  0.5875])\n",
      "cry\n",
      "Saved the embedding for cry.\n",
      "['crying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1552,  0.2176, -0.6197,  ...,  0.8939,  0.1088,  0.1103])\n",
      "crying\n",
      "Saved the embedding for crying.\n",
      "['cryptic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1138,  0.8384, -1.1461,  ...,  0.0086,  0.8276, -0.2305])\n",
      "cryptic\n",
      "Saved the embedding for cryptic.\n",
      "['cu', '##lp', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9311, -0.0253,  0.2104,  ..., -0.4463,  0.0023,  0.4477])\n",
      "culpable\n",
      "Saved the embedding for culpable.\n",
      "['cunning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3379,  0.3593,  0.2651,  ..., -1.0372,  0.2957,  0.4264])\n",
      "cunning\n",
      "Saved the embedding for cunning.\n",
      "['cu', '##rio', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3854, -0.1902,  0.2946,  ..., -0.1975,  0.1344,  0.4463])\n",
      "curios\n",
      "Saved the embedding for curios.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curiosity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0887,  1.0266, -1.1298,  ...,  0.4343,  0.2771, -0.1912])\n",
      "curiosity\n",
      "Saved the embedding for curiosity.\n",
      "['curious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0559,  1.3809, -1.9099,  ..., -0.3156,  0.8766, -0.1441])\n",
      "curious\n",
      "Saved the embedding for curious.\n",
      "['cutting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.5306,  0.2506, -0.5993,  ...,  1.2420,  0.3933,  0.6818])\n",
      "cutting\n",
      "Saved the embedding for cutting.\n",
      "['cy', '##nic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0129,  0.2191,  0.6293,  ..., -0.0789,  0.3549, -0.1174])\n",
      "cynic\n",
      "Saved the embedding for cynic.\n",
      "['cynical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2753,  0.1263, -0.8167,  ..., -0.8697,  0.4948, -1.1115])\n",
      "cynical\n",
      "Saved the embedding for cynical.\n",
      "['cy', '##nic', '##ism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0301,  0.0930,  0.5973,  ..., -0.1685,  0.8438,  0.2220])\n",
      "cynicism\n",
      "Saved the embedding for cynicism.\n",
      "['dal', '##lian', '##ce'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3497, -0.2202, -0.2056,  ...,  0.1366,  0.0325,  0.4012])\n",
      "dalliance\n",
      "Saved the embedding for dalliance.\n",
      "['dan', '##dy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.3925,  0.3675,  0.0974,  ...,  0.1591,  0.4649,  0.4922])\n",
      "dandy\n",
      "Saved the embedding for dandy.\n",
      "['dangerous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3937,  0.6791, -0.4974,  ..., -0.4739, -0.1919, -0.1823])\n",
      "dangerous\n",
      "Saved the embedding for dangerous.\n",
      "['darkly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0709,  1.1435, -1.6667,  ...,  0.4764,  0.3402, -0.1613])\n",
      "darkly\n",
      "Saved the embedding for darkly.\n",
      "['da', '##unt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1284,  0.1578, -0.8128,  ..., -0.2996,  0.5810, -0.7502])\n",
      "daunted\n",
      "Saved the embedding for daunted.\n",
      "['day', '##dre', '##am'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3297, -0.2149,  0.0978,  ...,  0.2793,  0.0669,  0.2784])\n",
      "daydream\n",
      "Saved the embedding for daydream.\n",
      "['day', '##dre', '##ami', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0227, -0.2191, -0.2755,  ...,  0.3253,  0.0111,  0.4716])\n",
      "daydreaming\n",
      "Saved the embedding for daydreaming.\n",
      "['dazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4666,  0.9340, -1.7920,  ...,  0.5687,  1.3177, -0.3167])\n",
      "dazed\n",
      "Saved the embedding for dazed.\n",
      "['da', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0355, -0.0854, -0.6605,  ..., -0.0831,  0.3384,  0.1835])\n",
      "dazzled\n",
      "Saved the embedding for dazzled.\n",
      "['deadly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3535,  0.8318, -1.1771,  ...,  0.0296,  0.7618,  0.0173])\n",
      "deadly\n",
      "Saved the embedding for deadly.\n",
      "['dead', '##pan'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.0788, 0.2780, 0.2058,  ..., 0.1853, 0.7124, 0.7180])\n",
      "deadpan\n",
      "Saved the embedding for deadpan.\n",
      "['debate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0950,  0.9616,  1.0490,  ..., -0.2933,  0.5502, -0.3555])\n",
      "debate\n",
      "Saved the embedding for debate.\n",
      "['debating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.3025, 0.4173, 0.2939,  ..., 0.1636, 0.1529, 0.0210])\n",
      "debating\n",
      "Saved the embedding for debating.\n",
      "['de', '##bau', '##ched'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4461, -0.0054,  0.7931,  ..., -0.3285,  0.4728,  1.2195])\n",
      "debauched\n",
      "Saved the embedding for debauched.\n",
      "['dec', '##eit', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4682,  1.5275, -0.6028,  ..., -0.3608,  0.5202,  0.3234])\n",
      "deceitful\n",
      "Saved the embedding for deceitful.\n",
      "['dec', '##ei', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6313,  0.2932,  0.3037,  ..., -0.5712,  0.6909,  0.3152])\n",
      "deceived\n",
      "Saved the embedding for deceived.\n",
      "['dec', '##ei', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3570,  0.9466, -0.1206,  ..., -0.1329,  0.6920,  0.5438])\n",
      "deceiving\n",
      "Saved the embedding for deceiving.\n",
      "['dec', '##ei', '##ving', '##ly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0459,  1.0456, -0.6781,  ...,  0.3005,  0.2017, -0.1904])\n",
      "deceivingly\n",
      "Saved the embedding for deceivingly.\n",
      "['deception'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4082,  0.7074, -0.0220,  ...,  0.1920,  0.2939,  0.1982])\n",
      "deception\n",
      "Saved the embedding for deception.\n",
      "['dec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4051,  1.5181, -0.1232,  ..., -0.3369,  1.2689, -0.0175])\n",
      "deceptive\n",
      "Saved the embedding for deceptive.\n",
      "['deciding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3743,  0.0950, -0.2321,  ...,  0.4031,  0.8057, -0.5430])\n",
      "deciding\n",
      "Saved the embedding for deciding.\n",
      "['decisive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2417,  1.3323,  0.9683,  ..., -0.7020,  0.5033, -0.3426])\n",
      "decisive\n",
      "Saved the embedding for decisive.\n",
      "['dedicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2282,  1.8002,  0.9378,  ..., -0.3476,  0.4164, -0.1804])\n",
      "dedicated\n",
      "Saved the embedding for dedicated.\n",
      "['defeat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6281,  0.8189,  0.0422,  ...,  0.0258, -0.0035, -0.6908])\n",
      "defeat\n",
      "Saved the embedding for defeat.\n",
      "['defeated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6050,  0.4534, -0.0562,  ...,  0.1429,  0.6846, -0.9852])\n",
      "defeated\n",
      "Saved the embedding for defeated.\n",
      "['defense', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7030,  1.4058,  0.9817,  ..., -0.5009,  0.6080, -0.0394])\n",
      "defenseless\n",
      "Saved the embedding for defenseless.\n",
      "['defensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4834,  1.2948, -0.1340,  ..., -0.5715,  0.5792, -1.1495])\n",
      "defensive\n",
      "Saved the embedding for defensive.\n",
      "['defiance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9775,  1.1316, -1.0410,  ...,  0.7909,  0.5275,  0.6294])\n",
      "defiance\n",
      "Saved the embedding for defiance.\n",
      "['defiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0685,  1.2959, -1.0776,  ...,  0.2142,  0.0750,  0.0990])\n",
      "defiant\n",
      "Saved the embedding for defiant.\n",
      "['def', '##lated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5206, -0.9611,  0.5746,  ...,  0.3274,  0.4334,  0.1431])\n",
      "deflated\n",
      "Saved the embedding for deflated.\n",
      "['de', '##ga', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8025,  0.0294,  0.8208,  ..., -0.4866,  0.0632,  0.5356])\n",
      "degage\n",
      "Saved the embedding for degage.\n",
      "['de', '##grad', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8163,  0.2625,  0.7881,  ..., -0.6822,  0.1247,  0.6315])\n",
      "degrading\n",
      "Saved the embedding for degrading.\n",
      "['de', '##jected'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2785, -0.0885,  0.5413,  ..., -0.2628, -0.0191,  0.0944])\n",
      "dejected\n",
      "Saved the embedding for dejected.\n",
      "['de', '##ject', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5005,  0.2271,  0.7193,  ..., -0.3031,  0.1198, -0.1483])\n",
      "dejection\n",
      "Saved the embedding for dejection.\n",
      "['deliberate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6217,  0.1829,  0.3809,  ...,  0.5120,  0.5498,  0.1966])\n",
      "deliberate\n",
      "Saved the embedding for deliberate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['del', '##ibe', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3813,  0.0335,  0.3423,  ..., -0.1098,  0.2765,  0.8089])\n",
      "deliberating\n",
      "Saved the embedding for deliberating.\n",
      "['delight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5849,  1.4482, -1.2832,  ...,  1.2346,  0.7432, -0.1954])\n",
      "delight\n",
      "Saved the embedding for delight.\n",
      "['delighted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1088,  0.2741, -1.0782,  ...,  0.4620,  0.6261, -0.3548])\n",
      "delighted\n",
      "Saved the embedding for delighted.\n",
      "['delightful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3036,  0.9345,  0.8303,  ..., -0.6799, -0.6274,  0.1997])\n",
      "delightful\n",
      "Saved the embedding for delightful.\n",
      "['del', '##iri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.4626e-01, -4.7090e-01, -9.3705e-04,  ...,  2.7005e-02,\n",
      "         3.8749e-01,  1.1042e+00])\n",
      "delirious\n",
      "Saved the embedding for delirious.\n",
      "['del', '##iri', '##um'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1762, -0.1442, -0.0724,  ..., -0.4300,  0.1845,  0.4754])\n",
      "delirium\n",
      "Saved the embedding for delirium.\n",
      "['del', '##ude'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8076, -0.3426,  0.3113,  ...,  0.0440,  0.1072,  0.7714])\n",
      "delude\n",
      "Saved the embedding for delude.\n",
      "['del', '##usion', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1579, -0.1055,  0.2320,  ..., -0.3189,  0.2725,  0.7266])\n",
      "delusional\n",
      "Saved the embedding for delusional.\n",
      "['demanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4315,  0.8101, -0.4549,  ...,  0.2341,  0.3538, -0.4670])\n",
      "demanding\n",
      "Saved the embedding for demanding.\n",
      "['dem', '##ean', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0650, -0.0708, -0.2146,  ..., -0.2594,  0.0947,  0.7005])\n",
      "demeaning\n",
      "Saved the embedding for demeaning.\n",
      "['dem', '##ented'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0204, -0.1182, -0.0815,  ...,  0.1034,  0.2348,  0.1036])\n",
      "demented\n",
      "Saved the embedding for demented.\n",
      "['demise', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2059,  0.0986, -0.1577,  ..., -0.4837,  0.6034, -0.5743])\n",
      "demised\n",
      "Saved the embedding for demised.\n",
      "['demo', '##ral', '##ized'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3469, 0.4419, 0.0367,  ..., 0.0243, 0.2374, 0.3607])\n",
      "demoralized\n",
      "Saved the embedding for demoralized.\n",
      "['dem', '##ure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7509, -0.5898,  0.0468,  ..., -0.2594,  0.5265,  0.5598])\n",
      "demure\n",
      "Saved the embedding for demure.\n",
      "['denied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0085,  0.8445,  0.5017,  ..., -0.3491,  0.4411, -0.4466])\n",
      "denied\n",
      "Saved the embedding for denied.\n",
      "['den', '##oun', '##cing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1625, -0.0280,  0.2046,  ..., -0.0071,  0.0556,  0.0767])\n",
      "denouncing\n",
      "Saved the embedding for denouncing.\n",
      "['depleted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4593,  1.2365, -0.8163,  ..., -0.0130,  1.2589, -1.4818])\n",
      "depleted\n",
      "Saved the embedding for depleted.\n",
      "['de', '##pl', '##ora', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5758,  0.0356,  0.9264,  ..., -0.5129,  0.2148,  0.8140])\n",
      "deplorable\n",
      "Saved the embedding for deplorable.\n",
      "['de', '##pre', '##cating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4876,  0.8470,  0.6254,  ..., -0.2935,  0.2160,  0.0049])\n",
      "deprecating\n",
      "Saved the embedding for deprecating.\n",
      "['depressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1560,  0.7234, -1.2691,  ...,  0.5850,  0.4780, -0.3497])\n",
      "depressed\n",
      "Saved the embedding for depressed.\n",
      "['depression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0578,  0.6736,  0.4506,  ...,  0.0711,  0.3533, -0.1193])\n",
      "depression\n",
      "Saved the embedding for depression.\n",
      "['deprived'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1321,  1.1884, -1.0700,  ..., -0.0272, -0.0858,  0.3170])\n",
      "deprived\n",
      "Saved the embedding for deprived.\n",
      "['der', '##ange', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8420,  0.7082, -0.3087,  ...,  0.2397,  0.5447,  0.3041])\n",
      "deranged\n",
      "Saved the embedding for deranged.\n",
      "['der', '##ision'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4074, -0.0023,  0.2709,  ...,  0.2171,  0.4283,  0.3760])\n",
      "derision\n",
      "Saved the embedding for derision.\n",
      "['der', '##isi', '##ve'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3085,  0.5203,  0.3418,  ..., -0.1136,  0.7720, -0.1899])\n",
      "derisive\n",
      "Saved the embedding for derisive.\n",
      "['der', '##oga', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3813,  0.4956,  0.4925,  ..., -0.3425,  0.3788,  0.3580])\n",
      "derogatory\n",
      "Saved the embedding for derogatory.\n",
      "['desire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6945,  0.7228, -0.3735,  ...,  0.1643, -0.4245, -0.2897])\n",
      "desire\n",
      "Saved the embedding for desire.\n",
      "['des', '##iring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5209,  0.8729,  0.6682,  ..., -0.2663, -0.1401,  0.4857])\n",
      "desiring\n",
      "Saved the embedding for desiring.\n",
      "['des', '##iro', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3974,  0.8511,  0.4080,  ..., -0.1823,  0.2719,  0.0261])\n",
      "desirous\n",
      "Saved the embedding for desirous.\n",
      "['des', '##olate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0579,  0.2764,  0.2477,  ..., -0.6048, -0.0587,  0.1045])\n",
      "desolate\n",
      "Saved the embedding for desolate.\n",
      "['despair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4034,  0.3480,  0.2473,  ..., -0.5377,  0.0480,  0.1112])\n",
      "despair\n",
      "Saved the embedding for despair.\n",
      "['despair', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1208,  0.8899,  0.5742,  ..., -0.0600,  0.1399,  0.3511])\n",
      "despaired\n",
      "Saved the embedding for despaired.\n",
      "['despair', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1457,  0.1137,  0.3353,  ..., -0.6268,  0.1410,  0.4097])\n",
      "despairing\n",
      "Saved the embedding for despairing.\n",
      "['desperate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2332,  1.1887, -1.1951,  ...,  0.5617,  0.5818, -0.1117])\n",
      "desperate\n",
      "Saved the embedding for desperate.\n",
      "['desperation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1212,  0.7337, -0.6744,  ...,  0.3102,  0.8268, -0.2944])\n",
      "desperation\n",
      "Saved the embedding for desperation.\n",
      "['des', '##pis', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2290,  0.5706,  0.7066,  ..., -0.6983, -0.3421, -0.0591])\n",
      "despise\n",
      "Saved the embedding for despise.\n",
      "['des', '##pon', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5636, -0.0025,  0.0320,  ..., -0.9764,  0.3154,  0.2067])\n",
      "despondent\n",
      "Saved the embedding for despondent.\n",
      "['des', '##ti', '##tute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7730,  0.8705,  0.7259,  ...,  0.1599, -0.5620,  0.0313])\n",
      "destitute\n",
      "Saved the embedding for destitute.\n",
      "['destroyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2311,  0.1053,  0.8536,  ...,  0.7243,  0.5682,  0.2505])\n",
      "destroyed\n",
      "Saved the embedding for destroyed.\n",
      "['detached'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6071,  1.0854, -0.3228,  ..., -0.3416,  0.8241, -0.6975])\n",
      "detached\n",
      "Saved the embedding for detached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['determination'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1605,  0.6582, -0.0027,  ..., -0.3860,  0.5737,  0.5906])\n",
      "determination\n",
      "Saved the embedding for determination.\n",
      "['determined'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6670,  0.0396,  0.6240,  ..., -0.1621,  0.4597,  0.2712])\n",
      "determined\n",
      "Saved the embedding for determined.\n",
      "['determining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1120,  0.1771,  0.5815,  ...,  0.2044,  0.6191,  0.1602])\n",
      "determining\n",
      "Saved the embedding for determining.\n",
      "['deter', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5412,  0.1244,  0.4389,  ..., -0.2651, -0.1264,  0.1172])\n",
      "deterred\n",
      "Saved the embedding for deterred.\n",
      "['det', '##est'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9375,  0.3597,  0.5620,  ...,  0.2095,  0.5505,  0.1648])\n",
      "detest\n",
      "Saved the embedding for detest.\n",
      "['det', '##est', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7652,  0.3880,  0.3150,  ...,  0.5367,  0.7230,  0.0309])\n",
      "detestable\n",
      "Saved the embedding for detestable.\n",
      "['det', '##est', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7559,  0.4764, -0.1248,  ...,  0.2682,  0.3603, -0.0055])\n",
      "detesting\n",
      "Saved the embedding for detesting.\n",
      "['det', '##rim', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2452,  0.7590,  0.2588,  ..., -0.7139,  0.1645,  0.2486])\n",
      "detriment\n",
      "Saved the embedding for detriment.\n",
      "['devastated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2218,  0.5233,  0.2112,  ...,  0.3417,  1.1382, -0.0709])\n",
      "devastated\n",
      "Saved the embedding for devastated.\n",
      "['devi', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0301,  0.0769,  0.0765,  ...,  0.4996,  0.5850,  0.3259])\n",
      "deviant\n",
      "Saved the embedding for deviant.\n",
      "['devil', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9622, -0.0065, -0.3817,  ...,  1.3280,  0.2387,  1.1118])\n",
      "devilish\n",
      "Saved the embedding for devilish.\n",
      "['devi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1168, -0.0517,  0.3312,  ...,  0.4058,  0.2609,  0.5334])\n",
      "devious\n",
      "Saved the embedding for devious.\n",
      "['devi', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5280,  0.0644,  0.1269,  ...,  0.5520,  0.2034,  0.2127])\n",
      "devising\n",
      "Saved the embedding for devising.\n",
      "['di', '##ffi', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2359,  0.0056,  0.9628,  ...,  0.1091,  0.1740,  0.5638])\n",
      "diffident\n",
      "Saved the embedding for diffident.\n",
      "['dil', '##atory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4012,  0.4347, -0.1873,  ...,  0.5676,  0.8870, -0.4908])\n",
      "dilatory\n",
      "Saved the embedding for dilatory.\n",
      "['dil', '##igen', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8518,  0.0347,  0.6738,  ...,  0.1423,  0.3427,  0.7295])\n",
      "diligent\n",
      "Saved the embedding for diligent.\n",
      "['dim', '##wi', '##tted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7853, -0.2384,  0.4291,  ...,  0.2370,  0.4727,  0.0202])\n",
      "dimwitted\n",
      "Saved the embedding for dimwitted.\n",
      "['dire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1909,  0.2648, -0.3438,  ..., -0.1290, -0.0035, -0.2687])\n",
      "dire\n",
      "Saved the embedding for dire.\n",
      "['disagree'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9137, -0.3142,  0.5384,  ...,  0.2495,  0.1385,  0.1669])\n",
      "disagree\n",
      "Saved the embedding for disagree.\n",
      "['disagree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1345, -0.1456,  0.0021,  ..., -0.0300,  0.7033, -0.1019])\n",
      "disagreeable\n",
      "Saved the embedding for disagreeable.\n",
      "['disagreement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3088,  0.6973, -0.4344,  ...,  0.4141, -0.1699, -0.6188])\n",
      "disagreement\n",
      "Saved the embedding for disagreement.\n",
      "['disappointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1753,  0.0597,  0.4601,  ...,  0.3190, -0.0537, -0.2268])\n",
      "disappointed\n",
      "Saved the embedding for disappointed.\n",
      "['disappointing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3463,  1.5575,  0.7879,  ..., -0.5201,  0.2211, -0.7601])\n",
      "disappointing\n",
      "Saved the embedding for disappointing.\n",
      "['disappointment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0630,  1.3392, -1.8822,  ...,  0.2986,  0.0907, -0.4676])\n",
      "disappointment\n",
      "Saved the embedding for disappointment.\n",
      "['disapproval'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6086,  0.4818, -0.1719,  ...,  0.4091,  0.2888, -0.3590])\n",
      "disapproval\n",
      "Saved the embedding for disapproval.\n",
      "['di', '##sa', '##pp', '##roving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4709,  0.2761,  0.3183,  ...,  0.0061, -0.0649,  0.6701])\n",
      "disapproving\n",
      "Saved the embedding for disapproving.\n",
      "['disbelief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4160,  1.5691, -1.7777,  ...,  0.6647,  0.8806, -0.0933])\n",
      "disbelief\n",
      "Saved the embedding for disbelief.\n",
      "['di', '##sb', '##eli', '##eve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0856,  0.9441,  0.3046,  ..., -0.3055,  0.0340,  0.6940])\n",
      "disbelieve\n",
      "Saved the embedding for disbelieve.\n",
      "['di', '##sb', '##eli', '##eving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1611,  0.3170,  0.5735,  ..., -0.2494, -0.1308,  0.5616])\n",
      "disbelieving\n",
      "Saved the embedding for disbelieving.\n",
      "['disc', '##ern', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.7977,  0.8937,  0.5676,  ..., -0.1591,  0.1656, -0.4344])\n",
      "discerning\n",
      "Saved the embedding for discerning.\n",
      "['disco', '##mbo', '##bula', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3635,  0.3513,  0.3117,  ..., -0.4248,  0.3472,  0.1343])\n",
      "discombobulated\n",
      "Saved the embedding for discombobulated.\n",
      "['disco', '##m', '##fi', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-1.2498,  0.7589, -0.2385,  ..., -0.3295, -0.6383, -0.8264])\n",
      "discomfited\n",
      "Saved the embedding for discomfited.\n",
      "['discomfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5861,  1.0048, -0.6600,  ..., -0.7652,  0.0069,  0.4754])\n",
      "discomfort\n",
      "Saved the embedding for discomfort.\n",
      "['discomfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2128,  1.7799, -1.2298,  ..., -0.4333,  0.5825,  0.1602])\n",
      "discomforted\n",
      "Saved the embedding for discomforted.\n",
      "['disco', '##nce', '##rted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2505,  1.6495, -0.3359,  ..., -0.9748, -0.1002, -0.2506])\n",
      "disconcerted\n",
      "Saved the embedding for disconcerted.\n",
      "['disconnected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7675, -0.0240, -0.5757,  ..., -0.2407,  0.1355,  0.0064])\n",
      "disconnected\n",
      "Saved the embedding for disconnected.\n",
      "['disco', '##ns', '##olate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5352,  0.5879, -0.0963,  ..., -0.2490,  0.4762, -0.5990])\n",
      "disconsolate\n",
      "Saved the embedding for disconsolate.\n",
      "['discontent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7742,  1.1437,  0.4815,  ...,  0.7778, -0.6676,  0.2307])\n",
      "discontent\n",
      "Saved the embedding for discontent.\n",
      "['discontent', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6787,  0.6938,  0.8927,  ...,  0.4222, -0.5588,  0.9468])\n",
      "discontented\n",
      "Saved the embedding for discontented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discount', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4136,  0.2690,  1.1072,  ..., -0.2054,  0.2983, -0.2464])\n",
      "discounted\n",
      "Saved the embedding for discounted.\n",
      "['discouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1423,  0.7236, -0.1094,  ..., -0.1900,  0.5113, -1.0597])\n",
      "discouraged\n",
      "Saved the embedding for discouraged.\n",
      "['discovery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0787,  1.1474, -0.9883,  ...,  0.1296,  0.7135, -0.4367])\n",
      "discovery\n",
      "Saved the embedding for discovery.\n",
      "['disc', '##rim', '##inating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4906,  0.4697,  0.4293,  ...,  0.2230,  0.1945,  0.0689])\n",
      "discriminating\n",
      "Saved the embedding for discriminating.\n",
      "['discussed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6686,  0.4457,  0.0229,  ...,  0.3608,  0.2394, -0.0097])\n",
      "discussed\n",
      "Saved the embedding for discussed.\n",
      "['disdain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5537,  2.1054, -0.8152,  ...,  0.6961,  0.1796, -0.1096])\n",
      "disdain\n",
      "Saved the embedding for disdain.\n",
      "['disdain', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.2172,  1.4451,  0.4012,  ...,  0.1455,  0.2706,  0.5959])\n",
      "disdained\n",
      "Saved the embedding for disdained.\n",
      "['disdain', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1364,  1.2567,  0.3204,  ..., -0.1127,  0.3027,  0.7723])\n",
      "disdainful\n",
      "Saved the embedding for disdainful.\n",
      "['disdain', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2859,  1.2111,  0.5612,  ...,  0.2060,  0.5134,  0.4628])\n",
      "disdainfully\n",
      "Saved the embedding for disdainfully.\n",
      "['di', '##sen', '##chan', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3999,  0.0345,  0.1767,  ...,  0.3986,  0.1260,  0.8656])\n",
      "disenchanted\n",
      "Saved the embedding for disenchanted.\n",
      "['di', '##sen', '##ga', '##ged'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2619,  0.3398,  0.2834,  ...,  0.2225,  0.0701,  0.6660])\n",
      "disengaged\n",
      "Saved the embedding for disengaged.\n",
      "['disgrace', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3368,  1.3454,  0.4978,  ...,  0.0119,  0.3600,  0.3721])\n",
      "disgraced\n",
      "Saved the embedding for disgraced.\n",
      "['di', '##sg', '##run', '##tled'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4628,  1.0024,  0.3997,  ..., -0.3190,  0.0824,  0.6826])\n",
      "disgruntled\n",
      "Saved the embedding for disgruntled.\n",
      "['di', '##sg', '##run', '##tlement'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1627,  0.4356,  0.4293,  ..., -0.0504,  0.1612,  0.5970])\n",
      "disgruntlement\n",
      "Saved the embedding for disgruntlement.\n",
      "['disgust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2203,  1.1386,  0.0902,  ..., -0.4667,  0.9308,  0.3331])\n",
      "disgust\n",
      "Saved the embedding for disgust.\n",
      "['disgusted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1021,  1.2695, -1.2246,  ...,  0.3600,  0.3542, -0.1209])\n",
      "disgusted\n",
      "Saved the embedding for disgusted.\n",
      "['disgusted', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5311,  0.5532,  0.0258,  ...,  0.3252,  0.4110,  0.3029])\n",
      "disgustedly\n",
      "Saved the embedding for disgustedly.\n",
      "['disgusting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5652,  1.4080, -1.0074,  ..., -0.5251,  0.6081, -0.1464])\n",
      "disgusting\n",
      "Saved the embedding for disgusting.\n",
      "['dish', '##ear', '##ten', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0076, -0.0684,  0.1253,  ..., -0.0309, -0.0251,  0.0876])\n",
      "disheartened\n",
      "Saved the embedding for disheartened.\n",
      "['dish', '##ones', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7207,  0.1361,  0.2187,  ...,  0.1244,  0.3338,  0.3819])\n",
      "dishonest\n",
      "Saved the embedding for dishonest.\n",
      "['di', '##sil', '##lusion', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3259,  0.4704, -0.0601,  ..., -0.0986, -0.1656,  0.2118])\n",
      "disillusioned\n",
      "Saved the embedding for disillusioned.\n",
      "['di', '##sin', '##cl', '##ined'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6100, -0.0660,  0.2171,  ...,  0.1739,  0.0133,  0.4643])\n",
      "disinclined\n",
      "Saved the embedding for disinclined.\n",
      "['di', '##sing', '##en', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4512,  0.2730,  0.6870,  ...,  0.2107, -0.1326,  0.5236])\n",
      "disingenuous\n",
      "Saved the embedding for disingenuous.\n",
      "['di', '##sin', '##ter', '##est'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4600,  0.5747, -0.5636,  ...,  0.0539, -0.1364,  1.0342])\n",
      "disinterest\n",
      "Saved the embedding for disinterest.\n",
      "['di', '##sin', '##ter', '##ested'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3928,  0.2286, -0.6076,  ..., -0.3158,  0.2305,  0.5988])\n",
      "disinterested\n",
      "Saved the embedding for disinterested.\n",
      "['di', '##s', '##jo', '##int', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0971,  0.6729, -0.1830,  ..., -0.1512,  0.1063,  1.1535])\n",
      "disjointed\n",
      "Saved the embedding for disjointed.\n",
      "['dislike'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0519,  1.2366, -1.0558,  ...,  0.2446,  0.1200, -0.1479])\n",
      "dislike\n",
      "Saved the embedding for dislike.\n",
      "['disliked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1079,  1.0565, -0.2574,  ...,  0.5091, -0.7991, -0.6509])\n",
      "disliked\n",
      "Saved the embedding for disliked.\n",
      "['di', '##sl', '##iki', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3943,  1.1245,  0.1293,  ..., -0.1187, -0.1191,  0.5905])\n",
      "disliking\n",
      "Saved the embedding for disliking.\n",
      "['di', '##sma', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3805,  0.4400, -0.7927,  ...,  0.4039,  0.3238,  0.4106])\n",
      "dismal\n",
      "Saved the embedding for dismal.\n",
      "['di', '##sman'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5100,  0.0792,  0.7205,  ...,  0.0386,  0.1033,  0.7560])\n",
      "disman\n",
      "Saved the embedding for disman.\n",
      "['dismay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1048,  1.0563,  0.6661,  ...,  0.0201,  0.5729,  0.4063])\n",
      "dismay\n",
      "Saved the embedding for dismay.\n",
      "['dismay', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0856,  1.5621,  1.0964,  ..., -0.0362,  0.5190,  0.1626])\n",
      "dismayed\n",
      "Saved the embedding for dismayed.\n",
      "['dismiss', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1941,  1.1336,  1.1077,  ..., -0.7850,  0.9437, -0.0100])\n",
      "dismissive\n",
      "Saved the embedding for dismissive.\n",
      "['di', '##so', '##bed', '##ient'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2334,  0.4279,  0.3237,  ...,  0.2063, -0.0286,  0.6664])\n",
      "disobedient\n",
      "Saved the embedding for disobedient.\n",
      "['disorder', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4965,  1.3175, -0.1229,  ..., -0.9952, -0.1301, -1.3708])\n",
      "disorderly\n",
      "Saved the embedding for disorderly.\n",
      "['di', '##sor', '##iente', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1936,  0.4370, -0.0072,  ...,  0.1274,  0.4432,  1.0053])\n",
      "disoriented\n",
      "Saved the embedding for disoriented.\n",
      "['di', '##sp', '##air'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8487, -0.3037, -0.4176,  ...,  0.1526,  0.2412,  0.7271])\n",
      "dispair\n",
      "Saved the embedding for dispair.\n",
      "['di', '##spar', '##aging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1379,  0.4583,  0.4948,  ..., -0.2499,  0.0442,  0.3878])\n",
      "disparaging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for disparaging.\n",
      "['di', '##sp', '##ass', '##ion', '##ate'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0930, -0.2498,  0.2627,  ..., -0.1241,  0.0627,  0.5590])\n",
      "dispassionate\n",
      "Saved the embedding for dispassionate.\n",
      "['di', '##sp', '##iri', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4464,  0.2442, -0.3300,  ..., -0.1907,  0.3127,  0.8845])\n",
      "dispirited\n",
      "Saved the embedding for dispirited.\n",
      "['di', '##sp', '##iri', '##ted', '##ness'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.2349, -0.1987,  0.1063,  ..., -0.1098,  0.2353,  0.8494])\n",
      "dispiritedness\n",
      "Saved the embedding for dispiritedness.\n",
      "['di', '##sp', '##lea', '##sed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3168, -0.0013,  0.6447,  ..., -0.1515, -0.1264,  0.4032])\n",
      "displeased\n",
      "Saved the embedding for displeased.\n",
      "['displeasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4428,  0.9948, -0.6045,  ..., -0.0143, -0.2624, -0.1293])\n",
      "displeasure\n",
      "Saved the embedding for displeasure.\n",
      "['di', '##s', '##qui', '##et'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([0.0705, 0.0258, 0.9580,  ..., 0.1049, 0.0922, 0.7411])\n",
      "disquiet\n",
      "Saved the embedding for disquiet.\n",
      "['di', '##s', '##qui', '##ete', '##d'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.1189, -0.0863,  0.5360,  ...,  0.5037,  0.2556,  1.1446])\n",
      "disquieted\n",
      "Saved the embedding for disquieted.\n",
      "['disregard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7653,  0.2371, -0.8533,  ..., -0.5516,  0.6267, -0.2718])\n",
      "disregard\n",
      "Saved the embedding for disregard.\n",
      "['di', '##sr', '##es', '##pe', '##ct', '##ful'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([0.0985, 0.8314, 0.3071,  ..., 0.0252, 0.1622, 1.0363])\n",
      "disrespectful\n",
      "Saved the embedding for disrespectful.\n",
      "['disrupted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2793,  0.9959, -1.4823,  ..., -0.3604,  0.1436, -0.4827])\n",
      "disrupted\n",
      "Saved the embedding for disrupted.\n",
      "['disrupt', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2015,  1.6135, -0.0651,  ...,  0.0372,  0.2613, -0.2459])\n",
      "disruptive\n",
      "Saved the embedding for disruptive.\n",
      "['dissatisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0943,  0.5347,  0.2945,  ...,  0.5952, -0.8020, -0.4031])\n",
      "dissatisfaction\n",
      "Saved the embedding for dissatisfaction.\n",
      "['dissatisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1934,  0.4179, -0.1409,  ...,  0.4952, -0.3886,  0.2245])\n",
      "dissatisfied\n",
      "Saved the embedding for dissatisfied.\n",
      "['di', '##ssa', '##tis', '##fy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0672, -0.1125,  0.1460,  ...,  0.1454, -0.0109,  0.3979])\n",
      "dissatisfy\n",
      "Saved the embedding for dissatisfy.\n",
      "['di', '##sse', '##cting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1238,  0.6166,  0.4108,  ..., -0.0847, -0.0723,  0.6690])\n",
      "dissecting\n",
      "Saved the embedding for dissecting.\n",
      "['di', '##sso', '##cia', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2652,  0.3653,  0.3894,  ...,  0.0420,  0.0820,  0.7372])\n",
      "dissociated\n",
      "Saved the embedding for dissociated.\n",
      "['di', '##sson', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4943,  0.7112, -0.1360,  ...,  0.4762,  0.4306,  0.8893])\n",
      "dissonant\n",
      "Saved the embedding for dissonant.\n",
      "['di', '##sta', '##in'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4181,  0.3512, -0.1991,  ...,  0.1492,  0.3651,  0.5847])\n",
      "distain\n",
      "Saved the embedding for distain.\n",
      "['distant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6398,  0.6907, -0.1666,  ..., -0.1441,  0.3148,  0.1081])\n",
      "distant\n",
      "Saved the embedding for distant.\n",
      "['di', '##sta', '##ste'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1675,  0.0348, -0.2497,  ..., -0.4360,  0.6352,  0.1136])\n",
      "distaste\n",
      "Saved the embedding for distaste.\n",
      "['di', '##sta', '##ste', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0620,  0.5029, -0.4910,  ..., -0.2614, -0.1108,  0.0016])\n",
      "distasteful\n",
      "Saved the embedding for distasteful.\n",
      "['distracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6882,  1.4507, -1.6076,  ...,  0.2153,  0.8240, -0.4311])\n",
      "distracted\n",
      "Saved the embedding for distracted.\n",
      "['distraught'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1272,  0.5451,  0.6010,  ..., -0.0712,  0.5126,  0.0213])\n",
      "distraught\n",
      "Saved the embedding for distraught.\n",
      "['distress'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3170,  0.4834, -0.4747,  ...,  0.0890,  0.2704, -0.3665])\n",
      "distress\n",
      "Saved the embedding for distress.\n",
      "['distressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9374,  1.3081, -0.6344,  ..., -0.1121,  0.1711,  0.3646])\n",
      "distressed\n",
      "Saved the embedding for distressed.\n",
      "['distress', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0554,  0.5150, -0.2713,  ...,  0.3072,  0.1047,  0.0529])\n",
      "distressing\n",
      "Saved the embedding for distressing.\n",
      "['distrust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1813,  0.6717, -0.5837,  ...,  0.4347, -0.1134, -0.2648])\n",
      "distrust\n",
      "Saved the embedding for distrust.\n",
      "['distrust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2540,  1.0238, -0.4134,  ...,  0.5849,  0.6021,  0.2465])\n",
      "distrustful\n",
      "Saved the embedding for distrustful.\n",
      "['distrust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1511,  1.4827, -0.6666,  ...,  0.4886,  0.8784,  0.4816])\n",
      "distrusting\n",
      "Saved the embedding for distrusting.\n",
      "['disturbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4539,  1.1721, -0.8109,  ...,  0.1403,  0.4475, -0.2565])\n",
      "disturbed\n",
      "Saved the embedding for disturbed.\n",
      "['diverted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7796,  0.1032,  0.4304,  ...,  0.0226,  0.5062,  0.0346])\n",
      "diverted\n",
      "Saved the embedding for diverted.\n",
      "['dod', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7455,  1.7388, -0.3782,  ..., -0.6421, -0.1913,  0.3371])\n",
      "dodgy\n",
      "Saved the embedding for dodgy.\n",
      "['do', '##le', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4066, -0.0527,  0.8651,  ...,  0.0497,  0.0043,  0.3195])\n",
      "doleful\n",
      "Saved the embedding for doleful.\n",
      "['do', '##lt', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1175,  0.0299,  0.1523,  ...,  0.3902,  0.4772,  0.7707])\n",
      "doltish\n",
      "Saved the embedding for doltish.\n",
      "['dominant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7995,  1.4011, -0.8974,  ...,  0.6464,  0.1813,  0.7250])\n",
      "dominant\n",
      "Saved the embedding for dominant.\n",
      "['dominating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-3.2832e-01,  1.6889e+00, -6.5249e-01,  ...,  4.1002e-01,\n",
      "        -6.0816e-01, -2.0454e-04])\n",
      "dominating\n",
      "Saved the embedding for dominating.\n",
      "['dom', '##ine', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0170,  0.3889, -0.2528,  ...,  0.5039, -0.5017,  0.5015])\n",
      "domineering\n",
      "Saved the embedding for domineering.\n",
      "['done'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3727,  1.1707, -1.4089,  ...,  0.1006,  1.1110, -0.7279])\n",
      "done\n",
      "Saved the embedding for done.\n",
      "['doomed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6528,  0.4211, -0.9289,  ..., -0.4160,  0.5021, -0.7569])\n",
      "doomed\n",
      "Saved the embedding for doomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5234,  0.7613, -0.0688,  ...,  0.5572,  0.4042,  0.4795])\n",
      "dopey\n",
      "Saved the embedding for dopey.\n",
      "['dot', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1959,  0.7269, -0.1643,  ..., -0.1431,  0.5493,  0.2836])\n",
      "doting\n",
      "Saved the embedding for doting.\n",
      "['doubt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3072,  0.3385, -0.8530,  ..., -0.2843,  0.5934, -0.5055])\n",
      "doubt\n",
      "Saved the embedding for doubt.\n",
      "['doubt', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3944,  0.1997,  0.3157,  ..., -0.1028,  0.4350, -0.4048])\n",
      "doubter\n",
      "Saved the embedding for doubter.\n",
      "['doubtful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1359,  0.8346, -0.2823,  ...,  0.1187,  0.7571, -0.2157])\n",
      "doubtful\n",
      "Saved the embedding for doubtful.\n",
      "['doubtful', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4539,  0.9517, -0.4823,  ...,  0.2805,  0.3765, -0.2390])\n",
      "doubtfully\n",
      "Saved the embedding for doubtfully.\n",
      "['doubtful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7065,  0.1523,  0.0721,  ...,  0.1452,  0.4603,  0.2796])\n",
      "doubtfulness\n",
      "Saved the embedding for doubtfulness.\n",
      "['doubt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0131,  0.9076, -0.2545,  ...,  0.2021,  0.6348, -0.3737])\n",
      "doubting\n",
      "Saved the embedding for doubting.\n",
      "['do', '##ur'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1186, -0.0159, -0.4065,  ...,  0.5170,  0.9210,  0.1319])\n",
      "dour\n",
      "Saved the embedding for dour.\n",
      "['down'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2773,  0.7483, -0.3297,  ..., -0.1254,  0.3854, -0.2540])\n",
      "down\n",
      "Saved the embedding for down.\n",
      "['down', '##cast'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0403,  1.1719, -0.6407,  ..., -0.0095,  0.7755, -0.0177])\n",
      "downcast\n",
      "Saved the embedding for downcast.\n",
      "['down', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0810,  0.2156, -0.0027,  ..., -0.0975,  0.4999, -0.4202])\n",
      "downhearted\n",
      "Saved the embedding for downhearted.\n",
      "['down', '##hearted', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1577,  0.8722, -0.7503,  ...,  0.4385,  0.6781, -0.0955])\n",
      "downheartedness\n",
      "Saved the embedding for downheartedness.\n",
      "['down', '##tro', '##dden'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3790,  0.6537, -0.1770,  ..., -0.2222,  0.2706,  0.3168])\n",
      "downtrodden\n",
      "Saved the embedding for downtrodden.\n",
      "['do', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2297,  0.0963, -0.1192,  ...,  0.2909,  0.5357,  0.1907])\n",
      "dozing\n",
      "Saved the embedding for dozing.\n",
      "['drained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4112,  0.3616, -0.9670,  ...,  0.0840,  0.0227, -0.8016])\n",
      "drained\n",
      "Saved the embedding for drained.\n",
      "['dramatic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2221,  1.7703,  0.6144,  ..., -0.7575,  0.4590, -0.3215])\n",
      "dramatic\n",
      "Saved the embedding for dramatic.\n",
      "['drawn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0733,  0.6116,  0.0226,  ..., -0.0807,  0.3081, -0.2811])\n",
      "drawn\n",
      "Saved the embedding for drawn.\n",
      "['dread'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1311,  0.9289, -0.5849,  ...,  0.1458,  0.3201, -0.0906])\n",
      "dread\n",
      "Saved the embedding for dread.\n",
      "['dreadful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4279,  1.7526,  0.3825,  ..., -0.2375,  0.6725,  0.3574])\n",
      "dreadful\n",
      "Saved the embedding for dreadful.\n",
      "['dread', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3792,  1.4326, -0.0677,  ...,  0.1950,  0.1376,  0.2616])\n",
      "dreading\n",
      "Saved the embedding for dreading.\n",
      "['dreaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0970,  0.6161, -0.6991,  ..., -0.2568,  0.4545,  0.0040])\n",
      "dreaming\n",
      "Saved the embedding for dreaming.\n",
      "['dream', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4867,  0.3934,  0.7138,  ...,  0.5430, -0.2959,  0.2506])\n",
      "dreamy\n",
      "Saved the embedding for dreamy.\n",
      "['dr', '##ear', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2463,  0.8204, -0.9954,  ...,  0.0733,  1.1975, -0.2604])\n",
      "dreary\n",
      "Saved the embedding for dreary.\n",
      "['driven'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5162,  0.1554, -0.7721,  ..., -0.0258,  1.1671,  0.0358])\n",
      "driven\n",
      "Saved the embedding for driven.\n",
      "['dr', '##ows', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1458,  0.6718, -0.4734,  ...,  0.1540,  1.1957,  0.1499])\n",
      "drowsy\n",
      "Saved the embedding for drowsy.\n",
      "['drugged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9570,  0.9877, -0.0990,  ...,  0.0263, -0.1245, -0.2046])\n",
      "drugged\n",
      "Saved the embedding for drugged.\n",
      "['drunk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1173,  0.3093, -0.8252,  ...,  0.8425,  0.2495,  0.4792])\n",
      "drunk\n",
      "Saved the embedding for drunk.\n",
      "['drunken', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.1011,  0.9607, -0.5753,  ...,  0.4380,  0.4096,  0.1919])\n",
      "drunkenness\n",
      "Saved the embedding for drunkenness.\n",
      "['dub', '##ie', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1010, -0.1937,  0.5538,  ...,  0.2261,  0.1233,  0.5027])\n",
      "dubiety\n",
      "Saved the embedding for dubiety.\n",
      "['dubious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1207,  0.8215, -0.7403,  ...,  0.5265,  0.5982, -0.2615])\n",
      "dubious\n",
      "Saved the embedding for dubious.\n",
      "['dubious', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3073,  0.7709, -0.3174,  ...,  0.2913,  0.6954, -0.0920])\n",
      "dubiously\n",
      "Saved the embedding for dubiously.\n",
      "['dull'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2409,  0.9496, -1.6428,  ..., -0.0148,  0.2405, -0.4318])\n",
      "dull\n",
      "Saved the embedding for dull.\n",
      "['dumb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0335,  0.8254, -0.6444,  ...,  0.0363,  0.4183,  0.1639])\n",
      "dumb\n",
      "Saved the embedding for dumb.\n",
      "['dumb', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6308,  0.5792,  0.2359,  ...,  0.5126, -0.0264,  0.4078])\n",
      "dumbfound\n",
      "Saved the embedding for dumbfound.\n",
      "['dumb', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4147,  1.0658,  0.7833,  ..., -0.2282,  0.2178, -0.3139])\n",
      "dumbfounded\n",
      "Saved the embedding for dumbfounded.\n",
      "['dumb', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5119,  0.1455,  0.7266,  ...,  0.0981,  0.1103, -0.1931])\n",
      "dumbstruck\n",
      "Saved the embedding for dumbstruck.\n",
      "['du', '##m', '##founded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1736,  1.3153,  0.9863,  ..., -0.2501, -0.2779,  0.1899])\n",
      "dumfounded\n",
      "Saved the embedding for dumfounded.\n",
      "['du', '##pe'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2746,  0.1696,  0.5986,  ...,  0.2649,  0.1444,  0.4835])\n",
      "dupe\n",
      "Saved the embedding for dupe.\n",
      "['du', '##pl', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.3148,  0.1270,  0.6585,  ..., -0.4080, -0.1089,  0.7842])\n",
      "duplicitous\n",
      "Saved the embedding for duplicitous.\n",
      "['d', '##ys', '##ph', '##oric'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6626,  0.6853,  0.0432,  ..., -0.3049,  0.2219,  0.1003])\n",
      "dysphoric\n",
      "Saved the embedding for dysphoric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eager'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5518,  0.6764, -0.4429,  ..., -0.2509,  0.4406, -0.0296])\n",
      "eager\n",
      "Saved the embedding for eager.\n",
      "['eager', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0428,  0.2632,  0.7444,  ...,  0.1799, -0.1494,  0.0544])\n",
      "eagerness\n",
      "Saved the embedding for eagerness.\n",
      "['earnest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3091,  2.1425,  0.6450,  ..., -0.3866,  0.3664,  0.0414])\n",
      "earnest\n",
      "Saved the embedding for earnest.\n",
      "['easy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0972,  0.6998, -0.2216,  ...,  0.5131,  0.5356,  0.1820])\n",
      "easy\n",
      "Saved the embedding for easy.\n",
      "['e', '##bu', '##llie', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2494, -0.7355,  0.5511,  ...,  0.0514,  0.5149,  0.6951])\n",
      "ebullient\n",
      "Saved the embedding for ebullient.\n",
      "['ecstasy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2627,  0.4554,  0.2731,  ..., -0.0158,  0.5161, -0.7254])\n",
      "ecstasy\n",
      "Saved the embedding for ecstasy.\n",
      "['ec', '##static'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2876,  0.0621,  0.4713,  ...,  0.3140,  0.2940,  0.4221])\n",
      "ecstatic\n",
      "Saved the embedding for ecstatic.\n",
      "['ec', '##static', '##ally'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0515,  0.0604, -0.0589,  ..., -0.0610,  0.5624,  0.0509])\n",
      "ecstatically\n",
      "Saved the embedding for ecstatically.\n",
      "['ed', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6563,  0.5200,  0.9546,  ..., -0.3040,  0.5720, -0.5544])\n",
      "edgy\n",
      "Saved the embedding for edgy.\n",
      "['eerie'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1085,  1.4404, -0.0274,  ..., -0.2757,  0.3624,  0.0811])\n",
      "eerie\n",
      "Saved the embedding for eerie.\n",
      "['e', '##ff', '##ul', '##gent'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0046, -0.5385,  0.5285,  ...,  0.4200,  0.2609,  0.6073])\n",
      "effulgent\n",
      "Saved the embedding for effulgent.\n",
      "['ego', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4266,  0.6692,  0.0462,  ...,  0.0420, -0.0832,  0.0668])\n",
      "egoistic\n",
      "Saved the embedding for egoistic.\n",
      "['ego', '##tist', '##ical'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2262,  1.2489, -0.2208,  ..., -0.0856,  0.2627,  0.0222])\n",
      "egotistical\n",
      "Saved the embedding for egotistical.\n",
      "['e', '##gre', '##gio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1001,  0.0498,  0.4810,  ...,  0.3598,  0.5792,  0.2752])\n",
      "egregious\n",
      "Saved the embedding for egregious.\n",
      "['el', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0431,  0.2981, -0.8235,  ..., -0.1895,  0.1006, -0.0725])\n",
      "elated\n",
      "Saved the embedding for elated.\n",
      "['el', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1981,  0.4076, -0.5843,  ..., -0.0212,  0.0776,  0.4408])\n",
      "elation\n",
      "Saved the embedding for elation.\n",
      "['electrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4828,  0.0639, -0.1153,  ...,  0.1044,  0.3114, -0.3196])\n",
      "electrified\n",
      "Saved the embedding for electrified.\n",
      "['elusive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7527,  0.8749, -1.8194,  ...,  0.1917,  0.9406,  0.1412])\n",
      "elusive\n",
      "Saved the embedding for elusive.\n",
      "['embarrassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7423,  1.1077, -1.0282,  ...,  0.1718,  0.1393, -0.1441])\n",
      "embarrassed\n",
      "Saved the embedding for embarrassed.\n",
      "['embarrassment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2057,  0.8731, -0.6199,  ..., -0.2205, -0.1328, -0.5476])\n",
      "embarrassment\n",
      "Saved the embedding for embarrassment.\n",
      "['em', '##bit', '##tered'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6972,  0.4673,  0.1671,  ..., -0.3918,  0.3595,  0.6385])\n",
      "embittered\n",
      "Saved the embedding for embittered.\n",
      "['em', '##body'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4653,  0.0006,  0.0937,  ...,  0.3064, -0.2388,  0.4550])\n",
      "embody\n",
      "Saved the embedding for embody.\n",
      "['emotional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9822,  1.4038,  0.2769,  ...,  0.5490,  0.0681,  0.3788])\n",
      "emotional\n",
      "Saved the embedding for emotional.\n",
      "['emotion', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3895,  1.4241, -0.4655,  ...,  0.2434,  0.5931, -0.1993])\n",
      "emotionless\n",
      "Saved the embedding for emotionless.\n",
      "['em', '##path', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0702,  0.6667, -0.5337,  ..., -0.2398, -0.0750,  0.1507])\n",
      "empathetic\n",
      "Saved the embedding for empathetic.\n",
      "['em', '##pathic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2188,  0.6466, -0.4384,  ..., -0.1570,  0.3341,  0.1217])\n",
      "empathic\n",
      "Saved the embedding for empathic.\n",
      "['empathy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4329,  1.4661,  0.3675,  ...,  0.0114,  0.0746,  0.2246])\n",
      "empathy\n",
      "Saved the embedding for empathy.\n",
      "['emptiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8916,  1.7310, -0.0515,  ..., -0.1994,  0.8965,  0.3615])\n",
      "emptiness\n",
      "Saved the embedding for emptiness.\n",
      "['empty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2591,  1.2367,  0.0032,  ..., -0.0413,  0.2659,  0.7244])\n",
      "empty\n",
      "Saved the embedding for empty.\n",
      "['en', '##amo', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0494,  0.3100,  1.0711,  ..., -0.3207, -0.2377,  0.1077])\n",
      "enamored\n",
      "Saved the embedding for enamored.\n",
      "['enchanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2606,  0.7296,  0.2178,  ..., -0.2463,  0.1084,  0.7044])\n",
      "enchanted\n",
      "Saved the embedding for enchanted.\n",
      "['encouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3972,  0.9210,  1.0637,  ..., -0.3881, -0.0636, -0.2320])\n",
      "encouraged\n",
      "Saved the embedding for encouraged.\n",
      "['encouragement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1573,  0.5227,  0.7556,  ..., -0.1560, -0.1586,  0.2014])\n",
      "encouragement\n",
      "Saved the embedding for encouragement.\n",
      "['encouraging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7820,  0.7197,  0.7444,  ..., -0.1112, -0.2310, -0.3652])\n",
      "encouraging\n",
      "Saved the embedding for encouraging.\n",
      "['end', '##ear', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8746,  1.1357,  0.7172,  ...,  0.0943,  0.4269, -0.0993])\n",
      "endeared\n",
      "Saved the embedding for endeared.\n",
      "['end', '##earing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1376, -0.2075,  0.3214,  ..., -0.3341,  0.4405,  0.0506])\n",
      "endearing\n",
      "Saved the embedding for endearing.\n",
      "['enduring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8370,  0.5346,  0.2899,  ...,  0.0756, -0.2818, -0.6343])\n",
      "enduring\n",
      "Saved the embedding for enduring.\n",
      "['energetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1094,  1.6564,  0.2768,  ...,  0.2153,  0.7568,  0.6726])\n",
      "energetic\n",
      "Saved the embedding for energetic.\n",
      "['en', '##er', '##gi', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2482, -0.1501,  0.2735,  ..., -0.0237, -0.3350,  0.6514])\n",
      "energized\n",
      "Saved the embedding for energized.\n",
      "['engaged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2139, 0.2547, 0.2472,  ..., 0.1291, 0.1680, 0.0781])\n",
      "engaged\n",
      "Saved the embedding for engaged.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', '##ross', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6183,  0.3337,  0.7556,  ..., -0.0667,  0.1365,  0.0736])\n",
      "engrossed\n",
      "Saved the embedding for engrossed.\n",
      "['eng', '##ross', '##ment'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1891,  0.8742,  0.5353,  ...,  0.3021,  0.2526,  0.3982])\n",
      "engrossment\n",
      "Saved the embedding for engrossment.\n",
      "['enigma', '##tic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5502,  0.9316, -0.1192,  ...,  0.2861,  0.1324,  0.7248])\n",
      "enigmatic\n",
      "Saved the embedding for enigmatic.\n",
      "['enjoy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6445,  0.4551, -0.1728,  ..., -0.3669,  0.6348, -1.2600])\n",
      "enjoy\n",
      "Saved the embedding for enjoy.\n",
      "['enjoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4083,  0.6953, -1.3897,  ...,  0.4798,  0.6407, -0.1406])\n",
      "enjoying\n",
      "Saved the embedding for enjoying.\n",
      "['enjoyment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1268,  0.9976, -1.6157,  ...,  1.0546,  0.4548, -0.2485])\n",
      "enjoyment\n",
      "Saved the embedding for enjoyment.\n",
      "['en', '##light', '##ened'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2066, -0.6177,  0.9386,  ..., -0.2217, -0.1840,  0.2672])\n",
      "enlightened\n",
      "Saved the embedding for enlightened.\n",
      "['en', '##mity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2685, -0.3862,  1.2698,  ..., -0.3209, -0.0388,  0.0609])\n",
      "enmity\n",
      "Saved the embedding for enmity.\n",
      "['en', '##nu', '##i'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1465, -0.1928,  0.6348,  ..., -0.0886, -0.2716,  0.3535])\n",
      "ennui\n",
      "Saved the embedding for ennui.\n",
      "['enraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4066,  1.5189,  0.2785,  ..., -0.0053,  0.2467, -0.1920])\n",
      "enraged\n",
      "Saved the embedding for enraged.\n",
      "['en', '##rag', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4039, -0.4412,  0.9911,  ..., -0.6460, -0.2462,  0.5467])\n",
      "enraging\n",
      "Saved the embedding for enraging.\n",
      "['en', '##ra', '##pt', '##ured'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0046, -0.4393,  0.4319,  ..., -0.0645,  0.0023,  0.4305])\n",
      "enraptured\n",
      "Saved the embedding for enraptured.\n",
      "['entertained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2140,  1.4714, -0.8424,  ..., -0.8857,  0.0271, -0.4371])\n",
      "entertained\n",
      "Saved the embedding for entertained.\n",
      "['en', '##th', '##ral', '##led'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5075,  0.0989,  0.5470,  ..., -0.3816,  0.0315,  0.3859])\n",
      "enthralled\n",
      "Saved the embedding for enthralled.\n",
      "['en', '##thus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2020, -0.4309,  0.4656,  ..., -0.2358, -0.1026,  0.4079])\n",
      "enthused\n",
      "Saved the embedding for enthused.\n",
      "['enthusiasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2740,  0.1149,  0.4728,  ...,  0.0831,  0.2658,  0.3441])\n",
      "enthusiasm\n",
      "Saved the embedding for enthusiasm.\n",
      "['enthusiastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4165,  1.1202,  1.0847,  ..., -0.5991,  0.7995,  0.2050])\n",
      "enthusiastic\n",
      "Saved the embedding for enthusiastic.\n",
      "['en', '##tic', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0243, -0.6947,  0.8142,  ..., -0.1780, -0.1825,  0.4563])\n",
      "enticed\n",
      "Saved the embedding for enticed.\n",
      "['entrance', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5034,  1.0895,  0.0938,  ..., -0.5287, -0.8111, -0.2528])\n",
      "entranced\n",
      "Saved the embedding for entranced.\n",
      "['en', '##vious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3702, -0.2296,  1.3680,  ..., -0.4750, -0.2276,  0.1408])\n",
      "envious\n",
      "Saved the embedding for envious.\n",
      "['envy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.3340, 0.4870, 0.5738,  ..., 0.3381, 0.3903, 0.6694])\n",
      "envy\n",
      "Saved the embedding for envy.\n",
      "['erotic', '##ally'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7830,  0.6315, -1.6800,  ..., -0.3457,  0.3738, -0.2763])\n",
      "erotically\n",
      "Saved the embedding for erotically.\n",
      "['estranged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2968,  0.6177, -0.1106,  ..., -0.7114,  0.6430, -0.1511])\n",
      "estranged\n",
      "Saved the embedding for estranged.\n",
      "['etched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5455,  1.7154, -0.0707,  ...,  0.3945,  1.2121, -0.2363])\n",
      "etched\n",
      "Saved the embedding for etched.\n",
      "['eu', '##ph', '##oric'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4479,  0.4078,  0.3806,  ..., -0.0454, -0.0462,  0.6276])\n",
      "euphoric\n",
      "Saved the embedding for euphoric.\n",
      "['evaluating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7706,  1.1251, -0.7134,  ...,  0.1939,  0.5190, -0.2742])\n",
      "evaluating\n",
      "Saved the embedding for evaluating.\n",
      "['eva', '##sive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6720, -0.2120,  0.7002,  ...,  0.0200,  0.6655,  0.8083])\n",
      "evasive\n",
      "Saved the embedding for evasive.\n",
      "['evil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0237,  1.1121,  0.5002,  ..., -0.3463,  0.0169, -0.0460])\n",
      "evil\n",
      "Saved the embedding for evil.\n",
      "['ev', '##oke'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5642,  0.2789,  0.1258,  ...,  0.0255,  0.1904,  0.0057])\n",
      "evoke\n",
      "Saved the embedding for evoke.\n",
      "['ex', '##ace', '##rba', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0608,  0.0526,  0.6478,  ..., -0.5556, -0.0599,  0.2801])\n",
      "exacerbated\n",
      "Saved the embedding for exacerbated.\n",
      "['ex', '##al', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3066,  0.1531,  0.0265,  ..., -0.2337,  0.0216,  0.3689])\n",
      "exalted\n",
      "Saved the embedding for exalted.\n",
      "['examining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1013,  0.7516, -0.8957,  ..., -0.2680,  0.4350, -0.4614])\n",
      "examining\n",
      "Saved the embedding for examining.\n",
      "['ex', '##as', '##per', '##ate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1713, -0.2564,  0.7356,  ..., -0.1677,  0.2791,  0.3763])\n",
      "exasperate\n",
      "Saved the embedding for exasperate.\n",
      "['exasperated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7475,  0.4939, -0.0636,  ..., -0.5797,  0.2463, -0.2381])\n",
      "exasperated\n",
      "Saved the embedding for exasperated.\n",
      "['ex', '##as', '##peration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7194, -0.3720,  0.4914,  ..., -0.4793, -0.1444,  0.8245])\n",
      "exasperation\n",
      "Saved the embedding for exasperation.\n",
      "['excited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3590,  1.2644, -0.0447,  ..., -0.0700,  0.1555,  0.3111])\n",
      "excited\n",
      "Saved the embedding for excited.\n",
      "['excitedly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1935,  0.4635, -0.5066,  ...,  0.0157, -0.4229, -0.4616])\n",
      "excitedly\n",
      "Saved the embedding for excitedly.\n",
      "['excitement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1288,  0.9165, -1.0112,  ..., -0.0368,  0.0751, -0.2469])\n",
      "excitement\n",
      "Saved the embedding for excitement.\n",
      "['ex', '##cl', '##ama', '##tion'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3170, -0.4549,  0.3972,  ..., -0.2922,  0.0914,  0.3806])\n",
      "exclamation\n",
      "Saved the embedding for exclamation.\n",
      "['ex', '##cl', '##ama', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1690, -0.4860,  0.6035,  ..., -0.2264,  0.1472,  0.4441])\n",
      "exclamatory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for exclamatory.\n",
      "['exhausted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8099,  0.8706, -0.6233,  ..., -0.1941,  0.1398, -0.9543])\n",
      "exhausted\n",
      "Saved the embedding for exhausted.\n",
      "['exhaustion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3739, -0.0341, -0.0057,  ...,  0.3555,  0.4834, -0.5527])\n",
      "exhaustion\n",
      "Saved the embedding for exhaustion.\n",
      "['exhaust', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5069,  0.8073, -0.5661,  ..., -0.4066,  1.1156, -1.0086])\n",
      "exhaustive\n",
      "Saved the embedding for exhaustive.\n",
      "['ex', '##hila', '##rated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4781, -0.5230,  0.5358,  ..., -0.3106,  0.2888,  0.2869])\n",
      "exhilarated\n",
      "Saved the embedding for exhilarated.\n",
      "['ex', '##hila', '##ration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0479, -0.4956,  0.3784,  ..., -0.3088,  0.1621,  0.3591])\n",
      "exhilaration\n",
      "Saved the embedding for exhilaration.\n",
      "['exited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5109,  1.2443, -0.9451,  ..., -0.3141,  0.1184, -0.0702])\n",
      "exited\n",
      "Saved the embedding for exited.\n",
      "['expect', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2543,  0.6252, -0.1603,  ...,  0.3457, -0.0978, -0.4837])\n",
      "expectant\n",
      "Saved the embedding for expectant.\n",
      "['expectation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2135,  1.8267,  0.0375,  ...,  0.0594,  0.7786, -0.4996])\n",
      "expectation\n",
      "Saved the embedding for expectation.\n",
      "['expecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6187,  1.2129, -0.7929,  ...,  0.2682, -0.1108, -0.3547])\n",
      "expecting\n",
      "Saved the embedding for expecting.\n",
      "['explain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5725,  0.6169, -0.3865,  ...,  0.4912,  0.8010, -0.1289])\n",
      "explain\n",
      "Saved the embedding for explain.\n",
      "['explaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3915,  0.5967, -0.4973,  ...,  0.5181,  0.2831, -0.1076])\n",
      "explaining\n",
      "Saved the embedding for explaining.\n",
      "['exploit', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5774,  1.2584,  0.1829,  ..., -0.3990, -0.1105, -0.1745])\n",
      "exploitive\n",
      "Saved the embedding for exploitive.\n",
      "['explosive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0396,  1.6723, -0.2573,  ..., -0.3052,  0.5541,  0.0125])\n",
      "explosive\n",
      "Saved the embedding for explosive.\n",
      "['exposure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4143,  1.0065,  0.4145,  ..., -0.5214,  0.2066, -0.2675])\n",
      "exposure\n",
      "Saved the embedding for exposure.\n",
      "['expressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3362,  1.6530, -0.0363,  ..., -0.2408,  0.2697, -0.4431])\n",
      "expressive\n",
      "Saved the embedding for expressive.\n",
      "['ex', '##uber', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0768,  0.0587,  0.3712,  ..., -0.5268,  0.2423,  0.4000])\n",
      "exuberant\n",
      "Saved the embedding for exuberant.\n",
      "['ex', '##ult', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2307,  0.2006,  0.4332,  ..., -0.1982,  0.4938,  0.1852])\n",
      "exultant\n",
      "Saved the embedding for exultant.\n",
      "['ex', '##ult', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1153,  0.0719,  0.6400,  ..., -0.3211,  0.1667,  0.0943])\n",
      "exulted\n",
      "Saved the embedding for exulted.\n",
      "['eye'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0240, 0.1725, 0.1985,  ..., 0.4867, 0.2728, 0.6860])\n",
      "eye\n",
      "Saved the embedding for eye.\n",
      "['eyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9696,  0.7408, -1.3888,  ...,  0.3970,  0.1785, -0.8266])\n",
      "eyed\n",
      "Saved the embedding for eyed.\n",
      "['faced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6938,  1.4274, -0.9275,  ...,  0.1940,  0.0395, -0.5811])\n",
      "faced\n",
      "Saved the embedding for faced.\n",
      "['face', '##tious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3867,  1.2370,  0.5565,  ...,  0.2226,  0.0731, -0.1198])\n",
      "facetious\n",
      "Saved the embedding for facetious.\n",
      "['failure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3801,  0.6914,  0.3684,  ..., -0.0093, -0.0228,  0.4331])\n",
      "failure\n",
      "Saved the embedding for failure.\n",
      "['faint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5017,  0.1270, -0.6830,  ..., -0.5027,  0.1109, -0.1340])\n",
      "faint\n",
      "Saved the embedding for faint.\n",
      "['fair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8813,  0.6447, -0.6163,  ...,  0.3154,  0.0619,  0.4393])\n",
      "fair\n",
      "Saved the embedding for fair.\n",
      "['fake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2851, -0.1287,  0.4517,  ..., -0.1535,  0.3692, -0.0306])\n",
      "fake\n",
      "Saved the embedding for fake.\n",
      "['fa', '##king'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1738,  0.3648,  0.0085,  ...,  0.3861,  0.3657, -0.0695])\n",
      "faking\n",
      "Saved the embedding for faking.\n",
      "['fa', '##lter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0599,  0.0708, -0.3081,  ...,  0.4359,  0.1907,  0.4593])\n",
      "falter\n",
      "Saved the embedding for falter.\n",
      "['fa', '##mis', '##hed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4880,  0.4390, -0.8080,  ...,  0.1566,  0.1412,  0.1010])\n",
      "famished\n",
      "Saved the embedding for famished.\n",
      "['fan', '##atic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3379,  0.9253,  0.6413,  ..., -0.7670,  0.2296,  0.1370])\n",
      "fanatic\n",
      "Saved the embedding for fanatic.\n",
      "['fan', '##ciful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1506,  0.7924,  1.3993,  ..., -0.3822,  0.2265,  0.0896])\n",
      "fanciful\n",
      "Saved the embedding for fanciful.\n",
      "['far', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0498,  0.5550,  0.4949,  ..., -0.0762,  0.1855,  0.2465])\n",
      "fart\n",
      "Saved the embedding for fart.\n",
      "['fascinated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0347,  0.9790, -0.7432,  ..., -0.1982,  0.7699, -0.7840])\n",
      "fascinated\n",
      "Saved the embedding for fascinated.\n",
      "['fast', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5444,  0.1689,  0.2721,  ..., -0.0666, -0.4574, -0.3882])\n",
      "fastidious\n",
      "Saved the embedding for fastidious.\n",
      "['fatigue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1785, -0.0065, -0.7114,  ...,  0.4516, -0.2256, -0.2616])\n",
      "fatigue\n",
      "Saved the embedding for fatigue.\n",
      "['fatigue', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7925,  0.5907,  0.2439,  ..., -0.2565, -0.5322, -0.4074])\n",
      "fatigued\n",
      "Saved the embedding for fatigued.\n",
      "['fault', '##fin', '##ding'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1229,  0.6688, -0.0453,  ..., -0.0707,  0.1743,  0.4728])\n",
      "faultfinding\n",
      "Saved the embedding for faultfinding.\n",
      "['favorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1641,  0.6542,  0.0835,  ...,  0.2360, -0.1045, -0.7168])\n",
      "favorable\n",
      "Saved the embedding for favorable.\n",
      "['fa', '##wn', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0159,  0.4588, -0.2108,  ...,  0.5912,  0.0582, -0.1275])\n",
      "fawning\n",
      "Saved the embedding for fawning.\n",
      "['fa', '##zed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1758,  0.1398,  0.2579,  ...,  0.4171, -0.0913,  0.3026])\n",
      "fazed\n",
      "Saved the embedding for fazed.\n",
      "['fear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2584,  1.3424, -1.1093,  ...,  0.1627, -0.3721, -0.3824])\n",
      "fear\n",
      "Saved the embedding for fear.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1501,  0.1288,  0.3425,  ..., -0.0146,  0.1106, -0.4962])\n",
      "feared\n",
      "Saved the embedding for feared.\n",
      "['fearful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5452,  0.8712, -0.4757,  ...,  0.2722,  0.2012, -0.0945])\n",
      "fearful\n",
      "Saved the embedding for fearful.\n",
      "['fearing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5610,  0.4636, -0.0186,  ...,  0.2207,  0.0051,  0.1376])\n",
      "fearing\n",
      "Saved the embedding for fearing.\n",
      "['fearless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2156,  1.6713,  0.2054,  ..., -0.0249,  0.2052,  1.0902])\n",
      "fearless\n",
      "Saved the embedding for fearless.\n",
      "['fears', '##ome'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4518,  0.7528, -0.3418,  ..., -0.3023,  0.6629, -0.0212])\n",
      "fearsome\n",
      "Saved the embedding for fearsome.\n",
      "['fe', '##ckle', '##ss'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1181,  0.2634,  0.0657,  ..., -0.1145, -0.0943, -0.1870])\n",
      "feckless\n",
      "Saved the embedding for feckless.\n",
      "['fed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7751,  1.1411, -0.6877,  ..., -0.5478,  0.8630,  0.2491])\n",
      "fed\n",
      "Saved the embedding for fed.\n",
      "['fee', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3449,  0.2264,  0.5554,  ...,  0.1959,  0.3191, -0.1512])\n",
      "feeble\n",
      "Saved the embedding for feeble.\n",
      "['fei', '##gn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2045,  0.3953, -0.6468,  ...,  0.7996, -0.0594, -0.1366])\n",
      "feign\n",
      "Saved the embedding for feign.\n",
      "['fe', '##lic', '##ito', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2668,  0.1344,  0.4022,  ..., -0.0103,  0.4062,  0.0008])\n",
      "felicitous\n",
      "Saved the embedding for felicitous.\n",
      "['ferocious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3256,  0.7103, -0.6705,  ..., -0.3784,  0.2621, -0.1576])\n",
      "ferocious\n",
      "Saved the embedding for ferocious.\n",
      "['fe', '##rocity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1728,  0.3109,  0.4434,  ..., -0.3124,  0.3325,  0.2266])\n",
      "ferocity\n",
      "Saved the embedding for ferocity.\n",
      "['fest', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4333,  1.0272,  0.2698,  ..., -0.1126,  0.0205,  0.2685])\n",
      "festive\n",
      "Saved the embedding for festive.\n",
      "['fi', '##dget', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5055, -0.3654, -0.0062,  ...,  0.5773,  0.5358,  0.1419])\n",
      "fidgety\n",
      "Saved the embedding for fidgety.\n",
      "['fi', '##end', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8222, -0.0909,  0.3498,  ..., -0.0399,  0.1368,  0.7135])\n",
      "fiendish\n",
      "Saved the embedding for fiendish.\n",
      "['fierce'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5189,  0.8155, -0.8142,  ..., -0.3782,  0.5124,  0.1014])\n",
      "fierce\n",
      "Saved the embedding for fierce.\n",
      "['fiery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4115,  0.9862, -0.5604,  ...,  0.4053,  0.2875, -0.0588])\n",
      "fiery\n",
      "Saved the embedding for fiery.\n",
      "['fighting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2085,  2.1764,  0.1492,  ...,  0.1764,  0.4940, -0.1830])\n",
      "fighting\n",
      "Saved the embedding for fighting.\n",
      "['fine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0234,  0.4886, -0.1017,  ..., -0.7845,  0.4315, -0.4450])\n",
      "fine\n",
      "Saved the embedding for fine.\n",
      "['finished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3697,  0.2452,  0.1642,  ..., -0.0931,  0.3186, -0.7043])\n",
      "finished\n",
      "Saved the embedding for finished.\n",
      "['firm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0437,  0.9463, -0.3109,  ...,  1.3328,  0.6474, -0.0342])\n",
      "firm\n",
      "Saved the embedding for firm.\n",
      "['fish', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6125,  0.5044, -1.2067,  ...,  0.2628,  0.1767, -0.3036])\n",
      "fishy\n",
      "Saved the embedding for fishy.\n",
      "['fix', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3188,  0.1045,  0.7922,  ..., -0.0211,  0.2598,  0.8028])\n",
      "fixated\n",
      "Saved the embedding for fixated.\n",
      "['fixed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7426,  0.4752,  1.0930,  ..., -0.3931,  0.4261,  0.5419])\n",
      "fixed\n",
      "Saved the embedding for fixed.\n",
      "['fl', '##ab', '##berg', '##ast', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.6828, -0.6150,  0.7397,  ...,  0.0525, -0.1677,  0.3786])\n",
      "flabbergasted\n",
      "Saved the embedding for flabbergasted.\n",
      "['flaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7260,  0.9331,  0.3362,  ..., -0.1611,  0.7741, -0.3128])\n",
      "flaming\n",
      "Saved the embedding for flaming.\n",
      "['flat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1697,  1.4168,  0.3420,  ..., -0.7350,  0.9108,  0.0197])\n",
      "flat\n",
      "Saved the embedding for flat.\n",
      "['fl', '##au', '##nting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7948, -0.1593,  0.1463,  ...,  0.3927,  0.2081,  0.1610])\n",
      "flaunting\n",
      "Saved the embedding for flaunting.\n",
      "['flight', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.3656, 0.2995, 0.2322,  ..., 0.6175, 0.1536, 0.4278])\n",
      "flighty\n",
      "Saved the embedding for flighty.\n",
      "['flip', '##pan', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0771,  0.9679,  0.4140,  ..., -0.3510,  0.0809,  0.1368])\n",
      "flippant\n",
      "Saved the embedding for flippant.\n",
      "['flipped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1075,  1.9542,  0.1665,  ...,  0.1357,  1.1522,  0.0440])\n",
      "flipped\n",
      "Saved the embedding for flipped.\n",
      "['flirt', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5939,  0.5591,  0.6787,  ..., -0.4045,  0.3510,  0.2144])\n",
      "flirtation\n",
      "Saved the embedding for flirtation.\n",
      "['flirt', '##ati', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2316,  0.8584,  0.4207,  ..., -0.7898,  0.3993, -0.5545])\n",
      "flirtatious\n",
      "Saved the embedding for flirtatious.\n",
      "['flirt', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0518,  1.3825, -0.1533,  ..., -0.5162,  0.1995, -0.3490])\n",
      "flirty\n",
      "Saved the embedding for flirty.\n",
      "['floor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5519,  0.9030, -0.3185,  ..., -0.6274,  0.4026,  0.4400])\n",
      "floored\n",
      "Saved the embedding for floored.\n",
      "['flu', '##mm', '##ox', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6285, -0.5968,  0.4309,  ...,  0.4516,  0.3600,  0.5520])\n",
      "flummoxed\n",
      "Saved the embedding for flummoxed.\n",
      "['flu', '##stered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0872, -0.4537,  0.8861,  ..., -0.2669,  0.5565, -0.3131])\n",
      "flustered\n",
      "Saved the embedding for flustered.\n",
      "['focus'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0952,  1.2077, -0.5747,  ..., -0.1331,  0.0217,  0.0043])\n",
      "focus\n",
      "Saved the embedding for focus.\n",
      "['focused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0570,  1.0518, -1.3865,  ...,  0.0372,  0.3359,  0.0877])\n",
      "focused\n",
      "Saved the embedding for focused.\n",
      "['focusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9004,  0.3329, -0.1383,  ...,  0.3393,  0.2391,  0.1574])\n",
      "focusing\n",
      "Saved the embedding for focusing.\n",
      "['foil', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4782,  0.4543, -0.1805,  ...,  0.2365,  0.1429,  0.5909])\n",
      "foiled\n",
      "Saved the embedding for foiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foolish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0308,  0.8201, -0.9820,  ..., -0.0695,  0.9513,  0.2258])\n",
      "foolish\n",
      "Saved the embedding for foolish.\n",
      "['for', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7535, -0.2512,  0.6949,  ..., -0.0350, -0.6964, -0.1669])\n",
      "forbearing\n",
      "Saved the embedding for forbearing.\n",
      "['forbid', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2735,  0.6298, -1.0290,  ...,  0.3084,  0.2092,  0.3779])\n",
      "forbidding\n",
      "Saved the embedding for forbidding.\n",
      "['forced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5998,  0.2714,  0.3786,  ...,  0.8086,  0.3311,  0.3569])\n",
      "forced\n",
      "Saved the embedding for forced.\n",
      "['forceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2638,  0.6706,  0.2305,  ..., -0.2790,  0.1487, -0.2512])\n",
      "forceful\n",
      "Saved the embedding for forceful.\n",
      "['for', '##feit', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3655, -0.0884,  0.3287,  ...,  0.0191, -0.2234,  0.3312])\n",
      "forfeited\n",
      "Saved the embedding for forfeited.\n",
      "['for', '##lor', '##n'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2694,  0.4919,  0.5672,  ...,  0.2778,  0.4472,  0.3559])\n",
      "forlorn\n",
      "Saved the embedding for forlorn.\n",
      "['fortunate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5021,  0.4756,  0.2009,  ..., -0.6573, -0.0261, -0.0375])\n",
      "fortunate\n",
      "Saved the embedding for fortunate.\n",
      "['forward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9901,  1.2488,  0.2521,  ...,  0.3880,  0.6169, -0.4694])\n",
      "forward\n",
      "Saved the embedding for forward.\n",
      "['foul'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4043,  1.6275,  0.0627,  ..., -0.4580,  0.4736, -0.0062])\n",
      "foul\n",
      "Saved the embedding for foul.\n",
      "['fra', '##ct', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8268,  0.7208, -0.1018,  ...,  0.8263,  0.4025,  1.1105])\n",
      "fractious\n",
      "Saved the embedding for fractious.\n",
      "['fragile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2154,  0.8466, -0.8788,  ...,  0.2788, -0.0292, -0.5541])\n",
      "fragile\n",
      "Saved the embedding for fragile.\n",
      "['frantic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5457,  0.0961, -0.7337,  ..., -0.2838,  1.1896, -0.2728])\n",
      "frantic\n",
      "Saved the embedding for frantic.\n",
      "['fraudulent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0123, -0.1109,  0.2362,  ...,  0.0462,  0.4673,  0.6667])\n",
      "fraudulent\n",
      "Saved the embedding for fraudulent.\n",
      "['fra', '##ught'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9133,  0.5825, -0.2552,  ..., -0.2784,  0.1838,  0.7220])\n",
      "fraught\n",
      "Saved the embedding for fraught.\n",
      "['fra', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0384,  0.4850, -0.0596,  ...,  0.6603,  0.4126,  0.9530])\n",
      "frazzled\n",
      "Saved the embedding for frazzled.\n",
      "['freaked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2812,  1.3295, -0.3574,  ...,  0.4811, -0.1547,  0.1690])\n",
      "freaked\n",
      "Saved the embedding for freaked.\n",
      "['fr', '##en', '##zie', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4952, -0.1862,  0.3578,  ...,  0.4231,  0.3466,  0.3595])\n",
      "frenzied\n",
      "Saved the embedding for frenzied.\n",
      "['fr', '##et', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9295,  0.6503,  0.5545,  ...,  0.0714, -0.1325,  0.4522])\n",
      "fretful\n",
      "Saved the embedding for fretful.\n",
      "['friend', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8582,  0.2843,  0.5821,  ..., -0.1445, -0.0922,  0.5704])\n",
      "friendliness\n",
      "Saved the embedding for friendliness.\n",
      "['friendly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1475,  0.8195, -1.0372,  ...,  0.6960,  0.0396, -0.4041])\n",
      "friendly\n",
      "Saved the embedding for friendly.\n",
      "['fright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2778, -0.1100,  0.1555,  ...,  0.1793,  0.4113,  0.1709])\n",
      "fright\n",
      "Saved the embedding for fright.\n",
      "['frightened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1772,  1.0361, -1.3355,  ...,  0.7207,  0.3742,  0.3789])\n",
      "frightened\n",
      "Saved the embedding for frightened.\n",
      "['frightening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1698,  1.3206, -1.5697,  ..., -0.4002,  0.6055, -0.1089])\n",
      "frightening\n",
      "Saved the embedding for frightening.\n",
      "['fr', '##ig', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5595, -0.1936,  0.9349,  ...,  0.6280,  0.0950,  0.1775])\n",
      "frigid\n",
      "Saved the embedding for frigid.\n",
      "['fr', '##isk', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.2803,  0.9082,  0.1326,  ...,  0.5463,  0.3777, -0.1626])\n",
      "frisky\n",
      "Saved the embedding for frisky.\n",
      "['fr', '##olic', '##ker'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7585,  1.0399,  0.4016,  ...,  0.3131,  0.0026,  0.2296])\n",
      "frolicker\n",
      "Saved the embedding for frolicker.\n",
      "['frown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9798,  1.3850, -0.4509,  ...,  0.0464,  0.1234, -0.7393])\n",
      "frown\n",
      "Saved the embedding for frown.\n",
      "['frowning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9952,  0.4994, -1.0773,  ...,  0.5326,  0.8275, -0.4695])\n",
      "frowning\n",
      "Saved the embedding for frowning.\n",
      "['frozen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7560,  1.1984, -0.1440,  ..., -0.0958,  0.6190,  0.3853])\n",
      "frozen\n",
      "Saved the embedding for frozen.\n",
      "['fr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4149, -0.3087,  0.9335,  ...,  0.5229, -0.1202,  0.0406])\n",
      "frumpy\n",
      "Saved the embedding for frumpy.\n",
      "['frustrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2611,  0.6024, -0.7282,  ..., -0.2311, -0.1528,  0.3317])\n",
      "frustrated\n",
      "Saved the embedding for frustrated.\n",
      "['frustration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0719,  0.0498, -0.3554,  ...,  0.0310, -0.1714, -0.0991])\n",
      "frustration\n",
      "Saved the embedding for frustration.\n",
      "['fulfilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1989,  0.4767, -1.5566,  ...,  0.3461, -0.0520, -0.1432])\n",
      "fulfilled\n",
      "Saved the embedding for fulfilled.\n",
      "['fu', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.2009,  0.8317, -0.0739,  ...,  0.3818, -0.1699,  0.0925])\n",
      "fumed\n",
      "Saved the embedding for fumed.\n",
      "['fu', '##ming'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5878,  0.7004, -0.2076,  ...,  0.3508,  0.2403,  0.2360])\n",
      "fuming\n",
      "Saved the embedding for fuming.\n",
      "['fun'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0927,  1.1161,  0.3717,  ...,  0.0563,  0.1228,  1.0424])\n",
      "fun\n",
      "Saved the embedding for fun.\n",
      "['funny'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1793,  1.1017, -0.8389,  ...,  0.3245,  0.0733, -0.0942])\n",
      "funny\n",
      "Saved the embedding for funny.\n",
      "['furious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1595,  0.5600, -0.7064,  ...,  0.3047,  0.6212,  0.1609])\n",
      "furious\n",
      "Saved the embedding for furious.\n",
      "['furiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1774,  0.6503, -0.8776,  ..., -0.2104,  0.1352, -0.3173])\n",
      "furiously\n",
      "Saved the embedding for furiously.\n",
      "['furious', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3168,  0.6682,  0.3925,  ...,  0.3418,  0.4699, -0.4423])\n",
      "furiousness\n",
      "Saved the embedding for furiousness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['furrowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1532,  0.3589,  0.0397,  ..., -0.6101,  0.3727, -0.0563])\n",
      "furrowed\n",
      "Saved the embedding for furrowed.\n",
      "['fur', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5498, -0.0429,  0.0174,  ...,  0.1546,  0.8871, -0.1897])\n",
      "furtive\n",
      "Saved the embedding for furtive.\n",
      "['fury'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0528,  1.5857,  0.2010,  ..., -0.3064,  0.4775, -0.1552])\n",
      "fury\n",
      "Saved the embedding for fury.\n",
      "['fuss', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2606,  1.2445, -0.5182,  ...,  0.5664,  0.2463,  0.1482])\n",
      "fussy\n",
      "Saved the embedding for fussy.\n",
      "['gall', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2005,  0.8964, -0.4442,  ...,  0.1267,  0.5849, -0.0285])\n",
      "galled\n",
      "Saved the embedding for galled.\n",
      "['gall', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0885,  1.0846, -0.9232,  ...,  0.0489,  0.8859, -0.5255])\n",
      "galling\n",
      "Saved the embedding for galling.\n",
      "['gasp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1812,  1.7983,  0.6629,  ..., -0.1499,  1.1656, -0.6678])\n",
      "gasp\n",
      "Saved the embedding for gasp.\n",
      "['gasped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9845,  0.6658, -0.5847,  ...,  0.1684,  0.0311,  0.2284])\n",
      "gasped\n",
      "Saved the embedding for gasped.\n",
      "['gasping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1423,  0.8033, -0.3867,  ...,  0.3167,  0.4744,  0.2582])\n",
      "gasping\n",
      "Saved the embedding for gasping.\n",
      "['gay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0188,  1.3349,  0.7229,  ...,  0.0237,  0.0829,  0.1555])\n",
      "gay\n",
      "Saved the embedding for gay.\n",
      "['gazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6147,  0.6954, -1.6855,  ...,  0.4157,  0.7949,  0.3418])\n",
      "gazing\n",
      "Saved the embedding for gazing.\n",
      "['gen', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2289,  0.6347, -0.3966,  ...,  0.1715,  0.6610, -0.0467])\n",
      "genial\n",
      "Saved the embedding for genial.\n",
      "['gentle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3925,  0.3750,  0.1342,  ...,  0.0414,  0.2033,  0.0082])\n",
      "gentle\n",
      "Saved the embedding for gentle.\n",
      "['genuine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5684,  0.4525,  0.2844,  ..., -0.2545,  0.2129, -0.3407])\n",
      "genuine\n",
      "Saved the embedding for genuine.\n",
      "['g', '##has', '##tly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5255, -0.0616,  1.1320,  ..., -0.1975,  0.0219,  0.2157])\n",
      "ghastly\n",
      "Saved the embedding for ghastly.\n",
      "['gi', '##ddy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4858, -0.5378,  0.3177,  ...,  0.4480,  0.7737,  0.1989])\n",
      "giddy\n",
      "Saved the embedding for giddy.\n",
      "['giggle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0465,  0.0458, -0.5857,  ...,  0.2800,  0.9692,  0.1285])\n",
      "giggle\n",
      "Saved the embedding for giggle.\n",
      "['giggling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0675,  0.5423, -1.0418,  ...,  0.3490,  0.6323, -0.1550])\n",
      "giggling\n",
      "Saved the embedding for giggling.\n",
      "['glad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6282,  0.8210, -0.4555,  ...,  0.3299,  0.3541, -0.0709])\n",
      "glad\n",
      "Saved the embedding for glad.\n",
      "['glad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5014,  0.8641,  1.1870,  ..., -0.1676, -0.0434,  0.1689])\n",
      "gladdened\n",
      "Saved the embedding for gladdened.\n",
      "['glad', '##iol', '##a'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1281,  0.1847, -0.2669,  ...,  0.4091, -0.1607,  0.3880])\n",
      "gladiola\n",
      "Saved the embedding for gladiola.\n",
      "['glad', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1918,  0.2723,  0.5944,  ..., -0.1156,  0.2738,  0.7779])\n",
      "gladness\n",
      "Saved the embedding for gladness.\n",
      "['glad', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3155,  0.3253,  0.6346,  ..., -0.0634, -0.1517,  0.0633])\n",
      "gladsome\n",
      "Saved the embedding for gladsome.\n",
      "['glare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0663,  1.0587, -1.3805,  ..., -0.2317,  0.7879, -0.4128])\n",
      "glare\n",
      "Saved the embedding for glare.\n",
      "['glaring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3083,  1.2409, -0.9019,  ...,  0.3747,  0.4332, -0.3676])\n",
      "glaring\n",
      "Saved the embedding for glaring.\n",
      "['glazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5384,  1.0614, -0.1256,  ..., -0.1719,  0.5865,  0.6158])\n",
      "glazed\n",
      "Saved the embedding for glazed.\n",
      "['glee'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2730, -0.2140, -1.0975,  ...,  0.2069,  0.8267, -0.4662])\n",
      "glee\n",
      "Saved the embedding for glee.\n",
      "['glee', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6938,  0.4944, -0.4577,  ..., -0.3552,  0.5898, -0.5637])\n",
      "gleeful\n",
      "Saved the embedding for gleeful.\n",
      "['glee', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7796,  0.5170,  0.2112,  ..., -0.2204,  0.5153, -0.4087])\n",
      "gleefully\n",
      "Saved the embedding for gleefully.\n",
      "['g', '##lib'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2395,  0.2061,  0.5819,  ...,  0.8456,  0.9354,  0.7098])\n",
      "glib\n",
      "Saved the embedding for glib.\n",
      "['g', '##lo', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3935,  0.0206,  0.3996,  ...,  0.4916,  0.1424,  0.4241])\n",
      "gloating\n",
      "Saved the embedding for gloating.\n",
      "['gloom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1253,  1.7049,  0.3366,  ..., -0.2761,  0.4343,  0.2366])\n",
      "gloom\n",
      "Saved the embedding for gloom.\n",
      "['gloom', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3711,  1.0603,  0.7384,  ...,  0.2050, -0.0199,  0.2365])\n",
      "gloomy\n",
      "Saved the embedding for gloomy.\n",
      "['glow', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2697,  0.7962,  0.6508,  ...,  0.0996,  0.4113, -0.3456])\n",
      "glowering\n",
      "Saved the embedding for glowering.\n",
      "['glowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 2.3529e-01,  1.0598e+00,  1.0513e-03,  ...,  7.4622e-01,\n",
      "         7.2901e-01, -4.4943e-01])\n",
      "glowing\n",
      "Saved the embedding for glowing.\n",
      "['g', '##lum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3858,  0.3603,  0.6320,  ...,  1.0035,  0.5168,  0.0306])\n",
      "glum\n",
      "Saved the embedding for glum.\n",
      "['g', '##nar', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3077,  0.1861,  0.3347,  ...,  1.0204,  0.5147, -0.1755])\n",
      "gnarl\n",
      "Saved the embedding for gnarl.\n",
      "['go', '##bs', '##mack', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0283, -0.4634,  0.2676,  ...,  0.0734,  0.3309,  0.4546])\n",
      "gobsmacked\n",
      "Saved the embedding for gobsmacked.\n",
      "['good'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6683,  0.5811, -0.3333,  ..., -0.0535,  0.2564, -0.4447])\n",
      "good\n",
      "Saved the embedding for good.\n",
      "['goofy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8312,  0.6131,  0.4400,  ...,  0.9524,  0.8106,  0.4807])\n",
      "goofy\n",
      "Saved the embedding for goofy.\n",
      "['gossip', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3386,  0.7059,  0.1345,  ...,  0.0822,  0.3507, -0.8090])\n",
      "gossipy\n",
      "Saved the embedding for gossipy.\n",
      "['grand', '##ios', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0307,  0.5401, -0.0255,  ..., -0.2325, -0.0840,  0.5131])\n",
      "grandiose\n",
      "Saved the embedding for grandiose.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grateful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5439,  0.4296, -1.5872,  ...,  0.4198,  0.6978, -0.5881])\n",
      "grateful\n",
      "Saved the embedding for grateful.\n",
      "['gr', '##ati', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3950,  0.8429,  1.0089,  ..., -0.2544,  0.2081,  0.5568])\n",
      "gratified\n",
      "Saved the embedding for gratified.\n",
      "['grave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5321,  1.3198,  0.8950,  ..., -0.0050,  0.0836,  0.6854])\n",
      "grave\n",
      "Saved the embedding for grave.\n",
      "['great'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.8502e-01,  8.2093e-01,  1.3554e+00,  ..., -9.7020e-02,\n",
      "         7.1746e-01,  1.2593e-03])\n",
      "great\n",
      "Saved the embedding for great.\n",
      "['greedy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2369,  1.5280, -0.1658,  ...,  0.0921, -0.1741, -0.6235])\n",
      "greedy\n",
      "Saved the embedding for greedy.\n",
      "['greeting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7341,  0.7666, -0.9666,  ...,  0.3163,  0.6623, -0.3583])\n",
      "greeting\n",
      "Saved the embedding for greeting.\n",
      "['grief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6834,  0.9088, -1.5762,  ...,  0.3819,  0.2798, -0.0757])\n",
      "grief\n",
      "Saved the embedding for grief.\n",
      "['gr', '##ie', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.4550, 0.9068, 0.1835,  ..., 0.6920, 0.6968, 0.0282])\n",
      "grieved\n",
      "Saved the embedding for grieved.\n",
      "['gr', '##ieving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2456,  0.1615,  0.5499,  ...,  0.5970,  0.2570,  0.1804])\n",
      "grieving\n",
      "Saved the embedding for grieving.\n",
      "['grim'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4410,  1.2135, -0.2542,  ..., -0.2806,  0.3669,  0.9683])\n",
      "grim\n",
      "Saved the embedding for grim.\n",
      "['grimace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3579,  1.3537, -1.5868,  ..., -0.1658,  0.5623, -0.6646])\n",
      "grimace\n",
      "Saved the embedding for grimace.\n",
      "['grim', '##acing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3192,  1.1320, -0.1866,  ..., -0.6329,  0.2235,  0.5934])\n",
      "grimacing\n",
      "Saved the embedding for grimacing.\n",
      "['grin'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8257,  1.3016,  0.0098,  ...,  0.2924,  0.1663, -0.2554])\n",
      "grin\n",
      "Saved the embedding for grin.\n",
      "['grinning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3932,  1.0830, -1.4199,  ...,  0.9091,  0.7084,  0.2712])\n",
      "grinning\n",
      "Saved the embedding for grinning.\n",
      "['grip', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9257,  1.3665, -0.7352,  ..., -0.0716,  0.9316, -0.5711])\n",
      "griping\n",
      "Saved the embedding for griping.\n",
      "['gross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7173,  0.9775, -0.3037,  ..., -0.1530,  0.3444,  0.1716])\n",
      "gross\n",
      "Saved the embedding for gross.\n",
      "['grossed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3300,  0.4410, -0.2780,  ..., -0.4055,  0.6765, -0.3033])\n",
      "grossed\n",
      "Saved the embedding for grossed.\n",
      "['gr', '##ou', '##chy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3619,  0.7692, -0.6910,  ...,  0.0055,  0.4474,  0.8098])\n",
      "grouchy\n",
      "Saved the embedding for grouchy.\n",
      "['growl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7647,  0.1796, -0.9285,  ..., -0.0306,  0.5665, -0.0194])\n",
      "growl\n",
      "Saved the embedding for growl.\n",
      "['growling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7062,  0.6114, -0.0800,  ...,  0.3223,  0.3159, -0.1345])\n",
      "growling\n",
      "Saved the embedding for growling.\n",
      "['gr', '##udge'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2005, -0.6690,  0.6993,  ...,  0.1106,  0.4843,  0.2431])\n",
      "grudge\n",
      "Saved the embedding for grudge.\n",
      "['gr', '##ud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5687,  0.4710, -0.4500,  ...,  0.5712, -0.1856, -0.0746])\n",
      "grudging\n",
      "Saved the embedding for grudging.\n",
      "['gruff'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0027,  0.4431, -0.4467,  ..., -0.5454,  0.2478,  0.2844])\n",
      "gruff\n",
      "Saved the embedding for gruff.\n",
      "['gr', '##umb', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2749,  0.1454,  0.1746,  ...,  0.5835,  0.2513,  0.2024])\n",
      "grumbling\n",
      "Saved the embedding for grumbling.\n",
      "['gr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6482,  0.6188,  1.0595,  ...,  0.6347,  0.4071,  0.6270])\n",
      "grumpy\n",
      "Saved the embedding for grumpy.\n",
      "['grunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1377,  0.3923, -0.3480,  ...,  0.3972,  0.8984, -0.6909])\n",
      "grunt\n",
      "Saved the embedding for grunt.\n",
      "['grunt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1471,  0.9168,  0.1843,  ...,  0.3748,  0.4619, -0.1146])\n",
      "grunting\n",
      "Saved the embedding for grunting.\n",
      "['guarded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1371,  0.8422, -0.5533,  ..., -0.3690,  0.0118, -0.6288])\n",
      "guarded\n",
      "Saved the embedding for guarded.\n",
      "['guilty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0998,  0.8922,  0.2074,  ..., -0.3589,  0.4107, -0.4808])\n",
      "guilty\n",
      "Saved the embedding for guilty.\n",
      "['gulp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5653,  1.1086, -1.2453,  ...,  0.1385,  0.9316, -0.3627])\n",
      "gulp\n",
      "Saved the embedding for gulp.\n",
      "['haggard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5258,  0.4773, -0.2827,  ..., -0.3003,  0.9668, -0.5372])\n",
      "haggard\n",
      "Saved the embedding for haggard.\n",
      "['half', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4902,  0.8900,  0.9051,  ..., -0.6588,  0.1766, -0.0995])\n",
      "halfhearted\n",
      "Saved the embedding for halfhearted.\n",
      "['halted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5332,  0.1990, -0.6830,  ..., -0.6692, -0.1310, -0.5603])\n",
      "halted\n",
      "Saved the embedding for halted.\n",
      "['ha', '##ples', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4530, -0.8444,  1.0097,  ..., -0.4196,  0.3978,  0.1819])\n",
      "hapless\n",
      "Saved the embedding for hapless.\n",
      "['happiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9763,  0.4887, -0.4486,  ...,  0.4674,  0.5012, -0.4227])\n",
      "happiness\n",
      "Saved the embedding for happiness.\n",
      "['happy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5161,  0.9230, -1.0155,  ...,  0.2680, -0.1714, -0.7903])\n",
      "happy\n",
      "Saved the embedding for happy.\n",
      "['harassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0293,  0.6693, -0.6560,  ...,  0.1758,  0.1718, -0.3813])\n",
      "harassed\n",
      "Saved the embedding for harassed.\n",
      "['hard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6910,  1.2892, -1.1824,  ...,  0.1380,  0.9097, -0.2307])\n",
      "hard\n",
      "Saved the embedding for hard.\n",
      "['hardened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6923,  0.2003, -0.5248,  ...,  0.5472, -0.2015,  0.3741])\n",
      "hardened\n",
      "Saved the embedding for hardened.\n",
      "['harmful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3274,  0.0917,  0.3479,  ..., -0.0951, -0.0183,  0.2245])\n",
      "harmful\n",
      "Saved the embedding for harmful.\n",
      "['ha', '##rrie', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0828, -0.0115,  0.2459,  ..., -0.2198,  0.6191,  0.0997])\n",
      "harried\n",
      "Saved the embedding for harried.\n",
      "['harsh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7087,  0.6194, -1.0126,  ...,  0.5261,  0.1991,  0.0374])\n",
      "harsh\n",
      "Saved the embedding for harsh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0653,  1.1206, -1.1841,  ...,  0.3572,  0.0322,  0.0620])\n",
      "hate\n",
      "Saved the embedding for hate.\n",
      "['hate', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2143,  1.6690, -0.8433,  ..., -0.1749,  0.4242, -0.2195])\n",
      "hateful\n",
      "Saved the embedding for hateful.\n",
      "['hating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4517,  0.8572, -0.4147,  ..., -0.1127,  0.3792,  0.5469])\n",
      "hating\n",
      "Saved the embedding for hating.\n",
      "['hatred'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0857,  1.1281,  0.4196,  ..., -0.1205,  0.3174,  0.0901])\n",
      "hatred\n",
      "Saved the embedding for hatred.\n",
      "['ha', '##ught', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4409,  0.0081,  0.7730,  ..., -0.2836,  0.1957,  0.2670])\n",
      "haughty\n",
      "Saved the embedding for haughty.\n",
      "['haunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3537, -0.0938,  0.5782,  ..., -0.1449,  0.5945,  0.3466])\n",
      "haunted\n",
      "Saved the embedding for haunted.\n",
      "['hazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8667,  0.7683, -1.3488,  ...,  0.9429,  0.9073, -0.6167])\n",
      "hazy\n",
      "Saved the embedding for hazy.\n",
      "['heads', '##hak', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6299,  0.7905,  0.9831,  ..., -0.2504,  0.3117,  0.0359])\n",
      "headshake\n",
      "Saved the embedding for headshake.\n",
      "['heart', '##ache'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4212,  1.0869,  0.2774,  ..., -0.4983, -0.3426,  0.0885])\n",
      "heartache\n",
      "Saved the embedding for heartache.\n",
      "['heart', '##broken'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3542,  1.2667,  0.8229,  ...,  0.0776, -0.1283, -0.0113])\n",
      "heartbroken\n",
      "Saved the embedding for heartbroken.\n",
      "['hearted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0305,  0.6588, -0.0466,  ..., -0.4322,  0.2320, -0.3881])\n",
      "hearted\n",
      "Saved the embedding for hearted.\n",
      "['hearts', '##ick'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5154,  0.7270,  0.2911,  ...,  0.3954, -0.0454,  0.7965])\n",
      "heartsick\n",
      "Saved the embedding for heartsick.\n",
      "['heated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1393,  0.4685, -0.2216,  ..., -0.5314,  0.0361,  0.3543])\n",
      "heated\n",
      "Saved the embedding for heated.\n",
      "['heavy', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4732,  1.2912,  0.3696,  ..., -0.3706,  0.2293, -0.9570])\n",
      "heavyhearted\n",
      "Saved the embedding for heavyhearted.\n",
      "['heck', '##le'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2134,  0.7319, -0.0552,  ..., -0.2404,  0.5886, -0.0428])\n",
      "heckle\n",
      "Saved the embedding for heckle.\n",
      "['hee', '##df', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3326, -0.0100,  0.5850,  ...,  0.2447,  0.1639,  0.2754])\n",
      "heedful\n",
      "Saved the embedding for heedful.\n",
      "['he', '##ino', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7517,  0.5699,  0.3367,  ..., -0.0459,  0.1241,  0.6971])\n",
      "heinous\n",
      "Saved the embedding for heinous.\n",
      "['helpful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0456,  0.5788, -0.6157,  ..., -0.4451, -0.2043,  0.0227])\n",
      "helpful\n",
      "Saved the embedding for helpful.\n",
      "['helpless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8715,  0.3712, -0.8326,  ...,  0.1431,  0.3937, -0.0027])\n",
      "helpless\n",
      "Saved the embedding for helpless.\n",
      "['hesitant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6065,  1.3222, -1.2970,  ...,  0.0155,  0.3925, -0.0679])\n",
      "hesitant\n",
      "Saved the embedding for hesitant.\n",
      "['hesitantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7273,  1.5467, -0.9632,  ..., -0.0173, -0.0763, -0.1470])\n",
      "hesitantly\n",
      "Saved the embedding for hesitantly.\n",
      "['he', '##sit', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0896,  0.1052, -0.2113,  ...,  0.5705, -0.4439, -0.1280])\n",
      "hesitating\n",
      "Saved the embedding for hesitating.\n",
      "['hesitation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4904,  0.2904, -0.9703,  ...,  0.1981,  0.1910, -0.3066])\n",
      "hesitation\n",
      "Saved the embedding for hesitation.\n",
      "['high'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4454,  1.0814, -1.1154,  ..., -0.1744,  1.1351,  0.0439])\n",
      "high\n",
      "Saved the embedding for high.\n",
      "['ho', '##ller', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2833,  0.4099,  0.2640,  ...,  0.1565, -0.2558,  0.1566])\n",
      "hollering\n",
      "Saved the embedding for hollering.\n",
      "['ho', '##mic', '##idal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2585,  0.2317,  0.8938,  ...,  0.3065,  0.6533, -0.4609])\n",
      "homicidal\n",
      "Saved the embedding for homicidal.\n",
      "['honest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0042,  0.6499,  0.3434,  ..., -0.2387,  0.1846,  0.2759])\n",
      "honest\n",
      "Saved the embedding for honest.\n",
      "['honorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2901,  0.4456,  0.5673,  ...,  0.1095, -0.1003,  0.2537])\n",
      "honorable\n",
      "Saved the embedding for honorable.\n",
      "['hope'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-3.5444e-01,  1.3703e+00, -1.1984e+00,  ...,  6.8933e-04,\n",
      "         2.1810e-01, -3.3776e-01])\n",
      "hope\n",
      "Saved the embedding for hope.\n",
      "['hopeful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6144,  0.9055, -1.1490,  ..., -1.0826,  0.1098, -0.8665])\n",
      "hopeful\n",
      "Saved the embedding for hopeful.\n",
      "['hopeful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8641,  0.1499,  0.8275,  ..., -0.2783,  0.1044, -0.3015])\n",
      "hopefulness\n",
      "Saved the embedding for hopefulness.\n",
      "['hopeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1471,  0.8365,  0.2032,  ...,  0.0073,  0.1786, -0.2369])\n",
      "hopeless\n",
      "Saved the embedding for hopeless.\n",
      "['hoping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0246,  0.1832, -0.3674,  ...,  0.5811,  0.6038, -0.5627])\n",
      "hoping\n",
      "Saved the embedding for hoping.\n",
      "['horn', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9547,  0.2062, -0.5716,  ...,  0.1298, -0.0099,  0.1531])\n",
      "horny\n",
      "Saved the embedding for horny.\n",
      "['horrible'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4331,  1.0672, -1.7558,  ...,  0.7019,  1.1411, -0.0775])\n",
      "horrible\n",
      "Saved the embedding for horrible.\n",
      "['horrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0542,  0.5996,  0.0578,  ..., -0.0241,  0.6696,  0.1790])\n",
      "horrified\n",
      "Saved the embedding for horrified.\n",
      "['ho', '##rri', '##fy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2535,  0.5494,  1.1481,  ...,  0.0514,  0.0109,  0.3120])\n",
      "horrify\n",
      "Saved the embedding for horrify.\n",
      "['ho', '##rri', '##fying'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.0294, 0.9473, 0.6560,  ..., 0.2511, 0.2625, 0.3798])\n",
      "horrifying\n",
      "Saved the embedding for horrifying.\n",
      "['horror'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3801,  1.8072, -0.0793,  ..., -0.0446,  0.7228, -0.6004])\n",
      "horror\n",
      "Saved the embedding for horror.\n",
      "['hostile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3382,  0.8256, -0.4046,  ...,  0.5191, -0.4588, -0.2451])\n",
      "hostile\n",
      "Saved the embedding for hostile.\n",
      "['hostility'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2388,  0.5653, -0.3272,  ..., -0.1824, -0.1259, -0.2677])\n",
      "hostility\n",
      "Saved the embedding for hostility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hot'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0904,  0.4664, -0.2412,  ..., -0.3534,  0.2074,  0.0857])\n",
      "hot\n",
      "Saved the embedding for hot.\n",
      "['hot', '##shot'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4799,  0.3302,  0.7781,  ..., -0.2547,  0.2604, -0.0457])\n",
      "hotshot\n",
      "Saved the embedding for hotshot.\n",
      "['huff', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6843,  0.9605,  0.5473,  ..., -0.0785, -0.1712,  0.3303])\n",
      "huffiness\n",
      "Saved the embedding for huffiness.\n",
      "['huff', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7372,  0.7603, -0.1738,  ..., -0.1344,  0.2386, -0.3204])\n",
      "huffy\n",
      "Saved the embedding for huffy.\n",
      "['humble'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1018,  1.3629,  0.5269,  ...,  0.1421, -0.0299,  0.4913])\n",
      "humble\n",
      "Saved the embedding for humble.\n",
      "['humble', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-2.8419e-01,  1.3386e+00,  8.9819e-01,  ..., -5.2815e-04,\n",
      "        -1.6875e-01,  6.6721e-01])\n",
      "humbled\n",
      "Saved the embedding for humbled.\n",
      "['hum', '##drum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2784,  0.5250, -0.1522,  ...,  0.1914,  0.1508,  0.1485])\n",
      "humdrum\n",
      "Saved the embedding for humdrum.\n",
      "['humiliated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.6379,  0.9412, -0.5192,  ...,  0.6180, -0.2170,  0.5360])\n",
      "humiliated\n",
      "Saved the embedding for humiliated.\n",
      "['hum', '##ility'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7712,  0.2955,  0.6346,  ..., -0.1038, -0.2097,  0.3766])\n",
      "humility\n",
      "Saved the embedding for humility.\n",
      "['humming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0515,  0.6395, -1.3041,  ...,  0.5799,  0.9905, -0.0850])\n",
      "humming\n",
      "Saved the embedding for humming.\n",
      "['humor'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5495,  1.3860,  0.5393,  ..., -0.3021,  0.4898,  0.6513])\n",
      "humor\n",
      "Saved the embedding for humor.\n",
      "['humor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0402,  1.1899,  0.2059,  ...,  0.1149,  0.2874,  0.0824])\n",
      "humored\n",
      "Saved the embedding for humored.\n",
      "['humorous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3798,  0.2212, -0.7023,  ...,  0.2851,  0.3242, -0.0095])\n",
      "humorous\n",
      "Saved the embedding for humorous.\n",
      "['hunger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9767,  0.9871,  0.0063,  ..., -0.0960,  0.2004,  0.1411])\n",
      "hunger\n",
      "Saved the embedding for hunger.\n",
      "['hungry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2891,  0.8977, -0.6714,  ..., -0.2839,  0.5286, -0.4274])\n",
      "hungry\n",
      "Saved the embedding for hungry.\n",
      "['hunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4025,  0.8238, -1.1233,  ..., -0.0514,  1.1835, -0.2518])\n",
      "hunted\n",
      "Saved the embedding for hunted.\n",
      "['hurt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2857,  0.8161, -0.4796,  ..., -0.2247, -0.2410,  0.1469])\n",
      "hurt\n",
      "Saved the embedding for hurt.\n",
      "['hurt', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3044,  0.6186,  0.2734,  ...,  0.1156,  0.1860,  0.3831])\n",
      "hurtful\n",
      "Saved the embedding for hurtful.\n",
      "['hurting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2365,  0.7954, -0.1581,  ...,  0.2381,  0.2468, -0.4003])\n",
      "hurting\n",
      "Saved the embedding for hurting.\n",
      "['hush'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4334,  1.4290, -1.3511,  ...,  0.4213,  1.0695,  0.0228])\n",
      "hush\n",
      "Saved the embedding for hush.\n",
      "['hushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2584,  0.5787, -0.6475,  ...,  0.1013,  0.7214, -0.1922])\n",
      "hushed\n",
      "Saved the embedding for hushed.\n",
      "['hyper'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5865,  0.3727, -1.0447,  ..., -0.1250,  0.0584,  0.2975])\n",
      "hyper\n",
      "Saved the embedding for hyper.\n",
      "['hyper', '##active'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3424,  0.6280, -0.2747,  ..., -0.2398,  0.2345, -0.9105])\n",
      "hyperactive\n",
      "Saved the embedding for hyperactive.\n",
      "['h', '##yp', '##not', '##ized'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8612,  0.4247, -0.1111,  ..., -0.0928,  0.2607,  0.3120])\n",
      "hypnotized\n",
      "Saved the embedding for hypnotized.\n",
      "['h', '##yp', '##oc', '##rit', '##ical'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.2946,  0.6347, -0.4658,  ..., -0.3560, -0.3595,  1.0544])\n",
      "hypocritical\n",
      "Saved the embedding for hypocritical.\n",
      "['hysteria'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1376,  0.2744,  0.4546,  ...,  0.1781,  0.4090, -0.2020])\n",
      "hysteria\n",
      "Saved the embedding for hysteria.\n",
      "['hysterical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7916,  1.3132, -0.9084,  ..., -0.2141,  0.4361, -0.3518])\n",
      "hysterical\n",
      "Saved the embedding for hysterical.\n",
      "['idiot', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6138,  0.8580,  0.4188,  ...,  0.6062, -0.0785,  0.6202])\n",
      "idiotic\n",
      "Saved the embedding for idiotic.\n",
      "['ignorant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2767,  1.3338,  0.6222,  ..., -0.8417,  0.5603,  0.4282])\n",
      "ignorant\n",
      "Saved the embedding for ignorant.\n",
      "['ignoring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3550,  1.3684, -0.1487,  ...,  0.2040,  0.7076, -0.0089])\n",
      "ignoring\n",
      "Saved the embedding for ignoring.\n",
      "['ill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0403,  1.1933,  1.1219,  ..., -0.0687,  0.1811,  0.3409])\n",
      "ill\n",
      "Saved the embedding for ill.\n",
      "['imaginative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7788,  0.4475,  0.3783,  ..., -0.0297,  0.8613, -0.2084])\n",
      "imaginative\n",
      "Saved the embedding for imaginative.\n",
      "['immature'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2094,  0.8930, -0.3665,  ...,  0.7897,  0.3165,  0.5458])\n",
      "immature\n",
      "Saved the embedding for immature.\n",
      "['immersed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7266,  0.7676, -1.0790,  ...,  0.0556, -0.0244,  0.0797])\n",
      "immersed\n",
      "Saved the embedding for immersed.\n",
      "['impacted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3839,  0.2293,  0.3082,  ..., -0.2820,  0.7564,  0.5213])\n",
      "impacted\n",
      "Saved the embedding for impacted.\n",
      "['imp', '##art', '##ial'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2052,  0.5573,  0.7378,  ..., -0.2826,  0.3444,  0.4104])\n",
      "impartial\n",
      "Saved the embedding for impartial.\n",
      "['imp', '##ass', '##ioned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3976,  0.1989,  1.0209,  ..., -0.5130,  0.3526,  0.6811])\n",
      "impassioned\n",
      "Saved the embedding for impassioned.\n",
      "['imp', '##ass', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7145,  0.6337,  0.8016,  ..., -0.7656,  0.2910,  0.3733])\n",
      "impassive\n",
      "Saved the embedding for impassive.\n",
      "['impatience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3900,  0.6286, -0.6364,  ...,  0.2372,  0.0017, -0.7066])\n",
      "impatience\n",
      "Saved the embedding for impatience.\n",
      "['impatient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7730,  1.0087, -0.4936,  ..., -0.2073, -0.2880, -0.4080])\n",
      "impatient\n",
      "Saved the embedding for impatient.\n",
      "['imp', '##eri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2659,  0.5456,  1.1320,  ..., -0.5995,  0.0715,  0.2538])\n",
      "imperious\n",
      "Saved the embedding for imperious.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imp', '##erson', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4764,  0.7731,  0.5018,  ..., -0.6992, -0.0931,  0.0955])\n",
      "impersonal\n",
      "Saved the embedding for impersonal.\n",
      "['imp', '##ert', '##inen', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1668,  0.5664,  0.9688,  ..., -0.3469, -0.0776,  0.5029])\n",
      "impertinent\n",
      "Saved the embedding for impertinent.\n",
      "['imp', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1453,  0.2965,  0.3850,  ..., -0.1747,  0.5154,  0.0557])\n",
      "impish\n",
      "Saved the embedding for impish.\n",
      "['implicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0233,  0.7588, -0.0860,  ..., -0.3993,  1.1227, -0.7900])\n",
      "implicated\n",
      "Saved the embedding for implicated.\n",
      "['imp', '##lor', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5167,  0.7561,  0.5459,  ..., -0.4004,  0.4923,  0.6172])\n",
      "imploring\n",
      "Saved the embedding for imploring.\n",
      "['important'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5617,  0.1795,  0.4362,  ...,  0.1769, -0.1413,  0.2194])\n",
      "important\n",
      "Saved the embedding for important.\n",
      "['impressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5417,  1.2540, -0.3115,  ..., -0.1391, -0.1699, -0.3228])\n",
      "impressed\n",
      "Saved the embedding for impressed.\n",
      "['imp', '##ulsive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0376,  0.4816,  0.4951,  ..., -0.5944,  0.7117, -0.0645])\n",
      "impulsive\n",
      "Saved the embedding for impulsive.\n",
      "['inactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0985,  0.6996, -0.2929,  ...,  0.2418, -0.4048, -0.4795])\n",
      "inactive\n",
      "Saved the embedding for inactive.\n",
      "['inadequate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1061,  0.4329,  0.3040,  ..., -0.0679,  0.4066, -0.0934])\n",
      "inadequate\n",
      "Saved the embedding for inadequate.\n",
      "['ina', '##rti', '##cula', '##te'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4035,  0.4000,  0.9452,  ...,  0.1630,  0.5498,  0.6636])\n",
      "inarticulate\n",
      "Saved the embedding for inarticulate.\n",
      "['ina', '##tten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1312,  0.5181,  0.3137,  ...,  0.0968,  0.6751,  0.7009])\n",
      "inattentive\n",
      "Saved the embedding for inattentive.\n",
      "['ina', '##udi', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0689,  0.6147,  1.1702,  ..., -0.0769,  0.1770,  0.5295])\n",
      "inaudible\n",
      "Saved the embedding for inaudible.\n",
      "['ina', '##uth', '##ent', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7861,  0.6597,  0.3481,  ...,  0.7725,  0.6377,  0.3488])\n",
      "inauthentic\n",
      "Saved the embedding for inauthentic.\n",
      "['incapable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6297,  0.0927, -0.1334,  ...,  0.5919, -0.3393, -0.4274])\n",
      "incapable\n",
      "Saved the embedding for incapable.\n",
      "['incense', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0850,  1.0975, -0.1635,  ...,  0.4239,  0.8727, -0.2703])\n",
      "incensed\n",
      "Saved the embedding for incensed.\n",
      "['inc', '##ert', '##ain'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5753,  0.8821,  0.6909,  ...,  0.1879,  0.3890,  0.4867])\n",
      "incertain\n",
      "Saved the embedding for incertain.\n",
      "['inc', '##ert', '##itude'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5834,  0.3056,  1.1756,  ...,  0.3895,  0.2324,  0.5403])\n",
      "incertitude\n",
      "Saved the embedding for incertitude.\n",
      "['inc', '##ited'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1388, -0.2877,  0.1461,  ...,  0.0508,  0.5684,  0.3516])\n",
      "incited\n",
      "Saved the embedding for incited.\n",
      "['inc', '##omp', '##re', '##hen', '##sible'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.3977,  0.7804,  1.0315,  ...,  0.1349, -0.1126,  0.1728])\n",
      "incomprehensible\n",
      "Saved the embedding for incomprehensible.\n",
      "['inc', '##ons', '##pic', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2071,  0.2942,  1.0197,  ...,  0.1864,  0.0234,  0.3615])\n",
      "inconspicuous\n",
      "Saved the embedding for inconspicuous.\n",
      "['inc', '##red', '##uli', '##ty'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2623,  0.2464,  0.3448,  ..., -0.0844,  0.1296,  0.8912])\n",
      "incredulity\n",
      "Saved the embedding for incredulity.\n",
      "['inc', '##red', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7457,  0.2060,  0.6911,  ...,  0.1569, -0.1869,  0.2997])\n",
      "incredulous\n",
      "Saved the embedding for incredulous.\n",
      "['inc', '##red', '##ulously'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6495,  0.2762,  0.6024,  ..., -0.0818, -0.1563,  0.0758])\n",
      "incredulously\n",
      "Saved the embedding for incredulously.\n",
      "['inc', '##ul', '##pate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8538,  0.8576,  0.4889,  ...,  0.0861,  0.2805,  0.4062])\n",
      "inculpate\n",
      "Saved the embedding for inculpate.\n",
      "['inc', '##uri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6115,  0.6002,  0.9310,  ...,  0.2505,  0.0734,  0.5238])\n",
      "incurious\n",
      "Saved the embedding for incurious.\n",
      "['ind', '##ec', '##ip', '##her', '##able'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0708, -0.1727,  0.3343,  ..., -0.3822, -0.2765,  0.8719])\n",
      "indecipherable\n",
      "Saved the embedding for indecipherable.\n",
      "['ind', '##ec', '##ision'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4289, -0.6275, -0.1166,  ...,  0.0523, -0.0996,  1.3505])\n",
      "indecision\n",
      "Saved the embedding for indecision.\n",
      "['ind', '##ec', '##isi', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-1.2944e-04,  1.8943e-01,  1.2664e-01,  ..., -1.3998e-01,\n",
      "         1.2364e-02,  3.5653e-01])\n",
      "indecisive\n",
      "Saved the embedding for indecisive.\n",
      "['indifferent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4363,  1.5595,  0.4973,  ..., -0.5664,  0.2775,  0.3797])\n",
      "indifferent\n",
      "Saved the embedding for indifferent.\n",
      "['indifferent', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6815,  1.1309,  0.9803,  ..., -0.2899, -0.0258,  0.7792])\n",
      "indifferently\n",
      "Saved the embedding for indifferently.\n",
      "['ind', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3037, -0.0735,  0.1686,  ...,  0.2672, -0.0854,  0.6985])\n",
      "indignant\n",
      "Saved the embedding for indignant.\n",
      "['indo', '##lent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0572, -0.3389, -0.1318,  ..., -0.1537,  0.3422,  0.1451])\n",
      "indolent\n",
      "Saved the embedding for indolent.\n",
      "['in', '##eb', '##riated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5452, -0.1753, -0.4684,  ..., -0.3730, -0.3408, -0.3593])\n",
      "inebriated\n",
      "Saved the embedding for inebriated.\n",
      "['in', '##ert'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1749,  0.3592, -0.6216,  ...,  0.5935,  0.5941, -0.0397])\n",
      "inert\n",
      "Saved the embedding for inert.\n",
      "['in', '##fat', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4339,  0.4557,  0.1171,  ..., -0.3019, -0.0978, -0.1110])\n",
      "infatuating\n",
      "Saved the embedding for infatuating.\n",
      "['inferior'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0433,  1.2061, -1.5162,  ...,  0.5059,  0.4698,  0.0034])\n",
      "inferior\n",
      "Saved the embedding for inferior.\n",
      "['inferior', '##ity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2307,  0.1627, -0.4875,  ...,  0.0302,  0.7372,  0.2322])\n",
      "inferiority\n",
      "Saved the embedding for inferiority.\n",
      "['in', '##fl', '##ame', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1380, -0.1121,  0.1376,  ...,  0.3405, -0.0490,  0.4800])\n",
      "inflamed\n",
      "Saved the embedding for inflamed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['informal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4475,  1.3650, -1.5099,  ..., -0.1778,  0.8080,  0.2640])\n",
      "informal\n",
      "Saved the embedding for informal.\n",
      "['informing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1615,  0.3715, -0.3023,  ...,  0.2089,  0.5030,  0.4539])\n",
      "informing\n",
      "Saved the embedding for informing.\n",
      "['in', '##fur', '##iated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0552, -0.2578,  0.2040,  ..., -0.0362, -0.0120,  0.1918])\n",
      "infuriated\n",
      "Saved the embedding for infuriated.\n",
      "['inhibit', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2269,  1.3959, -0.1157,  ...,  0.1218, -0.2006, -0.0588])\n",
      "inhibited\n",
      "Saved the embedding for inhibited.\n",
      "['inhibit', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2626,  1.2893, -0.7263,  ..., -0.3808, -0.2041, -0.2874])\n",
      "inhibiting\n",
      "Saved the embedding for inhibiting.\n",
      "['in', '##imi', '##cal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6425,  1.1548, -0.2764,  ..., -0.4891,  0.4087,  0.8750])\n",
      "inimical\n",
      "Saved the embedding for inimical.\n",
      "['injured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5704,  0.5895,  0.0891,  ...,  0.0223,  0.5756, -0.7581])\n",
      "injured\n",
      "Saved the embedding for injured.\n",
      "['innocent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5999,  0.6475, -0.0940,  ...,  0.5718,  0.4168,  0.0076])\n",
      "innocent\n",
      "Saved the embedding for innocent.\n",
      "['in', '##patient'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0577, -0.2843,  0.0619,  ...,  0.4186,  0.4335,  0.0504])\n",
      "inpatient\n",
      "Saved the embedding for inpatient.\n",
      "['in', '##qui', '##ring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7110,  0.7512,  0.2898,  ..., -0.1791,  0.1347,  0.5335])\n",
      "inquiring\n",
      "Saved the embedding for inquiring.\n",
      "['in', '##qui', '##sit', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1400,  0.3859,  0.2594,  ..., -0.0174, -0.5122,  0.5437])\n",
      "inquisitive\n",
      "Saved the embedding for inquisitive.\n",
      "['insane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0975,  1.4700, -1.2311,  ...,  0.1891,  0.1528, -0.1908])\n",
      "insane\n",
      "Saved the embedding for insane.\n",
      "['ins', '##cr', '##utable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8677,  1.1229,  0.5720,  ...,  0.7061, -0.0385,  0.2995])\n",
      "inscrutable\n",
      "Saved the embedding for inscrutable.\n",
      "['ins', '##ecure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0790,  0.2435,  0.6366,  ...,  0.0400,  0.1654,  0.6654])\n",
      "insecure\n",
      "Saved the embedding for insecure.\n",
      "['ins', '##ec', '##urity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6366,  0.4420,  0.1129,  ...,  0.1034,  0.1622,  0.9140])\n",
      "insecurity\n",
      "Saved the embedding for insecurity.\n",
      "['ins', '##ens', '##itive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5104,  0.5985,  0.3081,  ...,  0.0814, -0.1329,  0.1541])\n",
      "insensitive\n",
      "Saved the embedding for insensitive.\n",
      "['ins', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0027, -0.0397,  0.5872,  ..., -0.0492, -0.2392, -0.9355])\n",
      "insidious\n",
      "Saved the embedding for insidious.\n",
      "['ins', '##in', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2479,  0.5593,  0.3956,  ..., -0.2027, -0.5411, -0.0926])\n",
      "insinuating\n",
      "Saved the embedding for insinuating.\n",
      "['insistence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4763, -0.4796, -0.0489,  ..., -0.1880,  1.2995, -0.2259])\n",
      "insistence\n",
      "Saved the embedding for insistence.\n",
      "['insistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2795,  0.2889, -0.3125,  ..., -0.9139,  0.6554, -0.1789])\n",
      "insistent\n",
      "Saved the embedding for insistent.\n",
      "['insisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3087,  0.2825, -0.7345,  ...,  0.1312,  0.9175, -0.2388])\n",
      "insisting\n",
      "Saved the embedding for insisting.\n",
      "['ins', '##ole', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0753,  0.9093,  0.4314,  ...,  0.0573, -0.0398,  0.0996])\n",
      "insolent\n",
      "Saved the embedding for insolent.\n",
      "['ins', '##ou', '##cian', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1400,  0.3361, -0.0279,  ...,  0.2253, -0.0907,  0.3090])\n",
      "insouciance\n",
      "Saved the embedding for insouciance.\n",
      "['ins', '##ou', '##cian', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3707,  0.3465,  0.3729,  ...,  0.3564, -0.0537,  0.4565])\n",
      "insouciant\n",
      "Saved the embedding for insouciant.\n",
      "['inspired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1879,  0.8418,  0.2175,  ..., -0.1801,  0.4792,  0.2852])\n",
      "inspired\n",
      "Saved the embedding for inspired.\n",
      "['inspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5570,  1.0701,  1.4573,  ..., -0.1602,  0.0915, -0.1887])\n",
      "inspiring\n",
      "Saved the embedding for inspiring.\n",
      "['ins', '##ti', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3032,  0.1924,  0.5464,  ..., -0.1849, -0.0956,  0.0667])\n",
      "instigating\n",
      "Saved the embedding for instigating.\n",
      "['ins', '##tructing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3008,  0.5348,  0.3474,  ...,  0.1832, -0.2130,  0.3326])\n",
      "instructing\n",
      "Saved the embedding for instructing.\n",
      "['ins', '##ub', '##ord', '##inate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2136,  0.2313,  0.6441,  ...,  0.2720,  0.2074,  0.4181])\n",
      "insubordinate\n",
      "Saved the embedding for insubordinate.\n",
      "['ins', '##ular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1596,  0.3160,  0.1666,  ...,  0.0585,  0.4734,  0.3103])\n",
      "insular\n",
      "Saved the embedding for insular.\n",
      "['insulted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3735, -0.0198, -0.5592,  ...,  0.4362,  0.2267, -0.2146])\n",
      "insulted\n",
      "Saved the embedding for insulted.\n",
      "['insulting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1610,  0.6051, -0.0610,  ...,  0.2378,  0.3520, -0.4764])\n",
      "insulting\n",
      "Saved the embedding for insulting.\n",
      "['intelligence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3548,  1.1593,  0.6795,  ..., -0.0122, -0.3312, -0.1553])\n",
      "intelligence\n",
      "Saved the embedding for intelligence.\n",
      "['intense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6719,  0.4720, -1.0728,  ...,  0.5160, -0.0482, -0.3434])\n",
      "intense\n",
      "Saved the embedding for intense.\n",
      "['intensely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6221,  1.0948, -0.6279,  ..., -0.0820,  0.2810, -0.3864])\n",
      "intensely\n",
      "Saved the embedding for intensely.\n",
      "['intensity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6447,  0.7489, -0.4437,  ...,  0.5935, -0.5531, -0.3275])\n",
      "intensity\n",
      "Saved the embedding for intensity.\n",
      "['intensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9678,  0.6248,  0.2934,  ...,  0.3404,  0.5349,  0.8386])\n",
      "intensive\n",
      "Saved the embedding for intensive.\n",
      "['intent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0253,  1.0802, -0.4289,  ...,  0.0369,  0.4431,  0.1085])\n",
      "intent\n",
      "Saved the embedding for intent.\n",
      "['intentional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6781,  0.9290, -0.1183,  ..., -1.1254,  0.6707,  0.1298])\n",
      "intentional\n",
      "Saved the embedding for intentional.\n",
      "['interacting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8170,  0.8095,  0.0870,  ..., -0.0322,  0.6278,  0.6664])\n",
      "interacting\n",
      "Saved the embedding for interacting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5682,  0.8330, -1.0084,  ...,  0.5243,  0.5465, -0.5630])\n",
      "interest\n",
      "Saved the embedding for interest.\n",
      "['interested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8142,  0.6606, -0.9308,  ...,  0.0226, -0.0373, -0.0616])\n",
      "interested\n",
      "Saved the embedding for interested.\n",
      "['inter', '##ject', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7244,  1.8824, -0.5062,  ..., -0.9639,  0.1400,  0.7574])\n",
      "interjecting\n",
      "Saved the embedding for interjecting.\n",
      "['internal', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6207,  0.2096, -0.2952,  ...,  0.2161,  0.0993, -0.2791])\n",
      "internalizing\n",
      "Saved the embedding for internalizing.\n",
      "['inter', '##ro', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8082,  0.9366, -0.2887,  ..., -0.5954, -0.3797,  1.1698])\n",
      "interrogating\n",
      "Saved the embedding for interrogating.\n",
      "['interrupting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6260,  0.5552, -1.9464,  ...,  0.3656,  1.3525, -0.5972])\n",
      "interrupting\n",
      "Saved the embedding for interrupting.\n",
      "['intimidated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1798,  0.3951, -0.8035,  ...,  0.5527,  0.2164, -0.5826])\n",
      "intimidated\n",
      "Saved the embedding for intimidated.\n",
      "['intimidating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1563,  0.4019, -0.5490,  ...,  0.3019,  0.1521, -0.7443])\n",
      "intimidating\n",
      "Saved the embedding for intimidating.\n",
      "['into', '##ler', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6461, -0.0545, -0.2292,  ...,  0.0532, -0.0913, -0.2272])\n",
      "intolerant\n",
      "Saved the embedding for intolerant.\n",
      "['into', '##xi', '##cated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1031,  0.3433,  0.6552,  ..., -0.5414, -0.2535,  0.4594])\n",
      "intoxicated\n",
      "Saved the embedding for intoxicated.\n",
      "['int', '##rigue'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.1958, 0.1515, 0.3933,  ..., 0.0508, 0.3357, 0.0941])\n",
      "intrigue\n",
      "Saved the embedding for intrigue.\n",
      "['intrigued'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5398,  0.9340, -0.7190,  ..., -0.4129,  0.1052, -0.4116])\n",
      "intrigued\n",
      "Saved the embedding for intrigued.\n",
      "['intriguing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7179,  0.9007, -1.3185,  ..., -0.7076,  0.2220,  0.1131])\n",
      "intriguing\n",
      "Saved the embedding for intriguing.\n",
      "['intro', '##sp', '##ect', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8251,  0.5474, -0.1424,  ..., -0.0136, -0.6395, -0.3170])\n",
      "introspective\n",
      "Saved the embedding for introspective.\n",
      "['invested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4894,  0.5002,  0.0554,  ...,  0.6050,  0.2923,  0.1501])\n",
      "invested\n",
      "Saved the embedding for invested.\n",
      "['investigate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5735,  0.5440,  0.2469,  ...,  0.3901,  0.8103,  0.2075])\n",
      "investigate\n",
      "Saved the embedding for investigate.\n",
      "['investigative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2280,  1.3521,  0.1946,  ..., -0.3229,  0.6507, -0.9780])\n",
      "investigative\n",
      "Saved the embedding for investigative.\n",
      "['investigator', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([1.6768e-02, 1.1046e+00, 9.7928e-01,  ..., 3.4813e-01, 1.3238e-01,\n",
      "        1.2178e-04])\n",
      "investigatory\n",
      "Saved the embedding for investigatory.\n",
      "['in', '##vi', '##gor', '##ated'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2708, -0.8410,  0.0537,  ...,  0.3882,  0.3518,  0.0550])\n",
      "invigorated\n",
      "Saved the embedding for invigorated.\n",
      "['involved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0480, -0.1984, -0.2205,  ..., -0.2315,  0.0728,  0.1561])\n",
      "involved\n",
      "Saved the embedding for involved.\n",
      "['ira', '##sc', '##ible'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1385,  0.2476, -0.5362,  ...,  0.9127,  0.5858,  0.0275])\n",
      "irascible\n",
      "Saved the embedding for irascible.\n",
      "['ira', '##te'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1320, -0.2915,  0.2505,  ...,  0.6348,  0.3460,  0.1713])\n",
      "irate\n",
      "Saved the embedding for irate.\n",
      "['ir', '##e'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5423,  0.2402,  0.5631,  ...,  0.1947,  0.7062,  0.3325])\n",
      "ire\n",
      "Saved the embedding for ire.\n",
      "['ir', '##ef', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0174, -0.0836,  0.2804,  ..., -0.3243,  0.1792, -0.0994])\n",
      "ireful\n",
      "Saved the embedding for ireful.\n",
      "['ir', '##ked'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8120,  0.4980, -0.5069,  ...,  0.2427,  1.0505,  0.1131])\n",
      "irked\n",
      "Saved the embedding for irked.\n",
      "['ironic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3617,  1.3740, -0.2669,  ..., -0.4066,  0.6806, -0.2581])\n",
      "ironic\n",
      "Saved the embedding for ironic.\n",
      "['irony'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0702,  0.1998, -0.0200,  ..., -0.1667,  0.4471, -0.2779])\n",
      "irony\n",
      "Saved the embedding for irony.\n",
      "['ir', '##res', '##ol', '##ute'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-1.0186, -0.1850,  0.7613,  ...,  0.3134,  0.4171,  0.4494])\n",
      "irresolute\n",
      "Saved the embedding for irresolute.\n",
      "['ir', '##rita', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8138,  0.4276,  0.7412,  ...,  0.1612,  0.6911,  0.2773])\n",
      "irritable\n",
      "Saved the embedding for irritable.\n",
      "['ir', '##rita', '##bly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9939,  0.0377,  0.9146,  ..., -0.1957,  0.4332,  0.0287])\n",
      "irritably\n",
      "Saved the embedding for irritably.\n",
      "['irritated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8758,  0.6097, -0.5973,  ..., -0.5423,  0.0019, -0.5077])\n",
      "irritated\n",
      "Saved the embedding for irritated.\n",
      "['irritation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1022,  0.8798, -0.7329,  ..., -0.5432,  0.1857, -0.1103])\n",
      "irritation\n",
      "Saved the embedding for irritation.\n",
      "['isolated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0814,  0.7170, -0.7608,  ..., -0.4853,  0.2939,  0.3305])\n",
      "isolated\n",
      "Saved the embedding for isolated.\n",
      "['ja', '##bbed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1667, -0.4013, -0.1399,  ..., -0.1751,  0.2533, -0.2640])\n",
      "jabbed\n",
      "Saved the embedding for jabbed.\n",
      "['jade', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4067,  0.8417, -0.4789,  ...,  0.0462,  0.2011, -0.3573])\n",
      "jaded\n",
      "Saved the embedding for jaded.\n",
      "['jar', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0251,  0.0199, -0.0031,  ...,  0.2232, -0.8363, -0.3887])\n",
      "jarred\n",
      "Saved the embedding for jarred.\n",
      "['jar', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.4033e-02, -1.1817e-02,  1.2414e-02,  ...,  3.2790e-05,\n",
      "        -8.1242e-01, -5.8407e-01])\n",
      "jarring\n",
      "Saved the embedding for jarring.\n",
      "['ja', '##unt', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6786, -0.8082,  0.6165,  ...,  0.1884,  0.3011,  0.3299])\n",
      "jaunty\n",
      "Saved the embedding for jaunty.\n",
      "['jaw', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1334,  1.4588,  1.2073,  ..., -0.5275,  0.1788, -0.7224])\n",
      "jawed\n",
      "Saved the embedding for jawed.\n",
      "['jealous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6816,  0.9666,  0.2338,  ..., -0.4870, -0.2421,  0.1464])\n",
      "jealous\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for jealous.\n",
      "['je', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2414,  0.2001,  0.4985,  ...,  0.3487,  0.2426,  0.6462])\n",
      "jeering\n",
      "Saved the embedding for jeering.\n",
      "['je', '##sti', '##ng'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5249, -0.1958,  1.0406,  ...,  0.1516,  0.0324,  0.3487])\n",
      "jesting\n",
      "Saved the embedding for jesting.\n",
      "['ji', '##lt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0689,  0.8130, -0.0509,  ...,  0.2687,  0.3546,  0.0718])\n",
      "jilted\n",
      "Saved the embedding for jilted.\n",
      "['ji', '##tter', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8586,  0.0062,  0.5451,  ...,  0.6116,  0.4328,  0.3247])\n",
      "jittery\n",
      "Saved the embedding for jittery.\n",
      "['jo', '##cular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4538,  0.0231,  0.2294,  ...,  0.3266,  0.3143, -0.3760])\n",
      "jocular\n",
      "Saved the embedding for jocular.\n",
      "['joking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9473,  0.0928, -0.4967,  ...,  0.4729,  0.7857,  0.0440])\n",
      "joking\n",
      "Saved the embedding for joking.\n",
      "['jolly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.4729, 0.5730, 0.0860,  ..., 0.0772, 0.7179, 0.1673])\n",
      "jolly\n",
      "Saved the embedding for jolly.\n",
      "['jolted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0315,  0.5479, -1.6295,  ...,  0.6677,  0.1276, -0.4054])\n",
      "jolted\n",
      "Saved the embedding for jolted.\n",
      "['jo', '##vial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1409, -0.2731,  0.2501,  ...,  0.4331,  0.3571,  0.0845])\n",
      "jovial\n",
      "Saved the embedding for jovial.\n",
      "['joy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9382,  0.4727, -0.3027,  ...,  0.2765,  0.2883,  0.4034])\n",
      "joy\n",
      "Saved the embedding for joy.\n",
      "['joy', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2397,  0.2711,  0.2901,  ...,  0.0277,  0.2463,  0.0682])\n",
      "joyful\n",
      "Saved the embedding for joyful.\n",
      "['joy', '##fulness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6467,  0.2438,  0.8463,  ..., -0.0098, -0.0149,  0.2153])\n",
      "joyfulness\n",
      "Saved the embedding for joyfulness.\n",
      "['joy', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3093,  0.4401,  0.3945,  ...,  0.0900,  0.5176,  0.3759])\n",
      "joyless\n",
      "Saved the embedding for joyless.\n",
      "['joy', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4496,  0.2334,  0.4457,  ...,  0.2796,  0.3808,  0.4440])\n",
      "joyous\n",
      "Saved the embedding for joyous.\n",
      "['ju', '##bil', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1402,  0.3644,  0.2520,  ...,  0.0490, -0.2795, -0.1426])\n",
      "jubilant\n",
      "Saved the embedding for jubilant.\n",
      "['ju', '##bil', '##ation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3582,  0.4579,  0.7576,  ...,  0.2158, -0.0582,  0.2317])\n",
      "jubilation\n",
      "Saved the embedding for jubilation.\n",
      "['judgement', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0804,  1.3839, -0.2350,  ...,  0.2838,  0.3126, -0.1451])\n",
      "judgemental\n",
      "Saved the embedding for judgemental.\n",
      "['judging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2282, -0.1951, -0.6373,  ...,  0.6332, -0.1158, -0.4609])\n",
      "judging\n",
      "Saved the embedding for judging.\n",
      "['judgment', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1428,  0.9580, -0.0366,  ...,  0.1359,  0.3717,  0.3718])\n",
      "judgmental\n",
      "Saved the embedding for judgmental.\n",
      "['ju', '##dic', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4958,  0.5021,  0.9947,  ...,  0.3203,  0.0358,  0.1803])\n",
      "judicious\n",
      "Saved the embedding for judicious.\n",
      "['jump', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0269, -0.4286,  0.2613,  ...,  0.4770,  0.3043,  0.3262])\n",
      "jumpy\n",
      "Saved the embedding for jumpy.\n",
      "['justified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6043,  1.3839,  0.2340,  ..., -0.6249,  0.9072, -0.4234])\n",
      "justified\n",
      "Saved the embedding for justified.\n",
      "['keen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7560,  1.7918, -1.0279,  ..., -0.0304,  0.6835, -0.1707])\n",
      "keen\n",
      "Saved the embedding for keen.\n",
      "['kind'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3917, -0.0399, -1.7327,  ...,  0.0676,  0.4759, -0.3814])\n",
      "kind\n",
      "Saved the embedding for kind.\n",
      "['kind', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1783,  0.4096,  0.6162,  ..., -0.0834,  0.1707, -0.0372])\n",
      "kindhearted\n",
      "Saved the embedding for kindhearted.\n",
      "['kiss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3200,  0.3606, -0.4086,  ..., -0.6647,  0.6413, -0.1686])\n",
      "kiss\n",
      "Saved the embedding for kiss.\n",
      "['knowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3433,  0.2748, -0.4616,  ...,  0.2822,  0.4756,  0.0350])\n",
      "knowing\n",
      "Saved the embedding for knowing.\n",
      "['know', '##led', '##ga', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0880,  0.4838,  0.7815,  ...,  0.2032, -0.1274,  0.3933])\n",
      "knowledgable\n",
      "Saved the embedding for knowledgable.\n",
      "['knowledge', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1216,  0.9147,  0.7618,  ..., -0.3767, -0.3508,  0.0912])\n",
      "knowledgeable\n",
      "Saved the embedding for knowledgeable.\n",
      "['ko', '##sher'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0930, -0.2837,  0.4158,  ...,  0.2472,  0.3259,  0.1621])\n",
      "kosher\n",
      "Saved the embedding for kosher.\n",
      "['lack', '##ada', '##isi', '##cal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0974,  1.2130, -0.0559,  ..., -0.2641,  0.5621,  0.1559])\n",
      "lackadaisical\n",
      "Saved the embedding for lackadaisical.\n",
      "['lack', '##lus', '##ter'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1118, -0.0014,  0.3897,  ..., -0.0831,  0.4584,  0.4118])\n",
      "lackluster\n",
      "Saved the embedding for lackluster.\n",
      "['lac', '##onic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0691,  0.0370, -0.1831,  ...,  0.5931,  0.6638,  0.2733])\n",
      "laconic\n",
      "Saved the embedding for laconic.\n",
      "['lamb', '##ast', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3273,  1.3124, -0.7581,  ...,  0.3817,  0.6711,  0.0304])\n",
      "lambaste\n",
      "Saved the embedding for lambaste.\n",
      "['lame', '##nta', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1423, -0.1486,  0.5582,  ...,  0.6919,  0.0985,  0.5350])\n",
      "lamentable\n",
      "Saved the embedding for lamentable.\n",
      "['lame', '##nting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6524,  0.6594, -0.5169,  ..., -0.2083,  0.0173,  0.4174])\n",
      "lamenting\n",
      "Saved the embedding for lamenting.\n",
      "['las', '##ci', '##vious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5764, -0.4715,  0.0921,  ..., -0.0730, -0.0563,  0.4750])\n",
      "lascivious\n",
      "Saved the embedding for lascivious.\n",
      "['laugh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6135,  0.7611,  0.8603,  ...,  0.4923,  0.7429,  0.9804])\n",
      "laugh\n",
      "Saved the embedding for laugh.\n",
      "['laughing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0567,  0.3430, -0.3731,  ...,  0.7257,  0.6775, -0.3226])\n",
      "laughing\n",
      "Saved the embedding for laughing.\n",
      "['laughter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2016,  0.7898, -0.6939,  ...,  0.7890,  0.6648, -0.2929])\n",
      "laughter\n",
      "Saved the embedding for laughter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1937,  1.3681, -0.0039,  ..., -0.5442,  0.0179,  0.4252])\n",
      "lazy\n",
      "Saved the embedding for lazy.\n",
      "['leaving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3623,  1.0413, -0.2614,  ...,  0.3761, -0.1400,  0.0926])\n",
      "leaving\n",
      "Saved the embedding for leaving.\n",
      "['le', '##cher', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2865,  0.1583, -0.0729,  ...,  0.0214,  0.2563, -0.0618])\n",
      "lecherous\n",
      "Saved the embedding for lecherous.\n",
      "['le', '##cturing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0351, -0.6532, -0.1164,  ...,  0.2003,  0.0624,  0.2578])\n",
      "lecturing\n",
      "Saved the embedding for lecturing.\n",
      "['lee', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1763,  0.3733,  0.0740,  ...,  0.2444,  0.0860, -0.0250])\n",
      "leering\n",
      "Saved the embedding for leering.\n",
      "['lee', '##ry'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7292,  0.5505,  0.1111,  ...,  0.3166,  0.0937,  0.2519])\n",
      "leery\n",
      "Saved the embedding for leery.\n",
      "['let', '##down'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0716,  0.4760,  0.6658,  ..., -0.3087, -0.6264,  0.7649])\n",
      "letdown\n",
      "Saved the embedding for letdown.\n",
      "['let', '##har', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4355, -0.0467,  0.3957,  ...,  0.2127,  0.3803,  0.5753])\n",
      "lethargic\n",
      "Saved the embedding for lethargic.\n",
      "['level', '##head', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6344,  0.5764, -0.4800,  ...,  0.1790,  0.3788,  0.5010])\n",
      "levelheaded\n",
      "Saved the embedding for levelheaded.\n",
      "['lew', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8107,  1.4769,  0.0770,  ...,  0.2161, -0.6921,  0.4255])\n",
      "lewd\n",
      "Saved the embedding for lewd.\n",
      "['li', '##bid', '##ino', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.9582, -0.2473,  0.2171,  ..., -0.0891,  0.1987,  0.5704])\n",
      "libidinous\n",
      "Saved the embedding for libidinous.\n",
      "['lifeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0954,  1.5350, -1.4191,  ...,  0.1834,  0.7186, -0.4051])\n",
      "lifeless\n",
      "Saved the embedding for lifeless.\n",
      "['light', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.6029, 1.0015, 0.9268,  ..., 0.2469, 0.2084, 0.1981])\n",
      "lighthearted\n",
      "Saved the embedding for lighthearted.\n",
      "['lip', '##ped'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7971,  0.2146,  0.1696,  ...,  0.1801,  0.0593,  0.0817])\n",
      "lipped\n",
      "Saved the embedding for lipped.\n",
      "['listening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5352,  0.8914,  0.1352,  ...,  0.6523, -0.2242,  0.2656])\n",
      "listening\n",
      "Saved the embedding for listening.\n",
      "['list', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1015,  0.0916,  0.8795,  ..., -0.0308,  0.0380,  0.0308])\n",
      "listless\n",
      "Saved the embedding for listless.\n",
      "['lively'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6199,  0.8203, -0.4228,  ..., -0.6754,  0.9259, -0.0301])\n",
      "lively\n",
      "Saved the embedding for lively.\n",
      "['liv', '##id'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7604,  0.4181, -0.3300,  ...,  0.4818,  0.1779,  0.3218])\n",
      "livid\n",
      "Saved the embedding for livid.\n",
      "['loaded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.6612,  0.3678,  0.6397,  ...,  0.0345,  0.0458,  0.2485])\n",
      "loaded\n",
      "Saved the embedding for loaded.\n",
      "['lo', '##ath'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0599,  0.2728,  0.7689,  ..., -0.0615,  0.1925,  0.6068])\n",
      "loath\n",
      "Saved the embedding for loath.\n",
      "['lo', '##ath', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5085, -0.2697,  1.4804,  ...,  0.2751,  0.2193,  0.5566])\n",
      "loathe\n",
      "Saved the embedding for loathe.\n",
      "['lo', '##athing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3489,  0.1883,  0.9532,  ..., -0.4456,  0.5264,  0.4509])\n",
      "loathing\n",
      "Saved the embedding for loathing.\n",
      "['lo', '##ath', '##some'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1599, -0.0126,  0.6250,  ...,  0.4566,  0.2539,  0.2507])\n",
      "loathsome\n",
      "Saved the embedding for loathsome.\n",
      "['locked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2489,  0.9942,  0.5186,  ..., -0.1433,  0.4112, -0.1573])\n",
      "locked\n",
      "Saved the embedding for locked.\n",
      "['loneliness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8591,  0.1960, -0.1055,  ...,  0.4401,  0.5217,  0.6012])\n",
      "loneliness\n",
      "Saved the embedding for loneliness.\n",
      "['lonely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6679,  0.2161, -1.0524,  ...,  0.4078,  0.3134, -0.5069])\n",
      "lonely\n",
      "Saved the embedding for lonely.\n",
      "['longing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4443,  0.9440,  0.4476,  ..., -0.4462,  0.3434,  0.0257])\n",
      "longing\n",
      "Saved the embedding for longing.\n",
      "['looking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1922,  1.9015, -1.2307,  ..., -0.5162,  0.6256, -0.2203])\n",
      "looking\n",
      "Saved the embedding for looking.\n",
      "['lo', '##ony'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1359, -0.4150,  0.4334,  ...,  0.2704,  0.5506,  0.8950])\n",
      "loony\n",
      "Saved the embedding for loony.\n",
      "['loss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0653,  0.9410, -0.2291,  ..., -0.0780,  0.4995, -0.0211])\n",
      "loss\n",
      "Saved the embedding for loss.\n",
      "['lost'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5208,  0.2108, -0.2699,  ..., -0.6768,  0.7367,  0.4432])\n",
      "lost\n",
      "Saved the embedding for lost.\n",
      "['loud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6930,  1.5165,  0.1274,  ...,  0.1248,  0.2355, -0.1337])\n",
      "loud\n",
      "Saved the embedding for loud.\n",
      "['lou', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2977, -0.2098,  0.0855,  ...,  0.5042,  0.5197,  0.6537])\n",
      "lousy\n",
      "Saved the embedding for lousy.\n",
      "['love'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.8873, 0.3833, 0.5660,  ..., 0.0489, 0.2467, 0.0708])\n",
      "love\n",
      "Saved the embedding for love.\n",
      "['loving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8445,  0.6893, -0.2388,  ...,  0.4522,  0.1684,  0.5319])\n",
      "loving\n",
      "Saved the embedding for loving.\n",
      "['low', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1381,  0.5169,  0.3988,  ...,  0.0377,  0.0683,  0.2740])\n",
      "lowliness\n",
      "Saved the embedding for lowliness.\n",
      "['lu', '##rid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4111,  0.0317,  0.9963,  ..., -0.1009,  0.4211,  0.4433])\n",
      "lurid\n",
      "Saved the embedding for lurid.\n",
      "['lust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2282,  1.2038,  0.2171,  ..., -0.4429,  0.0616, -0.3110])\n",
      "lustful\n",
      "Saved the embedding for lustful.\n",
      "['lust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0056,  0.8411, -0.1662,  ..., -0.4028,  0.3846, -0.3493])\n",
      "lusting\n",
      "Saved the embedding for lusting.\n",
      "['mel', '##an', '##cho', '##lic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6580,  0.5162, -0.1444,  ...,  0.2214,  0.5613,  0.6306])\n",
      "melancholic\n",
      "Saved the embedding for melancholic.\n",
      "['melancholy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2397,  0.7419,  0.1126,  ..., -0.4946, -0.0238,  0.2729])\n",
      "melancholy\n",
      "Saved the embedding for melancholy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mel', '##low'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6693,  0.1115,  0.4886,  ...,  0.1280,  0.0189,  0.3515])\n",
      "mellow\n",
      "Saved the embedding for mellow.\n",
      "['menace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3942,  0.7986, -0.7077,  ..., -0.3850,  0.0357, -1.0829])\n",
      "menace\n",
      "Saved the embedding for menace.\n",
      "['menacing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1263,  0.1182, -0.7709,  ...,  0.1566, -0.1225, -0.1189])\n",
      "menacing\n",
      "Saved the embedding for menacing.\n",
      "['mental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2795,  0.7457, -0.3758,  ...,  0.4618,  0.5648,  0.2464])\n",
      "mental\n",
      "Saved the embedding for mental.\n",
      "['mer', '##rily'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3415,  0.2911,  0.3215,  ..., -0.0440,  0.4833,  0.3207])\n",
      "merrily\n",
      "Saved the embedding for merrily.\n",
      "['merry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6742,  1.0710,  0.3177,  ..., -0.2806,  0.0123,  0.1845])\n",
      "merry\n",
      "Saved the embedding for merry.\n",
      "['me', '##sm', '##eri', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2004, -0.2100,  0.1677,  ..., -0.2257, -0.0214,  0.2035])\n",
      "mesmerized\n",
      "Saved the embedding for mesmerized.\n",
      "['mi', '##ffed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.0427, 0.4878, 0.8487,  ..., 0.2558, 0.0345, 0.1417])\n",
      "miffed\n",
      "Saved the embedding for miffed.\n",
      "['mild'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7437, -0.2543, -0.1525,  ...,  0.0726,  0.1576, -0.8325])\n",
      "mild\n",
      "Saved the embedding for mild.\n",
      "['min', '##cing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 2.1899e-04, -6.1159e-02,  4.2922e-01,  ...,  5.5670e-01,\n",
      "        -1.1732e-01,  2.5588e-01])\n",
      "mincing\n",
      "Saved the embedding for mincing.\n",
      "['mind', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5159,  0.7491,  0.6151,  ..., -0.1594,  0.1293,  0.1586])\n",
      "mindful\n",
      "Saved the embedding for mindful.\n",
      "['mind', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0674,  0.4207,  0.2743,  ..., -0.2550,  0.2243,  0.3685])\n",
      "mindless\n",
      "Saved the embedding for mindless.\n",
      "['mirrored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7035,  0.7474, -0.6193,  ...,  0.2018,  0.2556,  0.2773])\n",
      "mirrored\n",
      "Saved the embedding for mirrored.\n",
      "['mir', '##th'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3319,  1.0921,  0.1837,  ..., -0.1434,  0.5718,  0.2854])\n",
      "mirth\n",
      "Saved the embedding for mirth.\n",
      "['mir', '##th', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4773,  0.4261,  0.1726,  ..., -0.3083,  0.7429,  0.1722])\n",
      "mirthful\n",
      "Saved the embedding for mirthful.\n",
      "['mis', '##ant', '##hr', '##op', '##ic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.7825,  0.9218, -0.0166,  ..., -0.4079, -0.1290,  0.1093])\n",
      "misanthropic\n",
      "Saved the embedding for misanthropic.\n",
      "['mischief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9701,  0.5191, -0.3417,  ...,  0.3070,  0.4380,  0.3134])\n",
      "mischief\n",
      "Saved the embedding for mischief.\n",
      "['mischievous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6873,  0.7873, -1.1071,  ...,  0.6605,  0.5614,  0.5969])\n",
      "mischievous\n",
      "Saved the embedding for mischievous.\n",
      "['mischievous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1687,  0.7398, -0.1668,  ...,  0.2462,  0.4148, -0.3653])\n",
      "mischievousness\n",
      "Saved the embedding for mischievousness.\n",
      "['miserable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7091,  0.8761, -1.2437,  ..., -0.2595,  0.5522, -0.0506])\n",
      "miserable\n",
      "Saved the embedding for miserable.\n",
      "['misery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4390,  0.6370, -0.5668,  ...,  0.0818,  0.1260,  0.2034])\n",
      "misery\n",
      "Saved the embedding for misery.\n",
      "['mis', '##giving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1265,  0.8890,  0.0993,  ..., -0.1720, -0.1512,  0.8374])\n",
      "misgiving\n",
      "Saved the embedding for misgiving.\n",
      "['mis', '##lea', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1023, -0.0685,  0.2321,  ..., -0.2370, -0.0721,  0.2247])\n",
      "mislead\n",
      "Saved the embedding for mislead.\n",
      "['mist', '##rus', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3157,  0.7758, -0.3090,  ...,  0.5210,  0.2621,  0.2410])\n",
      "mistrust\n",
      "Saved the embedding for mistrust.\n",
      "['mist', '##rus', '##tf', '##ul'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1505,  0.4404, -0.0828,  ..., -0.1978,  0.5211,  0.4246])\n",
      "mistrustful\n",
      "Saved the embedding for mistrustful.\n",
      "['mist', '##rus', '##ting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5035,  1.2667,  0.1908,  ..., -0.1350, -0.0399,  0.3800])\n",
      "mistrusting\n",
      "Saved the embedding for mistrusting.\n",
      "['misunderstood'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2299,  0.6099, -0.5540,  ...,  0.6618, -0.1777, -0.0305])\n",
      "misunderstood\n",
      "Saved the embedding for misunderstood.\n",
      "['mock', '##ery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6095,  1.0734,  0.2433,  ..., -0.0564,  0.1265,  0.3129])\n",
      "mockery\n",
      "Saved the embedding for mockery.\n",
      "['mocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2817, -0.0327, -0.5297,  ...,  0.3150, -0.0173,  0.3309])\n",
      "mocking\n",
      "Saved the embedding for mocking.\n",
      "['mocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4050,  0.5230,  0.2421,  ...,  0.5424,  0.1172,  0.2747])\n",
      "mockingly\n",
      "Saved the embedding for mockingly.\n",
      "['modest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5244,  1.2612,  0.8521,  ..., -0.6650,  0.0605, -0.3016])\n",
      "modest\n",
      "Saved the embedding for modest.\n",
      "['mono', '##tone'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5636,  1.2995,  0.1871,  ...,  0.5422,  0.0475,  0.3847])\n",
      "monotone\n",
      "Saved the embedding for monotone.\n",
      "['monster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5343,  1.0326,  0.2295,  ...,  0.1592,  0.4993,  0.0721])\n",
      "monster\n",
      "Saved the embedding for monster.\n",
      "['moody'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1976,  1.5394, -0.3941,  ..., -0.6318,  0.4930, -0.6241])\n",
      "moody\n",
      "Saved the embedding for moody.\n",
      "['mo', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2332, -0.1046,  0.4893,  ...,  0.1682,  0.4118,  0.3343])\n",
      "mopey\n",
      "Saved the embedding for mopey.\n",
      "['mor', '##ose'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2848,  0.4082, -0.4498,  ..., -0.2026,  0.6344, -0.0350])\n",
      "morose\n",
      "Saved the embedding for morose.\n",
      "['mort', '##ified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4873,  0.5078, -0.5222,  ..., -0.0401,  0.4948, -0.1065])\n",
      "mortified\n",
      "Saved the embedding for mortified.\n",
      "['motivated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3793,  1.7693, -0.1886,  ..., -0.2166,  0.4392,  0.4417])\n",
      "motivated\n",
      "Saved the embedding for motivated.\n",
      "['mo', '##urn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2506,  0.0306,  0.4865,  ...,  0.2594,  0.0910, -0.0969])\n",
      "mournful\n",
      "Saved the embedding for mournful.\n",
      "['mo', '##urn', '##fulness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1912,  0.0332,  0.5062,  ...,  0.3135,  0.1965,  0.4019])\n",
      "mournfulness\n",
      "Saved the embedding for mournfulness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mourning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0969,  1.7599,  0.1182,  ..., -0.0055,  0.3231, -0.0312])\n",
      "mourning\n",
      "Saved the embedding for mourning.\n",
      "['mouthed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0640,  1.6416, -0.5987,  ...,  0.1974,  0.6567,  0.0291])\n",
      "mouthed\n",
      "Saved the embedding for mouthed.\n",
      "['moved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3477,  1.4399, -1.5773,  ..., -0.3291,  0.5957,  0.1170])\n",
      "moved\n",
      "Saved the embedding for moved.\n",
      "['mud', '##dled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5903,  0.9293,  0.9612,  ..., -0.2270,  0.0139,  0.6110])\n",
      "muddled\n",
      "Saved the embedding for muddled.\n",
      "['mum'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1415, -0.1871,  0.2929,  ..., -0.1809,  0.4981,  0.2543])\n",
      "mum\n",
      "Saved the embedding for mum.\n",
      "['murderous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5361,  0.8175, -1.4258,  ..., -0.2852,  0.3948, -0.5920])\n",
      "murderous\n",
      "Saved the embedding for murderous.\n",
      "['musical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3465,  0.1906, -0.2375,  ...,  0.1313,  0.4394, -0.0330])\n",
      "musical\n",
      "Saved the embedding for musical.\n",
      "['mu', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3928,  0.6336, -0.1299,  ...,  0.2012, -0.1306,  0.2245])\n",
      "musing\n",
      "Saved the embedding for musing.\n",
      "['muster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6085, -0.0127,  0.6920,  ...,  0.1567,  0.1349,  0.2647])\n",
      "muster\n",
      "Saved the embedding for muster.\n",
      "['mute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3502,  0.3983,  0.4327,  ..., -0.2224,  0.4151,  0.0487])\n",
      "mute\n",
      "Saved the embedding for mute.\n",
      "['muted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0645,  1.0110,  0.0439,  ...,  0.6996,  0.5360, -0.7247])\n",
      "muted\n",
      "Saved the embedding for muted.\n",
      "['muttering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4647,  0.4227, -1.0278,  ...,  0.1576,  0.7922, -0.3546])\n",
      "muttering\n",
      "Saved the embedding for muttering.\n",
      "['mysterious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2528,  0.3453,  0.3590,  ..., -0.2000,  0.4971, -0.0544])\n",
      "mysterious\n",
      "Saved the embedding for mysterious.\n",
      "['mystical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0305, 0.7962, 0.1262,  ..., 0.4307, 0.1575, 0.5629])\n",
      "mystical\n",
      "Saved the embedding for mystical.\n",
      "['my', '##sti', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0272,  0.5615,  0.2435,  ...,  0.6369, -0.2756,  0.7207])\n",
      "mystified\n",
      "Saved the embedding for mystified.\n",
      "['naive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4762,  2.0844,  0.0593,  ..., -0.5192,  1.1260, -0.6341])\n",
      "naive\n",
      "Saved the embedding for naive.\n",
      "['nap', '##ping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5947,  0.5720, -0.2404,  ...,  0.5718,  0.5489,  0.4144])\n",
      "napping\n",
      "Saved the embedding for napping.\n",
      "['narrow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2682,  1.0441,  0.4721,  ..., -0.3302,  0.2310,  0.1148])\n",
      "narrow\n",
      "Saved the embedding for narrow.\n",
      "['nasty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5398,  0.8311, -1.1840,  ...,  0.7507,  0.7209, -0.1342])\n",
      "nasty\n",
      "Saved the embedding for nasty.\n",
      "['natural'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1999,  0.6457, -0.5442,  ...,  0.6558, -0.0027, -0.3270])\n",
      "natural\n",
      "Saved the embedding for natural.\n",
      "['nature', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5733,  0.2212,  0.5945,  ..., -0.4258, -0.1322,  0.9241])\n",
      "natured\n",
      "Saved the embedding for natured.\n",
      "['naughty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0949, -0.1365,  0.5138,  ...,  0.1313,  0.1346,  0.0366])\n",
      "naughty\n",
      "Saved the embedding for naughty.\n",
      "['nausea'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0103,  1.0959, -0.7050,  ...,  0.3769,  0.3336,  0.2197])\n",
      "nausea\n",
      "Saved the embedding for nausea.\n",
      "['nausea', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3339,  0.8683, -0.4905,  ...,  0.3551,  0.4908,  0.3199])\n",
      "nauseated\n",
      "Saved the embedding for nauseated.\n",
      "['na', '##use', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.0506, 0.1357, 0.9032,  ..., 0.0575, 0.3664, 0.4432])\n",
      "nauseous\n",
      "Saved the embedding for nauseous.\n",
      "['needy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1944, -0.0477, -0.4735,  ...,  0.5441,  0.2787,  0.0015])\n",
      "needy\n",
      "Saved the embedding for needy.\n",
      "['ne', '##far', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3202,  0.0558,  0.1962,  ..., -0.5051,  0.0141, -0.2040])\n",
      "nefarious\n",
      "Saved the embedding for nefarious.\n",
      "['ne', '##gating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1718, -0.2390,  0.6856,  ..., -0.4692,  0.3696,  0.4642])\n",
      "negating\n",
      "Saved the embedding for negating.\n",
      "['negative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4986,  1.0248,  0.2194,  ...,  1.0362,  0.0266,  0.7382])\n",
      "negative\n",
      "Saved the embedding for negative.\n",
      "['ne', '##gat', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4184,  0.7031,  1.0820,  ...,  0.3135, -0.2246,  0.1647])\n",
      "negativity\n",
      "Saved the embedding for negativity.\n",
      "['neglected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2925,  1.6043,  0.6281,  ..., -0.6768,  0.1826, -0.0606])\n",
      "neglected\n",
      "Saved the embedding for neglected.\n",
      "['ne', '##rdy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3128,  0.3198,  0.3606,  ...,  0.3174,  0.3881, -0.0030])\n",
      "nerdy\n",
      "Saved the embedding for nerdy.\n",
      "['nerve', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6739,  0.9364,  0.6059,  ..., -0.1298, -0.3066,  0.1551])\n",
      "nerved\n",
      "Saved the embedding for nerved.\n",
      "['nerves'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5712,  1.4450, -1.3743,  ..., -0.3147, -0.0694, -0.2349])\n",
      "nerves\n",
      "Saved the embedding for nerves.\n",
      "['nervous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2143,  1.1144, -1.2077,  ..., -0.2726, -0.3211, -0.3999])\n",
      "nervous\n",
      "Saved the embedding for nervous.\n",
      "['nervously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0800,  1.4282, -1.6696,  ...,  0.6898,  0.3029, -0.2506])\n",
      "nervously\n",
      "Saved the embedding for nervously.\n",
      "['nervous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4689,  1.2236, -0.8449,  ...,  0.0808,  0.2525, -0.6815])\n",
      "nervousness\n",
      "Saved the embedding for nervousness.\n",
      "['nes', '##cie', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1984,  0.6767, -0.4820,  ..., -0.7693,  0.6279, -0.3492])\n",
      "nescient\n",
      "Saved the embedding for nescient.\n",
      "['net', '##tled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1476,  0.1187,  0.7925,  ..., -0.2984,  0.1090,  0.7602])\n",
      "nettled\n",
      "Saved the embedding for nettled.\n",
      "['neutral'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2311,  1.0530, -1.3078,  ...,  0.2275,  0.5505, -0.1972])\n",
      "neutral\n",
      "Saved the embedding for neutral.\n",
      "['neutrality'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0670,  0.2012,  0.5179,  ..., -0.2018,  0.2082,  0.2366])\n",
      "neutrality\n",
      "Saved the embedding for neutrality.\n",
      "['nice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3059,  0.7893, -0.7902,  ...,  0.3861,  0.1585,  0.0294])\n",
      "nice\n",
      "Saved the embedding for nice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['noisy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2667,  1.5202,  0.2822,  ...,  0.1247,  0.2168,  0.4889])\n",
      "noisy\n",
      "Saved the embedding for noisy.\n",
      "['non', '##bel', '##ie', '##f'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4292, -0.2421,  0.2782,  ..., -0.4960, -1.1324,  0.1535])\n",
      "nonbelief\n",
      "Saved the embedding for nonbelief.\n",
      "['non', '##chal', '##ance'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5614,  0.3780,  0.1889,  ..., -0.7230, -0.0551,  0.8250])\n",
      "nonchalance\n",
      "Saved the embedding for nonchalance.\n",
      "['non', '##chal', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8140,  0.4278,  0.1874,  ..., -1.0487,  0.0079,  0.2824])\n",
      "nonchalant\n",
      "Saved the embedding for nonchalant.\n",
      "['non', '##com', '##mit', '##tal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7377,  0.6528, -0.4989,  ..., -0.2799, -0.7296,  0.4838])\n",
      "noncommittal\n",
      "Saved the embedding for noncommittal.\n",
      "['non', '##com', '##pl', '##ian', '##t'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2972, -0.0561,  0.3459,  ..., -0.0498, -0.7474,  0.6651])\n",
      "noncompliant\n",
      "Saved the embedding for noncompliant.\n",
      "['non', '##pl', '##uss', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6097,  0.4185, -0.2179,  ..., -0.3571, -0.1742,  0.8921])\n",
      "nonplussed\n",
      "Saved the embedding for nonplussed.\n",
      "['non', '##sen', '##sic', '##al'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3549,  0.8796,  0.3305,  ..., -1.0641, -0.0286, -0.4205])\n",
      "nonsensical\n",
      "Saved the embedding for nonsensical.\n",
      "['normal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7066,  0.8297, -1.2107,  ...,  0.4093,  0.0069,  0.4770])\n",
      "normal\n",
      "Saved the embedding for normal.\n",
      "['nose', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2426, -0.1794,  0.1483,  ...,  0.5938, -0.0259, -0.5375])\n",
      "nosey\n",
      "Saved the embedding for nosey.\n",
      "['nos', '##tal', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0395,  0.2031,  0.3522,  ..., -0.1466,  0.1977,  0.5037])\n",
      "nostalgic\n",
      "Saved the embedding for nostalgic.\n",
      "['nos', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5750,  0.5834,  0.2171,  ..., -0.2821,  0.1912,  0.9369])\n",
      "nosy\n",
      "Saved the embedding for nosy.\n",
      "['numb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9054,  1.5584, -1.3894,  ...,  0.6612,  0.3387, -0.0315])\n",
      "numb\n",
      "Saved the embedding for numb.\n",
      "['obe', '##die', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5854,  0.4599, -0.0584,  ..., -1.1068,  0.8849, -1.1553])\n",
      "obedient\n",
      "Saved the embedding for obedient.\n",
      "['object', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1060,  1.3356,  0.3673,  ..., -0.5706,  0.5677,  0.4124])\n",
      "objecting\n",
      "Saved the embedding for objecting.\n",
      "['objection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9263,  1.0789,  0.4827,  ...,  0.0955,  0.5893,  0.2777])\n",
      "objection\n",
      "Saved the embedding for objection.\n",
      "['objective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6573,  0.7446, -0.1574,  ...,  0.1139,  0.1534,  0.2867])\n",
      "objective\n",
      "Saved the embedding for objective.\n",
      "['obliged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1819,  0.2856, -0.9130,  ..., -0.6111,  0.3848, -0.3667])\n",
      "obliged\n",
      "Saved the embedding for obliged.\n",
      "['ob', '##li', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1832, -0.1407, -0.1129,  ..., -0.0801,  0.2323,  0.7627])\n",
      "obliging\n",
      "Saved the embedding for obliging.\n",
      "['oblivious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1281,  1.2307, -0.2072,  ...,  0.0690,  0.2998, -0.0104])\n",
      "oblivious\n",
      "Saved the embedding for oblivious.\n",
      "['ob', '##ser', '##vant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3881, -0.0541,  0.3593,  ...,  0.3454, -0.0183,  0.4267])\n",
      "observant\n",
      "Saved the embedding for observant.\n",
      "['observing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6804,  1.6547,  0.5295,  ...,  0.1046,  0.7639,  0.4138])\n",
      "observing\n",
      "Saved the embedding for observing.\n",
      "['obsessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3175,  0.4005,  0.0078,  ...,  0.2874,  0.3035, -0.1788])\n",
      "obsessed\n",
      "Saved the embedding for obsessed.\n",
      "['ob', '##sti', '##nate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4479,  0.3608, -0.1540,  ...,  0.5875,  0.1340,  0.3131])\n",
      "obstinate\n",
      "Saved the embedding for obstinate.\n",
      "['occupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2348,  1.3018, -0.9267,  ...,  0.0253,  0.6232,  0.0747])\n",
      "occupied\n",
      "Saved the embedding for occupied.\n",
      "['odd'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6658,  1.2369, -1.3125,  ..., -0.6563,  0.5292, -0.0139])\n",
      "odd\n",
      "Saved the embedding for odd.\n",
      "['odi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0782,  0.1071,  0.5652,  ..., -0.6307,  0.5071, -0.2844])\n",
      "odious\n",
      "Saved the embedding for odious.\n",
      "['off'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6062,  0.6927, -0.9883,  ..., -0.0612,  0.7719, -0.0579])\n",
      "off\n",
      "Saved the embedding for off.\n",
      "['offended'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3290,  0.1719, -0.9689,  ...,  0.5097,  0.2851, -0.5406])\n",
      "offended\n",
      "Saved the embedding for offended.\n",
      "['offensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2556,  1.0113,  0.2298,  ..., -0.6310,  0.3203, -1.0665])\n",
      "offensive\n",
      "Saved the embedding for offensive.\n",
      "['og', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6899,  1.1515, -0.8930,  ...,  0.3411,  0.3027,  0.2065])\n",
      "ogling\n",
      "Saved the embedding for ogling.\n",
      "['okay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4006,  1.2116, -0.9314,  ...,  0.1425,  0.2519,  0.4266])\n",
      "okay\n",
      "Saved the embedding for okay.\n",
      "['on'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5014,  0.6328,  0.2503,  ...,  0.1641,  0.1194, -0.0955])\n",
      "on\n",
      "Saved the embedding for on.\n",
      "['open'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1844,  0.8306, -0.6153,  ..., -0.1575, -0.1115,  0.0336])\n",
      "open\n",
      "Saved the embedding for open.\n",
      "['open', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0287,  0.6514,  0.0644,  ..., -0.3145,  0.6372, -0.2710])\n",
      "openness\n",
      "Saved the embedding for openness.\n",
      "['opposed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3734,  1.0051, -0.2274,  ..., -0.3753,  0.4715, -0.5479])\n",
      "opposed\n",
      "Saved the embedding for opposed.\n",
      "['opposition', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0417,  1.5540,  0.1752,  ..., -0.2150, -0.2495,  0.2062])\n",
      "oppositional\n",
      "Saved the embedding for oppositional.\n",
      "['op', '##pressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2997,  0.5211,  0.5426,  ...,  0.2685,  0.2565,  0.2777])\n",
      "oppressed\n",
      "Saved the embedding for oppressed.\n",
      "['optimism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0810,  0.9268,  0.6836,  ..., -0.5859,  0.2683, -0.1754])\n",
      "optimism\n",
      "Saved the embedding for optimism.\n",
      "['optimistic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1570,  0.9518,  0.7165,  ..., -0.9442,  0.0886, -0.2998])\n",
      "optimistic\n",
      "Saved the embedding for optimistic.\n",
      "['ordering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.1430, 0.4957, 0.4935,  ..., 0.1610, 0.6345, 0.3774])\n",
      "ordering\n",
      "Saved the embedding for ordering.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orgasm', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5696,  1.4446, -1.1823,  ..., -0.4134, -0.0474, -0.1189])\n",
      "orgasmic\n",
      "Saved the embedding for orgasmic.\n",
      "['or', '##nery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4271,  1.1348, -0.6695,  ..., -0.2594,  1.2613, -0.1973])\n",
      "ornery\n",
      "Saved the embedding for ornery.\n",
      "['ou', '##ch'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9488,  0.7390,  0.4891,  ..., -0.1268,  0.3332,  0.5422])\n",
      "ouch\n",
      "Saved the embedding for ouch.\n",
      "['out'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3877,  0.7306,  0.1990,  ...,  0.1867,  0.6051,  0.0837])\n",
      "out\n",
      "Saved the embedding for out.\n",
      "['outburst'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2673,  0.6277, -0.1211,  ..., -0.0424,  0.0033, -0.2655])\n",
      "outburst\n",
      "Saved the embedding for outburst.\n",
      "['out', '##cr', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3670,  0.3500,  0.4606,  ...,  0.6746, -0.0070,  0.3095])\n",
      "outcry\n",
      "Saved the embedding for outcry.\n",
      "['out', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4745,  0.5830,  0.4335,  ..., -0.1800,  0.1926, -0.0161])\n",
      "outed\n",
      "Saved the embedding for outed.\n",
      "['out', '##land', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7725,  0.4013, -0.1630,  ...,  0.2778,  0.4244,  0.6966])\n",
      "outlandish\n",
      "Saved the embedding for outlandish.\n",
      "['outrage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3099,  0.9923,  0.0769,  ...,  0.0226,  0.6296, -0.4528])\n",
      "outrage\n",
      "Saved the embedding for outrage.\n",
      "['outraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1709,  0.6418,  0.3054,  ...,  0.1128,  0.4865, -0.8502])\n",
      "outraged\n",
      "Saved the embedding for outraged.\n",
      "['outspoken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4964,  0.9546, -0.3554,  ...,  0.1516, -0.3722, -0.9398])\n",
      "outspoken\n",
      "Saved the embedding for outspoken.\n",
      "['over', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3311,  0.1068,  0.7180,  ...,  0.0267, -0.3964,  0.0864])\n",
      "overbearing\n",
      "Saved the embedding for overbearing.\n",
      "['over', '##ex', '##cite', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1416,  0.4197,  0.2186,  ...,  0.3949,  0.2444,  0.0315])\n",
      "overexcited\n",
      "Saved the embedding for overexcited.\n",
      "['over', '##joy', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1133,  0.5362,  0.1982,  ..., -0.0737,  0.2214,  0.4192])\n",
      "overjoyed\n",
      "Saved the embedding for overjoyed.\n",
      "['overshadowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6643,  0.5301, -1.7459,  ...,  0.2900,  0.4294, -0.4430])\n",
      "overshadowed\n",
      "Saved the embedding for overshadowed.\n",
      "['overs', '##tr', '##ung'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6800, -0.8577,  0.3252,  ...,  0.0543, -0.1470, -0.4291])\n",
      "overstrung\n",
      "Saved the embedding for overstrung.\n",
      "['overwhelmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5450,  1.2643, -1.0037,  ..., -0.5572,  0.2356,  0.0644])\n",
      "overwhelmed\n",
      "Saved the embedding for overwhelmed.\n",
      "['over', '##work', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0937,  1.1836, -0.3578,  ..., -0.1143,  1.1125, -0.5800])\n",
      "overworked\n",
      "Saved the embedding for overworked.\n",
      "['over', '##wr', '##ough', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4524,  0.1320,  0.2007,  ..., -0.0302,  0.1558, -0.0197])\n",
      "overwrought\n",
      "Saved the embedding for overwrought.\n",
      "['pain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3847,  0.5576, -1.3201,  ...,  0.6323,  0.4083, -0.6346])\n",
      "pain\n",
      "Saved the embedding for pain.\n",
      "['pained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7161,  0.6903,  0.0772,  ..., -0.8773,  1.0654, -0.8570])\n",
      "pained\n",
      "Saved the embedding for pained.\n",
      "['painful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1996,  1.6826, -0.8925,  ...,  0.4145, -0.0718, -0.3105])\n",
      "painful\n",
      "Saved the embedding for painful.\n",
      "['painfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0375,  1.4611, -1.2917,  ...,  0.0726,  0.8980, -0.7150])\n",
      "painfully\n",
      "Saved the embedding for painfully.\n",
      "['panic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1019,  1.9665, -0.9302,  ...,  0.0610,  0.9897,  0.0031])\n",
      "panic\n",
      "Saved the embedding for panic.\n",
      "['panicked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0134,  0.7220, -1.7656,  ...,  0.6134,  0.8547, -0.1169])\n",
      "panicked\n",
      "Saved the embedding for panicked.\n",
      "['panic', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0609,  1.0828, -0.5163,  ...,  0.3391,  1.1078,  0.3707])\n",
      "panicky\n",
      "Saved the embedding for panicky.\n",
      "['paralyzed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1849,  0.6737, -0.2884,  ...,  0.2451, -0.2397, -0.4284])\n",
      "paralyzed\n",
      "Saved the embedding for paralyzed.\n",
      "['paranoid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5246,  1.0105, -0.6986,  ..., -0.3575,  0.2411, -0.5517])\n",
      "paranoid\n",
      "Saved the embedding for paranoid.\n",
      "['passionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5344,  0.5439,  1.2638,  ..., -0.1622,  0.3807,  0.2149])\n",
      "passionate\n",
      "Saved the embedding for passionate.\n",
      "['passive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6712,  0.1579,  0.6443,  ...,  0.2514,  0.1505, -0.2092])\n",
      "passive\n",
      "Saved the embedding for passive.\n",
      "['patience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3290,  0.2541,  0.5792,  ...,  0.0854,  0.2143,  0.4848])\n",
      "patience\n",
      "Saved the embedding for patience.\n",
      "['patient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7024,  0.2026,  0.2701,  ...,  0.7540,  0.6184, -0.4448])\n",
      "patient\n",
      "Saved the embedding for patient.\n",
      "['patron', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3951,  0.6463, -1.1820,  ...,  0.3614,  0.4717,  0.1708])\n",
      "patronizing\n",
      "Saved the embedding for patronizing.\n",
      "['pause'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8818,  0.6510, -1.1582,  ...,  0.4053,  0.5921, -0.6596])\n",
      "pause\n",
      "Saved the embedding for pause.\n",
      "['pausing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2894,  0.4303,  0.1987,  ..., -0.3162,  0.2418, -0.3211])\n",
      "pausing\n",
      "Saved the embedding for pausing.\n",
      "['peaceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0981,  0.1122,  1.1290,  ...,  0.6274,  0.2214, -0.0413])\n",
      "peaceful\n",
      "Saved the embedding for peaceful.\n",
      "['peculiar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9475,  0.1275, -0.3150,  ...,  0.0257,  0.4735,  0.3157])\n",
      "peculiar\n",
      "Saved the embedding for peculiar.\n",
      "['peering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1446,  0.3065, -0.4678,  ...,  0.5927,  0.8558,  0.1102])\n",
      "peering\n",
      "Saved the embedding for peering.\n",
      "['pee', '##ved'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2856,  0.1279, -1.1103,  ...,  0.8741,  0.7830, -0.7310])\n",
      "peeved\n",
      "Saved the embedding for peeved.\n",
      "['pee', '##vish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7309,  0.0538, -0.1917,  ..., -0.2407,  0.4582,  0.4408])\n",
      "peevish\n",
      "Saved the embedding for peevish.\n",
      "['pens', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6959,  0.1079,  0.4215,  ...,  0.2369,  0.2132,  0.5336])\n",
      "pensive\n",
      "Saved the embedding for pensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pep', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1856, -0.0072, -0.2981,  ...,  0.2813, -0.0095, -0.0204])\n",
      "peppy\n",
      "Saved the embedding for peppy.\n",
      "['per', '##ceptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0955,  0.0580,  0.0962,  ...,  0.2014, -0.0164,  0.3017])\n",
      "perceptive\n",
      "Saved the embedding for perceptive.\n",
      "['per', '##fi', '##dio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5450, -0.1752, -0.4489,  ...,  0.4385,  0.0344,  0.0186])\n",
      "perfidious\n",
      "Saved the embedding for perfidious.\n",
      "['per', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6733, -0.4477, -0.1192,  ...,  0.3323,  0.1037,  0.3684])\n",
      "perky\n",
      "Saved the embedding for perky.\n",
      "['per', '##plex', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4627, -0.0200, -0.1296,  ...,  0.3654, -0.0192,  0.8681])\n",
      "perplexed\n",
      "Saved the embedding for perplexed.\n",
      "['per', '##plex', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4858,  0.2249, -0.2268,  ...,  0.1758, -0.0053,  0.6390])\n",
      "perplexing\n",
      "Saved the embedding for perplexing.\n",
      "['persistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3018, -0.0235,  0.3471,  ...,  0.1482, -0.0558, -0.1281])\n",
      "persistent\n",
      "Saved the embedding for persistent.\n",
      "['persona', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0361,  0.8234,  0.0911,  ...,  0.9142,  0.3014,  0.3098])\n",
      "personable\n",
      "Saved the embedding for personable.\n",
      "['per', '##tur', '##bed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6207, -0.5984,  0.1076,  ...,  0.2469, -0.0718,  0.5623])\n",
      "perturbed\n",
      "Saved the embedding for perturbed.\n",
      "['per', '##verse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1694, -0.2061,  0.4324,  ...,  0.0319, -0.2423,  0.5205])\n",
      "perverse\n",
      "Saved the embedding for perverse.\n",
      "['pe', '##sky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2907,  0.3154, -0.4492,  ...,  0.3586, -0.4656,  0.3632])\n",
      "pesky\n",
      "Saved the embedding for pesky.\n",
      "['pe', '##ssi', '##mism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1172, -0.5585, -0.5180,  ...,  0.0847,  0.3879,  0.2321])\n",
      "pessimism\n",
      "Saved the embedding for pessimism.\n",
      "['pe', '##ssi', '##mist', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1555, -0.1125, -0.4486,  ...,  0.7118, -0.1573,  0.1277])\n",
      "pessimistic\n",
      "Saved the embedding for pessimistic.\n",
      "['pest', '##ered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0668,  0.6580, -0.2445,  ..., -0.2271,  0.0907, -0.0962])\n",
      "pestered\n",
      "Saved the embedding for pestered.\n",
      "['petition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1330,  0.9841,  0.7283,  ..., -0.0392,  0.2807,  0.3117])\n",
      "petitioning\n",
      "Saved the embedding for petitioning.\n",
      "['pet', '##rified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1261, -0.4507,  0.2151,  ...,  0.4036,  0.3533,  0.2028])\n",
      "petrified\n",
      "Saved the embedding for petrified.\n",
      "['petty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5343,  0.6482, -0.1538,  ...,  0.5361,  0.7614, -0.4116])\n",
      "petty\n",
      "Saved the embedding for petty.\n",
      "['pet', '##ula', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7559, -0.2505, -0.0538,  ...,  0.6052,  0.8805, -0.2509])\n",
      "petulant\n",
      "Saved the embedding for petulant.\n",
      "['picked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8647,  1.0521, -1.0540,  ..., -0.0136,  0.4054,  0.0971])\n",
      "picked\n",
      "Saved the embedding for picked.\n",
      "['piercing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2767,  0.5915, -1.0234,  ...,  0.1804,  0.6708, -0.2988])\n",
      "piercing\n",
      "Saved the embedding for piercing.\n",
      "['pinched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1087,  1.4382, -1.1333,  ...,  0.2219,  0.6027, -0.8149])\n",
      "pinched\n",
      "Saved the embedding for pinched.\n",
      "['pious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.5814,  0.8487,  0.5333,  ...,  0.3248, -0.0340,  0.7055])\n",
      "pious\n",
      "Saved the embedding for pious.\n",
      "['pi', '##que', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4949, -0.1344,  0.5101,  ...,  0.1737,  0.6193,  0.2470])\n",
      "piqued\n",
      "Saved the embedding for piqued.\n",
      "['pissed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4317,  1.4451,  0.5272,  ..., -0.3075,  0.3093,  0.2639])\n",
      "pissed\n",
      "Saved the embedding for pissed.\n",
      "['pit', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1792, -0.0473,  0.8898,  ...,  0.2492,  0.3765, -0.5522])\n",
      "pitiable\n",
      "Saved the embedding for pitiable.\n",
      "['pit', '##iful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1695, -0.3413,  1.2198,  ...,  0.0926,  0.7107, -0.3493])\n",
      "pitiful\n",
      "Saved the embedding for pitiful.\n",
      "['pity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3079,  1.0468,  0.2459,  ...,  0.0573, -0.1993,  0.3116])\n",
      "pity\n",
      "Saved the embedding for pity.\n",
      "['pity', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8705,  1.0967,  0.4871,  ...,  0.1106, -0.0403,  0.0762])\n",
      "pitying\n",
      "Saved the embedding for pitying.\n",
      "['pl', '##aca', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4547, -0.2287,  0.6362,  ...,  0.5241,  0.0928,  0.9626])\n",
      "placated\n",
      "Saved the embedding for placated.\n",
      "['pl', '##aca', '##tion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1632, -0.3799,  0.8542,  ...,  0.7758,  0.4689,  0.5134])\n",
      "placation\n",
      "Saved the embedding for placation.\n",
      "['pl', '##ac', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9043, -0.4074,  0.6897,  ...,  0.5048,  0.3737,  0.5439])\n",
      "placid\n",
      "Saved the embedding for placid.\n",
      "['plain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8155,  1.3536, -0.0841,  ...,  0.0276, -0.2802, -0.3783])\n",
      "plain\n",
      "Saved the embedding for plain.\n",
      "['plain', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2698,  0.7338,  0.2831,  ..., -0.2097,  0.3459, -0.4927])\n",
      "plaintive\n",
      "Saved the embedding for plaintive.\n",
      "['planning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4638,  0.3504,  0.3089,  ..., -0.2765,  0.2180,  0.3557])\n",
      "planning\n",
      "Saved the embedding for planning.\n",
      "['playful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0069,  0.3618, -1.4458,  ..., -0.1167,  0.4194,  0.0697])\n",
      "playful\n",
      "Saved the embedding for playful.\n",
      "['playfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0955,  0.4697, -0.6283,  ..., -0.8559,  0.5772, -0.4098])\n",
      "playfully\n",
      "Saved the embedding for playfully.\n",
      "['pleading'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3826,  0.4324, -0.1418,  ...,  0.3618,  0.6757,  0.0304])\n",
      "pleading\n",
      "Saved the embedding for pleading.\n",
      "['pleasant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4023,  0.0018, -0.4769,  ...,  0.0339,  0.3118,  0.5191])\n",
      "pleasant\n",
      "Saved the embedding for pleasant.\n",
      "['pleased'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4657,  0.7506, -0.7845,  ...,  0.3456,  0.4539, -0.1538])\n",
      "pleased\n",
      "Saved the embedding for pleased.\n",
      "['pleasing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0113,  1.0594,  0.2352,  ..., -0.4584,  0.1934,  0.6056])\n",
      "pleasing\n",
      "Saved the embedding for pleasing.\n",
      "['pleas', '##urable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1904,  1.1275,  0.6201,  ..., -0.5364,  0.9715, -0.1769])\n",
      "pleasurable\n",
      "Saved the embedding for pleasurable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pleasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0231,  0.6162, -0.4066,  ..., -0.3462,  0.2983,  0.1029])\n",
      "pleasure\n",
      "Saved the embedding for pleasure.\n",
      "['pleasure', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4880,  0.2823,  0.0591,  ..., -0.3380,  0.3149, -0.0183])\n",
      "pleasured\n",
      "Saved the embedding for pleasured.\n",
      "['pl', '##ian', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2164, -0.2489,  1.0135,  ...,  0.3666,  0.2144,  0.4185])\n",
      "pliant\n",
      "Saved the embedding for pliant.\n",
      "['plotting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5518,  1.0190, -0.5127,  ...,  0.4126,  0.8506, -0.7856])\n",
      "plotting\n",
      "Saved the embedding for plotting.\n",
      "['po', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4140, -0.0944,  0.4332,  ...,  0.0613, -0.0804,  0.3813])\n",
      "poignant\n",
      "Saved the embedding for poignant.\n",
      "['pointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6316, -0.4181, -0.3819,  ...,  0.3033,  0.0457,  0.1393])\n",
      "pointed\n",
      "Saved the embedding for pointed.\n",
      "['poised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0440,  0.7940, -0.8595,  ...,  0.4505, -0.5210, -0.4434])\n",
      "poised\n",
      "Saved the embedding for poised.\n",
      "['polite'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1492,  1.0819,  0.2061,  ..., -0.5138, -0.2898,  0.4943])\n",
      "polite\n",
      "Saved the embedding for polite.\n",
      "['po', '##mp', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1834,  0.4501,  0.3341,  ...,  0.2168, -0.0041,  0.5661])\n",
      "pompous\n",
      "Saved the embedding for pompous.\n",
      "['ponder'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0286,  0.9828, -0.9826,  ...,  0.3148,  0.3992,  0.1061])\n",
      "ponder\n",
      "Saved the embedding for ponder.\n",
      "['ponder', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1744,  1.3566, -0.5331,  ...,  0.5333,  0.5476, -0.0791])\n",
      "pondering\n",
      "Saved the embedding for pondering.\n",
      "['po', '##oping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0496, -0.3993,  0.3293,  ...,  0.0111, -0.4457,  0.6666])\n",
      "pooping\n",
      "Saved the embedding for pooping.\n",
      "['pop'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2342,  1.6050, -0.5169,  ...,  0.2457,  0.3714, -0.1129])\n",
      "pop\n",
      "Saved the embedding for pop.\n",
      "['posing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2533,  0.6302,  0.3043,  ..., -0.0775,  0.4114,  0.0205])\n",
      "posing\n",
      "Saved the embedding for posing.\n",
      "['positive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0808,  0.5899,  0.5291,  ..., -0.1116,  0.2249,  0.2197])\n",
      "positive\n",
      "Saved the embedding for positive.\n",
      "['po', '##sit', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3963, -0.8491, -0.4668,  ...,  0.0424, -0.3810,  0.4990])\n",
      "positivity\n",
      "Saved the embedding for positivity.\n",
      "['possibly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2078,  0.4379,  0.6433,  ...,  0.1179,  0.4795,  0.0857])\n",
      "possibly\n",
      "Saved the embedding for possibly.\n",
      "['po', '##ut'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9895,  0.2214,  0.3122,  ...,  0.2498,  0.4269,  0.7215])\n",
      "pout\n",
      "Saved the embedding for pout.\n",
      "['po', '##uting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3273,  0.3021,  0.3559,  ...,  0.4497,  0.3746,  0.2698])\n",
      "pouting\n",
      "Saved the embedding for pouting.\n",
      "['po', '##ut', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5871,  0.8065,  1.0713,  ...,  0.5030, -0.1097,  0.6839])\n",
      "pouty\n",
      "Saved the embedding for pouty.\n",
      "['powerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5215,  0.9560, -0.3657,  ...,  0.2839,  0.7190,  0.7803])\n",
      "powerful\n",
      "Saved the embedding for powerful.\n",
      "['powerless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3587,  0.8095, -0.3860,  ...,  0.3994, -0.4096,  0.0120])\n",
      "powerless\n",
      "Saved the embedding for powerless.\n",
      "['prank', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4306,  0.1293, -0.4697,  ...,  0.3115,  0.0878,  0.5842])\n",
      "pranking\n",
      "Saved the embedding for pranking.\n",
      "['pre', '##car', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5612, -0.0178,  0.2469,  ...,  0.1028,  0.5350,  0.0677])\n",
      "precarious\n",
      "Saved the embedding for precarious.\n",
      "['predatory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1356,  0.5904, -0.7177,  ...,  0.6116,  0.3077,  0.6647])\n",
      "predatory\n",
      "Saved the embedding for predatory.\n",
      "['prejudice', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2620,  0.4175, -0.3582,  ...,  0.4130, -0.6212, -0.5890])\n",
      "prejudiced\n",
      "Saved the embedding for prejudiced.\n",
      "['preoccupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2468,  0.8570,  0.7395,  ...,  0.1014,  0.3691, -0.1308])\n",
      "preoccupied\n",
      "Saved the embedding for preoccupied.\n",
      "['prepared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4358,  0.9277, -1.0098,  ...,  0.2143, -0.0790, -0.4936])\n",
      "prepared\n",
      "Saved the embedding for prepared.\n",
      "['preparing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1160,  0.6608, -0.4645,  ...,  0.0791,  0.4868, -0.4044])\n",
      "preparing\n",
      "Saved the embedding for preparing.\n",
      "['pretending'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5980,  0.3238, -1.0214,  ...,  0.5405,  0.2785,  0.7012])\n",
      "pretending\n",
      "Saved the embedding for pretending.\n",
      "['pre', '##ten', '##tious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2483,  0.3948,  0.3939,  ..., -0.3399, -0.1163, -0.2847])\n",
      "pretentious\n",
      "Saved the embedding for pretentious.\n",
      "['pride', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2764,  0.6263,  0.3660,  ...,  0.4952, -0.1289, -0.2291])\n",
      "prideful\n",
      "Saved the embedding for prideful.\n",
      "['pri', '##gg', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3535,  0.4428,  0.3191,  ...,  0.4055,  0.3432,  1.7171])\n",
      "priggish\n",
      "Saved the embedding for priggish.\n",
      "['prime', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1454,  0.5645,  0.9229,  ..., -0.3850,  0.5384,  0.4779])\n",
      "primed\n",
      "Saved the embedding for primed.\n",
      "['private'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2364,  0.8185, -0.6958,  ...,  0.1472,  1.2224,  0.0776])\n",
      "private\n",
      "Saved the embedding for private.\n",
      "['processing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4320,  1.0140,  0.8606,  ..., -0.3013,  0.1963,  0.5781])\n",
      "processing\n",
      "Saved the embedding for processing.\n",
      "['proposition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6393,  0.7819,  0.8278,  ...,  0.1869,  0.0798,  0.2915])\n",
      "propositioning\n",
      "Saved the embedding for propositioning.\n",
      "['proud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8651,  0.4555, -0.7444,  ...,  0.0845,  0.3357, -0.8146])\n",
      "proud\n",
      "Saved the embedding for proud.\n",
      "['provocative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2667,  1.4797, -0.3159,  ..., -0.3217,  0.4111, -0.6773])\n",
      "provocative\n",
      "Saved the embedding for provocative.\n",
      "['provoke'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7293,  1.3046, -0.2766,  ..., -0.3843,  0.6010, -0.1055])\n",
      "provoke\n",
      "Saved the embedding for provoke.\n",
      "['provoked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4448,  0.3816,  0.1842,  ...,  0.3938,  0.0338, -0.3456])\n",
      "provoked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for provoked.\n",
      "['pro', '##voking'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.4477,  0.1996,  0.2587,  ..., -0.5888,  0.4777, -0.0522])\n",
      "provoking\n",
      "Saved the embedding for provoking.\n",
      "['pry', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8466,  0.6227, -0.9438,  ...,  0.5916,  1.1478, -0.6731])\n",
      "prying\n",
      "Saved the embedding for prying.\n",
      "['psycho'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5909, -0.1195,  0.0130,  ...,  0.6649,  0.4294, -0.0734])\n",
      "psycho\n",
      "Saved the embedding for psycho.\n",
      "['psychotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1226, -0.2172, -0.1510,  ...,  0.0042,  0.2293, -0.5207])\n",
      "psychotic\n",
      "Saved the embedding for psychotic.\n",
      "['puck', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1048, -0.2176, -0.0958,  ...,  0.4725,  0.4016,  0.5269])\n",
      "puckish\n",
      "Saved the embedding for puckish.\n",
      "['pu', '##eri', '##le'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2845,  0.1990,  0.5289,  ..., -0.1100,  0.5424,  0.1926])\n",
      "puerile\n",
      "Saved the embedding for puerile.\n",
      "['pu', '##gna', '##cious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3909, -0.4248, -0.0697,  ...,  0.0134, -0.2000,  0.1447])\n",
      "pugnacious\n",
      "Saved the embedding for pugnacious.\n",
      "['punished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7174,  0.8881, -1.1038,  ...,  0.9593,  0.2216,  0.3156])\n",
      "punished\n",
      "Saved the embedding for punished.\n",
      "['punish', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7265,  0.7643, -0.2915,  ..., -0.0954,  0.2763,  0.7055])\n",
      "punishing\n",
      "Saved the embedding for punishing.\n",
      "['pun', '##itive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.6280e-01,  9.1992e-02,  5.0560e-02,  ..., -7.5328e-02,\n",
      "        -6.1281e-05, -1.1377e-01])\n",
      "punitive\n",
      "Saved the embedding for punitive.\n",
      "['punk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2879,  1.7821, -0.1643,  ..., -0.3765,  0.1213,  0.1747])\n",
      "punk\n",
      "Saved the embedding for punk.\n",
      "['puppy', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6509,  0.2671, -0.9254,  ...,  1.2779,  0.8212, -0.8606])\n",
      "puppyish\n",
      "Saved the embedding for puppyish.\n",
      "['purpose', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4972,  1.0357,  0.2863,  ..., -0.1650,  0.0449,  0.4604])\n",
      "purposeful\n",
      "Saved the embedding for purposeful.\n",
      "['pursed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0612,  0.4535,  0.3808,  ..., -0.5526,  0.7714, -0.6459])\n",
      "pursed\n",
      "Saved the embedding for pursed.\n",
      "['put'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8169,  1.3414, -1.2167,  ...,  0.4292,  0.3960,  0.3235])\n",
      "put\n",
      "Saved the embedding for put.\n",
      "['putting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7026,  0.6612, -1.2639,  ...,  1.1257,  0.6701, -0.1838])\n",
      "putting\n",
      "Saved the embedding for putting.\n",
      "['puzzled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0206,  1.0883, -1.0189,  ...,  0.8767,  0.7271,  0.2793])\n",
      "puzzled\n",
      "Saved the embedding for puzzled.\n",
      "['puzzle', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9724,  0.1448,  0.0375,  ...,  0.1903,  0.8330, -0.1705])\n",
      "puzzlement\n",
      "Saved the embedding for puzzlement.\n",
      "['qu', '##al', '##ms'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2058,  0.5662,  0.4200,  ...,  0.3120,  0.2887,  0.5012])\n",
      "qualms\n",
      "Saved the embedding for qualms.\n",
      "['quarrel', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6271,  1.7164,  0.6373,  ..., -0.5140,  0.7478,  0.0581])\n",
      "quarrelsome\n",
      "Saved the embedding for quarrelsome.\n",
      "['que', '##as', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1064,  0.4203,  0.6502,  ..., -0.1089,  0.5935,  0.3411])\n",
      "queasy\n",
      "Saved the embedding for queasy.\n",
      "['que', '##nched'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7029, -0.0893, -0.1684,  ..., -0.0800,  0.3318,  0.3178])\n",
      "quenched\n",
      "Saved the embedding for quenched.\n",
      "['questionable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1160,  1.5807, -0.7461,  ..., -0.4038,  0.7992, -0.8833])\n",
      "questionable\n",
      "Saved the embedding for questionable.\n",
      "['questioning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1314,  0.6841, -0.8427,  ...,  0.0103,  0.5676, -0.0067])\n",
      "questioning\n",
      "Saved the embedding for questioning.\n",
      "['questioning', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2521,  0.7895, -0.2344,  ..., -0.2910,  0.2500, -0.0906])\n",
      "questioningly\n",
      "Saved the embedding for questioningly.\n",
      "['quiet'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1966,  0.6956,  0.2541,  ..., -0.0753,  0.4908, -0.3270])\n",
      "quiet\n",
      "Saved the embedding for quiet.\n",
      "['quiet', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0492,  0.1269,  0.3696,  ...,  0.2375,  0.2179, -0.0698])\n",
      "quietness\n",
      "Saved the embedding for quietness.\n",
      "['quilt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0825,  0.8058,  0.7381,  ..., -0.4873,  0.0521,  0.1301])\n",
      "quilt\n",
      "Saved the embedding for quilt.\n",
      "['qui', '##rky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5324, -0.5590,  0.6328,  ...,  0.8159,  0.4589,  0.9911])\n",
      "quirky\n",
      "Saved the embedding for quirky.\n",
      "['quiz', '##zic', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4520, -0.1475,  0.2545,  ...,  0.9331,  0.2551,  0.1475])\n",
      "quizzical\n",
      "Saved the embedding for quizzical.\n",
      "['ra', '##bid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2176,  0.4690, -0.2378,  ...,  0.7455,  0.3878,  0.8380])\n",
      "rabid\n",
      "Saved the embedding for rabid.\n",
      "['rack', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5997,  0.8771,  0.5035,  ..., -0.2587,  0.6180, -0.4250])\n",
      "racked\n",
      "Saved the embedding for racked.\n",
      "['radiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1286,  0.8281, -0.8277,  ...,  1.1171,  0.7335,  0.3191])\n",
      "radiant\n",
      "Saved the embedding for radiant.\n",
      "['rage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1220,  1.2875,  0.4128,  ..., -0.2755,  0.4786, -0.0514])\n",
      "rage\n",
      "Saved the embedding for rage.\n",
      "['raged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0770,  0.2596, -0.8956,  ...,  0.0353,  0.9665,  0.1370])\n",
      "raged\n",
      "Saved the embedding for raged.\n",
      "['ragged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2319,  1.3703, -1.5841,  ...,  0.0475,  1.1708,  0.2581])\n",
      "ragged\n",
      "Saved the embedding for ragged.\n",
      "['raging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2123,  0.8884, -1.3720,  ...,  0.6769,  0.4472, -0.6351])\n",
      "raging\n",
      "Saved the embedding for raging.\n",
      "['ran', '##cor', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2385,  0.6014,  0.2145,  ...,  0.4721,  0.4057,  0.0655])\n",
      "rancorous\n",
      "Saved the embedding for rancorous.\n",
      "['randy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3433,  0.8880, -0.8889,  ...,  0.8988,  1.0163,  0.6360])\n",
      "randy\n",
      "Saved the embedding for randy.\n",
      "['rap', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2179,  1.3732,  0.8527,  ..., -0.2104,  0.0239,  0.4193])\n",
      "rapt\n",
      "Saved the embedding for rapt.\n",
      "['rattled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0023,  0.3080, -0.9926,  ...,  0.6314,  0.2776, -0.4360])\n",
      "rattled\n",
      "Saved the embedding for rattled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ravi', '##ng'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2081,  0.8138,  0.4301,  ..., -0.4530,  0.1694, -0.3045])\n",
      "raving\n",
      "Saved the embedding for raving.\n",
      "['reactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9106,  1.0395,  0.7150,  ..., -0.6414,  0.5375,  0.2730])\n",
      "reactive\n",
      "Saved the embedding for reactive.\n",
      "['ready'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5413,  0.5083, -0.1867,  ...,  0.4113,  0.1582,  0.1823])\n",
      "ready\n",
      "Saved the embedding for ready.\n",
      "['realization'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0916,  1.5609, -0.1275,  ..., -0.1455,  0.4877, -0.0803])\n",
      "realization\n",
      "Saved the embedding for realization.\n",
      "['reassured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4392,  1.6080, -1.0795,  ...,  0.7814,  0.3198,  0.3505])\n",
      "reassured\n",
      "Saved the embedding for reassured.\n",
      "['rebellious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0696,  0.9967, -0.6598,  ...,  0.4058, -0.0166,  0.2713])\n",
      "rebellious\n",
      "Saved the embedding for rebellious.\n",
      "['re', '##bu', '##ke'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2351, -0.4065,  0.6318,  ...,  0.8925,  0.1710,  0.3216])\n",
      "rebuke\n",
      "Saved the embedding for rebuke.\n",
      "['recalling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2744,  0.3291,  0.2867,  ..., -0.3260, -0.0360, -0.2406])\n",
      "recalling\n",
      "Saved the embedding for recalling.\n",
      "['rec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3209,  0.0183,  0.5909,  ...,  0.5296,  0.2076, -0.2295])\n",
      "receptive\n",
      "Saved the embedding for receptive.\n",
      "['reckless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1474,  0.6044,  0.7853,  ..., -0.0265, -0.2618,  0.0505])\n",
      "reckless\n",
      "Saved the embedding for reckless.\n",
      "['recoil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2120,  1.2901, -0.2600,  ...,  0.0562,  0.9231, -0.8815])\n",
      "recoil\n",
      "Saved the embedding for recoil.\n",
      "['recoil', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.2621,  1.6938, -0.9307,  ..., -0.6912,  1.7329, -0.8116])\n",
      "recoiling\n",
      "Saved the embedding for recoiling.\n",
      "['reflecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0115,  0.6277,  0.2944,  ...,  0.0357,  0.2359,  0.3228])\n",
      "reflecting\n",
      "Saved the embedding for reflecting.\n",
      "['reflection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9723,  1.0685,  0.4418,  ...,  0.0258,  0.5011,  0.0228])\n",
      "reflection\n",
      "Saved the embedding for reflection.\n",
      "['reflective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6431,  0.3544, -0.5947,  ...,  0.1740,  0.0116,  0.4984])\n",
      "reflective\n",
      "Saved the embedding for reflective.\n",
      "['ref', '##ul', '##gent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1754, -0.4644,  0.7449,  ..., -0.0262,  0.2565,  0.0075])\n",
      "refulgent\n",
      "Saved the embedding for refulgent.\n",
      "['refusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7188,  1.2292, -0.3008,  ..., -0.1372,  0.1785,  0.5049])\n",
      "refusing\n",
      "Saved the embedding for refusing.\n",
      "['regret'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3416,  0.1888, -1.0357,  ..., -0.1322,  0.9872,  0.1639])\n",
      "regret\n",
      "Saved the embedding for regret.\n",
      "['regret', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3531,  1.5855, -0.1442,  ..., -0.0386,  0.8148, -0.3016])\n",
      "regretful\n",
      "Saved the embedding for regretful.\n",
      "['rejected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1067,  0.4926, -0.7161,  ..., -0.4469, -0.0939,  0.1242])\n",
      "rejected\n",
      "Saved the embedding for rejected.\n",
      "['rejecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7012,  0.2297, -0.7530,  ...,  0.6955,  0.9249, -0.0279])\n",
      "rejecting\n",
      "Saved the embedding for rejecting.\n",
      "['rejection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3407,  0.1266,  0.1069,  ...,  0.1617, -0.1464,  0.5310])\n",
      "rejection\n",
      "Saved the embedding for rejection.\n",
      "['re', '##jo', '##icing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2612, -0.3986,  0.6548,  ...,  0.0900,  0.2240,  0.0053])\n",
      "rejoicing\n",
      "Saved the embedding for rejoicing.\n",
      "['relaxation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3029,  0.8651, -0.5618,  ..., -0.1222, -0.1166,  0.1599])\n",
      "relaxation\n",
      "Saved the embedding for relaxation.\n",
      "['relaxed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3629,  1.2319, -0.7306,  ..., -0.8042,  0.4062, -0.1153])\n",
      "relaxed\n",
      "Saved the embedding for relaxed.\n",
      "['relentless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2321, -0.3880, -0.4551,  ..., -0.3616, -0.0481, -0.2602])\n",
      "relentless\n",
      "Saved the embedding for relentless.\n",
      "['relief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1968, -0.6616, -0.2763,  ...,  0.2378,  0.5949,  0.1055])\n",
      "relief\n",
      "Saved the embedding for relief.\n",
      "['relieved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6174,  0.9366,  0.1144,  ..., -0.0431,  0.2910, -0.9218])\n",
      "relieved\n",
      "Saved the embedding for relieved.\n",
      "['re', '##li', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3568,  0.7632,  0.3138,  ...,  0.0180,  0.6499, -0.3475])\n",
      "relived\n",
      "Saved the embedding for relived.\n",
      "['reluctant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9907,  1.4068, -1.6245,  ...,  0.6032,  0.2779, -0.1115])\n",
      "reluctant\n",
      "Saved the embedding for reluctant.\n",
      "['reluctantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8473,  1.8490, -0.7694,  ..., -0.4625, -0.6942, -0.2958])\n",
      "reluctantly\n",
      "Saved the embedding for reluctantly.\n",
      "['remorse'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7250,  1.0353, -0.0340,  ...,  0.7937,  0.1867, -0.0200])\n",
      "remorse\n",
      "Saved the embedding for remorse.\n",
      "['remorse', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0573,  0.8615,  0.1461,  ...,  0.0984,  0.4923, -0.2211])\n",
      "remorseful\n",
      "Saved the embedding for remorseful.\n",
      "['rep', '##elled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1697, -0.6677,  0.1968,  ..., -0.3615, -0.1834,  0.4485])\n",
      "repelled\n",
      "Saved the embedding for repelled.\n",
      "['rep', '##ressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0111, -0.2737, -0.2339,  ...,  0.3404,  0.0867,  0.7594])\n",
      "repressed\n",
      "Saved the embedding for repressed.\n",
      "['rep', '##ro', '##ach'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1611,  0.0828,  0.0704,  ...,  0.5203,  0.0988,  0.1757])\n",
      "reproach\n",
      "Saved the embedding for reproach.\n",
      "['rep', '##ro', '##ach', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0594,  0.5434,  0.5019,  ..., -0.1335, -0.2475,  0.3023])\n",
      "reproachful\n",
      "Saved the embedding for reproachful.\n",
      "['rep', '##ug', '##nan', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3362, -0.1171,  0.2183,  ...,  0.0449,  0.0877,  0.1693])\n",
      "repugnance\n",
      "Saved the embedding for repugnance.\n",
      "['rep', '##ug', '##nant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3202,  0.9090,  0.0990,  ..., -0.4224, -0.0936,  0.5750])\n",
      "repugnant\n",
      "Saved the embedding for repugnant.\n",
      "['repulsed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0805,  1.3534, -0.0365,  ..., -0.1041,  0.0217, -0.0231])\n",
      "repulsed\n",
      "Saved the embedding for repulsed.\n",
      "['rep', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1539, -0.1741, -0.0408,  ..., -0.1255, -0.0157,  0.5544])\n",
      "repulsion\n",
      "Saved the embedding for repulsion.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['res', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8119,  0.7059,  0.4224,  ...,  0.5156,  0.3991,  0.3232])\n",
      "resent\n",
      "Saved the embedding for resent.\n",
      "['res', '##ent', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4961,  0.6787,  1.1469,  ..., -0.0020, -0.2213,  0.2547])\n",
      "resentful\n",
      "Saved the embedding for resentful.\n",
      "['res', '##enting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0850,  0.7135,  1.1565,  ...,  0.0873, -0.2477, -0.4359])\n",
      "resenting\n",
      "Saved the embedding for resenting.\n",
      "['resentment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1651,  0.3080, -0.6607,  ..., -0.3694,  0.1074, -0.3617])\n",
      "resentment\n",
      "Saved the embedding for resentment.\n",
      "['reserved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9024,  0.1464, -0.2234,  ...,  0.4444,  0.6599, -0.1958])\n",
      "reserved\n",
      "Saved the embedding for reserved.\n",
      "['resignation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0603,  0.4144,  0.1680,  ..., -0.0108,  0.1964, -0.3132])\n",
      "resignation\n",
      "Saved the embedding for resignation.\n",
      "['resigned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4257,  0.4441, -0.7851,  ...,  0.5887,  0.1700,  0.3974])\n",
      "resigned\n",
      "Saved the embedding for resigned.\n",
      "['res', '##ili', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3414, 0.0564, 0.2388,  ..., 0.1496, 0.3120, 0.0013])\n",
      "resilience\n",
      "Saved the embedding for resilience.\n",
      "['resistance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7405,  0.0236,  0.4312,  ..., -0.0934,  0.1145, -0.0452])\n",
      "resistance\n",
      "Saved the embedding for resistance.\n",
      "['resistant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1751, -0.0257, -0.0782,  ..., -0.3041,  0.0627, -0.2667])\n",
      "resistant\n",
      "Saved the embedding for resistant.\n",
      "['resist', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2414,  0.7011,  0.3917,  ...,  0.4113,  0.5768, -0.1267])\n",
      "resistent\n",
      "Saved the embedding for resistent.\n",
      "['resisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9717,  0.3558, -1.4379,  ...,  0.6064,  0.0950, -0.1960])\n",
      "resisting\n",
      "Saved the embedding for resisting.\n",
      "['res', '##ol', '##ute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3391,  0.7505,  0.6210,  ..., -0.5226,  0.2969,  0.2209])\n",
      "resolute\n",
      "Saved the embedding for resolute.\n",
      "['resolved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6158,  0.1245, -1.2388,  ..., -0.2501,  0.5916,  0.1797])\n",
      "resolved\n",
      "Saved the embedding for resolved.\n",
      "['responsive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1654,  1.1647, -0.0488,  ...,  0.0757,  0.4859,  0.4085])\n",
      "responsive\n",
      "Saved the embedding for responsive.\n",
      "['rest', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3856, -0.2305,  0.2242,  ..., -0.0020, -0.0056,  0.1316])\n",
      "restful\n",
      "Saved the embedding for restful.\n",
      "['resting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3902,  0.7786, -0.5390,  ..., -0.4040,  0.0465, -0.6346])\n",
      "resting\n",
      "Saved the embedding for resting.\n",
      "['restless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1324,  0.8408, -0.5183,  ...,  0.4201, -0.1032, -0.4504])\n",
      "restless\n",
      "Saved the embedding for restless.\n",
      "['restless', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5056,  1.0561, -0.1590,  ...,  0.5980, -0.2668, -0.0301])\n",
      "restlessness\n",
      "Saved the embedding for restlessness.\n",
      "['restrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0149,  1.3903,  0.0877,  ...,  0.0649, -0.8031, -0.0474])\n",
      "restrained\n",
      "Saved the embedding for restrained.\n",
      "['restraint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4444,  0.9202, -1.0986,  ...,  0.5818,  0.2902,  0.1179])\n",
      "restraint\n",
      "Saved the embedding for restraint.\n",
      "['re', '##tal', '##iating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1728, -0.5800, -0.2647,  ...,  0.5834, -0.1355,  0.4985])\n",
      "retaliating\n",
      "Saved the embedding for retaliating.\n",
      "['re', '##tal', '##ia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2261, -0.2347,  0.3491,  ...,  0.2543,  0.2327,  0.4596])\n",
      "retaliatory\n",
      "Saved the embedding for retaliatory.\n",
      "['re', '##thi', '##nk', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1731, -0.4286,  0.2329,  ...,  0.3230,  0.1799,  0.6072])\n",
      "rethinking\n",
      "Saved the embedding for rethinking.\n",
      "['re', '##tic', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5965,  0.0756, -0.0642,  ...,  0.1020,  0.5148,  0.1604])\n",
      "reticence\n",
      "Saved the embedding for reticence.\n",
      "['re', '##tic', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.3202, 0.0825, 0.0602,  ..., 0.2750, 0.0339, 0.2424])\n",
      "reticent\n",
      "Saved the embedding for reticent.\n",
      "['revenge', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1713,  0.7949,  0.3106,  ..., -0.1271, -0.1832,  0.4868])\n",
      "revengeful\n",
      "Saved the embedding for revengeful.\n",
      "['rev', '##ere', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4071,  0.3199,  0.5566,  ..., -0.2776,  0.2116, -0.1662])\n",
      "reverent\n",
      "Saved the embedding for reverent.\n",
      "['revolt', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2481,  0.9430,  0.8861,  ..., -0.1122,  0.1314, -0.2155])\n",
      "revolted\n",
      "Saved the embedding for revolted.\n",
      "['rev', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0255,  0.4683,  0.0020,  ...,  0.1818, -0.0448,  0.0090])\n",
      "revulsion\n",
      "Saved the embedding for revulsion.\n",
      "['righteous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3252,  0.4039,  0.4512,  ...,  0.3188,  0.0701, -0.0566])\n",
      "righteous\n",
      "Saved the embedding for righteous.\n",
      "['rigid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7411,  0.2703, -0.9560,  ...,  0.8384, -0.2416,  0.5241])\n",
      "rigid\n",
      "Saved the embedding for rigid.\n",
      "['ri', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5808,  0.9278,  0.0873,  ...,  0.0314,  0.1957,  0.4413])\n",
      "riled\n",
      "Saved the embedding for riled.\n",
      "['riot', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.6617, 0.2620, 1.0606,  ..., 0.0107, 0.0170, 0.2924])\n",
      "riotous\n",
      "Saved the embedding for riotous.\n",
      "['ri', '##vet', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4144,  0.4278, -0.3741,  ...,  0.0801,  0.5373,  0.5518])\n",
      "riveted\n",
      "Saved the embedding for riveted.\n",
      "['roar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3276, -0.0194, -0.3892,  ...,  0.3067,  0.2047, -0.4372])\n",
      "roar\n",
      "Saved the embedding for roar.\n",
      "['ro', '##gui', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6010, -0.3810,  0.2992,  ...,  0.3367,  0.6432,  0.5783])\n",
      "roguish\n",
      "Saved the embedding for roguish.\n",
      "['roi', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4890,  0.7471, -0.0947,  ...,  0.0992,  0.3605,  0.3351])\n",
      "roiled\n",
      "Saved the embedding for roiled.\n",
      "['rough'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9239,  0.4858, -1.0281,  ...,  0.6986,  0.1919, -0.0350])\n",
      "rough\n",
      "Saved the embedding for rough.\n",
      "['rouse', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3832, -0.1672,  0.4145,  ..., -0.3911,  0.4254, -0.7054])\n",
      "roused\n",
      "Saved the embedding for roused.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2743,  1.4921, -1.3118,  ...,  0.6078,  0.0542,  0.3155])\n",
      "rude\n",
      "Saved the embedding for rude.\n",
      "['rue', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1947,  0.0231, -0.4452,  ..., -0.1316,  0.2934, -0.5996])\n",
      "rueful\n",
      "Saved the embedding for rueful.\n",
      "['ru', '##ffled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2122, -0.2337,  0.2148,  ...,  0.1517, -0.0937,  0.1688])\n",
      "ruffled\n",
      "Saved the embedding for ruffled.\n",
      "['rum', '##inating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6920,  0.6397, -0.2072,  ...,  0.7198,  0.3160,  0.3517])\n",
      "ruminating\n",
      "Saved the embedding for ruminating.\n",
      "['rust', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1814,  1.0177,  0.4662,  ..., -0.1460,  0.3409, -0.2930])\n",
      "rustled\n",
      "Saved the embedding for rustled.\n",
      "['ruthless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2330,  0.2471,  0.0716,  ..., -0.2124,  0.5803,  0.0346])\n",
      "ruthless\n",
      "Saved the embedding for ruthless.\n",
      "['sad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7434,  0.8154, -0.2292,  ...,  0.3713,  0.4636, -0.0745])\n",
      "sad\n",
      "Saved the embedding for sad.\n",
      "['sad', '##den'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1164,  1.3726, -0.6162,  ...,  0.4695,  0.8485,  0.5998])\n",
      "sadden\n",
      "Saved the embedding for sadden.\n",
      "['sad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8861,  1.3073,  1.0443,  ...,  0.3731, -0.0921, -0.0795])\n",
      "saddened\n",
      "Saved the embedding for saddened.\n",
      "['sad', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3614,  0.6466,  0.9232,  ...,  0.0599,  0.1409,  0.3862])\n",
      "sadistic\n",
      "Saved the embedding for sadistic.\n",
      "['sadness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2247, -0.0034, -0.2847,  ..., -0.1156,  0.0807,  0.0820])\n",
      "sadness\n",
      "Saved the embedding for sadness.\n",
      "['sal', '##acious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4282,  0.6914,  0.3949,  ..., -0.0834,  0.0377,  0.3717])\n",
      "salacious\n",
      "Saved the embedding for salacious.\n",
      "['saliva', '##ting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1614,  0.8247, -0.4102,  ...,  0.2073, -0.6482, -0.2313])\n",
      "salivating\n",
      "Saved the embedding for salivating.\n",
      "['san', '##ct', '##imo', '##nio', '##us'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.4200,  0.3606,  0.5129,  ...,  0.1745, -0.0602,  0.6044])\n",
      "sanctimonious\n",
      "Saved the embedding for sanctimonious.\n",
      "['sane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9873,  1.1432, -1.0257,  ...,  0.1576,  0.2206,  0.2854])\n",
      "sane\n",
      "Saved the embedding for sane.\n",
      "['sang', '##uin', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2768,  0.8977,  0.5678,  ...,  0.0368,  0.7316,  0.4626])\n",
      "sanguine\n",
      "Saved the embedding for sanguine.\n",
      "['sap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0972,  0.7622, -1.8182,  ...,  0.4085,  0.6278, -0.7138])\n",
      "sappy\n",
      "Saved the embedding for sappy.\n",
      "['sarcasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3202, -0.1014, -0.3608,  ...,  0.1996, -0.1448, -0.0383])\n",
      "sarcasm\n",
      "Saved the embedding for sarcasm.\n",
      "['sarcastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1896,  0.8418, -0.9390,  ...,  0.7047,  0.8436, -0.3299])\n",
      "sarcastic\n",
      "Saved the embedding for sarcastic.\n",
      "['sar', '##don', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6024,  0.2687,  0.4070,  ...,  0.0018,  0.5643,  0.4379])\n",
      "sardonic\n",
      "Saved the embedding for sardonic.\n",
      "['sas', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4877,  0.0801,  0.5338,  ...,  0.6298,  0.7107,  0.2236])\n",
      "sassy\n",
      "Saved the embedding for sassy.\n",
      "['sat', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([0.0301, 0.2771, 0.3473,  ..., 0.3134, 0.5854, 0.0025])\n",
      "sated\n",
      "Saved the embedding for sated.\n",
      "['sat', '##iated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2530,  0.7878,  0.8656,  ...,  0.5769,  0.6837, -0.2798])\n",
      "satiated\n",
      "Saved the embedding for satiated.\n",
      "['satirical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6717, -0.2548, -0.8904,  ...,  0.1273,  0.5001, -0.2333])\n",
      "satirical\n",
      "Saved the embedding for satirical.\n",
      "['satisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5781,  1.2094,  0.1975,  ..., -0.1799,  0.3277, -0.7476])\n",
      "satisfaction\n",
      "Saved the embedding for satisfaction.\n",
      "['satisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0594,  0.6780,  0.7405,  ..., -0.1439, -0.3649,  0.7161])\n",
      "satisfied\n",
      "Saved the embedding for satisfied.\n",
      "['satisfy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4176,  0.6347,  1.0847,  ..., -0.7718, -0.0649,  0.2537])\n",
      "satisfy\n",
      "Saved the embedding for satisfy.\n",
      "['saturn', '##ine'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8409,  0.8523,  0.3912,  ..., -0.0295,  0.6408, -0.1128])\n",
      "saturnine\n",
      "Saved the embedding for saturnine.\n",
      "['sa', '##uc', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5948, -0.1179,  0.8811,  ...,  0.0024,  0.6163,  0.7269])\n",
      "saucy\n",
      "Saved the embedding for saucy.\n",
      "['savage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0927,  0.1522, -0.1956,  ...,  0.3276,  0.3193,  0.6978])\n",
      "savage\n",
      "Saved the embedding for savage.\n",
      "['scandal', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2153,  0.9189,  0.3687,  ...,  0.4721,  0.8955,  0.0675])\n",
      "scandalized\n",
      "Saved the embedding for scandalized.\n",
      "['scare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0202,  0.0620, -0.5192,  ..., -0.1078,  0.1355,  0.2768])\n",
      "scare\n",
      "Saved the embedding for scare.\n",
      "['scared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0091,  0.6901, -0.8870,  ...,  0.1163,  0.0531,  0.1708])\n",
      "scared\n",
      "Saved the embedding for scared.\n",
      "['scary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0900,  0.7565,  0.7562,  ..., -0.4573,  0.1669,  0.0863])\n",
      "scary\n",
      "Saved the embedding for scary.\n",
      "['scattered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1801,  0.5962, -0.2844,  ...,  0.0252,  0.9925, -0.4390])\n",
      "scattered\n",
      "Saved the embedding for scattered.\n",
      "['sc', '##had', '##en', '##fr', '##eu', '##de'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([-0.6560,  0.2544,  0.2446,  ...,  0.1786,  0.3476,  0.2316])\n",
      "schadenfreude\n",
      "Saved the embedding for schadenfreude.\n",
      "['sc', '##hem', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3046,  0.0682,  0.5022,  ...,  0.4041,  0.3240,  0.0629])\n",
      "scheming\n",
      "Saved the embedding for scheming.\n",
      "['sc', '##off', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5491, -0.0021,  0.0015,  ...,  0.1424,  0.4965, -0.0434])\n",
      "scoffer\n",
      "Saved the embedding for scoffer.\n",
      "['sc', '##off', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5614,  0.2521,  0.2769,  ...,  0.3242,  0.2178, -0.0399])\n",
      "scoffing\n",
      "Saved the embedding for scoffing.\n",
      "['sc', '##orn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5489,  0.5375, -0.2035,  ...,  0.2795,  0.2986, -0.0180])\n",
      "scorn\n",
      "Saved the embedding for scorn.\n",
      "['sc', '##orne', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7579,  0.0484,  0.7119,  ..., -0.0206,  0.2747, -0.2406])\n",
      "scorned\n",
      "Saved the embedding for scorned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sc', '##orn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6392,  0.6409,  0.6498,  ...,  0.3199, -0.0337,  0.1653])\n",
      "scornful\n",
      "Saved the embedding for scornful.\n",
      "['scowl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4755,  1.5118, -0.2807,  ..., -0.9004,  0.5228, -0.3453])\n",
      "scowl\n",
      "Saved the embedding for scowl.\n",
      "['scowl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2111,  1.2100,  0.0470,  ..., -0.1680,  0.5137,  0.0280])\n",
      "scowling\n",
      "Saved the embedding for scowling.\n",
      "['scream'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.2164, 0.6354, 0.0186,  ..., 0.0978, 0.3162, 0.3296])\n",
      "scream\n",
      "Saved the embedding for scream.\n",
      "['screaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0957,  0.5750, -0.0155,  ...,  0.2512,  0.4541,  0.3795])\n",
      "screaming\n",
      "Saved the embedding for screaming.\n",
      "['sc', '##rut', '##ini', '##zing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2311, -0.3403,  0.0805,  ..., -0.0056,  0.4043,  0.1691])\n",
      "scrutinizing\n",
      "Saved the embedding for scrutinizing.\n",
      "['sealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4513,  0.5019,  0.2938,  ..., -0.2270,  0.5289, -0.1976])\n",
      "sealed\n",
      "Saved the embedding for sealed.\n",
      "['searching'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7860,  1.1702,  0.0878,  ...,  0.2159,  1.0637,  0.4216])\n",
      "searching\n",
      "Saved the embedding for searching.\n",
      "['secretive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3366,  1.1455, -1.4971,  ...,  0.1907,  0.6651,  0.0269])\n",
      "secretive\n",
      "Saved the embedding for secretive.\n",
      "['secretive', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0301,  1.4922, -0.5819,  ...,  0.0953,  0.0752, -0.0096])\n",
      "secretively\n",
      "Saved the embedding for secretively.\n",
      "['secure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8277,  0.6255,  0.5020,  ..., -0.1665,  0.2615,  0.0220])\n",
      "secure\n",
      "Saved the embedding for secure.\n",
      "['se', '##date'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7649, -0.3399,  0.1514,  ...,  0.3004,  0.4366,  0.5029])\n",
      "sedate\n",
      "Saved the embedding for sedate.\n",
      "['seduction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4263,  0.4638,  0.2160,  ..., -0.3900,  0.1953,  0.2731])\n",
      "seduction\n",
      "Saved the embedding for seduction.\n",
      "['seductive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3127,  0.6006,  0.5610,  ..., -0.5436, -0.0670, -0.4088])\n",
      "seductive\n",
      "Saved the embedding for seductive.\n",
      "['see', '##thing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3100,  0.5340,  0.1528,  ...,  0.4080,  0.0168,  0.2029])\n",
      "seething\n",
      "Saved the embedding for seething.\n",
      "['self'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1982,  1.0979, -0.0089,  ..., -0.2346,  0.3371, -0.4280])\n",
      "self\n",
      "Saved the embedding for self.\n",
      "['sensual'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0534,  0.2725,  0.0691,  ..., -0.3890,  0.1672,  0.0303])\n",
      "sensual\n",
      "Saved the embedding for sensual.\n",
      "['sentimental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9941,  0.8442, -0.1291,  ..., -0.3364,  0.4561, -0.0386])\n",
      "sentimental\n",
      "Saved the embedding for sentimental.\n",
      "['serene'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6001, -0.0533, -0.1156,  ...,  0.4097,  0.2343,  0.3003])\n",
      "serene\n",
      "Saved the embedding for serene.\n",
      "['serious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1324,  0.9613, -1.2295,  ..., -0.0929,  0.4054, -0.2284])\n",
      "serious\n",
      "Saved the embedding for serious.\n",
      "['seriousness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4070,  1.5144, -1.0614,  ..., -0.6231,  0.4344,  0.1764])\n",
      "seriousness\n",
      "Saved the embedding for seriousness.\n",
      "['ser', '##vil', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3080,  0.3544,  0.3684,  ..., -0.4084,  0.2503,  0.2308])\n",
      "servile\n",
      "Saved the embedding for servile.\n",
      "['set'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5316,  0.7403,  0.8258,  ...,  0.0115,  0.4237, -0.2583])\n",
      "set\n",
      "Saved the embedding for set.\n",
      "['severe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9307,  0.2335, -0.5456,  ..., -0.0104,  0.5628, -0.5393])\n",
      "severe\n",
      "Saved the embedding for severe.\n",
      "['sha', '##bby'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3127, -0.3442,  0.1189,  ..., -0.1292,  0.4009,  0.4427])\n",
      "shabby\n",
      "Saved the embedding for shabby.\n",
      "['shady'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4005,  1.1203, -0.5734,  ...,  0.3124,  0.1690, -0.3730])\n",
      "shady\n",
      "Saved the embedding for shady.\n",
      "['shaken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4667,  1.3983, -1.8086,  ..., -0.4540,  0.6556, -0.3363])\n",
      "shaken\n",
      "Saved the embedding for shaken.\n",
      "['shaky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8255, -0.0913, -0.0756,  ...,  0.2130, -0.0034,  0.0763])\n",
      "shaky\n",
      "Saved the embedding for shaky.\n",
      "['shame'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8939,  1.0805, -1.3125,  ...,  0.7667,  0.6643, -0.0202])\n",
      "shame\n",
      "Saved the embedding for shame.\n",
      "['shame', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0232,  0.2876, -0.2716,  ...,  0.4084,  0.4006, -0.0213])\n",
      "shamed\n",
      "Saved the embedding for shamed.\n",
      "['shame', '##face', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4174,  1.1807,  0.1798,  ..., -0.0349,  0.1978,  0.0846])\n",
      "shamefaced\n",
      "Saved the embedding for shamefaced.\n",
      "['shame', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0342,  1.6841, -0.6609,  ..., -0.1018,  0.1174,  0.1578])\n",
      "shameful\n",
      "Saved the embedding for shameful.\n",
      "['shame', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3683,  0.1758, -0.8254,  ...,  0.2595,  0.2359, -0.0328])\n",
      "shameless\n",
      "Saved the embedding for shameless.\n",
      "['sharp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5825,  1.2416, -1.5839,  ..., -0.2647,  0.6287,  0.0927])\n",
      "sharp\n",
      "Saved the embedding for sharp.\n",
      "['sheep', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2844,  0.9237, -0.5734,  ...,  0.7978,  0.5751, -0.4798])\n",
      "sheepish\n",
      "Saved the embedding for sheepish.\n",
      "['sheep', '##ish', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4630,  0.2449, -0.5382,  ...,  0.3755,  0.2209,  0.3853])\n",
      "sheepishness\n",
      "Saved the embedding for sheepishness.\n",
      "['shell', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1299,  0.8149, -0.3689,  ...,  0.0522,  0.1986,  0.0458])\n",
      "shelled\n",
      "Saved the embedding for shelled.\n",
      "['shift', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1311,  1.3059, -0.3165,  ...,  0.4514,  0.0287,  0.0530])\n",
      "shifty\n",
      "Saved the embedding for shifty.\n",
      "['shock'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2724,  1.3240, -1.6366,  ...,  0.4604, -0.0242, -0.3389])\n",
      "shock\n",
      "Saved the embedding for shock.\n",
      "['shocked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0801,  1.1219, -0.7102,  ...,  0.9214,  0.5007, -0.1817])\n",
      "shocked\n",
      "Saved the embedding for shocked.\n",
      "['shocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2748,  1.4235, -1.5055,  ...,  0.3556,  0.9304, -0.1396])\n",
      "shocking\n",
      "Saved the embedding for shocking.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1134,  1.5751, -0.3316,  ...,  0.5579,  0.5694, -0.3242])\n",
      "shockingly\n",
      "Saved the embedding for shockingly.\n",
      "['shook'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2943,  0.8700, -1.8979,  ...,  0.4321,  1.0311, -0.5007])\n",
      "shook\n",
      "Saved the embedding for shook.\n",
      "['shout'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2155,  0.7258,  0.0052,  ...,  0.4876,  1.2998, -0.5576])\n",
      "shout\n",
      "Saved the embedding for shout.\n",
      "['shouting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1856,  1.2181, -0.4316,  ...,  0.0904,  0.3564,  0.6262])\n",
      "shouting\n",
      "Saved the embedding for shouting.\n",
      "['sh', '##rew', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0278,  0.4411,  0.4081,  ..., -0.1615,  0.1131, -0.4956])\n",
      "shrewd\n",
      "Saved the embedding for shrewd.\n",
      "['shy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3070,  0.0893, -0.7205,  ...,  0.1124, -0.2094, -0.3293])\n",
      "shy\n",
      "Saved the embedding for shy.\n",
      "['shy', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2787,  0.3420, -0.0096,  ...,  0.0223,  0.2680, -0.1830])\n",
      "shyness\n",
      "Saved the embedding for shyness.\n",
      "['sick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6060,  1.6512, -0.6405,  ..., -0.2183,  0.8663, -0.4441])\n",
      "sick\n",
      "Saved the embedding for sick.\n",
      "['sick', '##en'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5898,  1.2971, -0.5778,  ..., -0.4339,  0.6908,  0.0609])\n",
      "sicken\n",
      "Saved the embedding for sicken.\n",
      "['sick', '##ened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3886,  0.8891,  0.4243,  ..., -0.0045,  0.1138, -0.0291])\n",
      "sickened\n",
      "Saved the embedding for sickened.\n",
      "['sigh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3352,  0.7218,  0.3585,  ..., -0.1388,  0.1952, -0.2399])\n",
      "sigh\n",
      "Saved the embedding for sigh.\n",
      "['silenced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7354,  0.2567, -1.0520,  ...,  0.3842,  1.2314, -0.6862])\n",
      "silenced\n",
      "Saved the embedding for silenced.\n",
      "['silent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4440,  0.3998, -1.0342,  ...,  0.3341,  0.4596, -1.0115])\n",
      "silent\n",
      "Saved the embedding for silent.\n",
      "['si', '##llin', '##ess'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7846,  0.2099,  0.2664,  ...,  0.2154,  0.1802,  0.8661])\n",
      "silliness\n",
      "Saved the embedding for silliness.\n",
      "['silly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3778,  0.7102, -0.9689,  ...,  0.2188,  1.2277,  0.9077])\n",
      "silly\n",
      "Saved the embedding for silly.\n",
      "['sim', '##mering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7077,  0.1266,  0.8313,  ..., -0.4357, -0.5071,  0.2757])\n",
      "simmering\n",
      "Saved the embedding for simmering.\n",
      "['sim', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.3008,  0.8295,  0.7895,  ..., -0.0679, -0.1407,  0.5240])\n",
      "simper\n",
      "Saved the embedding for simper.\n",
      "['sim', '##per', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0444,  0.6919,  0.6770,  ..., -0.2252,  0.1573,  0.5693])\n",
      "simpering\n",
      "Saved the embedding for simpering.\n",
      "['simple'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5415,  1.3699,  0.3815,  ..., -0.3215,  1.2106, -0.4687])\n",
      "simple\n",
      "Saved the embedding for simple.\n",
      "['simplicity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0574,  0.8443,  0.0648,  ..., -0.2836,  0.5678,  0.2520])\n",
      "simplicity\n",
      "Saved the embedding for simplicity.\n",
      "['sincere'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0575,  1.5139,  0.9159,  ..., -0.0789,  0.1490, -0.0539])\n",
      "sincere\n",
      "Saved the embedding for sincere.\n",
      "['sin', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5484,  0.7817,  0.4486,  ..., -0.3235,  0.1075,  0.1982])\n",
      "sinful\n",
      "Saved the embedding for sinful.\n",
      "['singing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6734,  0.2372,  0.2605,  ..., -0.1205,  0.1864,  0.2140])\n",
      "singing\n",
      "Saved the embedding for singing.\n",
      "['sinister'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1201,  0.4741,  0.1207,  ...,  0.3253,  0.4002, -0.2865])\n",
      "sinister\n",
      "Saved the embedding for sinister.\n",
      "['sinister', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5680,  0.2893,  0.8720,  ...,  0.1879,  0.3635,  0.4675])\n",
      "sinisterly\n",
      "Saved the embedding for sinisterly.\n",
      "['si', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8419,  0.4884, -0.2088,  ...,  0.4341,  0.5896,  0.4889])\n",
      "sizing\n",
      "Saved the embedding for sizing.\n",
      "['sk', '##ept', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2534, -0.0865,  0.3083,  ...,  0.3289,  0.4529,  0.5395])\n",
      "skeptic\n",
      "Saved the embedding for skeptic.\n",
      "['skeptical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6449,  1.4325, -0.5736,  ..., -0.0609,  0.1701, -0.4499])\n",
      "skeptical\n",
      "Saved the embedding for skeptical.\n",
      "['skeptical', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4590,  1.1867, -0.6959,  ...,  0.1567,  0.2061, -0.7034])\n",
      "skeptically\n",
      "Saved the embedding for skeptically.\n",
      "['skepticism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5025,  0.5344, -0.6652,  ..., -0.1049,  0.6103, -0.7726])\n",
      "skepticism\n",
      "Saved the embedding for skepticism.\n",
      "['sketch', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1005,  0.7947, -0.4616,  ...,  0.1862,  0.3491,  0.2918])\n",
      "sketchy\n",
      "Saved the embedding for sketchy.\n",
      "['ski', '##tti', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0747, -0.6865,  0.2629,  ...,  0.7281,  0.3834, -0.1524])\n",
      "skittish\n",
      "Saved the embedding for skittish.\n",
      "['slack'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5293,  0.0472, -1.5212,  ...,  0.2296,  0.2776,  0.1873])\n",
      "slack\n",
      "Saved the embedding for slack.\n",
      "['sl', '##ea', '##zy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3436, -0.4600,  0.7944,  ..., -0.2340,  0.0378,  0.4746])\n",
      "sleazy\n",
      "Saved the embedding for sleazy.\n",
      "['sleepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0691,  0.7642, -1.1614,  ..., -0.3082,  0.4656,  0.1116])\n",
      "sleepy\n",
      "Saved the embedding for sleepy.\n",
      "['slick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3836,  0.8307,  0.7957,  ..., -0.8094,  0.3783, -0.0989])\n",
      "slick\n",
      "Saved the embedding for slick.\n",
      "['slot', '##h', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3825,  1.3516,  0.6819,  ..., -0.2206,  0.5517, -0.3470])\n",
      "slothful\n",
      "Saved the embedding for slothful.\n",
      "['slow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1160,  1.1705,  0.1708,  ...,  0.0453,  0.2834, -0.0416])\n",
      "slow\n",
      "Saved the embedding for slow.\n",
      "['slug', '##gis', '##h'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1096,  0.9431, -0.1898,  ...,  0.5149,  0.5245,  0.9382])\n",
      "sluggish\n",
      "Saved the embedding for sluggish.\n",
      "['sly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1974,  0.6532, -0.0099,  ..., -0.2389,  0.2330,  0.1049])\n",
      "sly\n",
      "Saved the embedding for sly.\n",
      "['sm', '##arm', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0200, -0.0833,  0.0291,  ...,  0.3239,  0.6109,  0.3401])\n",
      "smarmy\n",
      "Saved the embedding for smarmy.\n",
      "['smart'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3544,  0.3818,  0.4900,  ...,  0.0840,  0.2420,  0.4620])\n",
      "smart\n",
      "Saved the embedding for smart.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smashed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2279,  0.5602, -0.1967,  ...,  0.1943,  1.4270, -0.0475])\n",
      "smashed\n",
      "Saved the embedding for smashed.\n",
      "['smile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2074,  0.2163,  0.1038,  ...,  0.8780,  0.2743,  0.2939])\n",
      "smile\n",
      "Saved the embedding for smile.\n",
      "['smiley'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5748, -0.6122, -0.2743,  ...,  0.4419, -0.3123,  0.1988])\n",
      "smiley\n",
      "Saved the embedding for smiley.\n",
      "['smiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4768,  0.6892, -1.1503,  ...,  0.4351,  0.4747, -0.0259])\n",
      "smiling\n",
      "Saved the embedding for smiling.\n",
      "['smirk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4651,  1.0724, -0.6079,  ..., -0.8278,  0.1095, -0.8049])\n",
      "smirk\n",
      "Saved the embedding for smirk.\n",
      "['smirk', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0554,  1.0695, -0.0592,  ..., -0.0823,  0.1118, -0.1506])\n",
      "smirking\n",
      "Saved the embedding for smirking.\n",
      "['sm', '##old', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3018,  0.0389, -0.6185,  ...,  0.7699,  0.4927,  0.4214])\n",
      "smoldering\n",
      "Saved the embedding for smoldering.\n",
      "['sm', '##oo', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6530,  0.2235,  0.3970,  ...,  0.2574,  0.2405,  0.5820])\n",
      "smooching\n",
      "Saved the embedding for smooching.\n",
      "['smooth'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5236,  0.3500, -0.7970,  ..., -0.0250,  0.7407,  0.2415])\n",
      "smooth\n",
      "Saved the embedding for smooth.\n",
      "['smug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9245,  0.3483, -0.8073,  ...,  0.2514,  0.7650, -0.3682])\n",
      "smug\n",
      "Saved the embedding for smug.\n",
      "['smug', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2336,  0.4406, -0.0535,  ...,  0.4501,  0.3389,  0.2399])\n",
      "smugness\n",
      "Saved the embedding for smugness.\n",
      "['snake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3942,  1.3468, -1.3394,  ...,  0.8017,  0.3118, -0.2506])\n",
      "snake\n",
      "Saved the embedding for snake.\n",
      "['snap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6465, -0.0421, -0.3552,  ...,  0.2332,  0.4022,  0.1762])\n",
      "snappy\n",
      "Saved the embedding for snappy.\n",
      "['s', '##nar', '##ky'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0703,  0.5704,  0.8363,  ..., -0.2027, -0.0362,  0.0310])\n",
      "snarky\n",
      "Saved the embedding for snarky.\n",
      "['snarl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0156,  1.3564,  0.5748,  ..., -0.2605,  0.4014, -0.4345])\n",
      "snarl\n",
      "Saved the embedding for snarl.\n",
      "['snarled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3424,  0.6598,  0.2144,  ...,  0.2378,  0.8277,  0.2532])\n",
      "snarled\n",
      "Saved the embedding for snarled.\n",
      "['snarl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2813,  1.0644,  0.2891,  ..., -0.2826,  0.2527, -0.1883])\n",
      "snarling\n",
      "Saved the embedding for snarling.\n",
      "['snarl', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2915,  0.8426,  0.9719,  ..., -0.1479,  0.1766, -0.0373])\n",
      "snarly\n",
      "Saved the embedding for snarly.\n",
      "['sneak', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7682,  0.2573, -0.5189,  ...,  0.6026, -0.1069,  0.2967])\n",
      "sneaky\n",
      "Saved the embedding for sneaky.\n",
      "['s', '##neer'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2776,  0.4319,  1.1295,  ..., -0.2230,  0.0176,  0.1870])\n",
      "sneer\n",
      "Saved the embedding for sneer.\n",
      "['s', '##neer', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4497,  0.8533,  0.0628,  ..., -0.0202, -0.3920,  0.4892])\n",
      "sneering\n",
      "Saved the embedding for sneering.\n",
      "['s', '##nee', '##ze'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3014,  0.1571,  0.8499,  ..., -0.1901, -0.2832,  0.0645])\n",
      "sneeze\n",
      "Saved the embedding for sneeze.\n",
      "['s', '##nee', '##zing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3598,  0.4028,  0.0557,  ..., -0.0102, -0.1090, -0.0224])\n",
      "sneezing\n",
      "Saved the embedding for sneezing.\n",
      "['s', '##nick', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3440,  0.4848,  0.5619,  ...,  0.5778, -0.0034,  0.5944])\n",
      "snicker\n",
      "Saved the embedding for snicker.\n",
      "['s', '##nick', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1320,  0.5298,  0.2029,  ..., -0.5479, -0.2039,  0.3337])\n",
      "snickering\n",
      "Saved the embedding for snickering.\n",
      "['s', '##ni', '##de'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4147,  0.5327,  0.8606,  ..., -0.1271, -0.0884,  0.6927])\n",
      "snide\n",
      "Saved the embedding for snide.\n",
      "['s', '##nig', '##ger', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5706,  0.3200,  0.2653,  ...,  0.8612, -0.7284,  0.8201])\n",
      "sniggering\n",
      "Saved the embedding for sniggering.\n",
      "['s', '##ni', '##vel', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0498,  0.8459, -0.2123,  ..., -0.1564, -0.1960, -0.0377])\n",
      "sniveling\n",
      "Saved the embedding for sniveling.\n",
      "['s', '##nob', '##bis', '##h'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1068,  0.4276,  0.1392,  ...,  0.2607,  0.0553,  0.7853])\n",
      "snobbish\n",
      "Saved the embedding for snobbish.\n",
      "['s', '##nob', '##by'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2245,  0.0566,  0.5390,  ...,  0.1276, -0.2159,  0.6945])\n",
      "snobby\n",
      "Saved the embedding for snobby.\n",
      "['s', '##no', '##ot', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0567,  0.2702,  0.1616,  ...,  0.4953,  0.1994,  0.6647])\n",
      "snooty\n",
      "Saved the embedding for snooty.\n",
      "['s', '##not', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0364,  0.6098,  0.5561,  ..., -0.0022, -0.0228,  0.4271])\n",
      "snotty\n",
      "Saved the embedding for snotty.\n",
      "['soc', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6740,  0.0497,  0.2776,  ..., -0.4421, -0.0055, -0.2629])\n",
      "sociable\n",
      "Saved the embedding for sociable.\n",
      "['soft'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7908,  0.3266, -0.5675,  ...,  0.7612,  0.4435, -0.3148])\n",
      "soft\n",
      "Saved the embedding for soft.\n",
      "['solemn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3172,  1.2928,  0.3989,  ..., -0.2196,  0.1259,  0.2410])\n",
      "solemn\n",
      "Saved the embedding for solemn.\n",
      "['sol', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0620, -0.2794,  0.6170,  ..., -0.2985, -0.2239,  0.3624])\n",
      "solicitous\n",
      "Saved the embedding for solicitous.\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Set up input and output paths.\n",
    "vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "layer_combining_function = cat_middle_four2\n",
    "embeddings_file = os.path.join('/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab', layer_combining_function.__name__ + '.txt')\n",
    "if os.path.exists(embeddings_file):\n",
    "    os.remove(embeddings_file)\n",
    "\n",
    "    # Create a list of vocabulary words we want embeddings for.\n",
    "vocab = make_vocab(vocab_file)\n",
    "\n",
    "# Tokenize the vocabulary and look up the BERT token indices.\n",
    "tokenized_text, indexed_tokens = tokenize_text(vocab)\n",
    "\n",
    "# Generate segment IDs for each token.\n",
    "segments_IDs = generate_segments_IDs(tokenized_text)\n",
    "\n",
    "# Generate and write out the contextual embeddings for the vocabulary words.\n",
    "# Embeddings are saved in a standard format that can be used for calcualting\n",
    "# the cosine distances between word vectors.\n",
    "for i in range(len(tokenized_text)):\n",
    "    # Convert indexed tokens and segments to tensors.\n",
    "    # Create a BERT model for the tokens.\n",
    "    # Get the encoded model layers and reshape them.\n",
    "    token_embeddings = generate_embeddings(indexed_tokens[i], segments_IDs[i])\n",
    "    print(f'{tokenized_text[i]} has a token embedding of size {token_embeddings.size()}')\n",
    "\n",
    "    # Extract the contextual embedding for a token.\n",
    "    contextual_embedding = layer_combining_function(token_embeddings)\n",
    "\n",
    "    # Write the embedding to a text file, with the vocabulary word prepended.\n",
    "    vocab_word = reconstruct_tokens(tokenized_text[i])\n",
    "    # Make sure we've got the correct vocabulary word.\n",
    "    assert vocab[i] == vocab_word\n",
    "    write_embedding(embeddings_file, vocab[i], contextual_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
