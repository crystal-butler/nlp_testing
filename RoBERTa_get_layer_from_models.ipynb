{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaForMaskedLM, RobertaConfig\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "# and Transformers documentation: https://huggingface.co/transformers/model_doc/roberta.html#robertaformaskedlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure we're in the transformers directory with fine-tuned model output.\n",
    "os.chdir('/home/jupyter/Notebooks/crystal/NLP/transformers/examples/')\n",
    "os.getcwd()\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_dicts_syns/')\n",
    "config = RobertaConfig.from_pretrained('./output_dicts_syns/')\n",
    "model_root_dir = './output_dicts_syns/checkpoints/'\n",
    "# model = RobertaForMaskedLM.from_pretrained('./output_CC-aef/', config=config)\n",
    "\n",
    "context_file = \"/home/jupyter/Notebooks/crystal/NLP/transformers/examples/wordnik_all.txt\"\n",
    "output_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/'\n",
    "count_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/'\n",
    "vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/data/vocab_files/FE_vocab_study.txt'\n",
    "vocab = make_vocab(vocab_file)\n",
    "\n",
    "FEATURE_COUNT = 768\n",
    "LAYER_COUNT = 13\n",
    "LAYER = 8\n",
    "MAX_LINES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-8000_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-8000_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([ 0.0286,  0.4057,  0.3317, -0.2682, -0.5567]) (768 features in tensor)\n",
      "Run time for stupefied was 2.287083222065121 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.1000, -0.0057,  0.0384,  0.2265, -0.3594]) (768 features in tensor)\n",
      "Run time for scornful was 6.120545833138749 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.0733, -0.2031,  0.1440,  0.8852, -0.0471]) (768 features in tensor)\n",
      "Run time for disbelieving was 2.0372233248781413 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.0498, -0.3801,  0.0906, -0.1741, -0.3159]) (768 features in tensor)\n",
      "Run time for disdainful was 6.014321617782116 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.1187,  0.1572,  0.0309,  0.8614, -0.8846]) (768 features in tensor)\n",
      "Run time for revolted was 3.7316922519821674 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.0665,  0.6314, -0.1081,  0.1888, -0.3037]) (768 features in tensor)\n",
      "Run time for miffed was 2.4927188479341567 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 0.0807, -0.3876, -0.1450,  0.3605, -0.0263]) (768 features in tensor)\n",
      "Run time for aghast was 5.505488887894899 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1548,  0.1701,  0.0288,  0.4013, -0.5231]) (768 features in tensor)\n",
      "Run time for incensed was 8.97352737491019 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([0.2622, 0.2001, 0.3350, 0.1263, 0.1629]) (768 features in tensor)\n",
      "Run time for dejected was 10.233194982865825 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.0637,  0.3914,  0.0066,  0.0777, -0.5000]) (768 features in tensor)\n",
      "Run time for repulsed was 4.928997620940208 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([0.0817, 0.5121, 0.0550, 0.3256, 0.6006]) (768 features in tensor)\n",
      "Run time for mournful was 12.176147813908756 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([ 2.8903e-02,  3.8069e-01,  2.7924e-04,  6.1616e-01, -3.2456e-02]) (768 features in tensor)\n",
      "Run time for displeased was 8.554423341993243 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.2798,  0.4469,  0.3636,  0.4993, -0.2916]) (768 features in tensor)\n",
      "Run time for infuriated was 3.0194423848297447 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1220,  0.2026,  0.0510, -0.3796, -0.0742]) (768 features in tensor)\n",
      "Run time for awed was 5.48616929887794 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1172,  0.2887,  0.0440,  0.5886, -0.3848]) (768 features in tensor)\n",
      "Run time for repelled was 5.239122645929456 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.0506, -0.2519,  0.2091,  0.6926, -0.2854]) (768 features in tensor)\n",
      "Run time for resentful was 5.922727379947901 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.1296, 0.2399, 0.3465, 0.7872, 0.4199]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.853425608947873 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.1465,  0.5160,  0.1434,  0.3314, -0.8329]) (768 features in tensor)\n",
      "Run time for irate was 2.98175355209969 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([ 0.0042,  0.2736,  0.2422,  0.3348, -0.0649]) (768 features in tensor)\n",
      "Run time for dismayed was 7.504901926964521 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.0316,  0.7054,  0.3493,  0.6256, -0.7863]) (768 features in tensor)\n",
      "Run time for elated was 5.925357692874968 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.1863,  0.1181,  0.1768,  0.0815, -0.4765]) (768 features in tensor)\n",
      "Run time for enraged was 10.762315856991336 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.1435, -0.3149,  0.3336,  0.8249, -0.7922]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.583483885973692 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0666,  0.1843,  0.0872,  0.3362, -0.0274]) (768 features in tensor)\n",
      "Run time for bewildered was 7.020544392056763 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.1088,  0.2665,  0.0951,  0.2122, -0.5033]) (768 features in tensor)\n",
      "Run time for astounded was 5.271520684007555 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([ 0.1090,  0.3738,  0.2118,  0.2685, -0.1733]) (768 features in tensor)\n",
      "Run time for perplexed was 9.9408843528945 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([-0.0112,  0.0149,  0.1997, -0.1440, -0.1143]) (768 features in tensor)\n",
      "Run time for appalled was 9.081909894943237 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1202, 0.2385, 0.1076, 0.5174, 0.4362]) (768 features in tensor)\n",
      "Run time for startled was 14.599041151814163 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.0366,  0.0740,  0.3483,  0.0107, -0.3805]) (768 features in tensor)\n",
      "Run time for astonished was 14.327282071113586 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0299,  0.2658,  0.1270,  0.2532, -0.1682]) (768 features in tensor)\n",
      "Run time for alarmed was 12.396405382081866 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0282, -0.1135,  0.1807, -0.3263, -0.2041]) (768 features in tensor)\n",
      "Run time for outraged was 10.49966391804628 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n",
      "Mean of 41 tensors is: tensor([ 0.0904, -0.0615,  0.2337, -0.0870, -0.1736]) (768 features in tensor)\n",
      "Run time for disgusted was 9.464625637046993 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n",
      "Mean of 100 tensors is: tensor([-0.0960,  0.0057, -0.0501,  0.5639,  0.0139]) (768 features in tensor)\n",
      "Run time for doubtful was 20.04057133407332 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n",
      "Mean of 48 tensors is: tensor([ 0.0524,  0.1014,  0.1661,  0.0569, -0.0599]) (768 features in tensor)\n",
      "Run time for dissatisfied was 8.169447237858549 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n",
      "Mean of 10 tensors is: tensor([-0.0152,  0.4110,  0.2610,  0.7907,  1.1665]) (768 features in tensor)\n",
      "Run time for saddened was 3.0900526670739055 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([-0.0069,  0.3160,  0.1768,  0.5044, -0.2821]) (768 features in tensor)\n",
      "Run time for irritated was 9.564214854966849 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n",
      "Mean of 78 tensors is: tensor([ 0.0349,  0.7922,  0.2095,  0.8020, -1.3073]) (768 features in tensor)\n",
      "Run time for amused was 17.47903013904579 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n",
      "Mean of 100 tensors is: tensor([ 0.0282, -0.0090,  0.1818,  0.6869,  0.6157]) (768 features in tensor)\n",
      "Run time for frightened was 23.83040680200793 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 48 tensors is: tensor([-0.0166,  0.4819,  0.2003,  0.0742, -0.2924]) (768 features in tensor)\n",
      "Run time for discouraged was 9.563135092146695 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([-0.0007, -0.0977,  0.2233,  0.0120,  0.1407]) (768 features in tensor)\n",
      "Run time for stunned was 9.364966409048066 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-0.1050, -0.3268,  0.0519,  0.5224,  0.8874]) (768 features in tensor)\n",
      "Run time for fearful was 20.804858966032043 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([-0.0051,  0.2121,  0.1126,  0.3770,  0.0150]) (768 features in tensor)\n",
      "Run time for pissed was 11.43406154983677 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1152, -0.2990,  0.1337,  0.4390,  0.7299]) (768 features in tensor)\n",
      "Run time for terrified was 8.978823464130983 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.1086,  0.2807,  0.0017, -0.0417, -0.8311]) (768 features in tensor)\n",
      "Run time for offended was 23.869986948091537 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.0164,  0.4480,  0.2047,  0.5881, -0.4012]) (768 features in tensor)\n",
      "Run time for annoyed was 11.58163180318661 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.0844,  0.0555,  0.1061, -0.1412,  0.3819]) (768 features in tensor)\n",
      "Run time for skeptical was 11.885165439918637 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([-0.0203,  0.1890,  0.0193, -0.3239,  0.8908]) (768 features in tensor)\n",
      "Run time for hostile was 20.24128096201457 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0201,  0.2249, -0.1214,  0.4489,  0.0809]) (768 features in tensor)\n",
      "Run time for furious was 20.099388966104016 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1189,  0.3732,  0.0939,  0.6061, -0.4999]) (768 features in tensor)\n",
      "Run time for bothered was 16.025479868985713 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.1585, 0.8271, 0.2567, 0.1057, 0.4635]) (768 features in tensor)\n",
      "Run time for joyful was 12.237358642043546 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n",
      "Mean of 100 tensors is: tensor([ 0.0173, -0.0943, -0.1553,  0.5785,  0.0654]) (768 features in tensor)\n",
      "Run time for uncertain was 21.015653883107007 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "cheerful\n",
      "Mean of 100 tensors is: tensor([ 0.1073,  0.7085,  0.1503, -0.0814,  0.5511]) (768 features in tensor)\n",
      "Run time for cheerful was 17.472147311083972 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "depressed\n",
      "Mean of 100 tensors is: tensor([0.0485, 0.4462, 0.3322, 0.2977, 0.2816]) (768 features in tensor)\n",
      "Run time for depressed was 18.602193492930382 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "anxious\n",
      "Mean of 100 tensors is: tensor([-0.0012, -0.0447,  0.0719,  0.5031,  0.2477]) (768 features in tensor)\n",
      "Run time for anxious was 20.861154789105058 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frustrated\n",
      "Mean of 81 tensors is: tensor([0.0289, 0.2177, 0.2230, 0.6199, 0.1555]) (768 features in tensor)\n",
      "Run time for frustrated was 17.319573706015944 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "distressed\n",
      "Mean of 57 tensors is: tensor([0.1521, 0.5241, 0.2848, 0.5253, 0.3632]) (768 features in tensor)\n",
      "Run time for distressed was 12.870486457832158 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bored\n",
      "Mean of 92 tensors is: tensor([-0.0942, -0.1905,  0.2437,  0.2309,  0.7282]) (768 features in tensor)\n",
      "Run time for bored was 22.253731267061085 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "suspicious\n",
      "Mean of 85 tensors is: tensor([-0.1342,  0.2278,  0.1183,  0.0658,  0.1278]) (768 features in tensor)\n",
      "Run time for suspicious was 18.55031249905005 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "shocked\n",
      "Mean of 88 tensors is: tensor([-0.0212, -0.0601,  0.1987,  0.3771, -0.0083]) (768 features in tensor)\n",
      "Run time for shocked was 20.23785607982427 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amazed\n",
      "Mean of 73 tensors is: tensor([-0.0520,  0.0652,  0.1476,  0.2411, -0.2892]) (768 features in tensor)\n",
      "Run time for amazed was 16.17469435487874 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "rejected\n",
      "Mean of 100 tensors is: tensor([-0.0041, -0.0304,  0.0187,  0.2494,  0.5423]) (768 features in tensor)\n",
      "Run time for rejected was 23.726612504106015 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disappointed\n",
      "Mean of 100 tensors is: tensor([-0.2353,  0.1291, -0.0623,  0.9915, -0.0040]) (768 features in tensor)\n",
      "Run time for disappointed was 22.97592556080781 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "upset\n",
      "Mean of 100 tensors is: tensor([-0.0487,  0.5860,  0.0056,  0.0978, -0.8370]) (768 features in tensor)\n",
      "Run time for upset was 19.819092507008463 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "delighted\n",
      "Mean of 100 tensors is: tensor([0.1783, 0.5243, 0.1116, 0.8583, 0.1560]) (768 features in tensor)\n",
      "Run time for delighted was 23.539279985940084 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "scared\n",
      "Mean of 92 tensors is: tensor([ 0.0112, -0.2593,  0.1226,  0.4482,  0.8119]) (768 features in tensor)\n",
      "Run time for scared was 23.12611456704326 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "worried\n",
      "Mean of 100 tensors is: tensor([-0.0876,  0.6394,  0.2086,  0.7194, -0.1857]) (768 features in tensor)\n",
      "Run time for worried was 22.626601380994543 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "confused\n",
      "Mean of 100 tensors is: tensor([-0.1617,  0.1768,  0.1028,  0.9193,  0.3411]) (768 features in tensor)\n",
      "Run time for confused was 19.240976949920878 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "neutral\n",
      "Mean of 100 tensors is: tensor([ 0.1605, -0.2157,  0.2417, -0.0319,  0.3853]) (768 features in tensor)\n",
      "Run time for neutral was 21.22411929280497 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "angry\n",
      "Mean of 100 tensors is: tensor([-0.1150,  0.0774, -0.1109,  0.8207,  0.1477]) (768 features in tensor)\n",
      "Run time for angry was 22.784095356008038 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "satisfied\n",
      "Mean of 100 tensors is: tensor([-0.0412, -0.0302, -0.0958,  0.2304, -0.4881]) (768 features in tensor)\n",
      "Run time for satisfied was 24.387498180847615 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "surprised\n",
      "Mean of 100 tensors is: tensor([-0.0922,  0.1730,  0.0973,  1.1477, -0.3621]) (768 features in tensor)\n",
      "Run time for surprised was 22.836017362074926 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pleased\n",
      "Mean of 100 tensors is: tensor([ 0.1423,  0.5884,  0.1298,  0.7486, -0.4405]) (768 features in tensor)\n",
      "Run time for pleased was 23.630443766945973 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "concerned\n",
      "Mean of 100 tensors is: tensor([-0.3497,  0.4892,  0.2804,  0.3350, -0.5135]) (768 features in tensor)\n",
      "Run time for concerned was 22.79176486399956 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "mad\n",
      "Mean of 100 tensors is: tensor([ 0.0280,  0.4025, -0.1641,  0.4704,  0.9365]) (768 features in tensor)\n",
      "Run time for mad was 22.574785432079807 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hurt\n",
      "Mean of 100 tensors is: tensor([ 0.1121,  0.3189, -0.1313, -0.3402,  0.1005]) (768 features in tensor)\n",
      "Run time for hurt was 22.597694827010855 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "excited\n",
      "Mean of 100 tensors is: tensor([ 0.2302,  0.5319,  0.1508,  0.2619, -0.9564]) (768 features in tensor)\n",
      "Run time for excited was 21.29604939208366 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "sad\n",
      "Mean of 100 tensors is: tensor([ 0.1284,  0.5422, -0.0842,  0.4114,  1.6424]) (768 features in tensor)\n",
      "Run time for sad was 22.68769619287923 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "interested\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([-0.2553,  0.5953,  0.1760,  1.1025, -0.7744]) (768 features in tensor)\n",
      "Run time for interested was 22.843540627975017 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "happy\n",
      "Mean of 100 tensors is: tensor([ 0.0460,  0.7747, -0.0757,  0.8351,  0.0995]) (768 features in tensor)\n",
      "Run time for happy was 23.796588724013418 seconds.\n",
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-13000_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-13000_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([ 0.0782,  0.3585,  0.1744, -0.1875, -0.4279]) (768 features in tensor)\n",
      "Run time for stupefied was 2.2603527740575373 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.1778, -0.0598, -0.0168,  0.3863, -0.2217]) (768 features in tensor)\n",
      "Run time for scornful was 6.024250604910776 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.1140, -0.1624,  0.1190,  1.0225,  0.0174]) (768 features in tensor)\n",
      "Run time for disbelieving was 1.9913567770272493 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.1208, -0.4197,  0.0783, -0.0585, -0.1592]) (768 features in tensor)\n",
      "Run time for disdainful was 5.924569599097595 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.0861,  0.1735, -0.0376,  0.8939, -0.6898]) (768 features in tensor)\n",
      "Run time for revolted was 3.6947162670549005 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.1073,  0.4969, -0.2168,  0.2921, -0.1648]) (768 features in tensor)\n",
      "Run time for miffed was 2.476976342033595 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 0.1032, -0.4319, -0.2137,  0.5243,  0.0748]) (768 features in tensor)\n",
      "Run time for aghast was 5.444462226005271 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1693,  0.1131, -0.0513,  0.4806, -0.3375]) (768 features in tensor)\n",
      "Run time for incensed was 8.715104361996055 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([0.3234, 0.1733, 0.2716, 0.2661, 0.2339]) (768 features in tensor)\n",
      "Run time for dejected was 10.046021402115002 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.1193,  0.3000, -0.0415,  0.1083, -0.3631]) (768 features in tensor)\n",
      "Run time for repulsed was 4.805986644001678 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([ 0.1649,  0.4326, -0.0380,  0.4787,  0.6833]) (768 features in tensor)\n",
      "Run time for mournful was 11.910990307107568 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([ 0.0860,  0.2848, -0.1264,  0.6807,  0.1899]) (768 features in tensor)\n",
      "Run time for displeased was 8.343492747051641 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.2794,  0.4159,  0.2950,  0.6290, -0.1403]) (768 features in tensor)\n",
      "Run time for infuriated was 2.9532236319500953 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1736,  0.2470, -0.0481, -0.3306,  0.1456]) (768 features in tensor)\n",
      "Run time for awed was 5.320618925150484 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1726,  0.1888, -0.0032,  0.5663, -0.2044]) (768 features in tensor)\n",
      "Run time for repelled was 5.179365146905184 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.0984, -0.2861,  0.0993,  0.8768, -0.0786]) (768 features in tensor)\n",
      "Run time for resentful was 5.821436860831454 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.2134, 0.1502, 0.2607, 0.9246, 0.5940]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.689549680100754 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.1786,  0.5536,  0.0799,  0.5029, -0.6311]) (768 features in tensor)\n",
      "Run time for irate was 2.9738214048556983 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([0.0449, 0.2716, 0.1491, 0.5122, 0.0748]) (768 features in tensor)\n",
      "Run time for dismayed was 7.325180111918598 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.0671,  0.6732,  0.3193,  0.6436, -0.6782]) (768 features in tensor)\n",
      "Run time for elated was 5.805828673066571 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.2030,  0.1304,  0.1455,  0.2186, -0.3215]) (768 features in tensor)\n",
      "Run time for enraged was 10.583440997870639 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.1452, -0.3759,  0.2781,  0.9482, -0.5878]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.443356739822775 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0257,  0.1958, -0.0084,  0.4056,  0.0924]) (768 features in tensor)\n",
      "Run time for bewildered was 6.875420919852331 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.0945,  0.2388, -0.0142,  0.3132, -0.3754]) (768 features in tensor)\n",
      "Run time for astounded was 5.134440837893635 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([ 0.1023,  0.3546,  0.1201,  0.2691, -0.0921]) (768 features in tensor)\n",
      "Run time for perplexed was 9.799800157081336 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([ 0.0079, -0.0658,  0.1185,  0.0349,  0.1132]) (768 features in tensor)\n",
      "Run time for appalled was 8.89894408499822 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1690, 0.1684, 0.0531, 0.5510, 0.5484]) (768 features in tensor)\n",
      "Run time for startled was 14.321236199932173 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.0729,  0.0593,  0.2578,  0.1407, -0.2468]) (768 features in tensor)\n",
      "Run time for astonished was 14.174672511173412 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0657,  0.2324,  0.0900,  0.3682, -0.0142]) (768 features in tensor)\n",
      "Run time for alarmed was 12.149900977965444 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0476, -0.1554,  0.1268, -0.1909, -0.0136]) (768 features in tensor)\n",
      "Run time for outraged was 10.21882488601841 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n",
      "Mean of 41 tensors is: tensor([ 0.1127, -0.1079,  0.1776,  0.0815,  0.0129]) (768 features in tensor)\n",
      "Run time for disgusted was 9.289862820878625 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n",
      "Mean of 100 tensors is: tensor([ 0.0037, -0.0559, -0.0058,  0.5432,  0.0481]) (768 features in tensor)\n",
      "Run time for doubtful was 19.489753050962463 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n",
      "Mean of 48 tensors is: tensor([0.1462, 0.0249, 0.0938, 0.1425, 0.1074]) (768 features in tensor)\n",
      "Run time for dissatisfied was 7.969863062025979 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n",
      "Mean of 10 tensors is: tensor([0.0107, 0.3804, 0.1404, 0.8338, 1.2740]) (768 features in tensor)\n",
      "Run time for saddened was 3.0535045738797635 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([ 0.0377,  0.3017,  0.0887,  0.5474, -0.1334]) (768 features in tensor)\n",
      "Run time for irritated was 9.44190426892601 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n",
      "Mean of 78 tensors is: tensor([ 0.0463,  0.7701,  0.1423,  0.9165, -1.1295]) (768 features in tensor)\n",
      "Run time for amused was 17.21843685512431 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([ 0.1238, -0.0583,  0.1403,  0.7902,  0.7318]) (768 features in tensor)\n",
      "Run time for frightened was 23.18917155591771 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n",
      "Mean of 48 tensors is: tensor([ 0.0422,  0.5148,  0.1926,  0.1690, -0.1525]) (768 features in tensor)\n",
      "Run time for discouraged was 9.370184995932505 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([ 0.0222, -0.1125,  0.1485,  0.1060,  0.2834]) (768 features in tensor)\n",
      "Run time for stunned was 9.186306765070185 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-5.0485e-04, -3.1465e-01,  5.0452e-02,  6.2283e-01,  9.8123e-01]) (768 features in tensor)\n",
      "Run time for fearful was 20.43459877022542 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([0.0522, 0.1563, 0.0843, 0.5140, 0.1329]) (768 features in tensor)\n",
      "Run time for pissed was 11.144503396004438 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1942, -0.3232,  0.0969,  0.4958,  0.8321]) (768 features in tensor)\n",
      "Run time for terrified was 8.70573003985919 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.0385,  0.1813, -0.0242,  0.0062, -0.6677]) (768 features in tensor)\n",
      "Run time for offended was 23.56582118314691 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.0807,  0.4253,  0.1305,  0.6947, -0.2680]) (768 features in tensor)\n",
      "Run time for annoyed was 11.363570311106741 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.0352,  0.0058,  0.0583, -0.0046,  0.5100]) (768 features in tensor)\n",
      "Run time for skeptical was 11.741868074983358 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([ 0.0406,  0.1628, -0.0211, -0.2013,  0.8841]) (768 features in tensor)\n",
      "Run time for hostile was 19.943531746044755 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0889,  0.2357, -0.1642,  0.5935,  0.1817]) (768 features in tensor)\n",
      "Run time for furious was 19.84317419794388 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1666,  0.3700,  0.0388,  0.6942, -0.4188]) (768 features in tensor)\n",
      "Run time for bothered was 15.728347292169929 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.1687, 0.7672, 0.1957, 0.1170, 0.5762]) (768 features in tensor)\n",
      "Run time for joyful was 12.095814526081085 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n",
      "Mean of 100 tensors is: tensor([ 0.0805, -0.0986, -0.1135,  0.5555,  0.1796]) (768 features in tensor)\n",
      "Run time for uncertain was 20.57571199396625 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "cheerful\n",
      "Mean of 100 tensors is: tensor([ 0.1253,  0.6397,  0.1166, -0.0362,  0.6501]) (768 features in tensor)\n",
      "Run time for cheerful was 17.05766766308807 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "depressed\n",
      "Mean of 100 tensors is: tensor([0.1193, 0.4028, 0.3043, 0.3625, 0.4174]) (768 features in tensor)\n",
      "Run time for depressed was 18.360480474075302 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "anxious\n",
      "Mean of 100 tensors is: tensor([ 0.0471, -0.0930,  0.0532,  0.6253,  0.3723]) (768 features in tensor)\n",
      "Run time for anxious was 20.450777825899422 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frustrated\n",
      "Mean of 81 tensors is: tensor([0.0452, 0.2300, 0.1504, 0.7185, 0.2960]) (768 features in tensor)\n",
      "Run time for frustrated was 17.12585042300634 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "distressed\n",
      "Mean of 57 tensors is: tensor([0.2151, 0.4986, 0.2235, 0.5177, 0.4827]) (768 features in tensor)\n",
      "Run time for distressed was 12.646496165776625 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bored\n",
      "Mean of 92 tensors is: tensor([-0.0086, -0.1920,  0.1830,  0.3818,  0.9051]) (768 features in tensor)\n",
      "Run time for bored was 21.781366819050163 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "suspicious\n",
      "Mean of 85 tensors is: tensor([-0.0742,  0.1740,  0.1184,  0.1514,  0.1926]) (768 features in tensor)\n",
      "Run time for suspicious was 18.319310115883127 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "shocked\n",
      "Mean of 88 tensors is: tensor([ 0.0019, -0.0854,  0.1770,  0.5357,  0.1456]) (768 features in tensor)\n",
      "Run time for shocked was 20.001134399091825 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amazed\n",
      "Mean of 73 tensors is: tensor([-0.0240,  0.0910,  0.0647,  0.3789, -0.0692]) (768 features in tensor)\n",
      "Run time for amazed was 15.952547184191644 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "rejected\n",
      "Mean of 100 tensors is: tensor([ 0.0565, -0.0644,  0.0323,  0.2221,  0.6319]) (768 features in tensor)\n",
      "Run time for rejected was 23.73634435911663 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disappointed\n",
      "Mean of 100 tensors is: tensor([-0.1576,  0.1122, -0.1177,  1.0559,  0.1809]) (768 features in tensor)\n",
      "Run time for disappointed was 22.707658930914477 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "upset\n",
      "Mean of 100 tensors is: tensor([ 0.0406,  0.5194,  0.0352,  0.2581, -0.7290]) (768 features in tensor)\n",
      "Run time for upset was 19.485063392901793 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "delighted\n",
      "Mean of 100 tensors is: tensor([0.1893, 0.4668, 0.0534, 0.9315, 0.3033]) (768 features in tensor)\n",
      "Run time for delighted was 23.346689188154414 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "scared\n",
      "Mean of 92 tensors is: tensor([ 0.0834, -0.2502,  0.0928,  0.5760,  0.9417]) (768 features in tensor)\n",
      "Run time for scared was 22.856831001816317 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "worried\n",
      "Mean of 100 tensors is: tensor([-0.0689,  0.5957,  0.1993,  0.7833, -0.0127]) (768 features in tensor)\n",
      "Run time for worried was 22.27741234889254 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "confused\n",
      "Mean of 100 tensors is: tensor([-0.0692,  0.2391,  0.1419,  0.9433,  0.3582]) (768 features in tensor)\n",
      "Run time for confused was 19.089272391982377 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "neutral\n",
      "Mean of 100 tensors is: tensor([ 0.1648, -0.1698,  0.3274,  0.0336,  0.4246]) (768 features in tensor)\n",
      "Run time for neutral was 20.778788015944883 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "angry\n",
      "Mean of 100 tensors is: tensor([-0.0583,  0.0274, -0.1335,  0.9126,  0.2838]) (768 features in tensor)\n",
      "Run time for angry was 22.60758927394636 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "satisfied\n",
      "Mean of 100 tensors is: tensor([-0.0079, -0.1043, -0.1231,  0.2437, -0.2943]) (768 features in tensor)\n",
      "Run time for satisfied was 23.893195477081463 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "surprised\n",
      "Mean of 100 tensors is: tensor([-0.0340,  0.1739,  0.0965,  1.2337, -0.2611]) (768 features in tensor)\n",
      "Run time for surprised was 22.368165760999545 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pleased\n",
      "Mean of 100 tensors is: tensor([ 0.2026,  0.5194,  0.0712,  0.7598, -0.2829]) (768 features in tensor)\n",
      "Run time for pleased was 23.204158269800246 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "concerned\n",
      "Mean of 100 tensors is: tensor([-0.2724,  0.4631,  0.2983,  0.4334, -0.3156]) (768 features in tensor)\n",
      "Run time for concerned was 22.75312207103707 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "mad\n",
      "Mean of 100 tensors is: tensor([ 0.0634,  0.4550, -0.1689,  0.5418,  0.9459]) (768 features in tensor)\n",
      "Run time for mad was 22.50312895490788 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hurt\n",
      "Mean of 100 tensors is: tensor([ 0.2040,  0.2940, -0.1263, -0.2658,  0.1457]) (768 features in tensor)\n",
      "Run time for hurt was 22.51292224507779 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "excited\n",
      "Mean of 100 tensors is: tensor([ 0.2554,  0.5001,  0.1280,  0.3890, -0.8213]) (768 features in tensor)\n",
      "Run time for excited was 20.963706569978967 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "sad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([ 0.2210,  0.5187, -0.0539,  0.5226,  1.6484]) (768 features in tensor)\n",
      "Run time for sad was 22.41531874286011 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "interested\n",
      "Mean of 100 tensors is: tensor([-0.1883,  0.5684,  0.0757,  1.1391, -0.5323]) (768 features in tensor)\n",
      "Run time for interested was 22.667293190956116 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "happy\n",
      "Mean of 100 tensors is: tensor([ 0.0862,  0.6915, -0.0519,  0.8578,  0.2617]) (768 features in tensor)\n",
      "Run time for happy was 23.773356503108516 seconds.\n",
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-3000_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-3000_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([-0.0759,  0.4591,  0.2879, -0.2053, -0.3999]) (768 features in tensor)\n",
      "Run time for stupefied was 2.3038990111090243 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.1526,  0.0655,  0.0609,  0.2407, -0.0692]) (768 features in tensor)\n",
      "Run time for scornful was 5.8864526599645615 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.0559, -0.1380,  0.2403,  0.9764,  0.1028]) (768 features in tensor)\n",
      "Run time for disbelieving was 2.0140157269779593 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.1756, -0.2447,  0.1290, -0.0351, -0.1277]) (768 features in tensor)\n",
      "Run time for disdainful was 5.890684186946601 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.1048,  0.2170,  0.1526,  0.8423, -0.6744]) (768 features in tensor)\n",
      "Run time for revolted was 3.63792769680731 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.0555,  0.6537,  0.0510,  0.3483, -0.1333]) (768 features in tensor)\n",
      "Run time for miffed was 2.4569999990053475 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 0.0261, -0.2216, -0.0068,  0.4337,  0.1538]) (768 features in tensor)\n",
      "Run time for aghast was 5.345110117923468 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1547,  0.2500,  0.1534,  0.4282, -0.3382]) (768 features in tensor)\n",
      "Run time for incensed was 8.59392039407976 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([0.2588, 0.2195, 0.4225, 0.1519, 0.2291]) (768 features in tensor)\n",
      "Run time for dejected was 10.029112260090187 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.0509,  0.4086,  0.1980,  0.1415, -0.4382]) (768 features in tensor)\n",
      "Run time for repulsed was 4.726781678153202 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([0.1292, 0.5934, 0.0686, 0.2678, 0.6936]) (768 features in tensor)\n",
      "Run time for mournful was 11.874624638119712 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([0.1097, 0.4142, 0.1742, 0.8449, 0.1564]) (768 features in tensor)\n",
      "Run time for displeased was 8.212690114974976 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.2717,  0.5916,  0.4131,  0.6353, -0.0726]) (768 features in tensor)\n",
      "Run time for infuriated was 2.9477080809883773 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1748,  0.2653,  0.1814, -0.3775,  0.0804]) (768 features in tensor)\n",
      "Run time for awed was 5.270996256964281 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1772,  0.3404,  0.1690,  0.6140, -0.3563]) (768 features in tensor)\n",
      "Run time for repelled was 5.070615184027702 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.0230, -0.1810,  0.2026,  0.7359, -0.0309]) (768 features in tensor)\n",
      "Run time for resentful was 5.7777218469418585 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.1551, 0.2932, 0.3798, 0.7567, 0.6287]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.784823606954888 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.1066,  0.6356,  0.2327,  0.4731, -0.5687]) (768 features in tensor)\n",
      "Run time for irate was 2.911952876020223 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([0.0638, 0.3940, 0.3055, 0.5666, 0.1462]) (768 features in tensor)\n",
      "Run time for dismayed was 7.240446309093386 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.1304,  0.7361,  0.4721,  0.6202, -0.4919]) (768 features in tensor)\n",
      "Run time for elated was 5.800436634803191 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.1898,  0.1982,  0.2191,  0.1734, -0.2772]) (768 features in tensor)\n",
      "Run time for enraged was 10.348006661981344 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.1462, -0.1619,  0.4199,  0.8501, -0.6240]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.394920230843127 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0906,  0.2935,  0.1982,  0.3015,  0.1786]) (768 features in tensor)\n",
      "Run time for bewildered was 6.837876413948834 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.1614,  0.3826,  0.2042,  0.2322, -0.3147]) (768 features in tensor)\n",
      "Run time for astounded was 5.158786691026762 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([0.0766, 0.4479, 0.2930, 0.3490, 0.0305]) (768 features in tensor)\n",
      "Run time for perplexed was 9.647901281015947 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([0.0572, 0.1196, 0.2891, 0.1276, 0.0514]) (768 features in tensor)\n",
      "Run time for appalled was 8.808648410951719 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1495, 0.2878, 0.2051, 0.4637, 0.5805]) (768 features in tensor)\n",
      "Run time for startled was 14.12966366787441 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.1173,  0.1731,  0.4129, -0.0312, -0.2167]) (768 features in tensor)\n",
      "Run time for astonished was 13.910794069059193 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0735,  0.3651,  0.2346,  0.2179, -0.0049]) (768 features in tensor)\n",
      "Run time for alarmed was 12.081665989942849 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0362,  0.0026,  0.2765, -0.2482, -0.0522]) (768 features in tensor)\n",
      "Run time for outraged was 10.300423564156517 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n",
      "Mean of 41 tensors is: tensor([ 0.1444, -0.0500,  0.3067, -0.0242, -0.0162]) (768 features in tensor)\n",
      "Run time for disgusted was 9.296203739009798 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n",
      "Mean of 100 tensors is: tensor([-0.0098,  0.0176, -0.0116,  0.4693,  0.1553]) (768 features in tensor)\n",
      "Run time for doubtful was 19.327190713956952 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n",
      "Mean of 48 tensors is: tensor([0.1488, 0.1624, 0.2786, 0.0512, 0.1055]) (768 features in tensor)\n",
      "Run time for dissatisfied was 7.924309951020405 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n",
      "Mean of 10 tensors is: tensor([-0.0049,  0.5280,  0.3116,  0.7599,  1.2639]) (768 features in tensor)\n",
      "Run time for saddened was 2.975355056114495 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([ 0.0241,  0.4981,  0.2559,  0.4839, -0.1634]) (768 features in tensor)\n",
      "Run time for irritated was 9.35307224909775 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 78 tensors is: tensor([ 0.1028,  0.9194,  0.2861,  0.7786, -1.1144]) (768 features in tensor)\n",
      "Run time for amused was 17.16114662005566 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n",
      "Mean of 100 tensors is: tensor([0.0860, 0.0842, 0.2368, 0.7494, 0.8256]) (768 features in tensor)\n",
      "Run time for frightened was 22.833268352085724 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n",
      "Mean of 48 tensors is: tensor([ 0.0415,  0.5877,  0.2832,  0.1234, -0.1294]) (768 features in tensor)\n",
      "Run time for discouraged was 9.240798650076613 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([0.0302, 0.0206, 0.2936, 0.0159, 0.4146]) (768 features in tensor)\n",
      "Run time for stunned was 9.04932796698995 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-0.0258, -0.2482,  0.0819,  0.5732,  1.1029]) (768 features in tensor)\n",
      "Run time for fearful was 20.205731589114293 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([0.0335, 0.3084, 0.1871, 0.4691, 0.1279]) (768 features in tensor)\n",
      "Run time for pissed was 11.138336756033823 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1926, -0.2071,  0.1919,  0.4495,  0.8836]) (768 features in tensor)\n",
      "Run time for terrified was 8.56081856880337 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.0555,  0.3109,  0.1444,  0.0065, -0.6614]) (768 features in tensor)\n",
      "Run time for offended was 23.368923587026075 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.0639,  0.5424,  0.3087,  0.5621, -0.2884]) (768 features in tensor)\n",
      "Run time for annoyed was 11.27238384494558 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.0188,  0.1625,  0.1938, -0.1293,  0.4744]) (768 features in tensor)\n",
      "Run time for skeptical was 11.732405015965924 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([ 0.0278,  0.2002,  0.0495, -0.1218,  0.9684]) (768 features in tensor)\n",
      "Run time for hostile was 19.726137538906187 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0426,  0.3348, -0.1327,  0.4313,  0.2595]) (768 features in tensor)\n",
      "Run time for furious was 19.496693732915446 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1969,  0.5102,  0.1898,  0.6058, -0.2945]) (768 features in tensor)\n",
      "Run time for bothered was 15.577969627920538 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.1832, 1.0257, 0.3051, 0.0810, 0.5791]) (768 features in tensor)\n",
      "Run time for joyful was 12.03438016306609 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n",
      "Mean of 100 tensors is: tensor([ 0.0942,  0.0715, -0.1017,  0.3934,  0.1527]) (768 features in tensor)\n",
      "Run time for uncertain was 20.324923474807292 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "cheerful\n",
      "Mean of 100 tensors is: tensor([ 0.1725,  0.8013,  0.2348, -0.1336,  0.6475]) (768 features in tensor)\n",
      "Run time for cheerful was 16.98947778204456 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "depressed\n",
      "Mean of 100 tensors is: tensor([0.1129, 0.5276, 0.3762, 0.1824, 0.3843]) (768 features in tensor)\n",
      "Run time for depressed was 18.00435085594654 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "anxious\n",
      "Mean of 100 tensors is: tensor([0.0208, 0.0546, 0.2105, 0.4557, 0.3330]) (768 features in tensor)\n",
      "Run time for anxious was 20.237529434030876 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frustrated\n",
      "Mean of 81 tensors is: tensor([-0.0101,  0.4307,  0.2829,  0.6144,  0.3006]) (768 features in tensor)\n",
      "Run time for frustrated was 16.926597496960312 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "distressed\n",
      "Mean of 57 tensors is: tensor([0.1731, 0.5424, 0.3519, 0.3843, 0.5074]) (768 features in tensor)\n",
      "Run time for distressed was 12.50901308003813 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bored\n",
      "Mean of 92 tensors is: tensor([-0.0468, -0.1018,  0.3370,  0.2736,  0.8671]) (768 features in tensor)\n",
      "Run time for bored was 21.55446454300545 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "suspicious\n",
      "Mean of 85 tensors is: tensor([-0.0731,  0.3248,  0.2104, -0.0193,  0.2194]) (768 features in tensor)\n",
      "Run time for suspicious was 18.194305686978623 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "shocked\n",
      "Mean of 88 tensors is: tensor([ 0.0248, -0.0072,  0.3130,  0.4399,  0.2181]) (768 features in tensor)\n",
      "Run time for shocked was 19.806883736979216 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amazed\n",
      "Mean of 73 tensors is: tensor([ 0.0163,  0.2132,  0.2331,  0.2642, -0.1201]) (768 features in tensor)\n",
      "Run time for amazed was 15.654766179155558 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "rejected\n",
      "Mean of 100 tensors is: tensor([ 0.0255, -0.1117,  0.1327,  0.2639,  0.5582]) (768 features in tensor)\n",
      "Run time for rejected was 23.377548980992287 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disappointed\n",
      "Mean of 100 tensors is: tensor([-0.1574,  0.1978,  0.1036,  0.9676,  0.1915]) (768 features in tensor)\n",
      "Run time for disappointed was 22.440731804119423 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "upset\n",
      "Mean of 100 tensors is: tensor([-0.0023,  0.5791,  0.1015,  0.2672, -0.7572]) (768 features in tensor)\n",
      "Run time for upset was 19.2762509919703 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "delighted\n",
      "Mean of 100 tensors is: tensor([0.2474, 0.6462, 0.2299, 0.8756, 0.4002]) (768 features in tensor)\n",
      "Run time for delighted was 22.9135074140504 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "scared\n",
      "Mean of 92 tensors is: tensor([ 0.0898, -0.1500,  0.2208,  0.4950,  0.8517]) (768 features in tensor)\n",
      "Run time for scared was 22.6362519080285 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "worried\n",
      "Mean of 100 tensors is: tensor([-0.0769,  0.6697,  0.2951,  0.7555, -0.0657]) (768 features in tensor)\n",
      "Run time for worried was 22.262060595909134 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "confused\n",
      "Mean of 100 tensors is: tensor([-0.1598,  0.2691,  0.1523,  0.8704,  0.2827]) (768 features in tensor)\n",
      "Run time for confused was 18.79251390788704 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "neutral\n",
      "Mean of 100 tensors is: tensor([ 0.1470, -0.2052,  0.3688, -0.0386,  0.3952]) (768 features in tensor)\n",
      "Run time for neutral was 20.537819389952347 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "angry\n",
      "Mean of 100 tensors is: tensor([-0.1196,  0.1533, -0.0302,  0.8647,  0.3123]) (768 features in tensor)\n",
      "Run time for angry was 22.3110837591812 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "satisfied\n",
      "Mean of 100 tensors is: tensor([ 0.0429,  0.0611,  0.0445,  0.3200, -0.4327]) (768 features in tensor)\n",
      "Run time for satisfied was 23.719939057016745 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "surprised\n",
      "Mean of 100 tensors is: tensor([-0.0043,  0.2511,  0.2267,  1.1213, -0.2171]) (768 features in tensor)\n",
      "Run time for surprised was 22.15299462294206 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pleased\n",
      "Mean of 100 tensors is: tensor([ 0.2502,  0.7259,  0.2707,  0.8705, -0.2347]) (768 features in tensor)\n",
      "Run time for pleased was 22.952595649985597 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "concerned\n",
      "Mean of 100 tensors is: tensor([-0.2923,  0.5091,  0.4314,  0.3393, -0.3935]) (768 features in tensor)\n",
      "Run time for concerned was 22.61851641186513 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "mad\n",
      "Mean of 100 tensors is: tensor([ 0.0389,  0.4539, -0.1761,  0.3794,  0.9742]) (768 features in tensor)\n",
      "Run time for mad was 22.240578525001183 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hurt\n",
      "Mean of 100 tensors is: tensor([ 0.1722,  0.3606, -0.0424, -0.3038,  0.1094]) (768 features in tensor)\n",
      "Run time for hurt was 22.460104200057685 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "excited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([ 0.3192,  0.6537,  0.2667,  0.2859, -0.7013]) (768 features in tensor)\n",
      "Run time for excited was 20.97781352396123 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "sad\n",
      "Mean of 100 tensors is: tensor([ 1.5201e-01,  6.7466e-01, -1.2655e-03,  2.9569e-01,  1.8363e+00]) (768 features in tensor)\n",
      "Run time for sad was 22.245700109982863 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "interested\n",
      "Mean of 100 tensors is: tensor([-0.1539,  0.5669,  0.2446,  1.1610, -0.5837]) (768 features in tensor)\n",
      "Run time for interested was 22.614367722999305 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "happy\n",
      "Mean of 100 tensors is: tensor([0.0800, 0.7872, 0.0525, 0.9568, 0.2843]) (768 features in tensor)\n",
      "Run time for happy was 23.475734634092078 seconds.\n",
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-12500_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-12500_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([ 0.0181,  0.3513,  0.1294, -0.2634, -0.4869]) (768 features in tensor)\n",
      "Run time for stupefied was 2.2958040691446513 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.1561, -0.0413, -0.0474,  0.3584, -0.2919]) (768 features in tensor)\n",
      "Run time for scornful was 5.8774463690351695 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.0828, -0.1410,  0.0982,  1.0036, -0.0327]) (768 features in tensor)\n",
      "Run time for disbelieving was 2.003380445064977 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.1019, -0.3961,  0.0266, -0.0825, -0.2121]) (768 features in tensor)\n",
      "Run time for disdainful was 5.8435931850690395 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.0638,  0.2171, -0.0612,  0.8645, -0.7999]) (768 features in tensor)\n",
      "Run time for revolted was 3.6658586661797017 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.0509,  0.5219, -0.2594,  0.2629, -0.2521]) (768 features in tensor)\n",
      "Run time for miffed was 2.4528998869936913 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 0.0775, -0.3760, -0.2665,  0.4559,  0.0009]) (768 features in tensor)\n",
      "Run time for aghast was 5.347884479211643 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1240,  0.1479, -0.0632,  0.4553, -0.4244]) (768 features in tensor)\n",
      "Run time for incensed was 8.670529742958024 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([0.2832, 0.1453, 0.2582, 0.2213, 0.2221]) (768 features in tensor)\n",
      "Run time for dejected was 10.055043681059033 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.0898,  0.3318, -0.0988,  0.0773, -0.4239]) (768 features in tensor)\n",
      "Run time for repulsed was 4.821763162035495 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([ 0.1172,  0.4311, -0.0660,  0.4027,  0.6561]) (768 features in tensor)\n",
      "Run time for mournful was 11.782407008111477 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([ 0.0322,  0.3075, -0.1310,  0.6706,  0.1125]) (768 features in tensor)\n",
      "Run time for displeased was 8.269022522959858 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.2672,  0.3999,  0.2913,  0.5650, -0.1849]) (768 features in tensor)\n",
      "Run time for infuriated was 2.920189496828243 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1338,  0.2722, -0.0511, -0.3736,  0.0632]) (768 features in tensor)\n",
      "Run time for awed was 5.295210665091872 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1098,  0.2178, -0.0469,  0.5395, -0.2842]) (768 features in tensor)\n",
      "Run time for repelled was 5.0180400928948075 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.0725, -0.2820,  0.0788,  0.8065, -0.1156]) (768 features in tensor)\n",
      "Run time for resentful was 5.738270236179233 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.1635, 0.1376, 0.2457, 0.8628, 0.6034]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.647575420094654 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.1574,  0.5562,  0.0657,  0.4744, -0.6796]) (768 features in tensor)\n",
      "Run time for irate was 2.9203547111246735 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([0.0146, 0.2656, 0.1316, 0.4542, 0.0461]) (768 features in tensor)\n",
      "Run time for dismayed was 7.241165537852794 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.0462,  0.6576,  0.2891,  0.5957, -0.7187]) (768 features in tensor)\n",
      "Run time for elated was 5.874012222047895 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.1641,  0.1132,  0.1444,  0.1567, -0.3536]) (768 features in tensor)\n",
      "Run time for enraged was 10.502173125976697 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.1157, -0.3837,  0.2444,  0.9216, -0.6551]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.4392078288365155 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0683,  0.2231, -0.0090,  0.3234,  0.0380]) (768 features in tensor)\n",
      "Run time for bewildered was 6.817673959070817 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.0667,  0.2625, -0.0436,  0.2561, -0.4580]) (768 features in tensor)\n",
      "Run time for astounded was 5.161685841158032 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([ 0.0694,  0.3649,  0.1084,  0.1922, -0.1414]) (768 features in tensor)\n",
      "Run time for perplexed was 9.61523678805679 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([-0.0130, -0.0599,  0.1006, -0.0295,  0.0573]) (768 features in tensor)\n",
      "Run time for appalled was 8.820006165187806 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1252, 0.1858, 0.0449, 0.5115, 0.5118]) (768 features in tensor)\n",
      "Run time for startled was 14.189913711044937 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.0315,  0.0548,  0.2311,  0.0695, -0.3068]) (768 features in tensor)\n",
      "Run time for astonished was 13.876668846933171 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0317,  0.2247,  0.0765,  0.3145, -0.0148]) (768 features in tensor)\n",
      "Run time for alarmed was 12.082081882981583 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0217, -0.1420,  0.1113, -0.2564, -0.0500]) (768 features in tensor)\n",
      "Run time for outraged was 10.327696650056168 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n",
      "Mean of 41 tensors is: tensor([ 0.0876, -0.0858,  0.1560,  0.0176, -0.0196]) (768 features in tensor)\n",
      "Run time for disgusted was 9.291118279099464 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n",
      "Mean of 100 tensors is: tensor([-0.0429, -0.0533, -0.0361,  0.5435, -0.0082]) (768 features in tensor)\n",
      "Run time for doubtful was 19.392212518956512 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n",
      "Mean of 48 tensors is: tensor([0.1206, 0.0072, 0.0904, 0.0962, 0.0992]) (768 features in tensor)\n",
      "Run time for dissatisfied was 7.957901353947818 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 10 tensors is: tensor([0.0019, 0.4117, 0.1222, 0.7782, 1.2577]) (768 features in tensor)\n",
      "Run time for saddened was 3.021476437104866 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([-0.0080,  0.2759,  0.0990,  0.4889, -0.1504]) (768 features in tensor)\n",
      "Run time for irritated was 9.359260830795392 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n",
      "Mean of 78 tensors is: tensor([ 0.0219,  0.8100,  0.1237,  0.8607, -1.2043]) (768 features in tensor)\n",
      "Run time for amused was 17.160289788851514 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n",
      "Mean of 100 tensors is: tensor([ 0.0871, -0.0551,  0.1181,  0.7638,  0.6898]) (768 features in tensor)\n",
      "Run time for frightened was 22.954135129926726 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n",
      "Mean of 48 tensors is: tensor([ 0.0114,  0.5307,  0.1891,  0.1344, -0.1548]) (768 features in tensor)\n",
      "Run time for discouraged was 9.299314436037093 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([-0.0078, -0.0940,  0.1283,  0.0558,  0.2609]) (768 features in tensor)\n",
      "Run time for stunned was 9.052857732167467 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-0.0365, -0.3026,  0.0369,  0.5813,  0.9203]) (768 features in tensor)\n",
      "Run time for fearful was 20.298911547055468 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([0.0018, 0.1686, 0.0584, 0.4821, 0.0821]) (768 features in tensor)\n",
      "Run time for pissed was 11.091163026168942 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1476, -0.2981,  0.0809,  0.4475,  0.8028]) (768 features in tensor)\n",
      "Run time for terrified was 8.662076467182487 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.0926,  0.1998, -0.0331, -0.0440, -0.7538]) (768 features in tensor)\n",
      "Run time for offended was 23.38457098393701 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.0387,  0.4008,  0.1331,  0.6561, -0.3038]) (768 features in tensor)\n",
      "Run time for annoyed was 11.209929041098803 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.0772,  0.0324,  0.0394, -0.0301,  0.4670]) (768 features in tensor)\n",
      "Run time for skeptical was 11.638840310974047 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([-7.8468e-04,  2.2025e-01, -3.5169e-02, -2.7033e-01,  8.6376e-01]) (768 features in tensor)\n",
      "Run time for hostile was 19.752129927976057 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0637,  0.2597, -0.1742,  0.5070,  0.1722]) (768 features in tensor)\n",
      "Run time for furious was 19.596881018020213 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1469,  0.3879, -0.0039,  0.6582, -0.4492]) (768 features in tensor)\n",
      "Run time for bothered was 15.626803849125281 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.1549, 0.7890, 0.1846, 0.0411, 0.5479]) (768 features in tensor)\n",
      "Run time for joyful was 11.936865619150922 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n",
      "Mean of 100 tensors is: tensor([ 0.0434, -0.0901, -0.1367,  0.5632,  0.1283]) (768 features in tensor)\n",
      "Run time for uncertain was 20.34616545191966 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "cheerful\n",
      "Mean of 100 tensors is: tensor([ 0.1144,  0.6792,  0.1357, -0.1063,  0.6453]) (768 features in tensor)\n",
      "Run time for cheerful was 16.970674104057252 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "depressed\n",
      "Mean of 100 tensors is: tensor([0.0687, 0.3731, 0.2934, 0.2917, 0.4219]) (768 features in tensor)\n",
      "Run time for depressed was 18.04350894014351 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "anxious\n",
      "Mean of 100 tensors is: tensor([ 0.0108, -0.0991,  0.0450,  0.5794,  0.3479]) (768 features in tensor)\n",
      "Run time for anxious was 20.238633567932993 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frustrated\n",
      "Mean of 81 tensors is: tensor([0.0048, 0.2264, 0.1552, 0.6612, 0.2844]) (768 features in tensor)\n",
      "Run time for frustrated was 16.95924951112829 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "distressed\n",
      "Mean of 57 tensors is: tensor([0.1587, 0.5030, 0.2218, 0.4810, 0.4419]) (768 features in tensor)\n",
      "Run time for distressed was 12.501341992989182 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bored\n",
      "Mean of 92 tensors is: tensor([-0.0487, -0.1884,  0.1669,  0.3392,  0.8863]) (768 features in tensor)\n",
      "Run time for bored was 21.501699250889942 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "suspicious\n",
      "Mean of 85 tensors is: tensor([-0.1068,  0.1784,  0.1054,  0.1205,  0.1760]) (768 features in tensor)\n",
      "Run time for suspicious was 18.164749999996275 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "shocked\n",
      "Mean of 88 tensors is: tensor([-0.0338, -0.0586,  0.1396,  0.4819,  0.1061]) (768 features in tensor)\n",
      "Run time for shocked was 19.85797305800952 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amazed\n",
      "Mean of 73 tensors is: tensor([-0.0575,  0.0818,  0.0440,  0.3241, -0.1093]) (768 features in tensor)\n",
      "Run time for amazed was 15.662366044009104 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "rejected\n",
      "Mean of 100 tensors is: tensor([ 0.0344, -0.0376, -0.0023,  0.2122,  0.5973]) (768 features in tensor)\n",
      "Run time for rejected was 23.280451357131824 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disappointed\n",
      "Mean of 100 tensors is: tensor([-0.2029,  0.1188, -0.1358,  1.0344,  0.1475]) (768 features in tensor)\n",
      "Run time for disappointed was 22.449152250075713 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "upset\n",
      "Mean of 100 tensors is: tensor([-0.0299,  0.5024,  0.0159,  0.1903, -0.7819]) (768 features in tensor)\n",
      "Run time for upset was 19.179528714856133 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "delighted\n",
      "Mean of 100 tensors is: tensor([0.1837, 0.5307, 0.0417, 0.8821, 0.2781]) (768 features in tensor)\n",
      "Run time for delighted was 22.927598953945562 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "scared\n",
      "Mean of 92 tensors is: tensor([ 0.0491, -0.2326,  0.0472,  0.5523,  0.9169]) (768 features in tensor)\n",
      "Run time for scared was 22.728752033086494 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "worried\n",
      "Mean of 100 tensors is: tensor([-0.0938,  0.6068,  0.1632,  0.7567, -0.0212]) (768 features in tensor)\n",
      "Run time for worried was 22.24915104196407 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "confused\n",
      "Mean of 100 tensors is: tensor([-0.0925,  0.2449,  0.1271,  0.8911,  0.3524]) (768 features in tensor)\n",
      "Run time for confused was 18.876681730151176 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "neutral\n",
      "Mean of 100 tensors is: tensor([ 0.1320, -0.1308,  0.3054, -0.0146,  0.3784]) (768 features in tensor)\n",
      "Run time for neutral was 20.70981745212339 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "angry\n",
      "Mean of 100 tensors is: tensor([-0.0841,  0.0373, -0.1435,  0.8495,  0.2465]) (768 features in tensor)\n",
      "Run time for angry was 22.44026122521609 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "satisfied\n",
      "Mean of 100 tensors is: tensor([-0.0431, -0.0969, -0.1520,  0.2018, -0.3326]) (768 features in tensor)\n",
      "Run time for satisfied was 23.69890885008499 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "surprised\n",
      "Mean of 100 tensors is: tensor([-0.0676,  0.1808,  0.0664,  1.2098, -0.2904]) (768 features in tensor)\n",
      "Run time for surprised was 22.053073457907885 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pleased\n",
      "Mean of 100 tensors is: tensor([ 0.1759,  0.5805,  0.0462,  0.7080, -0.3390]) (768 features in tensor)\n",
      "Run time for pleased was 22.84499462507665 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "concerned\n",
      "Mean of 100 tensors is: tensor([-0.2904,  0.4795,  0.2559,  0.3801, -0.3336]) (768 features in tensor)\n",
      "Run time for concerned was 22.614323343150318 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "mad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([ 0.0390,  0.4688, -0.1997,  0.5020,  0.9124]) (768 features in tensor)\n",
      "Run time for mad was 22.187959433998913 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hurt\n",
      "Mean of 100 tensors is: tensor([ 0.1350,  0.2988, -0.1637, -0.3230,  0.1196]) (768 features in tensor)\n",
      "Run time for hurt was 22.447653908049688 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "excited\n",
      "Mean of 100 tensors is: tensor([ 0.2298,  0.5526,  0.1029,  0.3288, -0.8689]) (768 features in tensor)\n",
      "Run time for excited was 21.043054829118773 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "sad\n",
      "Mean of 100 tensors is: tensor([ 0.1666,  0.5202, -0.0788,  0.4591,  1.6366]) (768 features in tensor)\n",
      "Run time for sad was 22.270573120797053 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "interested\n",
      "Mean of 100 tensors is: tensor([-0.1971,  0.6033,  0.0414,  1.1082, -0.5712]) (768 features in tensor)\n",
      "Run time for interested was 22.439967417158186 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "happy\n",
      "Mean of 100 tensors is: tensor([ 0.0708,  0.7474, -0.0721,  0.8043,  0.2535]) (768 features in tensor)\n",
      "Run time for happy was 23.52897517895326 seconds.\n",
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-1500_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-1500_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([-0.0378,  0.4474,  0.3961, -0.2618, -0.3889]) (768 features in tensor)\n",
      "Run time for stupefied was 2.270984302042052 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.1582,  0.1134,  0.1185,  0.1506, -0.2049]) (768 features in tensor)\n",
      "Run time for scornful was 5.952368640806526 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.0587, -0.1270,  0.2702,  0.9796,  0.0156]) (768 features in tensor)\n",
      "Run time for disbelieving was 2.036268986063078 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.1006, -0.2399,  0.2018, -0.2121, -0.2596]) (768 features in tensor)\n",
      "Run time for disdainful was 5.864280000794679 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.1558,  0.1603,  0.0881,  0.7562, -0.8166]) (768 features in tensor)\n",
      "Run time for revolted was 3.658299464965239 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.1035,  0.6822, -0.0405,  0.4171, -0.1571]) (768 features in tensor)\n",
      "Run time for miffed was 2.499299273826182 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 0.0360, -0.1501, -0.0544,  0.4424,  0.0833]) (768 features in tensor)\n",
      "Run time for aghast was 5.298222566023469 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1403,  0.3899,  0.1377,  0.5623, -0.4901]) (768 features in tensor)\n",
      "Run time for incensed was 8.645934502128512 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([ 0.2910,  0.2844,  0.3767, -0.0578,  0.1489]) (768 features in tensor)\n",
      "Run time for dejected was 10.00796777708456 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.1000,  0.5029,  0.0879,  0.0910, -0.6223]) (768 features in tensor)\n",
      "Run time for repulsed was 4.787241064012051 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([0.1854, 0.7716, 0.0037, 0.2109, 0.6259]) (768 features in tensor)\n",
      "Run time for mournful was 11.846955924062058 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([0.0989, 0.4063, 0.1855, 0.8331, 0.0059]) (768 features in tensor)\n",
      "Run time for displeased was 8.23659789818339 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.2366,  0.5456,  0.4191,  0.5853, -0.2084]) (768 features in tensor)\n",
      "Run time for infuriated was 2.951990111032501 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1771,  0.2489,  0.0996, -0.3701, -0.1085]) (768 features in tensor)\n",
      "Run time for awed was 5.327424948103726 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1946,  0.3387,  0.1365,  0.5690, -0.4524]) (768 features in tensor)\n",
      "Run time for repelled was 5.103860154980794 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.0240, -0.1464,  0.3306,  0.4893, -0.1644]) (768 features in tensor)\n",
      "Run time for resentful was 5.833160065114498 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.1633, 0.4904, 0.3593, 0.5731, 0.5108]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.691514055011794 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.1678,  0.7467,  0.2324,  0.3902, -0.5951]) (768 features in tensor)\n",
      "Run time for irate was 3.0037240530364215 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([0.1105, 0.3481, 0.2635, 0.4841, 0.0129]) (768 features in tensor)\n",
      "Run time for dismayed was 7.247817785013467 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.1333,  0.6429,  0.4663,  0.5351, -0.5943]) (768 features in tensor)\n",
      "Run time for elated was 5.832263264106587 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.1980,  0.1815,  0.1966,  0.2689, -0.3098]) (768 features in tensor)\n",
      "Run time for enraged was 10.437070437008515 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.0313, -0.0945,  0.5208,  0.7672, -0.6168]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.451716081006452 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0127,  0.2983,  0.1843,  0.3933,  0.0474]) (768 features in tensor)\n",
      "Run time for bewildered was 6.903901800047606 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.1339,  0.2771,  0.2017,  0.3122, -0.4266]) (768 features in tensor)\n",
      "Run time for astounded was 5.102028315886855 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([ 0.0850,  0.4219,  0.2377,  0.3699, -0.1007]) (768 features in tensor)\n",
      "Run time for perplexed was 9.721875238930807 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([ 0.0663,  0.1733,  0.2507,  0.1006, -0.0497]) (768 features in tensor)\n",
      "Run time for appalled was 8.860687882872298 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1455, 0.2600, 0.0967, 0.5492, 0.4953]) (768 features in tensor)\n",
      "Run time for startled was 14.207618177868426 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.1034,  0.1364,  0.3582,  0.0574, -0.2653]) (768 features in tensor)\n",
      "Run time for astonished was 13.897051087813452 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0380,  0.3353,  0.1752,  0.3961, -0.0536]) (768 features in tensor)\n",
      "Run time for alarmed was 12.057679309975356 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0847,  0.0220,  0.2610, -0.2140, -0.1962]) (768 features in tensor)\n",
      "Run time for outraged was 10.28971373802051 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n",
      "Mean of 41 tensors is: tensor([ 0.1277, -0.0101,  0.2961, -0.1115, -0.0955]) (768 features in tensor)\n",
      "Run time for disgusted was 9.358108978020027 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n",
      "Mean of 100 tensors is: tensor([-0.0845,  0.1171, -0.0108,  0.3257,  0.2438]) (768 features in tensor)\n",
      "Run time for doubtful was 19.38051664386876 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 48 tensors is: tensor([ 0.1180,  0.2147,  0.3429, -0.0667, -0.0200]) (768 features in tensor)\n",
      "Run time for dissatisfied was 8.049302458995953 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n",
      "Mean of 10 tensors is: tensor([0.0516, 0.5009, 0.2046, 0.7983, 1.0925]) (768 features in tensor)\n",
      "Run time for saddened was 3.0168720460496843 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([ 0.0505,  0.4495,  0.2946,  0.4139, -0.2576]) (768 features in tensor)\n",
      "Run time for irritated was 9.368348418036476 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n",
      "Mean of 78 tensors is: tensor([ 0.0779,  0.8246,  0.3030,  0.7579, -1.2170]) (768 features in tensor)\n",
      "Run time for amused was 17.30217722686939 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n",
      "Mean of 100 tensors is: tensor([0.0826, 0.1257, 0.2489, 0.7035, 0.7443]) (768 features in tensor)\n",
      "Run time for frightened was 22.967478501144797 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n",
      "Mean of 48 tensors is: tensor([ 0.0174,  0.6300,  0.3141,  0.0679, -0.1898]) (768 features in tensor)\n",
      "Run time for discouraged was 9.356877785176039 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([ 0.0686, -0.0298,  0.2542,  0.0704,  0.2688]) (768 features in tensor)\n",
      "Run time for stunned was 9.067193889059126 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-0.0852, -0.0883,  0.0756,  0.5362,  1.0409]) (768 features in tensor)\n",
      "Run time for fearful was 20.276185540948063 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([0.0667, 0.2390, 0.2141, 0.4035, 0.1148]) (768 features in tensor)\n",
      "Run time for pissed was 11.0954067138955 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1631, -0.0951,  0.1440,  0.4162,  0.8506]) (768 features in tensor)\n",
      "Run time for terrified was 8.686081734951586 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.0113,  0.2971,  0.1524,  0.0786, -0.7435]) (768 features in tensor)\n",
      "Run time for offended was 23.45490366802551 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.0703,  0.5048,  0.3107,  0.4758, -0.4129]) (768 features in tensor)\n",
      "Run time for annoyed was 11.310652680927888 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.1069,  0.1914,  0.1889, -0.2029,  0.4146]) (768 features in tensor)\n",
      "Run time for skeptical was 11.6600119729992 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([ 0.0167,  0.3226,  0.0598, -0.1025,  0.8930]) (768 features in tensor)\n",
      "Run time for hostile was 19.803084668936208 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0665,  0.4906, -0.1291,  0.3898,  0.2227]) (768 features in tensor)\n",
      "Run time for furious was 19.568646332016215 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1644,  0.3618,  0.1378,  0.5813, -0.3521]) (768 features in tensor)\n",
      "Run time for bothered was 15.700392017140985 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.1497, 0.9930, 0.3294, 0.0455, 0.4709]) (768 features in tensor)\n",
      "Run time for joyful was 12.03025167901069 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n",
      "Mean of 100 tensors is: tensor([-0.0293,  0.1470, -0.0960,  0.4371,  0.0627]) (768 features in tensor)\n",
      "Run time for uncertain was 20.38487746892497 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "cheerful\n",
      "Mean of 100 tensors is: tensor([ 0.1842,  0.8568,  0.3113, -0.2772,  0.6927]) (768 features in tensor)\n",
      "Run time for cheerful was 16.99684961605817 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "depressed\n",
      "Mean of 100 tensors is: tensor([0.0989, 0.5491, 0.4088, 0.1373, 0.2927]) (768 features in tensor)\n",
      "Run time for depressed was 18.033332513878122 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "anxious\n",
      "Mean of 100 tensors is: tensor([-0.0437,  0.1805,  0.2107,  0.4259,  0.3016]) (768 features in tensor)\n",
      "Run time for anxious was 20.21000830689445 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frustrated\n",
      "Mean of 81 tensors is: tensor([0.0290, 0.4330, 0.2630, 0.6058, 0.2341]) (768 features in tensor)\n",
      "Run time for frustrated was 16.93705811095424 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "distressed\n",
      "Mean of 57 tensors is: tensor([0.1925, 0.6524, 0.3000, 0.3579, 0.4483]) (768 features in tensor)\n",
      "Run time for distressed was 12.617915284121409 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bored\n",
      "Mean of 92 tensors is: tensor([-0.0589, -0.1583,  0.3845,  0.2321,  0.7050]) (768 features in tensor)\n",
      "Run time for bored was 21.53645522892475 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "suspicious\n",
      "Mean of 85 tensors is: tensor([-0.1154,  0.3797,  0.1955, -0.0124,  0.1657]) (768 features in tensor)\n",
      "Run time for suspicious was 18.241398757090792 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "shocked\n",
      "Mean of 88 tensors is: tensor([0.0198, 0.0084, 0.2210, 0.4315, 0.1165]) (768 features in tensor)\n",
      "Run time for shocked was 19.81036173598841 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amazed\n",
      "Mean of 73 tensors is: tensor([-0.0101,  0.2420,  0.1669,  0.3039, -0.2415]) (768 features in tensor)\n",
      "Run time for amazed was 15.75542159914039 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "rejected\n",
      "Mean of 100 tensors is: tensor([ 0.0417, -0.0256,  0.1140,  0.3286,  0.4769]) (768 features in tensor)\n",
      "Run time for rejected was 23.312243085820228 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disappointed\n",
      "Mean of 100 tensors is: tensor([-0.1559,  0.3047,  0.0824,  0.8690,  0.0590]) (768 features in tensor)\n",
      "Run time for disappointed was 22.54468733491376 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "upset\n",
      "Mean of 100 tensors is: tensor([ 0.0151,  0.6028,  0.0897,  0.1435, -0.8261]) (768 features in tensor)\n",
      "Run time for upset was 19.233379885088652 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "delighted\n",
      "Mean of 100 tensors is: tensor([0.2097, 0.6672, 0.1850, 0.8075, 0.1893]) (768 features in tensor)\n",
      "Run time for delighted was 22.883699434110895 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "scared\n",
      "Mean of 92 tensors is: tensor([ 0.0936, -0.1178,  0.2344,  0.5110,  0.7676]) (768 features in tensor)\n",
      "Run time for scared was 22.54636185290292 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "worried\n",
      "Mean of 100 tensors is: tensor([-0.1675,  0.7366,  0.2891,  0.7606, -0.0761]) (768 features in tensor)\n",
      "Run time for worried was 22.193084798986092 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "confused\n",
      "Mean of 100 tensors is: tensor([-0.1744,  0.3031,  0.1554,  1.0756,  0.2503]) (768 features in tensor)\n",
      "Run time for confused was 18.817480279132724 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "neutral\n",
      "Mean of 100 tensors is: tensor([ 0.1528, -0.0017,  0.3615, -0.0299,  0.2344]) (768 features in tensor)\n",
      "Run time for neutral was 20.583036097930744 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "angry\n",
      "Mean of 100 tensors is: tensor([-0.0951,  0.2200, -0.0221,  0.8139,  0.1346]) (768 features in tensor)\n",
      "Run time for angry was 22.425009615020826 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "satisfied\n",
      "Mean of 100 tensors is: tensor([ 0.0079,  0.0826,  0.0202,  0.2613, -0.5460]) (768 features in tensor)\n",
      "Run time for satisfied was 23.580228224163875 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "surprised\n",
      "Mean of 100 tensors is: tensor([-0.0684,  0.2461,  0.2078,  1.1534, -0.3048]) (768 features in tensor)\n",
      "Run time for surprised was 22.065471314126626 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pleased\n",
      "Mean of 100 tensors is: tensor([ 0.2318,  0.7436,  0.2497,  0.8660, -0.4097]) (768 features in tensor)\n",
      "Run time for pleased was 22.846131681930274 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "concerned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([-0.3515,  0.5877,  0.3840,  0.3447, -0.4377]) (768 features in tensor)\n",
      "Run time for concerned was 22.594069997081533 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "mad\n",
      "Mean of 100 tensors is: tensor([ 0.0544,  0.5666, -0.1593,  0.3923,  0.8714]) (768 features in tensor)\n",
      "Run time for mad was 22.251630371203646 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hurt\n",
      "Mean of 100 tensors is: tensor([ 0.1990,  0.3197, -0.1368, -0.2412,  0.0083]) (768 features in tensor)\n",
      "Run time for hurt was 22.378658795030788 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "excited\n",
      "Mean of 100 tensors is: tensor([ 0.2380,  0.6736,  0.2551,  0.3232, -0.8162]) (768 features in tensor)\n",
      "Run time for excited was 20.894616136094555 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "sad\n",
      "Mean of 100 tensors is: tensor([ 0.1606,  0.7841, -0.0682,  0.2827,  1.7083]) (768 features in tensor)\n",
      "Run time for sad was 22.308885232778266 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "interested\n",
      "Mean of 100 tensors is: tensor([-0.2178,  0.5696,  0.1960,  1.2172, -0.6712]) (768 features in tensor)\n",
      "Run time for interested was 22.555191077990457 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "happy\n",
      "Mean of 100 tensors is: tensor([0.0516, 0.9346, 0.0656, 0.8862, 0.1380]) (768 features in tensor)\n",
      "Run time for happy was 23.493604952003807 seconds.\n",
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-11500_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-11500_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([ 0.0743,  0.3895,  0.2063, -0.1963, -0.4797]) (768 features in tensor)\n",
      "Run time for stupefied was 2.258518193848431 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.2110,  0.0107, -0.0159,  0.3330, -0.3380]) (768 features in tensor)\n",
      "Run time for scornful was 5.882308905012906 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.1014, -0.0695,  0.1255,  0.9819, -0.0222]) (768 features in tensor)\n",
      "Run time for disbelieving was 1.9948109469842166 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.1653, -0.3130,  0.0896, -0.1289, -0.2738]) (768 features in tensor)\n",
      "Run time for disdainful was 5.912131350953132 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.1190,  0.2107,  0.0180,  0.9238, -0.8042]) (768 features in tensor)\n",
      "Run time for revolted was 3.6621364848688245 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.1106,  0.5164, -0.1889,  0.3228, -0.2385]) (768 features in tensor)\n",
      "Run time for miffed was 2.451558887027204 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 1.2711e-01, -4.1560e-01, -1.8448e-01,  5.3842e-01, -1.3275e-04]) (768 features in tensor)\n",
      "Run time for aghast was 5.27585557103157 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1832,  0.1309, -0.0365,  0.5180, -0.3800]) (768 features in tensor)\n",
      "Run time for incensed was 8.663723185891286 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([0.3344, 0.1847, 0.2941, 0.2081, 0.2254]) (768 features in tensor)\n",
      "Run time for dejected was 10.042069318005815 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.1166,  0.3309, -0.0497,  0.1359, -0.4658]) (768 features in tensor)\n",
      "Run time for repulsed was 4.794913009973243 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([ 0.1736,  0.4983, -0.0139,  0.4339,  0.6145]) (768 features in tensor)\n",
      "Run time for mournful was 11.818273280980065 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([ 0.0976,  0.3054, -0.1132,  0.7362,  0.1329]) (768 features in tensor)\n",
      "Run time for displeased was 8.25577351078391 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.3336,  0.4492,  0.3040,  0.6507, -0.1853]) (768 features in tensor)\n",
      "Run time for infuriated was 2.934650566894561 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1763,  0.2545, -0.0065, -0.2993,  0.0785]) (768 features in tensor)\n",
      "Run time for awed was 5.305816619889811 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1641,  0.2460, -0.0377,  0.5882, -0.2909]) (768 features in tensor)\n",
      "Run time for repelled was 5.044518755050376 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.1302, -0.2037,  0.1071,  0.7918, -0.1564]) (768 features in tensor)\n",
      "Run time for resentful was 5.7919400138780475 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.2139, 0.1906, 0.3077, 0.8689, 0.5613]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.715665295021608 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.2158,  0.5876,  0.0941,  0.5095, -0.6705]) (768 features in tensor)\n",
      "Run time for irate was 2.9534590949770063 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([0.0760, 0.2667, 0.1743, 0.5492, 0.0058]) (768 features in tensor)\n",
      "Run time for dismayed was 7.252605049870908 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.0614,  0.6923,  0.3050,  0.5888, -0.6968]) (768 features in tensor)\n",
      "Run time for elated was 5.869870179099962 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.2298,  0.1315,  0.1807,  0.2249, -0.3862]) (768 features in tensor)\n",
      "Run time for enraged was 10.444743130821735 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.1610, -0.3002,  0.3025,  0.8984, -0.6897]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.450662142131478 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0096,  0.2369,  0.0306,  0.3890,  0.0095]) (768 features in tensor)\n",
      "Run time for bewildered was 6.8500147820450366 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.1125,  0.2223, -0.0163,  0.2983, -0.4347]) (768 features in tensor)\n",
      "Run time for astounded was 5.094608579995111 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([ 0.1379,  0.3885,  0.1386,  0.3116, -0.1318]) (768 features in tensor)\n",
      "Run time for perplexed was 9.68335169297643 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([ 0.0410, -0.0495,  0.1477, -0.0012,  0.0049]) (768 features in tensor)\n",
      "Run time for appalled was 8.857969065895304 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1487, 0.2162, 0.0744, 0.6172, 0.4718]) (768 features in tensor)\n",
      "Run time for startled was 14.238451892044395 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.0732,  0.0959,  0.2759,  0.1725, -0.3085]) (768 features in tensor)\n",
      "Run time for astonished was 14.00368664599955 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0703,  0.2437,  0.1123,  0.3868, -0.0683]) (768 features in tensor)\n",
      "Run time for alarmed was 12.071914023952559 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0694, -0.1482,  0.1732, -0.2089, -0.0866]) (768 features in tensor)\n",
      "Run time for outraged was 10.262171559035778 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n",
      "Mean of 41 tensors is: tensor([ 0.1454, -0.0715,  0.1972,  0.0708, -0.0777]) (768 features in tensor)\n",
      "Run time for disgusted was 9.316105674952269 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([ 0.0031, -0.0303, -0.0201,  0.6117, -0.0304]) (768 features in tensor)\n",
      "Run time for doubtful was 19.416049152147025 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n",
      "Mean of 48 tensors is: tensor([0.1717, 0.0520, 0.1044, 0.1548, 0.0428]) (768 features in tensor)\n",
      "Run time for dissatisfied was 7.923818479059264 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n",
      "Mean of 10 tensors is: tensor([0.0371, 0.3751, 0.1680, 0.8978, 1.2086]) (768 features in tensor)\n",
      "Run time for saddened was 3.026290058158338 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([ 0.0758,  0.3054,  0.0967,  0.5846, -0.1447]) (768 features in tensor)\n",
      "Run time for irritated was 9.349324631039053 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n",
      "Mean of 78 tensors is: tensor([ 0.0789,  0.8139,  0.1421,  0.9145, -1.2029]) (768 features in tensor)\n",
      "Run time for amused was 17.088017347967252 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n",
      "Mean of 100 tensors is: tensor([ 0.1289, -0.0352,  0.1395,  0.8050,  0.6478]) (768 features in tensor)\n",
      "Run time for frightened was 22.94353065220639 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n",
      "Mean of 48 tensors is: tensor([ 0.0630,  0.5237,  0.1852,  0.1566, -0.1645]) (768 features in tensor)\n",
      "Run time for discouraged was 9.393462416017428 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([ 0.0378, -0.0687,  0.1775,  0.1388,  0.2231]) (768 features in tensor)\n",
      "Run time for stunned was 9.075723747024313 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-0.0040, -0.2664,  0.0726,  0.6234,  0.8881]) (768 features in tensor)\n",
      "Run time for fearful was 20.26126446481794 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([0.0535, 0.1671, 0.0819, 0.5225, 0.0659]) (768 features in tensor)\n",
      "Run time for pissed was 11.20623271400109 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1932, -0.2879,  0.1105,  0.4987,  0.7658]) (768 features in tensor)\n",
      "Run time for terrified was 8.652344622882083 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.0589,  0.1879, -0.0234,  0.0373, -0.7242]) (768 features in tensor)\n",
      "Run time for offended was 23.334238237934187 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.1003,  0.4355,  0.1418,  0.7307, -0.2918]) (768 features in tensor)\n",
      "Run time for annoyed was 11.239351799013093 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.0315,  0.0586,  0.0605, -0.0050,  0.4219]) (768 features in tensor)\n",
      "Run time for skeptical was 11.67881367309019 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([ 4.9818e-02,  2.3105e-01, -1.2377e-04, -2.6289e-01,  8.7734e-01]) (768 features in tensor)\n",
      "Run time for hostile was 19.7768627430778 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0962,  0.2705, -0.1385,  0.5764,  0.0985]) (768 features in tensor)\n",
      "Run time for furious was 19.616953792981803 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1654,  0.4119,  0.0317,  0.7004, -0.4503]) (768 features in tensor)\n",
      "Run time for bothered was 15.608977546915412 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.2095, 0.8849, 0.2165, 0.1232, 0.5331]) (768 features in tensor)\n",
      "Run time for joyful was 11.971712152007967 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n",
      "Mean of 100 tensors is: tensor([ 0.0816, -0.0632, -0.1083,  0.5949,  0.0995]) (768 features in tensor)\n",
      "Run time for uncertain was 20.368196598021314 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "cheerful\n",
      "Mean of 100 tensors is: tensor([ 0.1755,  0.7572,  0.1551, -0.0595,  0.6132]) (768 features in tensor)\n",
      "Run time for cheerful was 16.8901964048855 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "depressed\n",
      "Mean of 100 tensors is: tensor([0.1332, 0.4100, 0.2996, 0.3427, 0.4000]) (768 features in tensor)\n",
      "Run time for depressed was 18.036330484086648 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "anxious\n",
      "Mean of 100 tensors is: tensor([ 0.0633, -0.0543,  0.0808,  0.6635,  0.2597]) (768 features in tensor)\n",
      "Run time for anxious was 20.23335728282109 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frustrated\n",
      "Mean of 81 tensors is: tensor([0.0344, 0.2410, 0.1814, 0.7229, 0.2425]) (768 features in tensor)\n",
      "Run time for frustrated was 16.85483403201215 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "distressed\n",
      "Mean of 57 tensors is: tensor([0.2165, 0.5200, 0.2561, 0.5668, 0.4391]) (768 features in tensor)\n",
      "Run time for distressed was 12.50987602584064 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bored\n",
      "Mean of 92 tensors is: tensor([-0.0282, -0.1852,  0.1946,  0.4158,  0.8537]) (768 features in tensor)\n",
      "Run time for bored was 21.584038914879784 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "suspicious\n",
      "Mean of 85 tensors is: tensor([-0.0539,  0.2017,  0.1420,  0.0965,  0.1504]) (768 features in tensor)\n",
      "Run time for suspicious was 18.184882630128413 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "shocked\n",
      "Mean of 88 tensors is: tensor([ 0.0147, -0.0562,  0.1867,  0.5570,  0.0627]) (768 features in tensor)\n",
      "Run time for shocked was 19.793668790953234 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amazed\n",
      "Mean of 73 tensors is: tensor([-0.0075,  0.0824,  0.0808,  0.3998, -0.1430]) (768 features in tensor)\n",
      "Run time for amazed was 15.74529856396839 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "rejected\n",
      "Mean of 100 tensors is: tensor([ 0.0619, -0.0433,  0.0147,  0.2336,  0.5829]) (768 features in tensor)\n",
      "Run time for rejected was 23.245263064978644 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disappointed\n",
      "Mean of 100 tensors is: tensor([-0.1621,  0.0923, -0.1165,  1.0880,  0.1383]) (768 features in tensor)\n",
      "Run time for disappointed was 22.39067298010923 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "upset\n",
      "Mean of 100 tensors is: tensor([ 0.0481,  0.5653,  0.0345,  0.2139, -0.7800]) (768 features in tensor)\n",
      "Run time for upset was 19.271843667142093 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "delighted\n",
      "Mean of 100 tensors is: tensor([0.2327, 0.5615, 0.0793, 0.9468, 0.2458]) (768 features in tensor)\n",
      "Run time for delighted was 22.829237421043217 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "scared\n",
      "Mean of 92 tensors is: tensor([ 0.0678, -0.2521,  0.0794,  0.5774,  0.8936]) (768 features in tensor)\n",
      "Run time for scared was 22.71930168895051 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "worried\n",
      "Mean of 100 tensors is: tensor([-0.0530,  0.6025,  0.2012,  0.8145, -0.0764]) (768 features in tensor)\n",
      "Run time for worried was 22.178263466106728 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "confused\n",
      "Mean of 100 tensors is: tensor([-0.0699,  0.2483,  0.1252,  0.9277,  0.3110]) (768 features in tensor)\n",
      "Run time for confused was 18.73260091803968 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "neutral\n",
      "Mean of 100 tensors is: tensor([ 0.1645, -0.1416,  0.3006, -0.0169,  0.3919]) (768 features in tensor)\n",
      "Run time for neutral was 20.58381276507862 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "angry\n",
      "Mean of 100 tensors is: tensor([-0.0432,  0.0421, -0.1101,  0.9333,  0.2190]) (768 features in tensor)\n",
      "Run time for angry was 22.38990518404171 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "satisfied\n",
      "Mean of 100 tensors is: tensor([-0.0062, -0.0995, -0.1219,  0.2316, -0.3650]) (768 features in tensor)\n",
      "Run time for satisfied was 23.74517705081962 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "surprised\n",
      "Mean of 100 tensors is: tensor([-0.0252,  0.1662,  0.0646,  1.2457, -0.3071]) (768 features in tensor)\n",
      "Run time for surprised was 22.111194296041504 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pleased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 tensors is: tensor([ 0.2079,  0.5833,  0.0955,  0.7610, -0.3526]) (768 features in tensor)\n",
      "Run time for pleased was 22.944760938873515 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "concerned\n",
      "Mean of 100 tensors is: tensor([-0.2511,  0.4631,  0.2991,  0.4508, -0.4052]) (768 features in tensor)\n",
      "Run time for concerned was 22.681766452966258 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "mad\n",
      "Mean of 100 tensors is: tensor([ 0.0824,  0.4471, -0.1705,  0.5221,  0.9315]) (768 features in tensor)\n",
      "Run time for mad was 22.113673039944842 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hurt\n",
      "Mean of 100 tensors is: tensor([ 0.1781,  0.3157, -0.1401, -0.2304,  0.1131]) (768 features in tensor)\n",
      "Run time for hurt was 22.322853557998314 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "excited\n",
      "Mean of 100 tensors is: tensor([ 0.2771,  0.5653,  0.1512,  0.4025, -0.8990]) (768 features in tensor)\n",
      "Run time for excited was 20.92190687218681 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "sad\n",
      "Mean of 100 tensors is: tensor([ 0.2138,  0.5027, -0.0525,  0.5044,  1.6059]) (768 features in tensor)\n",
      "Run time for sad was 22.191178573062643 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "interested\n",
      "Mean of 100 tensors is: tensor([-0.1643,  0.6216,  0.1121,  1.1783, -0.6096]) (768 features in tensor)\n",
      "Run time for interested was 22.677338558016345 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "happy\n",
      "Mean of 100 tensors is: tensor([ 0.0952,  0.7491, -0.0321,  0.8601,  0.2342]) (768 features in tensor)\n",
      "Run time for happy was 23.535255019087344 seconds.\n",
      "/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-12000_layer8_wordnik.txt /home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/checkpoint-12000_layer8_wordnik_counts.txt\n",
      "\n",
      "There are 4 tokens in tokenized vocabulary word:\n",
      "st\n",
      "upe\n",
      "f\n",
      "ied\n",
      "Mean of 15 tensors is: tensor([ 0.0558,  0.4056,  0.1857, -0.2970, -0.4770]) (768 features in tensor)\n",
      "Run time for stupefied was 2.2974024179857224 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "scorn\n",
      "ful\n",
      "Mean of 31 tensors is: tensor([ 0.1720,  0.0531, -0.0505,  0.3159, -0.2537]) (768 features in tensor)\n",
      "Run time for scornful was 5.973449101205915 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disbel\n",
      "ieving\n",
      "Mean of 11 tensors is: tensor([ 0.0977, -0.0419,  0.0879,  0.9595, -0.0083]) (768 features in tensor)\n",
      "Run time for disbelieving was 2.037842147052288 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disdain\n",
      "ful\n",
      "Mean of 39 tensors is: tensor([ 0.1290, -0.2757,  0.0493, -0.1264, -0.1948]) (768 features in tensor)\n",
      "Run time for disdainful was 5.9475059129763395 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "revol\n",
      "ted\n",
      "Mean of 12 tensors is: tensor([ 0.0538,  0.2623, -0.0459,  0.8333, -0.7424]) (768 features in tensor)\n",
      "Run time for revolted was 3.6902951581869274 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "m\n",
      "iff\n",
      "ed\n",
      "Mean of 7 tensors is: tensor([ 0.0699,  0.5441, -0.2368,  0.2276, -0.2081]) (768 features in tensor)\n",
      "Run time for miffed was 2.4927280468400568 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "a\n",
      "gh\n",
      "ast\n",
      "Mean of 23 tensors is: tensor([ 0.0852, -0.3370, -0.2505,  0.4677,  0.0072]) (768 features in tensor)\n",
      "Run time for aghast was 5.368490562774241 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "inc\n",
      "ensed\n",
      "Mean of 38 tensors is: tensor([ 0.1471,  0.1636, -0.0730,  0.4651, -0.3785]) (768 features in tensor)\n",
      "Run time for incensed was 8.72968965396285 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "de\n",
      "jected\n",
      "Mean of 79 tensors is: tensor([0.3315, 0.2248, 0.2626, 0.1962, 0.2418]) (768 features in tensor)\n",
      "Run time for dejected was 10.044512489112094 seconds.\n",
      "\n",
      "There are 3 tokens in tokenized vocabulary word:\n",
      "rep\n",
      "uls\n",
      "ed\n",
      "Mean of 16 tensors is: tensor([ 0.0661,  0.3534, -0.0631,  0.0640, -0.4504]) (768 features in tensor)\n",
      "Run time for repulsed was 4.8078992769587785 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "mourn\n",
      "ful\n",
      "Mean of 63 tensors is: tensor([ 0.1416,  0.5180, -0.0663,  0.3835,  0.6809]) (768 features in tensor)\n",
      "Run time for mournful was 11.924213549122214 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "disple\n",
      "ased\n",
      "Mean of 39 tensors is: tensor([ 0.0515,  0.3597, -0.1483,  0.6875,  0.1273]) (768 features in tensor)\n",
      "Run time for displeased was 8.368851480074227 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "infuri\n",
      "ated\n",
      "Mean of 15 tensors is: tensor([ 0.2901,  0.4773,  0.2659,  0.6172, -0.1421]) (768 features in tensor)\n",
      "Run time for infuriated was 2.944977150997147 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "aw\n",
      "ed\n",
      "Mean of 22 tensors is: tensor([ 0.1361,  0.3227, -0.0258, -0.3946,  0.0565]) (768 features in tensor)\n",
      "Run time for awed was 5.312427333090454 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "repe\n",
      "lled\n",
      "Mean of 15 tensors is: tensor([ 0.1132,  0.2515, -0.0437,  0.5224, -0.2676]) (768 features in tensor)\n",
      "Run time for repelled was 5.115189551841468 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "resent\n",
      "ful\n",
      "Mean of 38 tensors is: tensor([ 0.1103, -0.2162,  0.0791,  0.7883, -0.0972]) (768 features in tensor)\n",
      "Run time for resentful was 5.843309576855972 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "sorrow\n",
      "ful\n",
      "Mean of 58 tensors is: tensor([0.2032, 0.1950, 0.2511, 0.8263, 0.5907]) (768 features in tensor)\n",
      "Run time for sorrowful was 8.643604998942465 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ir\n",
      "ate\n",
      "Mean of 13 tensors is: tensor([ 0.1721,  0.6359,  0.0576,  0.4440, -0.6317]) (768 features in tensor)\n",
      "Run time for irate was 2.9712173021398485 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "dismay\n",
      "ed\n",
      "Mean of 36 tensors is: tensor([0.0438, 0.3137, 0.1418, 0.4634, 0.0440]) (768 features in tensor)\n",
      "Run time for dismayed was 7.2543968700338155 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "el\n",
      "ated\n",
      "Mean of 37 tensors is: tensor([ 0.0620,  0.7238,  0.3002,  0.5827, -0.7122]) (768 features in tensor)\n",
      "Run time for elated was 5.8560963368508965 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "enraged\n",
      "Mean of 45 tensors is: tensor([ 0.1697,  0.1730,  0.1311,  0.1870, -0.3461]) (768 features in tensor)\n",
      "Run time for enraged was 10.419749977998435 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "apprehens\n",
      "ive\n",
      "Mean of 41 tensors is: tensor([ 0.1489, -0.2976,  0.2944,  0.9063, -0.6533]) (768 features in tensor)\n",
      "Run time for apprehensive was 6.501306903082877 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "bewild\n",
      "ered\n",
      "Mean of 37 tensors is: tensor([-0.0414,  0.2676, -0.0082,  0.3497,  0.0483]) (768 features in tensor)\n",
      "Run time for bewildered was 6.856036539888009 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "ast\n",
      "ounded\n",
      "Mean of 20 tensors is: tensor([ 0.0795,  0.3021, -0.0359,  0.2351, -0.4259]) (768 features in tensor)\n",
      "Run time for astounded was 5.107309333048761 seconds.\n",
      "\n",
      "There are 2 tokens in tokenized vocabulary word:\n",
      "perplex\n",
      "ed\n",
      "Mean of 47 tensors is: tensor([ 0.1062,  0.4216,  0.1371,  0.2162, -0.1186]) (768 features in tensor)\n",
      "Run time for perplexed was 9.6428428189829 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "appalled\n",
      "Mean of 38 tensors is: tensor([-0.0143,  0.0028,  0.0903, -0.0613,  0.0353]) (768 features in tensor)\n",
      "Run time for appalled was 8.837204796960577 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "startled\n",
      "Mean of 58 tensors is: tensor([0.1252, 0.2176, 0.0489, 0.4966, 0.5443]) (768 features in tensor)\n",
      "Run time for startled was 14.235240909969434 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "astonished\n",
      "Mean of 62 tensors is: tensor([ 0.0433,  0.1053,  0.2422,  0.0787, -0.2928]) (768 features in tensor)\n",
      "Run time for astonished was 13.88688142504543 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "alarmed\n",
      "Mean of 56 tensors is: tensor([ 0.0374,  0.2580,  0.0813,  0.3144, -0.0376]) (768 features in tensor)\n",
      "Run time for alarmed was 12.105570548214018 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "outraged\n",
      "Mean of 45 tensors is: tensor([ 0.0110, -0.1046,  0.1166, -0.2569, -0.0605]) (768 features in tensor)\n",
      "Run time for outraged was 10.288349076872692 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "disgusted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 41 tensors is: tensor([ 0.0991, -0.0316,  0.1635,  0.0106, -0.0299]) (768 features in tensor)\n",
      "Run time for disgusted was 9.303878074977547 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "doubtful\n",
      "Mean of 100 tensors is: tensor([-0.0410,  0.0029, -0.0398,  0.5341,  0.0117]) (768 features in tensor)\n",
      "Run time for doubtful was 19.303508579032496 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "dissatisfied\n",
      "Mean of 48 tensors is: tensor([0.1501, 0.0892, 0.0814, 0.0873, 0.0992]) (768 features in tensor)\n",
      "Run time for dissatisfied was 7.9814978069625795 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "saddened\n",
      "Mean of 10 tensors is: tensor([-0.0195,  0.4388,  0.1242,  0.7906,  1.2522]) (768 features in tensor)\n",
      "Run time for saddened was 3.0315249001141638 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "irritated\n",
      "Mean of 46 tensors is: tensor([ 0.0278,  0.3279,  0.0888,  0.5175, -0.0935]) (768 features in tensor)\n",
      "Run time for irritated was 9.38030824298039 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "amused\n",
      "Mean of 78 tensors is: tensor([ 0.0529,  0.8481,  0.1322,  0.8403, -1.1867]) (768 features in tensor)\n",
      "Run time for amused was 17.04527401784435 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "frightened\n",
      "Mean of 100 tensors is: tensor([ 0.0774, -0.0088,  0.1150,  0.7466,  0.7082]) (768 features in tensor)\n",
      "Run time for frightened was 22.881834694882855 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "discouraged\n",
      "Mean of 48 tensors is: tensor([ 0.0204,  0.5866,  0.1706,  0.1091, -0.1453]) (768 features in tensor)\n",
      "Run time for discouraged was 9.324487647041678 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "stunned\n",
      "Mean of 43 tensors is: tensor([ 0.0007, -0.0511,  0.1345,  0.0656,  0.2652]) (768 features in tensor)\n",
      "Run time for stunned was 9.082349335076287 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "fearful\n",
      "Mean of 100 tensors is: tensor([-0.0234, -0.2686,  0.0477,  0.5984,  0.9515]) (768 features in tensor)\n",
      "Run time for fearful was 20.19299398898147 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "pissed\n",
      "Mean of 49 tensors is: tensor([0.0105, 0.2141, 0.0637, 0.4616, 0.1029]) (768 features in tensor)\n",
      "Run time for pissed was 11.156060498207808 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "terrified\n",
      "Mean of 35 tensors is: tensor([ 0.1600, -0.2571,  0.0857,  0.4377,  0.8049]) (768 features in tensor)\n",
      "Run time for terrified was 8.645469567971304 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "offended\n",
      "Mean of 100 tensors is: tensor([-0.1028,  0.2321, -0.0477, -0.0095, -0.7123]) (768 features in tensor)\n",
      "Run time for offended was 23.27483111806214 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "annoyed\n",
      "Mean of 53 tensors is: tensor([ 0.0637,  0.4673,  0.1285,  0.6513, -0.2604]) (768 features in tensor)\n",
      "Run time for annoyed was 11.320192748913541 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "skeptical\n",
      "Mean of 56 tensors is: tensor([-0.0607,  0.0753,  0.0322, -0.0505,  0.4587]) (768 features in tensor)\n",
      "Run time for skeptical was 11.644708561012521 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "hostile\n",
      "Mean of 100 tensors is: tensor([ 0.0039,  0.2179, -0.0494, -0.2998,  0.9212]) (768 features in tensor)\n",
      "Run time for hostile was 19.7269761019852 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "furious\n",
      "Mean of 100 tensors is: tensor([ 0.0691,  0.2782, -0.1787,  0.5201,  0.1837]) (768 features in tensor)\n",
      "Run time for furious was 19.52135380008258 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "bothered\n",
      "Mean of 69 tensors is: tensor([ 0.1383,  0.4152,  0.0125,  0.6616, -0.4062]) (768 features in tensor)\n",
      "Run time for bothered was 15.582105902954936 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "joyful\n",
      "Mean of 73 tensors is: tensor([0.1827, 0.8702, 0.1830, 0.0737, 0.5778]) (768 features in tensor)\n",
      "Run time for joyful was 11.95868245093152 seconds.\n",
      "\n",
      "There are 1 tokens in tokenized vocabulary word:\n",
      "uncertain\n"
     ]
    }
   ],
   "source": [
    "# Get the 8th layer of the model for all checkpoints in a fine-tuning output directory.\n",
    "for dir, subdirs, files in os.walk(model_root_dir):\n",
    "    for subdir in subdirs:\n",
    "        model = RobertaForMaskedLM.from_pretrained(os.path.join(dir, subdir), config=config)\n",
    "        model.eval()\n",
    "        subdir_output_file = ''\n",
    "        subdir_count_file = ''\n",
    "        subdir_output_file = os.path.join(output_file, subdir + '_layer8_wordnik.txt')\n",
    "        subdir_count_file = os.path.join(count_file, subdir + '_layer8_wordnik_counts.txt')\n",
    "        print(subdir_output_file, subdir_count_file)\n",
    "        # Process vocabulary words in the middle loop.\n",
    "        for v in vocab:\n",
    "            start = timer()\n",
    "            with open(context_file, 'r') as lines:\n",
    "                v_sum = torch.zeros([1, FEATURE_COUNT])\n",
    "                v_tokens = tokenizer.encode(v)\n",
    "                print(f'\\nThere are {len(v_tokens) - 2} tokens in tokenized vocabulary word:')\n",
    "                for t in v_tokens[1:-1]:\n",
    "                    print(tokenizer.decode(t).strip())\n",
    "                count_sentence = 0\n",
    "                count_tensor = 0\n",
    "\n",
    "                # Process all lines in the context file in the inner loop.\n",
    "                for line in lines:\n",
    "                    # Check for this vocab word in this line; if found, split the line into individual sentences.\n",
    "                    if v in line.lower().split():\n",
    "                        for sentence in line.split('.'):\n",
    "                            if v in sentence.lower():\n",
    "                                line = sentence\n",
    "                                count_sentence += 1\n",
    "                                break\n",
    "                        # Split the new sentence-based line into tokens.\n",
    "                        # Use max_length to avoid overflowing the maximum sequence length for the model.\n",
    "                        tokenized_text = tokenizer.encode(line, add_special_tokens=True, max_length=512)\n",
    "                        indices = []              \n",
    "\n",
    "                        # Check to see whether the vocab word is found in this particular line.\n",
    "                        # Initially, some lines may have comprised multiple sentences, which were\n",
    "                        # broken out individually above.\n",
    "                        for t in v_tokens[1:-1]:\n",
    "                            for i, token_str in enumerate(tokenized_text):\n",
    "                                if tokenizer.decode(token_str).strip() == tokenizer.decode(t).strip():\n",
    "                                    indices.append(i)               \n",
    "\n",
    "                        # If the vocabulary word was found, process the containing line.\n",
    "                        if indices:\n",
    "\n",
    "                            # The vocab word was found in this line/sentence, at the locations in indices.\n",
    "                            # Get the feature vectors for all tokens in the line/sentence.\n",
    "                            token_embeddings = create_token_embeddings(tokenized_text)\n",
    "                            token_vecs_layer = get_token_vecs_layer(token_embeddings, LAYER)\n",
    "\n",
    "                            # Get the vocab word's contextual embedding for this line.\n",
    "                            tensor_layer = torch.zeros([1, FEATURE_COUNT])\n",
    "                            for i in range(len(indices)):\n",
    "                                v_index = i % len(v_tokens[1:-1])\n",
    "                                tensor_layer += token_vecs_layer[indices[i]]\n",
    "\n",
    "                            # If our vocab word is broken into more than one token, we need to get the mean of the token embeddings.\n",
    "                            tensor_layer /= len(indices)\n",
    "\n",
    "                            # Add the embedding distilled from this line to the sum of embeddings for all lines.\n",
    "                            v_sum += tensor_layer\n",
    "                            count_tensor += 1\n",
    "\n",
    "                    # Stop processing lines once we've found MAX_LINES instances of our vocab word.\n",
    "                    if count_tensor >= MAX_LINES:\n",
    "                        break\n",
    "\n",
    "                # We're done processing all lines of 512 tokens or less containing our vocab word.\n",
    "                # Get the mean embedding for the word.\n",
    "                v_mean = v_sum / count_tensor\n",
    "                print(f'Mean of {count_tensor} tensors is: {v_mean[0][:5]} ({len(v_mean[0])} features in tensor)')\n",
    "                write_embedding(subdir_output_file, v, v_mean)\n",
    "                try:\n",
    "                    with open(subdir_count_file, 'a') as counts:\n",
    "                        counts.write(v + ', ' + str(count_tensor) + '\\n')\n",
    "                except:\n",
    "                    print('Wha?! Could not write the sentence count.')\n",
    "            end = timer()\n",
    "            print(f'Run time for {v} was {end - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(vocab_file):\n",
    "    vocab = []\n",
    "    with open(vocab_file, 'r') as v:\n",
    "        vocab = v.read().splitlines()\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_token_embeddings(tokenized_text):\n",
    "    input_ids = torch.tensor(tokenized_text).unsqueeze(0)  # Batch size 1\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, masked_lm_labels=input_ids)\n",
    "        encoded_layers = outputs[2]\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "#         print(f'Size of token embeddings is {token_embeddings.size()}')\n",
    "        return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the last 4 layers' features\n",
    "def sum_last_four_token_vecs(token_embeddings):\n",
    "    token_vecs_sum_last_four = []\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "        # `token` is a [13 x 768] tensor\n",
    "        # Sum the vectors from the last 4 layers.\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "\n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_sum_last_four.append(sum_vec)\n",
    "\n",
    "#     print ('Shape of summed layers is: %d x %d' % (len(token_vecs_sum_last_four), len(token_vecs_sum_last_four[0])))\n",
    "    # Shape is: <token count> x 768\n",
    "    return token_vecs_sum_last_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a single layer of the model.\n",
    "def get_token_vecs_layer(token_embeddings, layer_number):\n",
    "    token_vecs_layer = []\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "        # `token` is a [13 x 768] tensor\n",
    "        # Sum the vectors from the last 4 layers.\n",
    "        layer_vec = token[layer_number]\n",
    "\n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_layer.append(layer_vec)\n",
    "\n",
    "#     print ('Shape of summed layers is: %d x %d' % (len(token_vecs_layer), len(token_vecs_layer[0])))\n",
    "    # Shape is: <token count> x 768\n",
    "    return token_vecs_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_embedding(embeddings_file, vocab_word, contextual_embedding):\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(vocab_word)\n",
    "            for value in contextual_embedding[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "#         print(f'Saved the embedding for {vocab_word}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
