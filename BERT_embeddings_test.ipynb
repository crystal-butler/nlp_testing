{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679/absl_py-0.9.0-py3-none-any.whl\n",
      "Requirement already satisfied: appnope==0.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.1.0)\n",
      "Collecting astor==0.8.1\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting astroid==2.3.3\n",
      "  Using cached astroid-2.3.3-py3-none-any.whl (205 kB)\n",
      "Requirement already satisfied: attrs==19.3.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (19.3.0)\n",
      "Requirement already satisfied: backcall==0.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.1.0)\n",
      "Collecting bleach==3.1.1\n",
      "  Using cached bleach-3.1.1-py2.py3-none-any.whl (150 kB)\n",
      "Collecting blis==0.4.1\n",
      "  Using cached blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "Collecting boto==2.49.0\n",
      "  Using cached boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: boto3==1.12.26 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (1.12.26)\n",
      "Requirement already satisfied: botocore==1.15.26 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (1.15.26)\n",
      "Collecting catalogue==1.0.0\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting certifi==2019.11.28\n",
      "  Using cached certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
      "Collecting chardet==3.0.4\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting Click==7.0\n",
      "  Using cached Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (0.10.0)\n",
      "Collecting cymem==2.0.3\n",
      "  Using cached cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl (32 kB)\n",
      "Collecting Cython==0.29.15\n",
      "  Using cached Cython-0.29.15-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting decorator==4.4.1\n",
      "  Using cached decorator-4.4.1-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting defusedxml==0.6.0\n",
      "  Using cached defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting docutils==0.15.2\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting entrypoints==0.3\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting filelock==3.0.12\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting gensim==3.8.1\n",
      "  Using cached gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "Collecting google-pasta==0.1.8\n",
      "  Using cached google_pasta-0.1.8-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio==1.27.2\n",
      "  Using cached grpcio-1.27.2-cp36-cp36m-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting h5py==2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting idna==2.9\n",
      "  Using cached idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting importlib-metadata==1.5.0\n",
      "  Using cached importlib_metadata-1.5.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ipykernel==5.1.4\n",
      "  Using cached ipykernel-5.1.4-py3-none-any.whl (116 kB)\n",
      "Collecting ipython==7.12.0\n",
      "  Using cached ipython-7.12.0-py3-none-any.whl (777 kB)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 33)) (0.2.0)\n",
      "Collecting ipywidgets==7.5.1\n",
      "  Using cached ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\n",
      "Collecting isort==4.3.21\n",
      "  Using cached isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
      "Collecting jedi==0.16.0\n",
      "  Using cached jedi-0.16.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting Jinja2==2.11.1\n",
      "  Using cached Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: jmespath==0.9.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 38)) (0.9.5)\n",
      "Collecting joblib==0.14.1\n",
      "  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting jsonschema==3.2.0\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 41)) (1.0.0)\n",
      "Collecting jupyter-client==6.0.0\n",
      "  Using cached jupyter_client-6.0.0-py3-none-any.whl (104 kB)\n",
      "Collecting jupyter-console==6.1.0\n",
      "  Using cached jupyter_console-6.1.0-py2.py3-none-any.whl (21 kB)\n",
      "Collecting jupyter-core==4.6.3\n",
      "  Using cached jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01/kaggle-1.5.6-py3-none-any.whl\n",
      "Collecting Keras==2.3.1\n",
      "  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "Collecting Keras-Applications==1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting Keras-Preprocessing==1.1.0\n",
      "  Using cached Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: kiwisolver==1.1.0 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 49)) (1.1.0)\n",
      "Requirement already satisfied: lazy-object-proxy==1.4.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 50)) (1.4.3)\n",
      "Collecting Markdown==3.2.1\n",
      "  Using cached Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "Collecting MarkupSafe==1.1.1\n",
      "  Using cached MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting matplotlib==3.2.1\n",
      "  Using cached matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "Collecting mccabe==0.6.1\n",
      "  Using cached mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting mistune==0.8.4\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting murmurhash==1.0.2\n",
      "  Using cached murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (19 kB)\n",
      "Collecting nbconvert==5.6.1\n",
      "  Using cached nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\n",
      "Collecting nbformat==5.0.4\n",
      "  Using cached nbformat-5.0.4-py3-none-any.whl (169 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/e3/c9/b0/ed26a73ef75a53145820825afa8e2d2c9b30fe9f6c10cd3202/nltk-3.4.5-py3-none-any.whl\n",
      "Collecting notebook==6.0.3\n",
      "  Using cached notebook-6.0.3-py3-none-any.whl (9.7 MB)\n",
      "Collecting numpy==1.18.1\n",
      "  Using cached numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Collecting pandas==1.0.3\n",
      "  Using cached pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/46/c4/40/718c6fd14c2129ccaee10e0cf03ef6c4d01d98cad5dbbfda38/pandocfilters-1.4.2-py3-none-any.whl\n",
      "Collecting parso==0.6.1\n",
      "  Using cached parso-0.6.1-py2.py3-none-any.whl (97 kB)\n",
      "Collecting pexpect==4.8.0\n",
      "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting pickleshare==0.7.5\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting Pillow==7.0.0\n",
      "  Using cached Pillow-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting plac==1.1.3\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting preshed==3.0.2\n",
      "  Using cached preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/1d/4a/79/a3ad3f74b3495b4555359375ca33ad7b64e77f8b7a53c8894f/prometheus_client-0.7.1-py3-none-any.whl\n",
      "Collecting prompt-toolkit==3.0.3\n",
      "  Using cached prompt_toolkit-3.0.3-py3-none-any.whl (348 kB)\n",
      "Collecting protobuf==3.11.3\n",
      "  Using cached protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting ptyprocess==0.6.0\n",
      "  Using cached ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting Pygments==2.5.2\n",
      "  Using cached Pygments-2.5.2-py2.py3-none-any.whl (896 kB)\n",
      "Collecting pylint==2.4.4\n",
      "  Using cached pylint-2.4.4-py3-none-any.whl (302 kB)\n",
      "Collecting pyparsing==2.4.6\n",
      "  Using cached pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/43/9a/e4/7f687f2bb934e9a26a6e1158778ed7c5436b9ea15db48c888a/pyrsistent-0.15.7-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting python-dateutil==2.8.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting python-magic==0.4.15\n",
      "  Using cached python_magic-0.4.15-py2.py3-none-any.whl (5.5 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/5f/a9/4b/aa1ee60ccbd4389a2fe11c9b94adf3d9fa61cecda46c1187a9/python_slugify-4.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytorch-pretrained-bert==0.6.2 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 81)) (0.6.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytz==2019.3\n",
      "  Using cached pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/b1/86/0d/10e6c39d3a2b85ba807d7657ee80f08cc16c03f2aa2adf8e46/PyYAML-5.3-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting pyzmq==19.0.0\n",
      "  Using cached pyzmq-19.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting qtconsole==4.6.0\n",
      "  Using cached qtconsole-4.6.0-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: regex==2020.2.20 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 86)) (2020.2.20)\n",
      "Collecting requests==2.23.0\n",
      "  Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/60/b3/ca/8fc8ebb3a1f4997459ada0bb5ac169e7ef56cd0f1be0f407d4/s3cmd-2.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: s3transfer==0.3.3 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 89)) (0.3.3)\n",
      "Processing /home/jupyter/.cache/pip/wheels/03/e9/be/8b52f6e7e8c333b56f9440575b4c5eb4d96d27b5d22df5a71e/sacremoses-0.0.38-py3-none-any.whl\n",
      "Collecting scikit-learn==0.22.1\n",
      "  Using cached scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0 MB)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting searchtweets==1.7.4\n",
      "  Using cached searchtweets-1.7.4-py3-none-any.whl (26 kB)\n",
      "Collecting Send2Trash==1.5.0\n",
      "  Using cached Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
      "Collecting sentencepiece==0.1.85\n",
      "  Using cached sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/1f/1b/a6/a808a7e4d1f7584e42f5e279664cd48bf24ed8392218ce6be4/seqeval-0.0.12-py3-none-any.whl\n",
      "Collecting six==1.14.0\n",
      "  Using cached six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/8e/9f/cd/dbf5c1362c59abb699a218c1151679033b8ccb5b6db559d512/smart_open-1.9.0-py3-none-any.whl\n",
      "Collecting spacy==2.2.3\n",
      "  Using cached spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/4c/d4/87/69218a9183d82b15a47ddaeb44d53a0707e18c40377f320728/spacy_lookups_data-0.2.0-py2.py3-none-any.whl\n",
      "Collecting srsly==1.0.1\n",
      "  Using cached srsly-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (185 kB)\n",
      "Collecting tensorboard==1.14.0\n",
      "  Using cached tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting tensorboardX==2.0\n",
      "  Using cached tensorboardX-2.0-py2.py3-none-any.whl (195 kB)\n",
      "Collecting tensorflow==1.14.0\n",
      "  Using cached tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
      "Collecting tensorflow-estimator==1.14.0\n",
      "  Using cached tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting terminado==0.8.3\n",
      "  Using cached terminado-0.8.3-py2.py3-none-any.whl (33 kB)\n",
      "Collecting testpath==0.4.4\n",
      "  Using cached testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting text-unidecode==1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting thinc==7.3.1\n",
      "  Using cached thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting tokenizers==0.5.0\n",
      "  Using cached tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\n",
      "Collecting torch==1.4.0\n",
      "  Using cached torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4 MB)\n",
      "Collecting torchvision==0.5.0\n",
      "  Using cached torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/b2/92/5c/3bfc125cdf46ab0487727e574f513f9568e9b7974b15237abf/tornado-6.0.3-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting tqdm==4.43.0\n",
      "  Using cached tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting traitlets==4.3.3\n",
      "  Using cached traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting transformers==2.5.0\n",
      "  Using cached transformers-2.5.0-py3-none-any.whl (481 kB)\n",
      "Collecting tweet-parser==1.13.2\n",
      "  Using cached tweet_parser-1.13.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: typed-ast==1.4.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 119)) (1.4.1)\n",
      "Collecting urllib3==1.25.8\n",
      "  Using cached urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
      "Collecting wasabi==0.6.0\n",
      "  Using cached wasabi-0.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting wcwidth==0.1.8\n",
      "  Using cached wcwidth-0.1.8-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 123)) (0.5.1)\n",
      "Collecting Werkzeug==1.0.0\n",
      "  Using cached Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)\n",
      "Collecting widgetsnbextension==3.5.1\n",
      "  Using cached widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/0d/85/48/15d7bfab92a2d0e87372224c1f628fc57db7447a663a58e86c/wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting zipp==3.0.0\n",
      "  Using cached zipp-3.0.0-py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/jupyter/anaconda3/lib/python3.6/site-packages (from ipython==7.12.0->-r requirements.txt (line 32)) (40.8.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/jupyter/anaconda3/lib/python3.6/site-packages (from tensorboard==1.14.0->-r requirements.txt (line 102)) (0.29.0)\n",
      "\u001b[31mERROR: scikit-image 0.15.0 has requirement networkx>=2.0, but you'll have networkx 1.11 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.8 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 40.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, absl-py, astor, wrapt, astroid, bleach, numpy, blis, boto, zipp, importlib-metadata, catalogue, certifi, chardet, Click, cymem, Cython, decorator, defusedxml, docutils, entrypoints, filelock, gast, idna, urllib3, requests, smart-open, scipy, gensim, google-pasta, grpcio, h5py, pyzmq, tornado, traitlets, jupyter-core, python-dateutil, jupyter-client, wcwidth, prompt-toolkit, ptyprocess, pexpect, Pygments, parso, jedi, pickleshare, ipython, ipykernel, mistune, testpath, pandocfilters, pyrsistent, jsonschema, nbformat, MarkupSafe, Jinja2, nbconvert, Send2Trash, terminado, prometheus-client, notebook, widgetsnbextension, ipywidgets, isort, joblib, jupyter-console, text-unidecode, python-slugify, tqdm, kaggle, Keras-Applications, Keras-Preprocessing, PyYAML, Keras, Markdown, pyparsing, matplotlib, mccabe, murmurhash, nltk, pytz, pandas, Pillow, plac, preshed, protobuf, pylint, python-magic, qtconsole, s3cmd, sacremoses, scikit-learn, tweet-parser, searchtweets, sentencepiece, seqeval, wasabi, srsly, thinc, spacy, spacy-lookups-data, Werkzeug, tensorboard, tensorboardX, termcolor, tensorflow-estimator, tensorflow, tokenizers, torch, torchvision, transformers\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.10.0\n",
      "\u001b[31mERROR: Cannot uninstall 'six'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgusted'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]\n",
    "list(tokenizer.vocab.keys())[17733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'she', 'made', 'a', 'disgusted', 'po', '##ut', '[SEP]', 'her', 'disgusted', 'expression', 'was', 'con', '##tag', '##ious', '[SEP]']\n",
      "[CLS]           101\n",
      "she           2,016\n",
      "made          2,081\n",
      "a             1,037\n",
      "disgusted    17,733\n",
      "po           13,433\n",
      "##ut          4,904\n",
      "[SEP]           102\n",
      "her           2,014\n",
      "disgusted    17,733\n",
      "expression    3,670\n",
      "was           2,001\n",
      "con           9,530\n",
      "##tag        15,900\n",
      "##ious        6,313\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "# text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "#        \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# text = \"[CLS] Why the disgusted face [SEP] Did you smell some disgustingly ripe cheese [SEP]\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Add the special tokens.\n",
    "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "# tokenized_text = tokenizer.tokenize(marked_text)\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'disgusted', '[SEP]']\n",
      "[CLS]           101\n",
      "disgusted    17,733\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "# text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "#        \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# text = \"[CLS] Why the disgusted face [SEP] Did you smell some disgustingly ripe cheese [SEP]\"\n",
    "text = \"[CLS] disgusted [SEP]\"\n",
    "\n",
    "# Add the special tokens.\n",
    "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "# tokenized_text = tokenizer.tokenize(marked_text)\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "[101, 17733, 102]\n",
      "disgusted\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the tokens as belonging to sentence \"0\" or \"1\".\n",
    "# segments_ids = [1] * len(tokenized_text)\n",
    "segments_ids = [0,0,0]\n",
    "# segments_ids = [0,0,0,1,1]\n",
    "print (segments_ids)\n",
    "print(indexed_tokens)\n",
    "print(tokenized_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 3\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 1\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 1\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# print(vec)\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type of encoded_layers:  <class 'list'>\n",
      "Tensor shape for each layer:  torch.Size([1, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 3, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:4], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_first.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_first), len(token_vecs_sum_first[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[4:8], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle1.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle1), len(token_vecs_sum_middle1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[8:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle2.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle2), len(token_vecs_sum_middle2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 9216\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3], token[4], token[5], token[6], token[7], token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_all.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_all), len(token_vecs_cat_all[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_all.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_all), len(token_vecs_sum_all[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n",
      "tensor(-0.1680)\n",
      "tensor(-0.1680)\n",
      "Shape of sentences vector is: 768\n",
      "tensor(-0.1680)\n"
     ]
    }
   ],
   "source": [
    "# Make a single vector to represent the pair of sentences by averaging across tokens.\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "sentences_vec = []\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "for s in sentence_embedding:\n",
    "    sentences_vec.append(s)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "print(sentence_embedding[767])\n",
    "print(sentence_embedding[-1])\n",
    "print(f'Shape of sentences vector is: {len(sentences_vec)}')\n",
    "print(sentences_vec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 disgusted\n",
      "2 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_string in enumerate(tokenized_text):\n",
    "    print(i, token_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of disgusted and disgusted in token_vecs_cat is: 1.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ccf33d5dd0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vecs_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_vecs_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Similarity of {tokenized_text[1]} and {tokenized_text[1]} in token_vecs_cat is: {similarity}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vecs_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_vecs_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vecs_cat_first\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_vecs_cat_first\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "similarity = 1 - cosine(token_vecs_cat[1], token_vecs_cat[1])\n",
    "print(f'Similarity of {tokenized_text[1]} and {tokenized_text[1]} in token_vecs_cat is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum[4], token_vecs_sum[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_first[4], token_vecs_cat_first[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_first is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_first[4], token_vecs_sum_first[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_first is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_middle1[4], token_vecs_cat_middle1[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle1 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_middle1[4], token_vecs_sum_middle1[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle1 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_middle2[4], token_vecs_cat_middle2[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle2 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_middle2[4], token_vecs_sum_middle2[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle2 is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_cat_all[4], token_vecs_cat_all[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_all is: {similarity}')\n",
    "similarity = 1 - cosine(token_vecs_sum_all[4], token_vecs_sum_all[9])\n",
    "print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_all is: {similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
