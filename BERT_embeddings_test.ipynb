{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Notebooks/crystal/NLP/nlp_testing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the tutorial at https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgusted'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]\n",
    "list(tokenizer.vocab.keys())[17733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'she', 'made', 'a', 'disgusted', 'po', '##ut', '[SEP]', 'her', 'disgusted', 'expression', 'was', 'con', '##tag', '##ious', '[SEP]']\n",
      "[CLS]           101\n",
      "she           2,016\n",
      "made          2,081\n",
      "a             1,037\n",
      "disgusted    17,733\n",
      "po           13,433\n",
      "##ut          4,904\n",
      "[SEP]           102\n",
      "her           2,014\n",
      "disgusted    17,733\n",
      "expression    3,670\n",
      "was           2,001\n",
      "con           9,530\n",
      "##tag        15,900\n",
      "##ious        6,313\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"disgusted\"\n",
    "text = \"[CLS] She made a disgusted pout [SEP] Her disgusted expression was contagious [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "[11113, 16368, 5596]\n",
      "['ab', '##hor', '##red']\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the tokens as belonging to sentence \"0\" or \"1\".\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text[3])\n",
    "# segments_ids = [0,0,0]\n",
    "print (segments_ids)\n",
    "print(indexed_tokens)\n",
    "print(tokenized_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens[3]])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 3\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 1\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For our token, select its feature values from layer 5.\n",
    "token_i = 1\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# print(vec)\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type of encoded_layers:  <class 'list'>\n",
      "Tensor shape for each layer:  torch.Size([1, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 3, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_first.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_first), len(token_vecs_cat_first[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_first = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:4], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_first.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_first), len(token_vecs_sum_first[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[4], token[5], token[6], token[7]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle1.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle1), len(token_vecs_cat_middle1[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle1 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[4:8], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle1.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle1), len(token_vecs_sum_middle1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_middle2.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_middle2), len(token_vecs_cat_middle2[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_middle2 = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[8:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_middle2.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_middle2), len(token_vecs_sum_middle2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 9216\n",
      "tensor([-0.0637,  0.3612, -0.0899,  ..., -0.4850, -0.3801,  0.8791])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[0], token[1], token[2], token[3], token[4], token[5], token[6], token[7], token[8], token[9], token[10], token[11]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat_all.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat_all), len(token_vecs_cat_all[0])))\n",
    "print(token_vecs_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 3 x 768\n"
     ]
    }
   ],
   "source": [
    "# Sum the last 4 hidden layers to create word embeddings.\n",
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum_all = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum_all.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum_all), len(token_vecs_sum_all[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n",
      "tensor(-0.1680)\n",
      "tensor(-0.1680)\n",
      "Shape of sentences vector is: 768\n",
      "tensor(-0.1680)\n"
     ]
    }
   ],
   "source": [
    "# Make a single vector to represent the pair of sentences by averaging across tokens.\n",
    "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
    "sentences_vec = []\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = encoded_layers[11][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "for s in sentence_embedding:\n",
    "    sentences_vec.append(s)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "print(sentence_embedding[767])\n",
    "print(sentence_embedding[-1])\n",
    "print(f'Shape of sentences vector is: {len(sentences_vec)}')\n",
    "print(sentences_vec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "BEGIN TESTING STATIC CONTEXTUAL EMBEDDING CREATION\n",
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(vocab_file):\n",
    "    # start = timer()\n",
    "    vocab = []\n",
    "    # vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "    with open(vocab_file, 'r') as v:\n",
    "        vocab = v.read().splitlines()\n",
    "    # end = timer()\n",
    "    # run_time = end - start\n",
    "#     print(f'There are {len(vocab)} words in the vocabulary.\\n')\n",
    "#     print(f'It took {run_time} seconds to read the vocabulary file into memory.')\n",
    "#     print(f'Test word is {vocab[2]}.')\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(vocab):\n",
    "    tokenized_text = []\n",
    "    indexed_tokens = []\n",
    "    for word in vocab:\n",
    "        # Add the special tokens.\n",
    "    #     marked_text = \"[CLS] \" + word + \" [SEP]\"\n",
    "        marked_text = word\n",
    "\n",
    "        # Split the sentence into tokens.\n",
    "        # tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        tokenized_text.append(tokenizer.tokenize(marked_text))\n",
    "#         print(f'Added {tokenized_text[-1]} to the tokenized_text array.')\n",
    "\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens.append(tokenizer.convert_tokens_to_ids(tokenized_text[-1]))\n",
    "\n",
    "        # Display the words with their indeces.\n",
    "    #     print(f'The word {tokenized_text[-1][1]} is at index {indexed_tokens[-1]}.')\n",
    "#         for tup in zip(tokenized_text[-1], indexed_tokens[-1]):\n",
    "#             print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "    return tokenized_text, indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreate vocabulary words from their tokenized representations.\n",
    "for t in tokenized_text:\n",
    "    this_word = ''\n",
    "    for token in t:\n",
    "        this_word += token.strip('#')\n",
    "#     print(this_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_segments_IDs(tokenized_text):\n",
    "    # Create segment IDs for sentence 1 (there can be a sentence 0 to compare to\n",
    "    # sentence 1, but we're not doing that).\n",
    "    # Check that indices and token indices look correct.\n",
    "    segments_IDs = []\n",
    "    for i in range(len(tokenized_text)):\n",
    "        segments_IDs.append([1] * len(tokenized_text[i]))\n",
    "#     for i in range(len(segments_IDs)):\n",
    "#         print (segments_IDs[i])\n",
    "#         print(tokenized_text[i])\n",
    "    return segments_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aback'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2373,  0.8259, -0.6190,  ..., -0.3836, -0.5039,  0.6153])\n",
      "aback\n",
      "Saved the embedding for aback.\n",
      "['aba', '##shed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1037, -0.2061,  0.1823,  ..., -0.5667, -1.2614,  0.1785])\n",
      "abashed\n",
      "Saved the embedding for abashed.\n",
      "['ab', '##hor'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8100,  0.2958,  0.1761,  ..., -0.9277, -0.8062,  0.7046])\n",
      "abhor\n",
      "Saved the embedding for abhor.\n",
      "['ab', '##hor', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1539,  0.0500,  0.2618,  ..., -1.0918, -0.8056,  0.2805])\n",
      "abhorred\n",
      "Saved the embedding for abhorred.\n",
      "['ab', '##hor', '##rence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0112, -0.1689,  0.0145,  ..., -1.3856, -0.4802,  0.5721])\n",
      "abhorrence\n",
      "Saved the embedding for abhorrence.\n",
      "['ab', '##hor', '##rent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7003,  0.2077, -0.1644,  ..., -0.7574, -0.6082,  0.7269])\n",
      "abhorrent\n",
      "Saved the embedding for abhorrent.\n",
      "['ab', '##omi', '##nable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3632,  0.3420, -0.0184,  ..., -0.8016, -0.5560,  0.4945])\n",
      "abominable\n",
      "Saved the embedding for abominable.\n",
      "['ab', '##ound'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4796,  0.3083,  0.4205,  ..., -0.9699, -0.6195,  0.5936])\n",
      "abound\n",
      "Saved the embedding for abound.\n",
      "['absent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2708, -0.1306,  0.1428,  ..., -0.9095, -0.4269,  0.4357])\n",
      "absent\n",
      "Saved the embedding for absent.\n",
      "['absorbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6000,  0.4997, -0.1557,  ..., -0.8168,  0.2081,  0.8431])\n",
      "absorbed\n",
      "Saved the embedding for absorbed.\n",
      "['acceptance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2750,  0.0333, -0.1074,  ..., -0.9110, -0.0890,  0.9780])\n",
      "acceptance\n",
      "Saved the embedding for acceptance.\n",
      "['accepted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0041,  0.4423, -0.3754,  ...,  0.3482, -1.2463,  0.4428])\n",
      "accepted\n",
      "Saved the embedding for accepted.\n",
      "['accepting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5105,  0.1028,  0.3867,  ...,  0.5304, -0.7425, -0.1306])\n",
      "accepting\n",
      "Saved the embedding for accepting.\n",
      "['acc', '##om', '##mo', '##dating'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7920,  0.4755,  0.1106,  ..., -0.1346, -0.3157,  0.2619])\n",
      "accommodating\n",
      "Saved the embedding for accommodating.\n",
      "['accomplished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5843, -0.0792, -0.0899,  ..., -1.4975,  0.0648, -0.2409])\n",
      "accomplished\n",
      "Saved the embedding for accomplished.\n",
      "['accord', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3542, -0.7072,  0.4754,  ..., -1.7806,  0.0599,  0.3717])\n",
      "accordant\n",
      "Saved the embedding for accordant.\n",
      "['acc', '##urse', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0540,  0.6120, -0.2778,  ..., -0.6644, -0.6046,  0.0739])\n",
      "accursed\n",
      "Saved the embedding for accursed.\n",
      "['acc', '##usa', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5983,  0.6879, -0.2571,  ..., -0.5666, -0.4279,  0.0431])\n",
      "accusatory\n",
      "Saved the embedding for accusatory.\n",
      "['accused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0690,  0.4033,  0.3813,  ...,  0.3111, -0.0225,  0.2333])\n",
      "accused\n",
      "Saved the embedding for accused.\n",
      "['accusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0907,  0.2723,  0.2785,  ..., -0.7853, -0.7943,  0.8752])\n",
      "accusing\n",
      "Saved the embedding for accusing.\n",
      "['ace', '##rb', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4581,  0.0637, -0.6935,  ..., -0.7794, -0.6992,  0.2288])\n",
      "acerbic\n",
      "Saved the embedding for acerbic.\n",
      "['acidic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7677,  0.1286, -0.0383,  ...,  0.5036, -0.9351,  0.8139])\n",
      "acidic\n",
      "Saved the embedding for acidic.\n",
      "['active'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2689, -0.0689, -0.0900,  ..., -0.2531, -0.4038,  0.1764])\n",
      "active\n",
      "Saved the embedding for active.\n",
      "['acute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3161,  0.3277, -0.0563,  ..., -0.2590,  0.1832,  0.1889])\n",
      "acute\n",
      "Saved the embedding for acute.\n",
      "['adamant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3315,  0.5140, -0.0323,  ...,  0.2222,  0.2586,  1.7581])\n",
      "adamant\n",
      "Saved the embedding for adamant.\n",
      "['add', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1139,  0.3247,  0.7486,  ..., -0.9490, -0.2298,  1.1215])\n",
      "addled\n",
      "Saved the embedding for addled.\n",
      "['admiration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2719,  0.5031, -0.3238,  ...,  0.1310, -0.6015,  0.8009])\n",
      "admiration\n",
      "Saved the embedding for admiration.\n",
      "['admit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1357, -0.1807,  0.3170,  ...,  0.8142, -0.2286,  1.1910])\n",
      "admit\n",
      "Saved the embedding for admit.\n",
      "['ad', '##oration'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2362,  0.7565,  0.3785,  ..., -1.0365, -0.3349,  0.9947])\n",
      "adoration\n",
      "Saved the embedding for adoration.\n",
      "['ad', '##orin', '##g'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3333,  0.2409,  0.3639,  ..., -1.6787, -1.3319, -0.4478])\n",
      "adoring\n",
      "Saved the embedding for adoring.\n",
      "['ad', '##rift'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0313,  0.1849,  0.6698,  ..., -1.7563, -0.5052,  0.8380])\n",
      "adrift\n",
      "Saved the embedding for adrift.\n",
      "['ad', '##vers', '##aria', '##l'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3280,  0.6008,  0.2973,  ..., -0.8354, -0.4468,  0.4731])\n",
      "adversarial\n",
      "Saved the embedding for adversarial.\n",
      "['af', '##fa', '##bility'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2286,  0.5322,  0.3789,  ..., -1.6908, -0.9226,  0.3890])\n",
      "affability\n",
      "Saved the embedding for affability.\n",
      "['affected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1301,  0.1637, -0.2379,  ...,  0.1358, -0.4344,  0.3097])\n",
      "affected\n",
      "Saved the embedding for affected.\n",
      "['affection', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0943,  0.8675,  0.0496,  ...,  0.3261, -1.2256,  0.5957])\n",
      "affectionate\n",
      "Saved the embedding for affectionate.\n",
      "['af', '##flict', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0861,  0.2911,  0.0872,  ..., -1.3500, -0.3538,  0.2539])\n",
      "afflicted\n",
      "Saved the embedding for afflicted.\n",
      "['af', '##front', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3762, -0.2510,  0.3312,  ..., -0.8264, -0.5662,  0.8707])\n",
      "affronted\n",
      "Saved the embedding for affronted.\n",
      "['afl', '##utter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0084, -0.2027,  0.2687,  ..., -0.4899, -0.6923,  1.1249])\n",
      "aflutter\n",
      "Saved the embedding for aflutter.\n",
      "['afraid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3205, -0.1837,  0.1936,  ..., -0.3755, -0.7044,  1.1062])\n",
      "afraid\n",
      "Saved the embedding for afraid.\n",
      "['ag', '##ape'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4893,  0.3159,  0.1739,  ..., -0.4965, -0.5257,  0.5663])\n",
      "agape\n",
      "Saved the embedding for agape.\n",
      "['aggravated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2621,  0.2851, -0.1411,  ..., -1.3743, -0.2912, -0.0267])\n",
      "aggravated\n",
      "Saved the embedding for aggravated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ag', '##gra', '##vation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4945,  0.4427, -0.4905,  ...,  0.3184, -0.1085,  0.4077])\n",
      "aggravation\n",
      "Saved the embedding for aggravation.\n",
      "['aggression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0964, -0.3315, -0.4422,  ..., -0.7226, -0.8147,  0.6407])\n",
      "aggression\n",
      "Saved the embedding for aggression.\n",
      "['aggressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1769, -0.2582, -0.0493,  ...,  0.1390, -0.6079,  0.6387])\n",
      "aggressive\n",
      "Saved the embedding for aggressive.\n",
      "['ag', '##gr', '##ie', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4852, -0.0223,  0.2060,  ..., -0.7569, -0.1021,  0.4570])\n",
      "aggrieve\n",
      "Saved the embedding for aggrieve.\n",
      "['ag', '##gr', '##ie', '##ved'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8501, -0.0982,  0.5716,  ..., -1.7265,  0.1769, -0.1532])\n",
      "aggrieved\n",
      "Saved the embedding for aggrieved.\n",
      "['ag', '##has', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9525,  0.4587,  0.1513,  ..., -1.2460, -0.1107,  0.5333])\n",
      "aghast\n",
      "Saved the embedding for aghast.\n",
      "['agitated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7322, -0.3774, -0.0408,  ..., -1.1506,  0.0442,  0.2357])\n",
      "agitated\n",
      "Saved the embedding for agitated.\n",
      "['ago', '##g'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0907,  0.2185,  0.1729,  ..., -0.1004, -0.4458,  0.2241])\n",
      "agog\n",
      "Saved the embedding for agog.\n",
      "['ago', '##ni', '##zed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0648,  0.0734,  0.8986,  ..., -0.9070, -0.8837, -0.0660])\n",
      "agonized\n",
      "Saved the embedding for agonized.\n",
      "['agree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4927,  0.0340,  0.7553,  ..., -0.6633, -0.6205, -0.1947])\n",
      "agreeable\n",
      "Saved the embedding for agreeable.\n",
      "['ag', '##ress', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7180,  0.2221,  0.0947,  ...,  0.1374, -0.2592,  0.5267])\n",
      "agressive\n",
      "Saved the embedding for agressive.\n",
      "['air', '##head'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1131, -0.0616,  0.6318,  ..., -0.2125, -0.8215,  0.2158])\n",
      "airhead\n",
      "Saved the embedding for airhead.\n",
      "['alarm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4408,  0.6039,  0.4678,  ..., -1.2180,  0.0292,  0.8078])\n",
      "alarm\n",
      "Saved the embedding for alarm.\n",
      "['alarmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9173,  0.1258, -0.1044,  ..., -0.3449, -0.5166,  0.5035])\n",
      "alarmed\n",
      "Saved the embedding for alarmed.\n",
      "['alarm', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4135,  0.5137,  0.2220,  ..., -1.5530, -0.1155,  0.8775])\n",
      "alarming\n",
      "Saved the embedding for alarming.\n",
      "['alert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4819,  0.1837, -0.4875,  ..., -1.3898, -0.0469,  1.0680])\n",
      "alert\n",
      "Saved the embedding for alert.\n",
      "['alerted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.3487,  0.8050,  0.2461,  ..., -0.1347, -0.3578,  0.5232])\n",
      "alerted\n",
      "Saved the embedding for alerted.\n",
      "['alien', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4017,  0.4536,  0.0623,  ..., -0.4019,  0.0789,  0.5852])\n",
      "alienated\n",
      "Saved the embedding for alienated.\n",
      "['allergic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4287,  0.2403,  0.7898,  ..., -0.2957,  0.4079,  0.4774])\n",
      "allergic\n",
      "Saved the embedding for allergic.\n",
      "['alleviate', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6702, -0.4932,  0.4466,  ..., -1.0551, -0.7797,  0.8286])\n",
      "alleviated\n",
      "Saved the embedding for alleviated.\n",
      "['all', '##uring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1305, -0.0170, -0.0709,  ..., -0.2038, -1.0485,  0.3278])\n",
      "alluring\n",
      "Saved the embedding for alluring.\n",
      "['al', '##oof'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1029,  0.2316,  0.0316,  ..., -1.0534, -0.1947,  0.8658])\n",
      "aloof\n",
      "Saved the embedding for aloof.\n",
      "['ama', '##tory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1919,  0.0887,  0.2247,  ..., -1.3527, -1.5234,  1.3223])\n",
      "amatory\n",
      "Saved the embedding for amatory.\n",
      "['amazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2819,  0.1723, -0.0864,  ...,  0.0060, -0.5109,  0.9866])\n",
      "amazed\n",
      "Saved the embedding for amazed.\n",
      "['amazement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1924,  0.3301,  0.2287,  ..., -0.4325, -0.1302,  1.1591])\n",
      "amazement\n",
      "Saved the embedding for amazement.\n",
      "['amazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1168, -0.4531, -0.4541,  ..., -1.3009, -1.1459,  1.0407])\n",
      "amazing\n",
      "Saved the embedding for amazing.\n",
      "['ambition'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9133,  0.3705, -0.3574,  ..., -0.7685, -0.9231,  0.1898])\n",
      "ambition\n",
      "Saved the embedding for ambition.\n",
      "['ambitious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3204,  0.7909, -0.1531,  ..., -1.3316, -0.4857,  0.1356])\n",
      "ambitious\n",
      "Saved the embedding for ambitious.\n",
      "['am', '##bi', '##vale', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2435, -0.3014,  0.1312,  ..., -0.5940, -0.4755,  0.1346])\n",
      "ambivalence\n",
      "Saved the embedding for ambivalence.\n",
      "['am', '##bi', '##valent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7171,  0.2322, -0.3888,  ..., -0.9257, -0.1040,  0.0186])\n",
      "ambivalent\n",
      "Saved the embedding for ambivalent.\n",
      "['am', '##ena', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2598, -0.3560,  0.0454,  ..., -0.6404, -0.7686, -0.0317])\n",
      "amenable\n",
      "Saved the embedding for amenable.\n",
      "['ami', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1037,  0.2970, -0.2802,  ..., -0.6394, -0.6790,  0.8653])\n",
      "amiable\n",
      "Saved the embedding for amiable.\n",
      "['ami', '##cable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0748, -0.0053,  0.4045,  ..., -0.8139, -1.1059,  0.9505])\n",
      "amicable\n",
      "Saved the embedding for amicable.\n",
      "['amused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4531,  0.6412,  0.3406,  ..., -1.3181, -0.3632, -0.1923])\n",
      "amused\n",
      "Saved the embedding for amused.\n",
      "['amusement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3070,  0.1172,  0.5320,  ..., -0.3696, -0.4828,  1.3844])\n",
      "amusement\n",
      "Saved the embedding for amusement.\n",
      "['analytical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2199, -0.0057, -0.4314,  ...,  0.0694, -0.0505,  1.0146])\n",
      "analytical\n",
      "Saved the embedding for analytical.\n",
      "['analyzing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7818,  0.0674,  0.1211,  ..., -0.3825, -0.2171,  0.7254])\n",
      "analyzing\n",
      "Saved the embedding for analyzing.\n",
      "['anger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0296, -0.2050,  0.2602,  ...,  0.2567, -0.5500,  1.1205])\n",
      "anger\n",
      "Saved the embedding for anger.\n",
      "['angered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3882,  0.3671,  0.5460,  ..., -1.0539,  0.1104,  1.1467])\n",
      "angered\n",
      "Saved the embedding for angered.\n",
      "['angrily'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5947,  0.1541,  0.4653,  ..., -1.0226, -0.1298,  0.4084])\n",
      "angrily\n",
      "Saved the embedding for angrily.\n",
      "['angry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3963, -0.0317,  0.0876,  ...,  0.0359, -0.4109,  0.8028])\n",
      "angry\n",
      "Saved the embedding for angry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ang', '##st'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4853,  0.1324,  0.4863,  ..., -0.7058, -0.4154,  0.3137])\n",
      "angst\n",
      "Saved the embedding for angst.\n",
      "['anguish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2006,  0.2713, -0.4094,  ..., -0.7437,  0.3730, -0.2416])\n",
      "anguish\n",
      "Saved the embedding for anguish.\n",
      "['anguish', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2117,  0.0008, -0.4303,  ..., -0.7570, -0.0793, -0.3513])\n",
      "anguished\n",
      "Saved the embedding for anguished.\n",
      "['animated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0165,  0.4059,  0.2465,  ..., -0.1559, -0.0591,  0.7104])\n",
      "animated\n",
      "Saved the embedding for animated.\n",
      "['an', '##imo', '##sity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.0127,  1.1249,  0.7201,  ..., -1.0992, -0.5671,  0.9526])\n",
      "animosity\n",
      "Saved the embedding for animosity.\n",
      "['annoyance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1460,  0.2150,  0.0861,  ...,  0.0328, -0.4941,  0.6567])\n",
      "annoyance\n",
      "Saved the embedding for annoyance.\n",
      "['annoyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2345,  0.3697,  0.3863,  ...,  0.1740, -0.2896,  0.4167])\n",
      "annoyed\n",
      "Saved the embedding for annoyed.\n",
      "['annoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0371,  0.2048,  0.2920,  ..., -0.5341, -0.2467,  0.8403])\n",
      "annoying\n",
      "Saved the embedding for annoying.\n",
      "['antagonist', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5019,  0.8729, -0.3280,  ..., -1.0934, -0.2346,  0.5792])\n",
      "antagonistic\n",
      "Saved the embedding for antagonistic.\n",
      "['ant', '##ago', '##ni', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0575,  1.2248, -0.2260,  ..., -0.2740, -0.3910, -0.1688])\n",
      "antagonized\n",
      "Saved the embedding for antagonized.\n",
      "['anticipated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5296,  0.2431, -0.5398,  ...,  0.2525, -1.1772,  0.0375])\n",
      "anticipated\n",
      "Saved the embedding for anticipated.\n",
      "['anticipating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6501,  0.4298, -0.2304,  ..., -0.4565, -0.5258,  0.2487])\n",
      "anticipating\n",
      "Saved the embedding for anticipating.\n",
      "['anticipation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0071,  0.5307,  0.0635,  ..., -1.5622,  0.1144,  0.3832])\n",
      "anticipation\n",
      "Saved the embedding for anticipation.\n",
      "['anti', '##ci', '##pati', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0123,  0.3868, -0.1501,  ..., -1.2574,  0.2238, -0.1776])\n",
      "anticipative\n",
      "Saved the embedding for anticipative.\n",
      "['anti', '##ci', '##pa', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1752,  0.5887,  0.3335,  ..., -0.7100, -0.0787,  0.2465])\n",
      "anticipatory\n",
      "Saved the embedding for anticipatory.\n",
      "['anti', '##pathy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2279,  0.6311,  0.2111,  ..., -1.5682, -0.5801,  0.8457])\n",
      "antipathy\n",
      "Saved the embedding for antipathy.\n",
      "['ants', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1124,  0.5277, -0.3294,  ..., -1.1690, -0.9452,  0.8203])\n",
      "antsy\n",
      "Saved the embedding for antsy.\n",
      "['anxiety'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0502, -0.2964, -0.2046,  ...,  0.7279, -0.7108,  0.5635])\n",
      "anxiety\n",
      "Saved the embedding for anxiety.\n",
      "['anxious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1354,  0.5848,  0.3970,  ..., -0.3244, -0.3684, -0.1216])\n",
      "anxious\n",
      "Saved the embedding for anxious.\n",
      "['anxiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5266, -0.0009,  0.2004,  ..., -0.5359, -0.2201,  0.0913])\n",
      "anxiously\n",
      "Saved the embedding for anxiously.\n",
      "['ap', '##ath', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6342,  0.5019, -0.0249,  ..., -0.7898,  0.0538,  0.4499])\n",
      "apathetic\n",
      "Saved the embedding for apathetic.\n",
      "['ap', '##athy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0295,  0.4919, -0.0917,  ..., -1.6390, -0.8107,  0.1106])\n",
      "apathy\n",
      "Saved the embedding for apathy.\n",
      "['apologetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1332,  0.2657, -0.4385,  ..., -0.7535, -0.5398,  0.6289])\n",
      "apologetic\n",
      "Saved the embedding for apologetic.\n",
      "['appalled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5962,  0.1078, -0.2629,  ..., -0.9594, -0.3276,  0.3759])\n",
      "appalled\n",
      "Saved the embedding for appalled.\n",
      "['app', '##all', '##ingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2851,  0.7168,  0.4470,  ..., -0.5601, -0.0405,  0.0338])\n",
      "appallingly\n",
      "Saved the embedding for appallingly.\n",
      "['app', '##eased'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1458,  0.3612,  0.7695,  ..., -0.8541,  0.1871,  0.2380])\n",
      "appeased\n",
      "Saved the embedding for appeased.\n",
      "['app', '##ea', '##sing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0209,  0.1074,  0.4885,  ..., -0.6922, -0.0683,  0.0427])\n",
      "appeasing\n",
      "Saved the embedding for appeasing.\n",
      "['app', '##re', '##cia', '##tive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2460,  0.3259,  0.4682,  ..., -0.1415, -0.2342,  0.1417])\n",
      "appreciative\n",
      "Saved the embedding for appreciative.\n",
      "['apprehension'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0307, -0.0607,  0.6147,  ..., -0.2570, -0.2261,  0.5004])\n",
      "apprehension\n",
      "Saved the embedding for apprehension.\n",
      "['app', '##re', '##hen', '##sive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3470,  0.6160,  0.1611,  ..., -0.5913,  0.0902,  0.5981])\n",
      "apprehensive\n",
      "Saved the embedding for apprehensive.\n",
      "['approve'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5701,  0.4328, -0.1224,  ..., -0.6791, -0.4873,  0.6092])\n",
      "approve\n",
      "Saved the embedding for approve.\n",
      "['approved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8869,  0.2494, -0.7879,  ..., -0.6093, -0.1666,  0.8195])\n",
      "approved\n",
      "Saved the embedding for approved.\n",
      "['app', '##roving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0459,  0.1951,  0.4114,  ..., -1.3983,  0.0180,  0.5507])\n",
      "approving\n",
      "Saved the embedding for approving.\n",
      "['argue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0868,  0.0038,  0.1861,  ..., -0.1942,  0.1664,  0.3342])\n",
      "argue\n",
      "Saved the embedding for argue.\n",
      "['argument', '##ative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0261,  0.3607,  0.3159,  ..., -0.3852, -0.0646,  0.7994])\n",
      "argumentative\n",
      "Saved the embedding for argumentative.\n",
      "['aroused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4446,  1.4970, -0.0639,  ..., -1.0276, -0.4701,  0.7040])\n",
      "aroused\n",
      "Saved the embedding for aroused.\n",
      "['arrogance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.6816,  0.2519, -0.3034,  ..., -0.3440, -1.1434,  1.2203])\n",
      "arrogance\n",
      "Saved the embedding for arrogance.\n",
      "['arrogant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5059, -0.0785,  0.2325,  ..., -0.1202, -0.5168,  0.3829])\n",
      "arrogant\n",
      "Saved the embedding for arrogant.\n",
      "['arrogant', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0555,  0.8686,  0.0151,  ..., -0.4352, -0.7162,  0.2477])\n",
      "arrogantly\n",
      "Saved the embedding for arrogantly.\n",
      "['artificial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4388,  0.2134,  0.0869,  ..., -0.3584, -0.4470,  0.6959])\n",
      "artificial\n",
      "Saved the embedding for artificial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ashamed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5104,  0.4469, -0.3548,  ..., -0.0204, -0.7246,  0.7084])\n",
      "ashamed\n",
      "Saved the embedding for ashamed.\n",
      "['aspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7016, -0.0617, -1.1961,  ..., -0.2038, -1.0683,  1.2431])\n",
      "aspiring\n",
      "Saved the embedding for aspiring.\n",
      "['assert', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5499, -0.0697, -0.8019,  ..., -0.6104, -0.8485,  0.4657])\n",
      "assertive\n",
      "Saved the embedding for assertive.\n",
      "['assert', '##ively'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4839,  0.8503, -0.5544,  ..., -0.8873,  0.2028, -0.2159])\n",
      "assertively\n",
      "Saved the embedding for assertively.\n",
      "['assessing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0186,  0.1184, -0.3297,  ..., -0.7483, -0.5208,  1.1083])\n",
      "assessing\n",
      "Saved the embedding for assessing.\n",
      "['assured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7166, -0.3712,  0.6573,  ..., -1.1613,  0.3929,  0.1652])\n",
      "assured\n",
      "Saved the embedding for assured.\n",
      "['astonished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3399,  0.3407,  0.4948,  ..., -0.0054, -0.4249,  0.8933])\n",
      "astonished\n",
      "Saved the embedding for astonished.\n",
      "['astonishment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1869,  0.5405, -0.1556,  ..., -0.7669, -0.4782,  0.3620])\n",
      "astonishment\n",
      "Saved the embedding for astonishment.\n",
      "['as', '##tou', '##nded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5395,  0.0406, -0.1097,  ..., -1.5908, -0.6306, -0.3841])\n",
      "astounded\n",
      "Saved the embedding for astounded.\n",
      "['attempting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4019,  0.3356,  0.1329,  ...,  0.3382, -0.3530,  0.9844])\n",
      "attempting\n",
      "Saved the embedding for attempting.\n",
      "['at', '##ten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2164,  0.7888, -0.0299,  ..., -0.4480, -0.3174,  0.2977])\n",
      "attentive\n",
      "Saved the embedding for attentive.\n",
      "['at', '##ten', '##tive', '##ness'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2364, -0.2173,  0.3044,  ..., -0.1702,  0.0867,  0.7080])\n",
      "attentiveness\n",
      "Saved the embedding for attentiveness.\n",
      "['attracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3870, -0.1811,  0.3081,  ...,  0.2035, -0.7250,  0.8382])\n",
      "attracted\n",
      "Saved the embedding for attracted.\n",
      "['ave', '##nging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0648,  0.4168, -0.1308,  ..., -0.9410, -0.4395, -0.0040])\n",
      "avenging\n",
      "Saved the embedding for avenging.\n",
      "['ave', '##rse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0632, -0.0841,  0.1396,  ..., -1.0465, -0.2185,  0.1702])\n",
      "averse\n",
      "Saved the embedding for averse.\n",
      "['ave', '##rs', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1085, -0.0822,  0.0886,  ..., -0.8092, -0.6732,  0.1751])\n",
      "aversion\n",
      "Saved the embedding for aversion.\n",
      "['ave', '##rs', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1194, -0.1478,  0.5269,  ..., -0.8781, -0.6246,  0.4997])\n",
      "aversive\n",
      "Saved the embedding for aversive.\n",
      "['avid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3166, -0.0697,  0.0464,  ...,  0.2028, -1.0079,  0.4844])\n",
      "avid\n",
      "Saved the embedding for avid.\n",
      "['avoiding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6749,  0.2247,  0.1691,  ..., -0.5893,  0.0312,  1.3298])\n",
      "avoiding\n",
      "Saved the embedding for avoiding.\n",
      "['awaiting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0347,  0.3839,  0.3216,  ..., -0.9704, -0.5542, -0.6992])\n",
      "awaiting\n",
      "Saved the embedding for awaiting.\n",
      "['awakened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7557,  0.2353,  0.1054,  ..., -0.0774,  0.2463,  1.2361])\n",
      "awakened\n",
      "Saved the embedding for awakened.\n",
      "['aware'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.8051,  0.5814, -0.0792,  ...,  0.7209,  0.0882,  1.1838])\n",
      "aware\n",
      "Saved the embedding for aware.\n",
      "['awareness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3492,  0.4044, -0.0841,  ..., -0.8759,  0.5400,  0.5398])\n",
      "awareness\n",
      "Saved the embedding for awareness.\n",
      "['awe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3326,  0.0256,  0.3353,  ..., -0.5840, -0.4848,  0.9494])\n",
      "awe\n",
      "Saved the embedding for awe.\n",
      "['awe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3129, -0.1591,  0.4619,  ..., -0.9658, -0.4937,  0.5756])\n",
      "awed\n",
      "Saved the embedding for awed.\n",
      "['awe', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2636, -0.0391,  0.2240,  ..., -1.2056, -0.2060,  0.0586])\n",
      "awestruck\n",
      "Saved the embedding for awestruck.\n",
      "['awful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3784,  0.1189, -0.3947,  ..., -0.8062,  0.3209,  0.3162])\n",
      "awful\n",
      "Saved the embedding for awful.\n",
      "['awkward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1125, -0.0632,  0.0598,  ..., -0.4483, -0.2888,  0.9865])\n",
      "awkward\n",
      "Saved the embedding for awkward.\n",
      "['awkward', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0534,  0.3169,  0.1526,  ..., -1.5927, -1.2385,  1.2734])\n",
      "awkwardness\n",
      "Saved the embedding for awkwardness.\n",
      "['axe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4161, -0.0519,  0.0889,  ..., -0.0523, -0.7193, -0.1776])\n",
      "axed\n",
      "Saved the embedding for axed.\n",
      "['back', '##hand', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4065,  0.2649, -0.3874,  ..., -1.0114,  0.2886, -0.3901])\n",
      "backhanded\n",
      "Saved the embedding for backhanded.\n",
      "['badly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4128,  0.5742, -0.3833,  ..., -0.4888, -0.2154,  0.6921])\n",
      "badly\n",
      "Saved the embedding for badly.\n",
      "['ba', '##ffle'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2387, -0.1460,  0.0517,  ..., -0.8838, -1.5396,  0.2604])\n",
      "baffle\n",
      "Saved the embedding for baffle.\n",
      "['baffled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3526,  0.2781, -0.1379,  ...,  0.2109, -0.3834,  0.8931])\n",
      "baffled\n",
      "Saved the embedding for baffled.\n",
      "['ba', '##ff', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7850,  0.2377, -0.2657,  ..., -0.8690, -0.5926,  0.0353])\n",
      "baffling\n",
      "Saved the embedding for baffling.\n",
      "['baked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0280, -0.0199, -0.5006,  ..., -0.1509, -1.2044,  1.1742])\n",
      "baked\n",
      "Saved the embedding for baked.\n",
      "['ban', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0907,  0.1220,  0.4547,  ..., -0.1315, -0.2077, -0.1647])\n",
      "banal\n",
      "Saved the embedding for banal.\n",
      "['barking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4616,  0.4319, -0.8586,  ..., -0.7334, -0.0031,  0.5622])\n",
      "barking\n",
      "Saved the embedding for barking.\n",
      "['bash', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3709,  0.0487,  0.5238,  ..., -1.1940, -0.0326,  0.6984])\n",
      "bashful\n",
      "Saved the embedding for bashful.\n",
      "['beaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4522,  0.0273, -0.0981,  ..., -1.1632, -0.1206,  0.5280])\n",
      "beaming\n",
      "Saved the embedding for beaming.\n",
      "['bear', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2877,  0.5540, -0.4932,  ..., -0.3219, -0.7756,  0.6495])\n",
      "bearish\n",
      "Saved the embedding for bearish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3186, -0.3382,  0.0280,  ..., -0.2010, -0.0573,  1.0928])\n",
      "beat\n",
      "Saved the embedding for beat.\n",
      "['beaten'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2192,  0.2330,  0.3545,  ..., -0.1227, -0.0687, -0.0435])\n",
      "beaten\n",
      "Saved the embedding for beaten.\n",
      "['bed', '##ev', '##iled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1200,  0.0374,  0.4366,  ..., -0.4766, -0.3909,  0.0325])\n",
      "bedeviled\n",
      "Saved the embedding for bedeviled.\n",
      "['be', '##fu', '##ddled'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4222, -0.2418,  0.4857,  ..., -1.1165, -0.8866, -0.1426])\n",
      "befuddled\n",
      "Saved the embedding for befuddled.\n",
      "['begging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0286,  0.4366, -0.0744,  ..., -0.1301, -0.3846,  0.3227])\n",
      "begging\n",
      "Saved the embedding for begging.\n",
      "['beg', '##rud', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4831, -0.2751, -0.0234,  ..., -0.8963, -0.2041,  0.6126])\n",
      "begrudge\n",
      "Saved the embedding for begrudge.\n",
      "['beg', '##rud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1032,  0.0604, -0.5153,  ..., -0.9023, -0.4937,  0.6917])\n",
      "begrudging\n",
      "Saved the embedding for begrudging.\n",
      "['beg', '##rud', '##gingly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4142,  0.3589,  0.3039,  ..., -0.9637, -0.6683,  0.1088])\n",
      "begrudgingly\n",
      "Saved the embedding for begrudgingly.\n",
      "['beg', '##uil', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3083, -0.0273,  0.2288,  ..., -0.9959, -0.5822,  0.1043])\n",
      "beguiled\n",
      "Saved the embedding for beguiled.\n",
      "['bela', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3525,  0.1334,  0.1293,  ..., -0.9758, -0.2210,  0.4676])\n",
      "belated\n",
      "Saved the embedding for belated.\n",
      "['bel', '##itt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1305, -0.0191, -0.3347,  ..., -0.4928, -0.1524,  0.1854])\n",
      "belittling\n",
      "Saved the embedding for belittling.\n",
      "['bell', '##iger', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1599, -0.2665,  0.3764,  ..., -0.3462, -0.2781,  0.5534])\n",
      "belligerence\n",
      "Saved the embedding for belligerence.\n",
      "['bell', '##iger', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4112, -0.5631,  0.6621,  ..., -0.1346, -0.5962, -0.2791])\n",
      "belligerent\n",
      "Saved the embedding for belligerent.\n",
      "['belonging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1174,  0.7227,  0.2021,  ..., -0.2344, -1.0281,  0.9984])\n",
      "belonging\n",
      "Saved the embedding for belonging.\n",
      "['be', '##mus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6395, -0.4287, -0.3103,  ..., -1.2985, -0.1221, -0.0459])\n",
      "bemused\n",
      "Saved the embedding for bemused.\n",
      "['be', '##mus', '##ement'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0477, -0.0893,  0.3246,  ..., -0.5261, -0.4678,  1.2492])\n",
      "bemusement\n",
      "Saved the embedding for bemusement.\n",
      "['ben', '##ev', '##ole', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1873,  0.1083, -0.4788,  ..., -0.8986, -0.5660,  0.5356])\n",
      "benevolence\n",
      "Saved the embedding for benevolence.\n",
      "['benevolent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5114,  0.0897, -0.2755,  ..., -0.7632, -0.9224,  1.1169])\n",
      "benevolent\n",
      "Saved the embedding for benevolent.\n",
      "['ben', '##umb', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1016, -0.1053,  0.5247,  ..., -1.0534, -0.5756,  0.6012])\n",
      "benumbed\n",
      "Saved the embedding for benumbed.\n",
      "['be', '##rate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1025, -0.3128, -0.2390,  ..., -0.4260,  0.0678,  0.6333])\n",
      "berate\n",
      "Saved the embedding for berate.\n",
      "['be', '##rating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6562,  0.0384, -0.0166,  ..., -0.9359,  0.0566,  0.2583])\n",
      "berating\n",
      "Saved the embedding for berating.\n",
      "['be', '##rea', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4604, -0.4311, -0.0494,  ..., -0.9228, -0.5101,  0.0314])\n",
      "bereaved\n",
      "Saved the embedding for bereaved.\n",
      "['be', '##re', '##ft'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0360, -0.6866,  0.4457,  ..., -0.8973, -0.3257,  0.6740])\n",
      "bereft\n",
      "Saved the embedding for bereft.\n",
      "['be', '##see', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4584,  0.2154,  0.1483,  ..., -0.8175, -1.2167, -0.3564])\n",
      "beseeching\n",
      "Saved the embedding for beseeching.\n",
      "['best', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5057,  0.0107,  0.4579,  ..., -1.1882, -0.3615,  0.2776])\n",
      "bested\n",
      "Saved the embedding for bested.\n",
      "['betrayal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2836,  0.0024,  0.1987,  ...,  0.0027, -1.0944,  0.3051])\n",
      "betrayal\n",
      "Saved the embedding for betrayal.\n",
      "['betrayed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0762,  0.0323, -0.0579,  ..., -0.6925, -0.5480,  1.0018])\n",
      "betrayed\n",
      "Saved the embedding for betrayed.\n",
      "['bewildered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0780, -0.0034,  0.0931,  ..., -0.4553, -1.0151,  0.3047])\n",
      "bewildered\n",
      "Saved the embedding for bewildered.\n",
      "['be', '##wil', '##der', '##ment'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4473, -0.0356, -0.0520,  ..., -1.3028, -0.0225,  0.7477])\n",
      "bewilderment\n",
      "Saved the embedding for bewilderment.\n",
      "['bi'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0074, -0.1054,  0.2444,  ..., -0.3296, -0.5406,  0.6477])\n",
      "bi\n",
      "Saved the embedding for bi.\n",
      "['bi', '##lio', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3590,  0.2324,  0.6931,  ...,  0.0578,  0.2980,  0.7563])\n",
      "bilious\n",
      "Saved the embedding for bilious.\n",
      "['bit'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0352, -0.3033,  0.6089,  ..., -1.0055, -0.0597,  0.7884])\n",
      "bit\n",
      "Saved the embedding for bit.\n",
      "['biting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1401,  0.4624, -0.7796,  ..., -0.7532, -0.7601,  0.8822])\n",
      "biting\n",
      "Saved the embedding for biting.\n",
      "['bitter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0507, -0.1921, -0.0814,  ..., -0.5165, -0.0054,  0.7746])\n",
      "bitter\n",
      "Saved the embedding for bitter.\n",
      "['bitter', '##sw', '##eet'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4197,  0.5839, -0.1657,  ..., -0.3342,  0.3399,  0.5504])\n",
      "bittersweet\n",
      "Saved the embedding for bittersweet.\n",
      "['blaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2263,  0.1849,  0.3242,  ..., -1.2296, -0.6096,  0.5428])\n",
      "blaming\n",
      "Saved the embedding for blaming.\n",
      "['bland'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3179,  0.0951, -0.6046,  ..., -0.3888, -0.3647,  0.5801])\n",
      "bland\n",
      "Saved the embedding for bland.\n",
      "['blank'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1888,  0.0436, -0.4856,  ..., -0.2996, -0.1801,  0.4094])\n",
      "blank\n",
      "Saved the embedding for blank.\n",
      "['b', '##lase'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0963, -0.1761,  0.0832,  ..., -0.7500, -0.2323,  0.4380])\n",
      "blase\n",
      "Saved the embedding for blase.\n",
      "['blazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2986, -0.2644, -0.2871,  ..., -0.4102, -0.1085,  0.6645])\n",
      "blazed\n",
      "Saved the embedding for blazed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bleak'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1330,  0.1329, -0.3797,  ..., -0.9772, -0.2545,  0.5260])\n",
      "bleak\n",
      "Saved the embedding for bleak.\n",
      "['b', '##lea', '##ry'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1147, -0.0241, -0.4997,  ..., -0.7672, -1.3000,  0.3609])\n",
      "bleary\n",
      "Saved the embedding for bleary.\n",
      "['blessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5280,  0.5087,  0.0342,  ..., -0.5946, -0.2725,  0.7242])\n",
      "blessed\n",
      "Saved the embedding for blessed.\n",
      "['blew'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4337, -0.1070, -0.2291,  ..., -0.4218, -0.5849,  0.3551])\n",
      "blew\n",
      "Saved the embedding for blew.\n",
      "['blinded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2770, -0.2773, -0.1820,  ...,  0.2322, -0.0723,  0.9322])\n",
      "blinded\n",
      "Saved the embedding for blinded.\n",
      "['blinds', '##ided'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3759, -0.1033,  0.2804,  ..., -0.0194, -0.3413,  0.7585])\n",
      "blindsided\n",
      "Saved the embedding for blindsided.\n",
      "['bliss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7174,  0.8498,  0.5561,  ..., -1.0609, -0.3666,  1.2035])\n",
      "bliss\n",
      "Saved the embedding for bliss.\n",
      "['bliss', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1155,  0.4489, -0.2088,  ..., -1.4172, -0.4060,  0.7113])\n",
      "blissful\n",
      "Saved the embedding for blissful.\n",
      "['bliss', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5327,  0.6168,  0.0078,  ..., -1.7137, -0.3684,  0.6183])\n",
      "blissfully\n",
      "Saved the embedding for blissfully.\n",
      "['b', '##lit', '##he'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2037, -0.0075,  0.1170,  ..., -0.9623, -0.9202,  0.7285])\n",
      "blithe\n",
      "Saved the embedding for blithe.\n",
      "['blown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1257,  0.0722, -0.3833,  ..., -0.3172, -1.1386,  0.6534])\n",
      "blown\n",
      "Saved the embedding for blown.\n",
      "['blue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1963,  0.2461, -0.5347,  ..., -0.5023, -0.3102,  0.4353])\n",
      "blue\n",
      "Saved the embedding for blue.\n",
      "['blues'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0986,  0.3410, -0.7109,  ..., -0.5091,  0.1273, -0.1152])\n",
      "blues\n",
      "Saved the embedding for blues.\n",
      "['bluff', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4448,  0.3329,  0.2057,  ..., -1.0106, -0.9397,  0.6150])\n",
      "bluffing\n",
      "Saved the embedding for bluffing.\n",
      "['blunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6124, -0.0969, -0.0031,  ...,  0.0897, -0.3688,  0.2937])\n",
      "blunt\n",
      "Saved the embedding for blunt.\n",
      "['blushing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8315,  0.5491,  0.1118,  ...,  0.2562,  0.3102,  0.2917])\n",
      "blushing\n",
      "Saved the embedding for blushing.\n",
      "['blu', '##ster', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1991, -0.2240, -0.3495,  ..., -0.8115, -0.4980,  0.8985])\n",
      "blustering\n",
      "Saved the embedding for blustering.\n",
      "['bo', '##ast', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3230,  0.1139,  0.0737,  ..., -1.5085, -0.5181,  0.1444])\n",
      "boastful\n",
      "Saved the embedding for boastful.\n",
      "['bog', '##gled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2369, -0.0193,  0.0239,  ..., -1.0939, -0.5171,  0.2449])\n",
      "boggled\n",
      "Saved the embedding for boggled.\n",
      "['boiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4313, -0.0578, -0.4701,  ...,  0.5585,  0.1315,  1.3049])\n",
      "boiling\n",
      "Saved the embedding for boiling.\n",
      "['bois', '##ter', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4271,  0.3205,  0.6556,  ..., -0.6510, -0.1042,  0.8385])\n",
      "boisterous\n",
      "Saved the embedding for boisterous.\n",
      "['bold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.6368, -0.2388,  0.4973,  ...,  0.2671, -0.1445,  0.3186])\n",
      "bold\n",
      "Saved the embedding for bold.\n",
      "['bored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2102,  0.2292,  0.1239,  ..., -0.7215, -0.0813,  1.2127])\n",
      "bored\n",
      "Saved the embedding for bored.\n",
      "['boredom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3228,  0.6172, -0.3912,  ..., -1.0782, -0.3094,  0.7976])\n",
      "boredom\n",
      "Saved the embedding for boredom.\n",
      "['boring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6875,  0.3444,  0.2672,  ...,  0.0248, -0.3339,  0.9684])\n",
      "boring\n",
      "Saved the embedding for boring.\n",
      "['bothered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1974, -0.3303,  0.8900,  ..., -0.2854, -0.4835,  0.6109])\n",
      "bothered\n",
      "Saved the embedding for bothered.\n",
      "['bound', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2581,  0.3561, -0.0603,  ..., -0.7504,  0.2683,  0.6587])\n",
      "bounder\n",
      "Saved the embedding for bounder.\n",
      "['bra', '##sh', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0880,  0.3411, -0.2192,  ..., -0.8882, -0.2160,  0.0411])\n",
      "brashness\n",
      "Saved the embedding for brashness.\n",
      "['brat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3779,  0.5251,  0.3667,  ..., -0.5086, -1.0928,  0.4654])\n",
      "bratty\n",
      "Saved the embedding for bratty.\n",
      "['brave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3380,  0.3522,  0.6311,  ..., -0.2650, -0.1983,  0.3292])\n",
      "brave\n",
      "Saved the embedding for brave.\n",
      "['bright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0485,  0.5544,  0.0548,  ..., -0.4371, -0.8819,  0.8380])\n",
      "bright\n",
      "Saved the embedding for bright.\n",
      "['br', '##ist', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0107, -0.1572,  0.1474,  ..., -0.4746, -0.4652,  0.2887])\n",
      "bristling\n",
      "Saved the embedding for bristling.\n",
      "['broken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0421,  0.1179, -1.0677,  ..., -1.6772,  0.0670,  0.3044])\n",
      "broken\n",
      "Saved the embedding for broken.\n",
      "['broken', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5762,  0.1985,  0.2163,  ..., -1.3099, -0.6843, -0.2208])\n",
      "brokenhearted\n",
      "Saved the embedding for brokenhearted.\n",
      "['broken', '##hearted', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6233,  0.1911, -0.4099,  ..., -1.1447, -0.3321, -0.9200])\n",
      "brokenheartedly\n",
      "Saved the embedding for brokenheartedly.\n",
      "['brooding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0581, -0.0993, -0.3764,  ..., -0.7569, -0.0172, -0.3285])\n",
      "brooding\n",
      "Saved the embedding for brooding.\n",
      "['brood', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0397,  0.4471,  0.5954,  ..., -0.1498, -0.2327,  0.6656])\n",
      "broody\n",
      "Saved the embedding for broody.\n",
      "['bruised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0728,  0.3560,  0.1698,  ..., -0.2318, -0.7227,  0.6688])\n",
      "bruised\n",
      "Saved the embedding for bruised.\n",
      "['br', '##us', '##que'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9480, -0.1478,  0.4584,  ..., -0.5443,  0.2179,  0.7403])\n",
      "brusque\n",
      "Saved the embedding for brusque.\n",
      "['bug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-7.6159e-04,  1.0510e-01,  3.0668e-01,  ..., -1.8711e+00,\n",
      "        -1.8633e-01,  4.4253e-01])\n",
      "bug\n",
      "Saved the embedding for bug.\n",
      "['bulging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3160,  0.5217, -0.1643,  ...,  0.2251, -0.3639,  0.8025])\n",
      "bulging\n",
      "Saved the embedding for bulging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6595,  0.3447,  0.3987,  ...,  0.4893, -0.7898, -0.0581])\n",
      "bully\n",
      "Saved the embedding for bully.\n",
      "['bullying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2629,  0.1817,  0.8786,  ...,  0.4557, -0.3481, -0.3209])\n",
      "bullying\n",
      "Saved the embedding for bullying.\n",
      "['bum', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1493,  0.0150,  0.4361,  ..., -0.5599, -0.3190,  0.7930])\n",
      "bummed\n",
      "Saved the embedding for bummed.\n",
      "['bu', '##oya', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4209, -0.1897,  0.3018,  ..., -1.4227, -0.4613,  0.5842])\n",
      "buoyant\n",
      "Saved the embedding for buoyant.\n",
      "['burden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0419, -0.2074, -0.4295,  ..., -0.6852, -0.2515,  0.2873])\n",
      "burdened\n",
      "Saved the embedding for burdened.\n",
      "['burn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2699,  0.1364,  1.4643,  ..., -1.0506, -0.4297,  1.7284])\n",
      "burn\n",
      "Saved the embedding for burn.\n",
      "['bursting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6201,  0.2282,  0.2972,  ..., -1.0811, -0.7386,  0.3187])\n",
      "bursting\n",
      "Saved the embedding for bursting.\n",
      "['bush', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1138,  0.0809,  0.0969,  ..., -0.5472, -0.5812,  0.2781])\n",
      "bushed\n",
      "Saved the embedding for bushed.\n",
      "['cage', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3435,  0.5931, -0.0805,  ...,  0.0062, -0.7033,  0.6495])\n",
      "cagey\n",
      "Saved the embedding for cagey.\n",
      "['ca', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9881, -0.1798, -0.0499,  ..., -0.7809, -0.3857,  0.5410])\n",
      "cagy\n",
      "Saved the embedding for cagy.\n",
      "['calculating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4107,  0.7385, -0.4382,  ..., -0.7180,  0.0279,  0.9109])\n",
      "calculating\n",
      "Saved the embedding for calculating.\n",
      "['call', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1784,  0.4592, -0.4992,  ..., -0.5492,  0.1751,  1.0559])\n",
      "callous\n",
      "Saved the embedding for callous.\n",
      "['call', '##used'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0339,  0.2852, -0.2914,  ..., -0.5769,  0.1248,  1.0158])\n",
      "callused\n",
      "Saved the embedding for callused.\n",
      "['calm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4507, -0.8206, -0.7667,  ..., -0.5858, -0.1320,  0.4523])\n",
      "calm\n",
      "Saved the embedding for calm.\n",
      "['calming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3589,  0.0314, -0.2963,  ..., -0.5621, -1.0262,  1.1640])\n",
      "calming\n",
      "Saved the embedding for calming.\n",
      "['calm', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3061,  0.0661,  0.0992,  ..., -1.5235, -1.2252,  1.1012])\n",
      "calmness\n",
      "Saved the embedding for calmness.\n",
      "['can', '##ny'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5747, -0.2230, -0.2649,  ...,  0.4093, -0.0827,  1.2715])\n",
      "canny\n",
      "Saved the embedding for canny.\n",
      "['can', '##tan', '##ker', '##ous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3043,  0.5744,  0.0518,  ..., -1.4886,  0.1782,  0.1707])\n",
      "cantankerous\n",
      "Saved the embedding for cantankerous.\n",
      "['capable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5716,  0.8983, -0.7931,  ..., -0.0426, -0.6942,  0.7421])\n",
      "capable\n",
      "Saved the embedding for capable.\n",
      "['cap', '##ric', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0175, -0.2220, -0.1378,  ..., -0.7396, -0.4522, -0.0585])\n",
      "capricious\n",
      "Saved the embedding for capricious.\n",
      "['capt', '##ivated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1267, -0.5194,  0.7850,  ..., -0.7495, -0.2461,  0.4283])\n",
      "captivated\n",
      "Saved the embedding for captivated.\n",
      "['captive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1842,  0.3158, -0.1662,  ..., -0.4923, -0.3145, -0.1780])\n",
      "captive\n",
      "Saved the embedding for captive.\n",
      "['care', '##free'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1415, -0.0347,  0.0245,  ..., -1.0238, -0.3193,  0.5934])\n",
      "carefree\n",
      "Saved the embedding for carefree.\n",
      "['careful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3535,  0.1023, -0.0577,  ..., -0.0575, -0.2399,  0.8204])\n",
      "careful\n",
      "Saved the embedding for careful.\n",
      "['careless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4465,  0.6776,  0.1115,  ..., -0.5275, -0.8937,  1.2850])\n",
      "careless\n",
      "Saved the embedding for careless.\n",
      "['caring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7539,  0.3304,  0.1054,  ..., -0.0168, -0.6030,  1.2177])\n",
      "caring\n",
      "Saved the embedding for caring.\n",
      "['cat', '##ty'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3806, -0.2681,  0.3871,  ..., -0.8343, -0.2205,  1.0742])\n",
      "catty\n",
      "Saved the embedding for catty.\n",
      "['ca', '##ust', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3835,  0.5586,  0.2877,  ..., -1.2203, -0.5813,  1.0646])\n",
      "caustic\n",
      "Saved the embedding for caustic.\n",
      "['caution', '##ary'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1217,  0.3781, -0.3512,  ..., -1.3956, -0.1554,  0.0236])\n",
      "cautionary\n",
      "Saved the embedding for cautionary.\n",
      "['cautious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6950,  0.0709, -0.3969,  ..., -1.2951,  0.1048, -0.1185])\n",
      "cautious\n",
      "Saved the embedding for cautious.\n",
      "['cavalier'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2787,  0.3641,  0.0771,  ..., -0.9331,  0.0714,  0.1565])\n",
      "cavalier\n",
      "Saved the embedding for cavalier.\n",
      "['celebrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0569,  1.1855,  0.1257,  ..., -0.5966, -0.1297,  1.2287])\n",
      "celebrating\n",
      "Saved the embedding for celebrating.\n",
      "['celebration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 2.0964e-01,  9.5144e-01,  3.1395e-02,  ..., -6.0245e-05,\n",
      "        -2.3752e-01,  6.2871e-01])\n",
      "celebration\n",
      "Saved the embedding for celebration.\n",
      "['ce', '##ns', '##ure'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3399,  0.9976,  0.1432,  ..., -0.9985, -0.6834,  0.0359])\n",
      "censure\n",
      "Saved the embedding for censure.\n",
      "['centered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6027, -0.2298, -0.2166,  ...,  0.6380, -0.5262,  1.0056])\n",
      "centered\n",
      "Saved the embedding for centered.\n",
      "['certain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0446, -0.0683, -0.0360,  ..., -0.2166, -0.9035,  0.9074])\n",
      "certain\n",
      "Saved the embedding for certain.\n",
      "['cha', '##fed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7222,  0.2358,  0.4500,  ..., -0.5360, -1.0846, -0.8889])\n",
      "chafed\n",
      "Saved the embedding for chafed.\n",
      "['cha', '##grin'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0224, -0.1149,  0.1018,  ..., -1.8530, -0.5811,  0.4467])\n",
      "chagrin\n",
      "Saved the embedding for chagrin.\n",
      "['cha', '##grin', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1485,  0.3223,  0.1014,  ..., -1.4999, -0.2241, -0.0882])\n",
      "chagrined\n",
      "Saved the embedding for chagrined.\n",
      "['cha', '##grin', '##ned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4929,  0.1266, -0.1291,  ..., -1.6526,  0.0113, -0.2729])\n",
      "chagrinned\n",
      "Saved the embedding for chagrinned.\n",
      "['challenge'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4263,  0.1645,  0.1945,  ..., -0.2099, -0.0672,  1.0301])\n",
      "challenge\n",
      "Saved the embedding for challenge.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['challenged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8241,  0.6032,  0.7930,  ..., -0.6740, -0.3437,  1.2468])\n",
      "challenged\n",
      "Saved the embedding for challenged.\n",
      "['challenging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7438, -0.3002, -0.2622,  ..., -0.4557, -0.1921,  0.8395])\n",
      "challenging\n",
      "Saved the embedding for challenging.\n",
      "['chaotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3295, -0.1395,  0.0214,  ..., -0.9724, -0.1039,  0.7766])\n",
      "chaotic\n",
      "Saved the embedding for chaotic.\n",
      "['charged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4290,  0.2998, -0.0408,  ...,  0.1488,  0.2866,  0.5824])\n",
      "charged\n",
      "Saved the embedding for charged.\n",
      "['charm', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0690, -0.1625,  0.6502,  ..., -1.1069, -0.1206, -0.2439])\n",
      "charmed\n",
      "Saved the embedding for charmed.\n",
      "['charming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2940,  0.4197,  0.5774,  ..., -0.5639, -0.2903,  1.1357])\n",
      "charming\n",
      "Saved the embedding for charming.\n",
      "['char', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2850,  0.2495,  0.2915,  ..., -1.7130, -0.8691,  1.0779])\n",
      "chary\n",
      "Saved the embedding for chary.\n",
      "['cheated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2059,  0.2418,  0.5766,  ...,  0.3806, -0.1989,  0.4145])\n",
      "cheated\n",
      "Saved the embedding for cheated.\n",
      "['cheek', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0522,  0.5859,  0.3995,  ..., -0.3704, -0.5290,  1.1025])\n",
      "cheeky\n",
      "Saved the embedding for cheeky.\n",
      "['cheered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3336,  0.2587, -0.4086,  ..., -0.5564, -0.7609,  0.3938])\n",
      "cheered\n",
      "Saved the embedding for cheered.\n",
      "['cheerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4258,  0.0241,  0.2769,  ..., -0.9754, -0.5520,  0.2926])\n",
      "cheerful\n",
      "Saved the embedding for cheerful.\n",
      "['cheering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0112,  0.2467, -0.4014,  ..., -0.3846, -0.1914,  1.2574])\n",
      "cheering\n",
      "Saved the embedding for cheering.\n",
      "['cheer', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1103, -0.1255,  0.4115,  ..., -0.5708,  0.0864,  0.8021])\n",
      "cheerless\n",
      "Saved the embedding for cheerless.\n",
      "['cheer', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0833,  0.2257,  0.2596,  ..., -0.5986, -0.4049,  0.4847])\n",
      "cheery\n",
      "Saved the embedding for cheery.\n",
      "['che', '##es', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0321,  0.4596, -0.5641,  ..., -0.8944, -0.4527,  0.3350])\n",
      "cheesy\n",
      "Saved the embedding for cheesy.\n",
      "['chest', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2240,  0.0985,  0.0615,  ..., -1.5909, -0.7778,  0.5163])\n",
      "chesty\n",
      "Saved the embedding for chesty.\n",
      "['chi', '##de'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5492,  0.4304,  0.3011,  ..., -0.9103, -0.8226,  0.5279])\n",
      "chide\n",
      "Saved the embedding for chide.\n",
      "['chi', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0078,  0.2092,  0.6042,  ..., -0.6983, -1.3320,  0.4355])\n",
      "chiding\n",
      "Saved the embedding for chiding.\n",
      "['childish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1725, -0.1828,  0.3066,  ..., -0.0345, -1.1693,  0.5652])\n",
      "childish\n",
      "Saved the embedding for childish.\n",
      "['childish', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4559,  0.5438,  0.6288,  ..., -1.1881, -1.2616,  0.8387])\n",
      "childishly\n",
      "Saved the embedding for childishly.\n",
      "['child', '##like'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1057,  0.0809, -0.0766,  ..., -0.6232, -0.8018,  0.6112])\n",
      "childlike\n",
      "Saved the embedding for childlike.\n",
      "['chill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1510, -0.7576, -1.0656,  ..., -0.9359, -0.4210,  0.3755])\n",
      "chill\n",
      "Saved the embedding for chill.\n",
      "['chilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3693, -0.0953, -0.5362,  ..., -0.5028,  0.5375,  0.1960])\n",
      "chilled\n",
      "Saved the embedding for chilled.\n",
      "['chilling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1953,  0.4555,  0.0711,  ..., -1.2421, -0.1697, -0.1968])\n",
      "chilling\n",
      "Saved the embedding for chilling.\n",
      "['chip', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6372, -0.0185,  0.1103,  ..., -0.4908,  0.2443,  0.1323])\n",
      "chipper\n",
      "Saved the embedding for chipper.\n",
      "['chi', '##rp', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5453,  0.7512,  0.3175,  ..., -0.6309, -0.6809,  0.6420])\n",
      "chirpy\n",
      "Saved the embedding for chirpy.\n",
      "['cho', '##ler', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1961,  0.4180,  0.7780,  ..., -0.7558, -0.0171,  0.9690])\n",
      "choleric\n",
      "Saved the embedding for choleric.\n",
      "['cho', '##rt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3356, -0.3882,  0.0099,  ..., -0.7087, -0.0907,  0.0151])\n",
      "chortling\n",
      "Saved the embedding for chortling.\n",
      "['chuckle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2346, -0.1872,  0.6870,  ..., -0.2304, -0.5270,  0.7212])\n",
      "chuckle\n",
      "Saved the embedding for chuckle.\n",
      "['chuck', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7982,  0.1748,  0.7249,  ..., -0.6489, -0.9034,  0.9010])\n",
      "chuckling\n",
      "Saved the embedding for chuckling.\n",
      "['chu', '##rl', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1157,  0.2220,  0.2980,  ..., -0.6559, -0.4894,  0.8560])\n",
      "churlish\n",
      "Saved the embedding for churlish.\n",
      "['ci', '##rc', '##ums', '##pe', '##ct'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.1327,  0.3573, -0.3195,  ..., -0.6306,  0.1509,  0.2055])\n",
      "circumspect\n",
      "Saved the embedding for circumspect.\n",
      "['cl', '##amo', '##rous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2843,  0.6166,  0.2250,  ..., -2.2392, -0.2456,  0.2851])\n",
      "clamorous\n",
      "Saved the embedding for clamorous.\n",
      "['clash'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5945, -0.0045, -0.0158,  ..., -0.9555, -0.0813, -0.8038])\n",
      "clash\n",
      "Saved the embedding for clash.\n",
      "['clear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6086,  0.4213,  0.5426,  ..., -0.6011,  0.1036,  0.4879])\n",
      "clear\n",
      "Saved the embedding for clear.\n",
      "['clenched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6520, -0.4585, -0.0685,  ...,  0.0232, -0.7153,  0.8356])\n",
      "clenched\n",
      "Saved the embedding for clenched.\n",
      "['clever'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0450,  0.6848, -0.5254,  ..., -0.7080, -0.5735,  0.3561])\n",
      "clever\n",
      "Saved the embedding for clever.\n",
      "['close'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4128,  0.6260, -0.4275,  ...,  0.3896, -1.1802,  1.0543])\n",
      "close\n",
      "Saved the embedding for close.\n",
      "['closed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1289,  0.6499, -0.1158,  ..., -0.8183, -0.3609,  0.6741])\n",
      "closed\n",
      "Saved the embedding for closed.\n",
      "['close', '##mouth', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1996, -0.0059,  0.2541,  ..., -0.3631, -0.4783,  0.1730])\n",
      "closemouthed\n",
      "Saved the embedding for closemouthed.\n",
      "['cl', '##oy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7342,  0.2519,  0.2430,  ..., -0.8512, -0.9708,  0.3578])\n",
      "cloy\n",
      "Saved the embedding for cloy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clue', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4185,  0.3037,  0.1674,  ..., -0.6846, -0.1050,  0.9772])\n",
      "clueless\n",
      "Saved the embedding for clueless.\n",
      "['clutched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1055,  0.6900,  0.2380,  ..., -0.4523, -0.6954,  0.7763])\n",
      "clutched\n",
      "Saved the embedding for clutched.\n",
      "['cl', '##uttered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1100,  0.1295, -0.0494,  ..., -0.9315, -0.3524,  0.2269])\n",
      "cluttered\n",
      "Saved the embedding for cluttered.\n",
      "['cock', '##eye', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2250,  0.3780,  0.0018,  ..., -0.5734, -0.6652, -0.1029])\n",
      "cockeyed\n",
      "Saved the embedding for cockeyed.\n",
      "['cock', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0098, -0.0118, -0.1453,  ..., -0.9219, -0.8229,  1.2585])\n",
      "cockiness\n",
      "Saved the embedding for cockiness.\n",
      "['cock', '##sure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8614,  0.2930, -0.6954,  ..., -0.1919, -0.6513,  0.4591])\n",
      "cocksure\n",
      "Saved the embedding for cocksure.\n",
      "['cocky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0339,  0.4715, -0.4649,  ...,  0.2651, -0.9429,  0.1038])\n",
      "cocky\n",
      "Saved the embedding for cocky.\n",
      "['co', '##gni', '##zan', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4711, -0.3961,  0.1709,  ..., -1.0014,  0.1102,  0.1392])\n",
      "cognizant\n",
      "Saved the embedding for cognizant.\n",
      "['cold'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6240,  0.2652, -0.5718,  ..., -0.0013, -0.3894,  0.8213])\n",
      "cold\n",
      "Saved the embedding for cold.\n",
      "['collected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9608, -0.1617, -0.0454,  ...,  0.0431, -1.3462,  1.1381])\n",
      "collected\n",
      "Saved the embedding for collected.\n",
      "['col', '##lus', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3204, -0.6799,  0.1447,  ..., -0.8938,  0.2360,  0.4197])\n",
      "collusive\n",
      "Saved the embedding for collusive.\n",
      "['colon', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4844, -0.1457,  0.3565,  ..., -0.5492, -0.5763,  1.6182])\n",
      "colonized\n",
      "Saved the embedding for colonized.\n",
      "['combat', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2446, -0.2617,  0.5312,  ..., -0.0448,  0.4362,  0.7119])\n",
      "combative\n",
      "Saved the embedding for combative.\n",
      "['comedic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5939, -1.1925, -0.5916,  ..., -0.1964,  0.2274, -0.7073])\n",
      "comedic\n",
      "Saved the embedding for comedic.\n",
      "['comfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1695,  0.4327,  0.6894,  ..., -0.5599, -0.5968,  0.9404])\n",
      "comfort\n",
      "Saved the embedding for comfort.\n",
      "['comfortable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0350, -0.1777,  0.6455,  ..., -0.3717, -0.5187,  0.8716])\n",
      "comfortable\n",
      "Saved the embedding for comfortable.\n",
      "['comfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0567,  0.2310,  0.2512,  ..., -0.9598, -0.7670,  0.3993])\n",
      "comforted\n",
      "Saved the embedding for comforted.\n",
      "['comical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0541,  0.0092,  0.3416,  ..., -0.6251, -0.4147,  0.8171])\n",
      "comical\n",
      "Saved the embedding for comical.\n",
      "['commanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1608,  0.6374, -0.9519,  ...,  0.2761, -0.4656,  0.2979])\n",
      "commanding\n",
      "Saved the embedding for commanding.\n",
      "['com', '##mise', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0609, -0.4746, -0.0314,  ..., -1.0895,  0.2518,  1.1104])\n",
      "commiserating\n",
      "Saved the embedding for commiserating.\n",
      "['com', '##mise', '##rative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4104, -0.6159, -0.1503,  ..., -0.3758,  0.2075,  0.5435])\n",
      "commiserative\n",
      "Saved the embedding for commiserative.\n",
      "['com', '##mun', '##icative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4455, -0.1340,  0.6432,  ..., -1.2174,  0.4043,  0.7438])\n",
      "communicative\n",
      "Saved the embedding for communicative.\n",
      "['compassion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5538,  0.7871,  0.0821,  ..., -0.9042, -0.4803,  1.1277])\n",
      "compassion\n",
      "Saved the embedding for compassion.\n",
      "['compassionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5454,  0.7818, -0.5216,  ...,  0.1774,  0.0588,  0.6512])\n",
      "compassionate\n",
      "Saved the embedding for compassionate.\n",
      "['competent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6267,  0.8551, -0.0086,  ..., -0.9293, -0.6671,  1.4130])\n",
      "competent\n",
      "Saved the embedding for competent.\n",
      "['competitive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2662, -0.0664, -0.7022,  ..., -1.0552,  0.2282,  0.3069])\n",
      "competitive\n",
      "Saved the embedding for competitive.\n",
      "['com', '##pl', '##ace', '##nce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0574, -0.5820, -0.3340,  ...,  0.0456,  0.1555,  1.3416])\n",
      "complacence\n",
      "Saved the embedding for complacence.\n",
      "['com', '##pl', '##ace', '##ncy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1204, -0.3919,  0.1462,  ...,  0.1409,  0.5341,  0.8223])\n",
      "complacency\n",
      "Saved the embedding for complacency.\n",
      "['com', '##pl', '##ace', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4462, -0.5267,  0.3284,  ..., -0.3139,  0.1325,  0.9733])\n",
      "complacent\n",
      "Saved the embedding for complacent.\n",
      "['com', '##pl', '##ace', '##ntly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1257, -0.4576, -0.2303,  ..., -0.5690,  0.6305,  1.1715])\n",
      "complacently\n",
      "Saved the embedding for complacently.\n",
      "['complain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0036,  0.3597,  0.1557,  ..., -0.7761,  0.1353,  1.3964])\n",
      "complain\n",
      "Saved the embedding for complain.\n",
      "['complaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3023,  0.3273,  0.1887,  ..., -0.0422, -0.2936,  1.3973])\n",
      "complaining\n",
      "Saved the embedding for complaining.\n",
      "['composed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0354,  0.5528, -0.4809,  ..., -0.1857, -0.5062,  0.8076])\n",
      "composed\n",
      "Saved the embedding for composed.\n",
      "['comprehend', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4100,  0.1134,  0.2143,  ..., -0.6370, -0.6054,  0.4783])\n",
      "comprehending\n",
      "Saved the embedding for comprehending.\n",
      "['com', '##pu', '##ls', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5890, -0.2142,  0.5626,  ..., -0.1117,  0.1790,  0.3477])\n",
      "compulsive\n",
      "Saved the embedding for compulsive.\n",
      "['concealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2523,  0.0346, -0.5389,  ..., -0.5222, -1.2049,  0.8590])\n",
      "concealed\n",
      "Saved the embedding for concealed.\n",
      "['con', '##ced', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5007, -0.2462,  0.6002,  ..., -0.9203, -0.6082,  1.2818])\n",
      "conceding\n",
      "Saved the embedding for conceding.\n",
      "['con', '##ce', '##ited'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6666,  0.0797,  0.2913,  ...,  0.0047, -0.3533,  1.2538])\n",
      "conceited\n",
      "Saved the embedding for conceited.\n",
      "['concentrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1750,  0.1828,  0.4169,  ...,  0.1362,  0.2116,  0.4844])\n",
      "concentrated\n",
      "Saved the embedding for concentrated.\n",
      "['concentrating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2700,  0.2874, -0.4621,  ..., -0.1008, -0.6704,  1.2084])\n",
      "concentrating\n",
      "Saved the embedding for concentrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concentration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0359,  0.2681, -0.2709,  ..., -0.8553,  0.1728,  1.2216])\n",
      "concentration\n",
      "Saved the embedding for concentration.\n",
      "['concern'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4547,  0.3462,  0.2862,  ..., -0.2359, -0.5249,  0.4341])\n",
      "concern\n",
      "Saved the embedding for concern.\n",
      "['concerned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3273,  0.2658,  0.4718,  ...,  0.3076, -0.5044,  0.2820])\n",
      "concerned\n",
      "Saved the embedding for concerned.\n",
      "['con', '##ci', '##lia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0198, -0.2473,  0.3366,  ..., -0.3022, -0.3590,  0.8848])\n",
      "conciliatory\n",
      "Saved the embedding for conciliatory.\n",
      "['con', '##clusive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2490, -0.1562, -0.1391,  ..., -0.0278, -0.7220,  1.1955])\n",
      "conclusive\n",
      "Saved the embedding for conclusive.\n",
      "['condemning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0483,  0.1652, -0.2248,  ..., -0.1036,  0.0514,  0.2999])\n",
      "condemning\n",
      "Saved the embedding for condemning.\n",
      "['conde', '##sc', '##ending'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3372,  0.5698, -0.2098,  ..., -1.1586, -0.1022,  0.0314])\n",
      "condescending\n",
      "Saved the embedding for condescending.\n",
      "['condo', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2296,  1.5987,  0.4547,  ...,  1.1174, -0.2745,  0.8832])\n",
      "condoling\n",
      "Saved the embedding for condoling.\n",
      "['confidence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4266, -0.2207, -0.1763,  ..., -0.9113, -1.0210,  0.9290])\n",
      "confidence\n",
      "Saved the embedding for confidence.\n",
      "['confident'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8275, -0.2430,  0.2912,  ..., -0.5563, -0.7712,  0.0723])\n",
      "confident\n",
      "Saved the embedding for confident.\n",
      "['confidently'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2783,  0.3573,  0.0762,  ..., -0.3837, -0.4298,  0.5100])\n",
      "confidently\n",
      "Saved the embedding for confidently.\n",
      "['conflict', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1239, -0.1409, -0.1259,  ..., -0.5853, -1.1142,  0.6021])\n",
      "conflicted\n",
      "Saved the embedding for conflicted.\n",
      "['con', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2992, -0.0280,  0.1205,  ..., -0.4299, -0.7222,  1.1405])\n",
      "confound\n",
      "Saved the embedding for confound.\n",
      "['con', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1077,  0.4801, -0.3141,  ..., -0.1193, -0.7603,  0.5713])\n",
      "confounded\n",
      "Saved the embedding for confounded.\n",
      "['confrontation', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0557,  0.8394,  0.2781,  ..., -0.8189, -0.5699,  0.4974])\n",
      "confrontational\n",
      "Saved the embedding for confrontational.\n",
      "['confused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0688,  0.2377, -0.2959,  ..., -1.3083,  0.0019,  0.0624])\n",
      "confused\n",
      "Saved the embedding for confused.\n",
      "['confusion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2989, -0.0938,  0.0230,  ..., -1.1808, -0.1321, -0.0182])\n",
      "confusion\n",
      "Saved the embedding for confusion.\n",
      "['cong', '##enia', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0305,  0.4248,  0.2277,  ..., -0.8163,  0.1412,  0.3333])\n",
      "congenial\n",
      "Saved the embedding for congenial.\n",
      "['cong', '##rat', '##ulator', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1031,  0.5150,  0.1810,  ..., -0.9039, -0.4238,  0.3094])\n",
      "congratulatory\n",
      "Saved the embedding for congratulatory.\n",
      "['con', '##ni', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4081,  0.4074, -0.0751,  ...,  0.1043, -0.5075,  1.5031])\n",
      "conniving\n",
      "Saved the embedding for conniving.\n",
      "['conscious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7823,  0.0973, -0.6340,  ..., -0.5917, -0.5542,  0.1424])\n",
      "conscious\n",
      "Saved the embedding for conscious.\n",
      "['conservative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6056,  0.8932,  1.1556,  ...,  0.0323, -0.9658,  0.6832])\n",
      "conservative\n",
      "Saved the embedding for conservative.\n",
      "['consider', '##ate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0212,  0.2434, -0.0895,  ...,  0.0674, -0.7657,  0.4411])\n",
      "considerate\n",
      "Saved the embedding for considerate.\n",
      "['considering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5138,  0.3526,  0.1700,  ..., -0.2276, -0.7542,  1.1569])\n",
      "considering\n",
      "Saved the embedding for considering.\n",
      "['con', '##sol', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2501,  0.7429, -0.1243,  ...,  0.0612, -0.8985,  0.5544])\n",
      "consoling\n",
      "Saved the embedding for consoling.\n",
      "['con', '##sp', '##ira', '##tori', '##al'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0447, -0.0474,  0.3141,  ..., -0.6681, -0.5306,  0.5563])\n",
      "conspiratorial\n",
      "Saved the embedding for conspiratorial.\n",
      "['con', '##sp', '##iring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4217,  0.0450, -0.3424,  ..., -0.6486, -0.7173,  1.0361])\n",
      "conspiring\n",
      "Saved the embedding for conspiring.\n",
      "['con', '##ster', '##nation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4457,  0.3232,  1.0253,  ...,  0.7845, -0.3041,  1.3152])\n",
      "consternation\n",
      "Saved the embedding for consternation.\n",
      "['con', '##sti', '##pate', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1166,  0.3207,  0.2954,  ..., -1.1479, -0.7824,  0.7888])\n",
      "constipated\n",
      "Saved the embedding for constipated.\n",
      "['constrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1334,  0.2159,  0.2483,  ..., -0.2366, -0.1983,  0.4255])\n",
      "constrained\n",
      "Saved the embedding for constrained.\n",
      "['consumed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2971,  0.0848, -1.1737,  ..., -0.8725,  0.5444,  0.2389])\n",
      "consumed\n",
      "Saved the embedding for consumed.\n",
      "['consuming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3126, -0.3105, -1.0825,  ..., -0.3042, -0.9451,  0.5875])\n",
      "consuming\n",
      "Saved the embedding for consuming.\n",
      "['contained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3735,  0.3130, -0.3572,  ...,  0.0881, -0.4131,  0.8764])\n",
      "contained\n",
      "Saved the embedding for contained.\n",
      "['con', '##tem', '##plate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6293,  0.2550, -0.0074,  ...,  0.3104, -0.6498,  1.0607])\n",
      "contemplate\n",
      "Saved the embedding for contemplate.\n",
      "['contemplating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1547,  0.2375,  0.6229,  ...,  0.2191, -0.8102,  0.1477])\n",
      "contemplating\n",
      "Saved the embedding for contemplating.\n",
      "['con', '##tem', '##pl', '##ation'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2095,  0.4267,  0.3305,  ..., -1.2635, -0.5594,  0.0203])\n",
      "contemplation\n",
      "Saved the embedding for contemplation.\n",
      "['con', '##tem', '##pl', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6909,  0.5734, -0.0926,  ..., -1.0893, -0.4220,  0.4549])\n",
      "contemplative\n",
      "Saved the embedding for contemplative.\n",
      "['contempt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0369,  0.2344,  0.8156,  ...,  0.0211, -0.7759,  1.4452])\n",
      "contempt\n",
      "Saved the embedding for contempt.\n",
      "['contempt', '##uous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1037,  0.5175,  0.6642,  ..., -0.7069, -1.0303,  1.6381])\n",
      "contemptuous\n",
      "Saved the embedding for contemptuous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0144,  1.0302,  0.1368,  ..., -0.3608,  0.3433,  0.9893])\n",
      "content\n",
      "Saved the embedding for content.\n",
      "['content', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5165,  0.6496,  0.2588,  ..., -0.3828,  0.0771,  0.8645])\n",
      "contented\n",
      "Saved the embedding for contented.\n",
      "['contentious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1609,  0.1812,  0.1119,  ..., -0.2186, -0.9244, -0.3554])\n",
      "contentious\n",
      "Saved the embedding for contentious.\n",
      "['content', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1764,  0.8661,  0.0397,  ..., -1.1885, -0.2975,  0.7752])\n",
      "contently\n",
      "Saved the embedding for contently.\n",
      "['content', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1212,  0.6930,  0.1077,  ..., -0.6260,  0.1187,  0.7944])\n",
      "contentment\n",
      "Saved the embedding for contentment.\n",
      "['contradictory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2225,  0.4489,  0.0702,  ..., -0.1916, -0.3119,  0.0666])\n",
      "contradictory\n",
      "Saved the embedding for contradictory.\n",
      "['contrary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6762, -0.2512, -0.3869,  ..., -0.5208, -0.7813,  0.5957])\n",
      "contrary\n",
      "Saved the embedding for contrary.\n",
      "['con', '##tri', '##te'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3936,  0.1686,  0.1235,  ..., -0.7750, -0.5837,  0.9314])\n",
      "contrite\n",
      "Saved the embedding for contrite.\n",
      "['controlled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3125, -0.3220, -0.3611,  ..., -0.6983, -0.7905,  0.8942])\n",
      "controlled\n",
      "Saved the embedding for controlled.\n",
      "['controlling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0647, -0.5260, -0.8496,  ...,  0.0671, -0.3509,  0.0891])\n",
      "controlling\n",
      "Saved the embedding for controlling.\n",
      "['controversial'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1455, -0.1154, -0.1032,  ..., -1.3281, -0.6100, -0.8573])\n",
      "controversial\n",
      "Saved the embedding for controversial.\n",
      "['con', '##tum', '##acious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0267,  0.4954,  0.3162,  ..., -0.9060, -0.7016,  0.7182])\n",
      "contumacious\n",
      "Saved the embedding for contumacious.\n",
      "['convinced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5086,  0.7443,  0.5449,  ...,  0.0693, -0.0849,  1.5398])\n",
      "convinced\n",
      "Saved the embedding for convinced.\n",
      "['cool'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0711, -0.3094,  0.6979,  ..., -0.9755, -0.5089,  1.4819])\n",
      "cool\n",
      "Saved the embedding for cool.\n",
      "['cooperative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3979, -0.0076, -0.6446,  ..., -1.2551, -0.4233,  0.6969])\n",
      "cooperative\n",
      "Saved the embedding for cooperative.\n",
      "['cord', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3176,  0.3529, -0.0546,  ..., -0.7291, -0.7345,  0.8683])\n",
      "cordial\n",
      "Saved the embedding for cordial.\n",
      "['courageous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2929,  0.2631,  0.7685,  ..., -0.0538, -0.2699,  0.1784])\n",
      "courageous\n",
      "Saved the embedding for courageous.\n",
      "['covert'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5623,  0.8378, -0.1491,  ..., -0.0967, -0.4365,  0.3917])\n",
      "covert\n",
      "Saved the embedding for covert.\n",
      "['coward', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2727, -0.1331,  0.1341,  ..., -0.4713, -0.4813,  0.5777])\n",
      "cowardly\n",
      "Saved the embedding for cowardly.\n",
      "['co', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3096,  0.2799,  0.6067,  ..., -0.4862,  0.1184,  0.6271])\n",
      "coy\n",
      "Saved the embedding for coy.\n",
      "['crab', '##by'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1206,  0.0623, -0.2367,  ..., -0.3506,  0.2638,  0.0727])\n",
      "crabby\n",
      "Saved the embedding for crabby.\n",
      "['craft', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0499,  0.3863, -0.2026,  ..., -0.5565, -0.4220,  1.3353])\n",
      "crafty\n",
      "Saved the embedding for crafty.\n",
      "['crank', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3507, -0.5996,  0.9121,  ..., -0.3761, -0.2964,  0.8180])\n",
      "cranky\n",
      "Saved the embedding for cranky.\n",
      "['crazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1165,  0.4436, -0.0593,  ..., -0.5345, -0.8514,  0.9236])\n",
      "crazed\n",
      "Saved the embedding for crazed.\n",
      "['crazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2438,  0.0128, -0.2572,  ..., -0.4651, -0.2582,  0.6256])\n",
      "crazy\n",
      "Saved the embedding for crazy.\n",
      "['cr', '##ed', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0269, -0.1248,  0.4576,  ..., -0.6941, -0.2820,  0.6481])\n",
      "credulous\n",
      "Saved the embedding for credulous.\n",
      "['creepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7689,  0.1196,  0.0921,  ..., -0.1650, -0.3740,  0.5827])\n",
      "creepy\n",
      "Saved the embedding for creepy.\n",
      "['crest', '##fall', '##en'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2019, -0.1817, -0.1760,  ..., -1.4525, -0.8291, -0.3051])\n",
      "crestfallen\n",
      "Saved the embedding for crestfallen.\n",
      "['cr', '##inging'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4675,  0.0527,  0.6695,  ..., -1.0240, -0.8488,  0.3970])\n",
      "cringing\n",
      "Saved the embedding for cringing.\n",
      "['critical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2501,  0.4752,  0.1843,  ..., -0.3322, -0.0760,  0.4278])\n",
      "critical\n",
      "Saved the embedding for critical.\n",
      "['cross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1167,  0.4725,  0.0805,  ..., -0.1835, -0.8437,  0.3960])\n",
      "cross\n",
      "Saved the embedding for cross.\n",
      "['crotch', '##ety'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0662,  0.2790, -0.2842,  ..., -0.7505, -0.6885,  0.5324])\n",
      "crotchety\n",
      "Saved the embedding for crotchety.\n",
      "['crude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7201,  0.1703, -0.1136,  ..., -1.9454, -0.1047,  0.0563])\n",
      "crude\n",
      "Saved the embedding for crude.\n",
      "['cruel'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6385, -0.1284, -0.0700,  ..., -0.0699, -0.0779,  0.6691])\n",
      "cruel\n",
      "Saved the embedding for cruel.\n",
      "['crushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0854, -0.2881, -0.5678,  ..., -0.6722, -0.2150,  0.0170])\n",
      "crushed\n",
      "Saved the embedding for crushed.\n",
      "['cry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8179, -0.1594,  0.0419,  ..., -0.9611,  0.6231,  0.9188])\n",
      "cry\n",
      "Saved the embedding for cry.\n",
      "['crying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2924,  0.3035,  0.4109,  ...,  0.0203, -0.2999,  0.7436])\n",
      "crying\n",
      "Saved the embedding for crying.\n",
      "['cryptic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0666,  0.2229,  0.1762,  ..., -0.8657, -0.2141, -0.1227])\n",
      "cryptic\n",
      "Saved the embedding for cryptic.\n",
      "['cu', '##lp', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7343, -0.4092,  0.3052,  ..., -0.8578, -0.5481,  0.1282])\n",
      "culpable\n",
      "Saved the embedding for culpable.\n",
      "['cunning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1876,  0.1161, -0.1248,  ..., -0.6182, -0.4275,  0.4330])\n",
      "cunning\n",
      "Saved the embedding for cunning.\n",
      "['cu', '##rio', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3214, -0.3303,  0.4584,  ..., -0.4175, -0.3867,  0.6363])\n",
      "curios\n",
      "Saved the embedding for curios.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curiosity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4938,  0.1625, -0.0689,  ..., -0.4770, -0.8498,  0.7550])\n",
      "curiosity\n",
      "Saved the embedding for curiosity.\n",
      "['curious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3554,  0.1518, -0.5690,  ..., -1.2279,  0.1953,  0.1932])\n",
      "curious\n",
      "Saved the embedding for curious.\n",
      "['cutting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5108,  0.6118,  0.3939,  ...,  0.6303, -0.3443,  0.8765])\n",
      "cutting\n",
      "Saved the embedding for cutting.\n",
      "['cy', '##nic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0311, -0.2899,  0.1165,  ..., -0.5906,  0.2950,  0.7172])\n",
      "cynic\n",
      "Saved the embedding for cynic.\n",
      "['cynical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0111, -0.0900,  0.7567,  ..., -0.9884,  0.0257,  0.0450])\n",
      "cynical\n",
      "Saved the embedding for cynical.\n",
      "['cy', '##nic', '##ism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5114,  0.3169,  0.5332,  ..., -0.6745,  0.5320,  1.1729])\n",
      "cynicism\n",
      "Saved the embedding for cynicism.\n",
      "['dal', '##lian', '##ce'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4364,  0.2256, -0.1975,  ..., -1.2716, -1.0846, -0.0143])\n",
      "dalliance\n",
      "Saved the embedding for dalliance.\n",
      "['dan', '##dy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4241,  0.1596,  0.4733,  ..., -0.5824, -0.5764, -0.1376])\n",
      "dandy\n",
      "Saved the embedding for dandy.\n",
      "['dangerous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0950,  0.1426,  0.5353,  ..., -0.4721, -0.8434,  0.4904])\n",
      "dangerous\n",
      "Saved the embedding for dangerous.\n",
      "['darkly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3399, -0.6346, -0.5280,  ..., -1.2933,  0.2496,  0.1405])\n",
      "darkly\n",
      "Saved the embedding for darkly.\n",
      "['da', '##unt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2354, -0.3769, -0.3046,  ..., -1.3325, -0.0710, -0.2393])\n",
      "daunted\n",
      "Saved the embedding for daunted.\n",
      "['day', '##dre', '##am'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2823, -0.2734,  0.1302,  ..., -0.5310, -0.1337,  0.8083])\n",
      "daydream\n",
      "Saved the embedding for daydream.\n",
      "['day', '##dre', '##ami', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6013, -0.1693,  0.1191,  ..., -0.7469, -0.5736,  0.2160])\n",
      "daydreaming\n",
      "Saved the embedding for daydreaming.\n",
      "['dazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4421, -0.0760, -0.3299,  ..., -0.5538, -0.3911,  0.5066])\n",
      "dazed\n",
      "Saved the embedding for dazed.\n",
      "['da', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0718,  0.1553,  0.1631,  ..., -1.1946, -0.8532,  0.3537])\n",
      "dazzled\n",
      "Saved the embedding for dazzled.\n",
      "['deadly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4371, -0.3586, -0.4195,  ..., -1.2260, -0.2426,  0.0965])\n",
      "deadly\n",
      "Saved the embedding for deadly.\n",
      "['dead', '##pan'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1119, -0.1133,  0.3954,  ..., -0.9043, -0.1564,  0.8832])\n",
      "deadpan\n",
      "Saved the embedding for deadpan.\n",
      "['debate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1201,  0.2045, -0.5218,  ..., -0.3007, -0.3164,  0.3002])\n",
      "debate\n",
      "Saved the embedding for debate.\n",
      "['debating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1031,  0.3624,  0.2460,  ..., -0.6131, -0.2385,  0.1704])\n",
      "debating\n",
      "Saved the embedding for debating.\n",
      "['de', '##bau', '##ched'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1301,  0.1570,  0.3432,  ...,  0.0332,  0.3456,  1.0756])\n",
      "debauched\n",
      "Saved the embedding for debauched.\n",
      "['dec', '##eit', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2234, -0.0203,  0.5185,  ..., -0.7283, -0.0916,  0.4652])\n",
      "deceitful\n",
      "Saved the embedding for deceitful.\n",
      "['dec', '##ei', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1806,  0.0899,  0.3172,  ..., -0.7394,  0.9362,  0.2670])\n",
      "deceived\n",
      "Saved the embedding for deceived.\n",
      "['dec', '##ei', '##ving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0480,  0.2120, -0.1684,  ..., -0.9271,  0.4065,  0.5503])\n",
      "deceiving\n",
      "Saved the embedding for deceiving.\n",
      "['dec', '##ei', '##ving', '##ly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4691,  0.0531, -0.5099,  ..., -0.6815, -0.2647,  0.2682])\n",
      "deceivingly\n",
      "Saved the embedding for deceivingly.\n",
      "['deception'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2672, -0.0468, -0.4365,  ..., -0.4974,  0.0034,  0.5870])\n",
      "deception\n",
      "Saved the embedding for deception.\n",
      "['dec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7194,  1.0488, -0.3994,  ..., -0.5499,  0.9719,  0.0114])\n",
      "deceptive\n",
      "Saved the embedding for deceptive.\n",
      "['deciding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1876, -0.6171,  0.1842,  ..., -0.4055, -0.6254,  0.3021])\n",
      "deciding\n",
      "Saved the embedding for deciding.\n",
      "['decisive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1598,  0.2074, -0.1150,  ..., -0.8526, -0.0991,  0.4518])\n",
      "decisive\n",
      "Saved the embedding for decisive.\n",
      "['dedicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0157,  0.4669,  0.0543,  ...,  0.2463, -0.1921,  0.7229])\n",
      "dedicated\n",
      "Saved the embedding for dedicated.\n",
      "['defeat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9937, -0.4084,  0.3949,  ...,  0.3130, -0.3243, -0.0502])\n",
      "defeat\n",
      "Saved the embedding for defeat.\n",
      "['defeated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1456, -0.6948, -0.3560,  ..., -0.4707,  0.1281, -0.1590])\n",
      "defeated\n",
      "Saved the embedding for defeated.\n",
      "['defense', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6249,  0.4812, -0.4754,  ..., -0.6353,  0.2090, -0.1956])\n",
      "defenseless\n",
      "Saved the embedding for defenseless.\n",
      "['defensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2343, -0.3178, -0.2151,  ..., -0.6503,  1.0739, -0.6586])\n",
      "defensive\n",
      "Saved the embedding for defensive.\n",
      "['defiance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5805,  0.1846, -0.5733,  ..., -0.3102,  0.2310,  0.7838])\n",
      "defiance\n",
      "Saved the embedding for defiance.\n",
      "['defiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0891,  0.5229,  0.1130,  ..., -0.0072, -0.1923,  0.9495])\n",
      "defiant\n",
      "Saved the embedding for defiant.\n",
      "['def', '##lated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4463, -0.4661, -0.4036,  ..., -0.8390, -0.3031, -0.2786])\n",
      "deflated\n",
      "Saved the embedding for deflated.\n",
      "['de', '##ga', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2250,  0.1217,  0.4404,  ..., -0.2833, -0.3399,  0.9059])\n",
      "degage\n",
      "Saved the embedding for degage.\n",
      "['de', '##grad', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3841,  0.0928,  0.4893,  ...,  0.2016, -0.0668,  1.0853])\n",
      "degrading\n",
      "Saved the embedding for degrading.\n",
      "['de', '##jected'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3569,  0.1758,  0.4027,  ..., -0.5711, -0.2328,  0.1950])\n",
      "dejected\n",
      "Saved the embedding for dejected.\n",
      "['de', '##ject', '##ion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0331,  0.1937,  0.4121,  ...,  0.0991, -0.1310,  0.4767])\n",
      "dejection\n",
      "Saved the embedding for dejection.\n",
      "['deliberate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6378,  0.3640,  0.5816,  ..., -0.6671, -0.9848,  0.1432])\n",
      "deliberate\n",
      "Saved the embedding for deliberate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['del', '##ibe', '##rating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1196, -0.1439,  0.4765,  ..., -1.1946, -0.3878,  0.5008])\n",
      "deliberating\n",
      "Saved the embedding for deliberating.\n",
      "['delight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0058, -0.1501, -0.7442,  ..., -0.2575, -0.2765,  1.2016])\n",
      "delight\n",
      "Saved the embedding for delight.\n",
      "['delighted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7438,  0.2008, -0.0937,  ..., -0.1465, -0.7249,  0.9160])\n",
      "delighted\n",
      "Saved the embedding for delighted.\n",
      "['delightful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3387,  0.5431,  0.2850,  ..., -0.7200, -0.2394,  1.1215])\n",
      "delightful\n",
      "Saved the embedding for delightful.\n",
      "['del', '##iri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3813, -0.0087,  0.8099,  ..., -1.4150, -0.1262,  0.2830])\n",
      "delirious\n",
      "Saved the embedding for delirious.\n",
      "['del', '##iri', '##um'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5039,  0.2715,  0.0116,  ..., -0.9151, -0.4221,  0.8431])\n",
      "delirium\n",
      "Saved the embedding for delirium.\n",
      "['del', '##ude'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2860, -0.1451,  0.9983,  ..., -0.2134,  0.5995,  1.2254])\n",
      "delude\n",
      "Saved the embedding for delude.\n",
      "['del', '##usion', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0917, -0.2661,  0.3358,  ..., -1.1247,  0.1393,  0.6716])\n",
      "delusional\n",
      "Saved the embedding for delusional.\n",
      "['demanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4302,  0.0045,  0.4171,  ..., -0.2548, -0.8514,  0.3820])\n",
      "demanding\n",
      "Saved the embedding for demanding.\n",
      "['dem', '##ean', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0664,  0.3984,  0.1537,  ..., -0.9258, -0.6411,  0.3114])\n",
      "demeaning\n",
      "Saved the embedding for demeaning.\n",
      "['dem', '##ented'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5399, -0.2991,  0.0381,  ..., -0.9978, -0.2779,  0.2731])\n",
      "demented\n",
      "Saved the embedding for demented.\n",
      "['demise', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1210, -0.3756,  0.7944,  ..., -1.1728,  0.6786, -0.2970])\n",
      "demised\n",
      "Saved the embedding for demised.\n",
      "['demo', '##ral', '##ized'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1954,  0.0212, -0.1517,  ..., -0.9015, -0.1198,  0.0202])\n",
      "demoralized\n",
      "Saved the embedding for demoralized.\n",
      "['dem', '##ure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3089, -0.0019,  0.2583,  ..., -0.8945, -0.2107,  0.7387])\n",
      "demure\n",
      "Saved the embedding for demure.\n",
      "['denied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0197,  0.4749,  0.2828,  ..., -1.0515, -0.3610, -0.0051])\n",
      "denied\n",
      "Saved the embedding for denied.\n",
      "['den', '##oun', '##cing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1854,  0.1929,  0.1331,  ..., -0.2500, -0.5425,  0.4943])\n",
      "denouncing\n",
      "Saved the embedding for denouncing.\n",
      "['depleted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0008, -0.0434, -0.8121,  ..., -0.1898, -0.1732, -0.3172])\n",
      "depleted\n",
      "Saved the embedding for depleted.\n",
      "['de', '##pl', '##ora', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1275, -0.0387,  0.2918,  ..., -0.5479,  0.0221,  0.5721])\n",
      "deplorable\n",
      "Saved the embedding for deplorable.\n",
      "['de', '##pre', '##cating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.1321, 0.7559, 0.3579,  ..., 0.0080, 0.0212, 0.5258])\n",
      "deprecating\n",
      "Saved the embedding for deprecating.\n",
      "['depressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0113, -0.0229,  0.1441,  ..., -0.5100, -0.3740,  0.9099])\n",
      "depressed\n",
      "Saved the embedding for depressed.\n",
      "['depression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8325, -0.2500,  0.4316,  ..., -0.6641,  0.0952,  0.1729])\n",
      "depression\n",
      "Saved the embedding for depression.\n",
      "['deprived'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3335,  0.4890,  0.0112,  ..., -0.0147, -0.0863,  0.7852])\n",
      "deprived\n",
      "Saved the embedding for deprived.\n",
      "['der', '##ange', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0819,  0.6697,  0.3522,  ..., -0.2299, -0.2815,  0.8745])\n",
      "deranged\n",
      "Saved the embedding for deranged.\n",
      "['der', '##ision'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0830,  0.3035,  0.0816,  ..., -0.5302,  0.1055,  0.9303])\n",
      "derision\n",
      "Saved the embedding for derision.\n",
      "['der', '##isi', '##ve'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.5844, 0.6025, 0.4499,  ..., 0.1429, 0.1446, 0.4995])\n",
      "derisive\n",
      "Saved the embedding for derisive.\n",
      "['der', '##oga', '##tory'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1389,  0.3825, -0.1708,  ..., -0.5798, -0.1921,  0.8099])\n",
      "derogatory\n",
      "Saved the embedding for derogatory.\n",
      "['desire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3239,  0.1043, -0.1175,  ..., -1.4453,  0.0083,  0.7210])\n",
      "desire\n",
      "Saved the embedding for desire.\n",
      "['des', '##iring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7637,  0.4514,  0.9736,  ..., -0.3766,  0.4811,  0.2936])\n",
      "desiring\n",
      "Saved the embedding for desiring.\n",
      "['des', '##iro', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3382,  0.5058,  0.4666,  ...,  0.1796, -0.2499,  0.0385])\n",
      "desirous\n",
      "Saved the embedding for desirous.\n",
      "['des', '##olate'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2172,  0.2645,  0.2144,  ..., -0.5934,  0.0738,  0.5497])\n",
      "desolate\n",
      "Saved the embedding for desolate.\n",
      "['despair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2336,  0.1149, -0.0676,  ..., -0.7565,  0.2843,  0.5779])\n",
      "despair\n",
      "Saved the embedding for despair.\n",
      "['despair', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1086, -0.0096,  0.4726,  ..., -1.0704, -0.3009,  0.5978])\n",
      "despaired\n",
      "Saved the embedding for despaired.\n",
      "['despair', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2326, -0.0521,  0.1810,  ..., -1.6236,  0.1364,  0.7585])\n",
      "despairing\n",
      "Saved the embedding for despairing.\n",
      "['desperate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0995,  0.0575,  0.0196,  ..., -0.6303, -0.2512,  0.7162])\n",
      "desperate\n",
      "Saved the embedding for desperate.\n",
      "['desperation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1742,  0.0057,  0.1891,  ..., -1.0259, -0.5101,  0.7819])\n",
      "desperation\n",
      "Saved the embedding for desperation.\n",
      "['des', '##pis', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3163,  0.1792, -0.4981,  ..., -0.5555, -0.0895,  0.4596])\n",
      "despise\n",
      "Saved the embedding for despise.\n",
      "['des', '##pon', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2435,  0.3559,  0.1652,  ..., -0.7227,  0.1489,  0.7400])\n",
      "despondent\n",
      "Saved the embedding for despondent.\n",
      "['des', '##ti', '##tute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3215, -0.6486, -0.1123,  ..., -0.1844, -0.4604,  1.2996])\n",
      "destitute\n",
      "Saved the embedding for destitute.\n",
      "['destroyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8010, -0.1061,  0.0415,  ..., -0.7850,  0.3710,  0.7985])\n",
      "destroyed\n",
      "Saved the embedding for destroyed.\n",
      "['detached'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1243,  0.2617, -0.2505,  ..., -0.9069,  1.0475,  0.8019])\n",
      "detached\n",
      "Saved the embedding for detached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['determination'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5277,  0.1303,  0.0709,  ..., -1.1588, -0.0573,  0.6104])\n",
      "determination\n",
      "Saved the embedding for determination.\n",
      "['determined'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7999,  0.0562,  0.2695,  ..., -1.5268, -0.5233,  0.4093])\n",
      "determined\n",
      "Saved the embedding for determined.\n",
      "['determining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2708,  0.3253,  0.6310,  ..., -1.0668, -0.1971,  0.7289])\n",
      "determining\n",
      "Saved the embedding for determining.\n",
      "['deter', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1352,  0.3341, -0.3183,  ..., -1.1441, -0.4603,  1.1193])\n",
      "deterred\n",
      "Saved the embedding for deterred.\n",
      "['det', '##est'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6483,  0.3771,  0.0533,  ..., -0.2097, -0.3880,  1.1985])\n",
      "detest\n",
      "Saved the embedding for detest.\n",
      "['det', '##est', '##able'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2831,  0.3969,  0.0239,  ..., -0.7475, -0.2197,  1.1484])\n",
      "detestable\n",
      "Saved the embedding for detestable.\n",
      "['det', '##est', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6674,  0.5189, -0.5044,  ..., -0.4081, -0.3376,  0.9049])\n",
      "detesting\n",
      "Saved the embedding for detesting.\n",
      "['det', '##rim', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0210,  0.6029, -0.4070,  ..., -1.2721, -0.2501,  0.7006])\n",
      "detriment\n",
      "Saved the embedding for detriment.\n",
      "['devastated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0635,  0.6469, -0.4585,  ..., -0.7168,  0.0548,  1.0626])\n",
      "devastated\n",
      "Saved the embedding for devastated.\n",
      "['devi', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0110, -0.1141, -0.4210,  ..., -1.5357, -0.4350,  0.7777])\n",
      "deviant\n",
      "Saved the embedding for deviant.\n",
      "['devil', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9446, -0.3640,  0.5032,  ..., -0.3427, -0.0747,  0.3578])\n",
      "devilish\n",
      "Saved the embedding for devilish.\n",
      "['devi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3019, -0.0036, -0.4546,  ..., -1.3214, -0.7072,  0.8713])\n",
      "devious\n",
      "Saved the embedding for devious.\n",
      "['devi', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4808, -0.1179,  0.1427,  ..., -1.2139, -0.7520,  1.1483])\n",
      "devising\n",
      "Saved the embedding for devising.\n",
      "['di', '##ffi', '##dent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2456,  0.2008,  0.4295,  ..., -0.7905,  0.3825,  1.3386])\n",
      "diffident\n",
      "Saved the embedding for diffident.\n",
      "['dil', '##atory'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8718,  0.6468,  0.1836,  ..., -0.8894, -0.9288,  1.0131])\n",
      "dilatory\n",
      "Saved the embedding for dilatory.\n",
      "['dil', '##igen', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7517, -0.4681,  0.2058,  ..., -1.3403, -0.4843,  1.0950])\n",
      "diligent\n",
      "Saved the embedding for diligent.\n",
      "['dim', '##wi', '##tted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5486, -0.0364,  0.3821,  ..., -0.0683,  0.0264,  0.5077])\n",
      "dimwitted\n",
      "Saved the embedding for dimwitted.\n",
      "['dire'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1984, -0.0107, -0.0293,  ..., -1.6094,  0.3801,  0.1578])\n",
      "dire\n",
      "Saved the embedding for dire.\n",
      "['disagree'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7041,  0.0506,  0.5586,  ..., -0.0879, -0.4931,  0.9791])\n",
      "disagree\n",
      "Saved the embedding for disagree.\n",
      "['disagree', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1678,  0.1807,  0.4142,  ..., -0.5729, -0.8742,  0.9839])\n",
      "disagreeable\n",
      "Saved the embedding for disagreeable.\n",
      "['disagreement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0287,  0.1015,  0.0562,  ...,  1.0288, -1.0867, -0.1179])\n",
      "disagreement\n",
      "Saved the embedding for disagreement.\n",
      "['disappointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3960, -0.0172,  0.5924,  ..., -0.1131, -0.8728,  0.6038])\n",
      "disappointed\n",
      "Saved the embedding for disappointed.\n",
      "['disappointing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1205, -0.1259,  0.0413,  ...,  0.2411, -0.7203,  0.8739])\n",
      "disappointing\n",
      "Saved the embedding for disappointing.\n",
      "['disappointment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4504,  0.2111,  0.1439,  ..., -0.2225,  0.2026,  0.1037])\n",
      "disappointment\n",
      "Saved the embedding for disappointment.\n",
      "['disapproval'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4145,  0.5453, -0.3317,  ...,  0.1053, -0.9236,  0.6986])\n",
      "disapproval\n",
      "Saved the embedding for disapproval.\n",
      "['di', '##sa', '##pp', '##roving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3501, -0.0119,  0.1677,  ..., -0.7483, -0.4620,  0.3128])\n",
      "disapproving\n",
      "Saved the embedding for disapproving.\n",
      "['disbelief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4445, -0.6349, -0.3941,  ..., -0.4897,  0.1688,  0.5639])\n",
      "disbelief\n",
      "Saved the embedding for disbelief.\n",
      "['di', '##sb', '##eli', '##eve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2204,  0.2256,  0.1240,  ..., -0.4329,  0.2185,  0.7141])\n",
      "disbelieve\n",
      "Saved the embedding for disbelieve.\n",
      "['di', '##sb', '##eli', '##eving'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1790, -0.1219,  0.1657,  ..., -0.9889, -0.1153,  0.1927])\n",
      "disbelieving\n",
      "Saved the embedding for disbelieving.\n",
      "['disc', '##ern', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7604,  0.0412, -0.1776,  ..., -0.6068, -0.6912, -0.1022])\n",
      "discerning\n",
      "Saved the embedding for discerning.\n",
      "['disco', '##mbo', '##bula', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2992,  0.4885,  0.5600,  ..., -0.9304,  0.2370, -0.0327])\n",
      "discombobulated\n",
      "Saved the embedding for discombobulated.\n",
      "['disco', '##m', '##fi', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.9461,  0.1503,  0.2085,  ..., -0.9677,  0.2309, -0.5254])\n",
      "discomfited\n",
      "Saved the embedding for discomfited.\n",
      "['discomfort'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4262,  0.5966,  0.1321,  ..., -0.3422,  0.0724,  1.3762])\n",
      "discomfort\n",
      "Saved the embedding for discomfort.\n",
      "['discomfort', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0989,  0.4374,  0.1605,  ..., -1.1138, -0.1373,  0.6953])\n",
      "discomforted\n",
      "Saved the embedding for discomforted.\n",
      "['disco', '##nce', '##rted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0791,  0.8786, -0.2640,  ..., -0.8341,  0.1084,  0.0337])\n",
      "disconcerted\n",
      "Saved the embedding for disconcerted.\n",
      "['disconnected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6539, -0.7723, -0.0906,  ..., -0.3800, -0.0242,  0.4285])\n",
      "disconnected\n",
      "Saved the embedding for disconnected.\n",
      "['disco', '##ns', '##olate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5090, -0.0388, -0.6863,  ..., -0.5367,  0.1847, -0.1472])\n",
      "disconsolate\n",
      "Saved the embedding for disconsolate.\n",
      "['discontent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7236,  0.0618,  0.6872,  ..., -0.3515, -0.9574,  0.5241])\n",
      "discontent\n",
      "Saved the embedding for discontent.\n",
      "['discontent', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9100, -0.2664,  0.6733,  ..., -0.6627, -0.4657,  0.4465])\n",
      "discontented\n",
      "Saved the embedding for discontented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discount', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2474,  0.3807,  0.2794,  ..., -0.6461, -0.8495,  0.1587])\n",
      "discounted\n",
      "Saved the embedding for discounted.\n",
      "['discouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9798, -0.0387, -0.3839,  ..., -0.2456, -0.1778,  0.1200])\n",
      "discouraged\n",
      "Saved the embedding for discouraged.\n",
      "['discovery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5146,  0.7006, -1.6729,  ..., -0.2180, -0.9743,  0.9419])\n",
      "discovery\n",
      "Saved the embedding for discovery.\n",
      "['disc', '##rim', '##inating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1541,  0.4210, -0.1649,  ..., -0.8608,  0.0293,  0.7341])\n",
      "discriminating\n",
      "Saved the embedding for discriminating.\n",
      "['discussed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5883, -0.2621, -0.6074,  ..., -0.1763, -0.5054,  0.6671])\n",
      "discussed\n",
      "Saved the embedding for discussed.\n",
      "['disdain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3551,  0.0359, -0.5323,  ..., -0.7040, -0.5135,  1.2667])\n",
      "disdain\n",
      "Saved the embedding for disdain.\n",
      "['disdain', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5347,  0.0848,  0.1883,  ..., -0.2041, -0.8289,  0.8917])\n",
      "disdained\n",
      "Saved the embedding for disdained.\n",
      "['disdain', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0629,  0.4612, -0.1575,  ..., -0.9758, -0.8842,  0.7794])\n",
      "disdainful\n",
      "Saved the embedding for disdainful.\n",
      "['disdain', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2622,  0.5559,  0.2179,  ..., -0.3285, -0.9260,  0.6707])\n",
      "disdainfully\n",
      "Saved the embedding for disdainfully.\n",
      "['di', '##sen', '##chan', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0548,  0.0142, -0.0039,  ..., -0.1867, -0.3343,  0.6167])\n",
      "disenchanted\n",
      "Saved the embedding for disenchanted.\n",
      "['di', '##sen', '##ga', '##ged'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0657,  0.1048,  0.3475,  ..., -0.1965, -0.3256,  0.5059])\n",
      "disengaged\n",
      "Saved the embedding for disengaged.\n",
      "['disgrace', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6072,  0.1344,  0.2370,  ..., -0.4417, -0.8844,  0.5419])\n",
      "disgraced\n",
      "Saved the embedding for disgraced.\n",
      "['di', '##sg', '##run', '##tled'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6381,  0.2512, -0.2144,  ..., -0.5051, -0.6171,  0.6103])\n",
      "disgruntled\n",
      "Saved the embedding for disgruntled.\n",
      "['di', '##sg', '##run', '##tlement'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3117,  0.4384,  0.1886,  ..., -0.2573, -0.6419,  0.8610])\n",
      "disgruntlement\n",
      "Saved the embedding for disgruntlement.\n",
      "['disgust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5300,  0.3231, -0.5734,  ..., -0.7674,  0.2140,  0.9300])\n",
      "disgust\n",
      "Saved the embedding for disgust.\n",
      "['disgusted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1759,  0.5428, -0.4706,  ..., -0.0215, -0.1463,  0.6145])\n",
      "disgusted\n",
      "Saved the embedding for disgusted.\n",
      "['disgusted', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4046,  0.2207,  0.4741,  ..., -0.5659, -1.0628,  0.6098])\n",
      "disgustedly\n",
      "Saved the embedding for disgustedly.\n",
      "['disgusting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1588,  0.3753, -0.0082,  ..., -0.7056, -0.8806,  0.2857])\n",
      "disgusting\n",
      "Saved the embedding for disgusting.\n",
      "['dish', '##ear', '##ten', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2896, -0.1316,  0.0253,  ..., -0.5754, -0.2188,  0.0463])\n",
      "disheartened\n",
      "Saved the embedding for disheartened.\n",
      "['dish', '##ones', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1364,  0.0234,  0.0627,  ..., -0.5491, -0.5305,  0.2026])\n",
      "dishonest\n",
      "Saved the embedding for dishonest.\n",
      "['di', '##sil', '##lusion', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0890,  0.0732, -0.0663,  ..., -0.6278, -0.7807,  0.4951])\n",
      "disillusioned\n",
      "Saved the embedding for disillusioned.\n",
      "['di', '##sin', '##cl', '##ined'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0512,  0.6374,  0.4062,  ...,  0.4364, -0.0515,  1.2455])\n",
      "disinclined\n",
      "Saved the embedding for disinclined.\n",
      "['di', '##sing', '##en', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1256, -0.0341,  0.3403,  ..., -0.4352, -0.8810,  0.7621])\n",
      "disingenuous\n",
      "Saved the embedding for disingenuous.\n",
      "['di', '##sin', '##ter', '##est'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.9941,  0.5013, -0.7280,  ..., -0.3204, -0.5156,  1.6768])\n",
      "disinterest\n",
      "Saved the embedding for disinterest.\n",
      "['di', '##sin', '##ter', '##ested'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2111,  0.5533, -0.6407,  ..., -0.5013, -0.5750,  1.3044])\n",
      "disinterested\n",
      "Saved the embedding for disinterested.\n",
      "['di', '##s', '##jo', '##int', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.4637,  0.3778, -0.6643,  ..., -0.2563, -0.3000,  1.2208])\n",
      "disjointed\n",
      "Saved the embedding for disjointed.\n",
      "['dislike'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2535,  0.1830, -0.0041,  ..., -0.2536, -0.9404,  1.0659])\n",
      "dislike\n",
      "Saved the embedding for dislike.\n",
      "['disliked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0096, -0.1864,  0.4555,  ...,  0.2606, -1.2312,  0.8727])\n",
      "disliked\n",
      "Saved the embedding for disliked.\n",
      "['di', '##sl', '##iki', '##ng'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8277,  0.5954, -0.1641,  ..., -1.3904, -0.4988,  0.8472])\n",
      "disliking\n",
      "Saved the embedding for disliking.\n",
      "['di', '##sma', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5163,  0.7849, -0.6610,  ..., -0.9936, -0.2720,  0.6969])\n",
      "dismal\n",
      "Saved the embedding for dismal.\n",
      "['di', '##sman'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5109,  0.0366,  0.4695,  ..., -0.6575, -0.0999,  1.1413])\n",
      "disman\n",
      "Saved the embedding for disman.\n",
      "['dismay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1711,  0.1419,  0.7455,  ..., -0.2766,  0.3007,  0.8259])\n",
      "dismay\n",
      "Saved the embedding for dismay.\n",
      "['dismay', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3676,  0.3288,  0.7835,  ..., -0.2655,  0.4220,  0.4187])\n",
      "dismayed\n",
      "Saved the embedding for dismayed.\n",
      "['dismiss', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0498,  0.6932,  0.1268,  ..., -1.0893, -0.3661,  0.7339])\n",
      "dismissive\n",
      "Saved the embedding for dismissive.\n",
      "['di', '##so', '##bed', '##ient'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1751, -0.0476,  0.2693,  ..., -0.3643, -0.3220,  0.6769])\n",
      "disobedient\n",
      "Saved the embedding for disobedient.\n",
      "['disorder', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0804,  0.5910, -0.2271,  ..., -1.7132, -0.4136, -0.7687])\n",
      "disorderly\n",
      "Saved the embedding for disorderly.\n",
      "['di', '##sor', '##iente', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0413,  0.1803,  0.0267,  ..., -0.4738, -0.1681,  1.0142])\n",
      "disoriented\n",
      "Saved the embedding for disoriented.\n",
      "['di', '##sp', '##air'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6959, -0.3826, -0.1913,  ..., -1.5926,  0.2400,  0.8434])\n",
      "dispair\n",
      "Saved the embedding for dispair.\n",
      "['di', '##spar', '##aging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0979,  0.2862,  0.1783,  ..., -0.5829, -0.6848,  0.5112])\n",
      "disparaging\n",
      "Saved the embedding for disparaging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['di', '##sp', '##ass', '##ion', '##ate'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0596,  0.0333,  0.3343,  ..., -0.2350, -0.5530,  1.0503])\n",
      "dispassionate\n",
      "Saved the embedding for dispassionate.\n",
      "['di', '##sp', '##iri', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4413,  0.2158,  0.1771,  ..., -1.0111, -0.2633,  0.5836])\n",
      "dispirited\n",
      "Saved the embedding for dispirited.\n",
      "['di', '##sp', '##iri', '##ted', '##ness'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0195,  0.2064,  0.4503,  ..., -0.9635, -0.5029,  1.0136])\n",
      "dispiritedness\n",
      "Saved the embedding for dispiritedness.\n",
      "['di', '##sp', '##lea', '##sed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2945,  0.2486,  0.4643,  ..., -0.6296, -0.5571,  0.3090])\n",
      "displeased\n",
      "Saved the embedding for displeased.\n",
      "['displeasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0101,  0.4227,  0.1439,  ..., -0.4003, -0.7993,  0.6628])\n",
      "displeasure\n",
      "Saved the embedding for displeasure.\n",
      "['di', '##s', '##qui', '##et'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0780,  0.1137,  0.3358,  ...,  0.2871,  0.2698,  0.8528])\n",
      "disquiet\n",
      "Saved the embedding for disquiet.\n",
      "['di', '##s', '##qui', '##ete', '##d'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.0317, -0.1196,  0.5222,  ...,  0.1959,  0.1324,  0.7334])\n",
      "disquieted\n",
      "Saved the embedding for disquieted.\n",
      "['disregard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7897, -0.3240,  0.0945,  ..., -1.3132, -0.7145,  0.3391])\n",
      "disregard\n",
      "Saved the embedding for disregard.\n",
      "['di', '##sr', '##es', '##pe', '##ct', '##ful'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([-0.2073,  0.4900,  0.0311,  ..., -0.4774, -0.4696,  1.0995])\n",
      "disrespectful\n",
      "Saved the embedding for disrespectful.\n",
      "['disrupted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4529,  0.1334, -0.2713,  ..., -0.6008, -0.0854,  0.8625])\n",
      "disrupted\n",
      "Saved the embedding for disrupted.\n",
      "['disrupt', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0237,  0.2735, -0.4877,  ..., -0.6377, -0.6006,  0.8412])\n",
      "disruptive\n",
      "Saved the embedding for disruptive.\n",
      "['dissatisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2523, -0.4830,  0.4628,  ...,  0.1930, -0.8086,  0.0603])\n",
      "dissatisfaction\n",
      "Saved the embedding for dissatisfaction.\n",
      "['dissatisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3394, -0.6754,  0.3572,  ..., -0.0583, -0.7435,  0.6280])\n",
      "dissatisfied\n",
      "Saved the embedding for dissatisfied.\n",
      "['di', '##ssa', '##tis', '##fy'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1821,  0.1547,  0.6494,  ...,  0.0102, -0.2441,  0.8031])\n",
      "dissatisfy\n",
      "Saved the embedding for dissatisfy.\n",
      "['di', '##sse', '##cting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0192,  0.1482,  0.3632,  ..., -0.4507, -0.0856,  1.2676])\n",
      "dissecting\n",
      "Saved the embedding for dissecting.\n",
      "['di', '##sso', '##cia', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1188,  0.2558,  0.4491,  ..., -0.1016,  0.0819,  1.0172])\n",
      "dissociated\n",
      "Saved the embedding for dissociated.\n",
      "['di', '##sson', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0356,  0.0082, -0.5504,  ...,  0.2600,  0.0370,  1.4840])\n",
      "dissonant\n",
      "Saved the embedding for dissonant.\n",
      "['di', '##sta', '##in'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8271,  0.3293, -0.8245,  ..., -1.3976, -0.1210,  1.0306])\n",
      "distain\n",
      "Saved the embedding for distain.\n",
      "['distant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0019, -0.2102,  0.3364,  ...,  0.2825, -0.0257,  0.3935])\n",
      "distant\n",
      "Saved the embedding for distant.\n",
      "['di', '##sta', '##ste'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2033,  0.4393,  0.0083,  ..., -2.0261, -0.2694,  0.3086])\n",
      "distaste\n",
      "Saved the embedding for distaste.\n",
      "['di', '##sta', '##ste', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1565,  0.4528, -0.3071,  ..., -1.5390, -0.6976,  0.5152])\n",
      "distasteful\n",
      "Saved the embedding for distasteful.\n",
      "['distracted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5958, -0.1066,  0.2824,  ..., -0.0440,  0.0162,  0.3665])\n",
      "distracted\n",
      "Saved the embedding for distracted.\n",
      "['distraught'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1420, -0.0467, -0.0020,  ..., -0.9672, -0.0907,  0.7778])\n",
      "distraught\n",
      "Saved the embedding for distraught.\n",
      "['distress'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6516,  0.2162,  0.1742,  ..., -0.0678, -0.6978,  0.6407])\n",
      "distress\n",
      "Saved the embedding for distress.\n",
      "['distressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0186,  0.3871, -0.4152,  ...,  0.4224, -0.3449,  0.3565])\n",
      "distressed\n",
      "Saved the embedding for distressed.\n",
      "['distress', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3335,  0.2908,  0.3051,  ..., -0.7387, -0.9216,  0.5188])\n",
      "distressing\n",
      "Saved the embedding for distressing.\n",
      "['distrust'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5640,  0.0029,  0.0675,  ...,  0.1290, -0.6405,  0.9046])\n",
      "distrust\n",
      "Saved the embedding for distrust.\n",
      "['distrust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3911, -0.0222, -0.0189,  ..., -0.5545, -0.9738,  0.5570])\n",
      "distrustful\n",
      "Saved the embedding for distrustful.\n",
      "['distrust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2415,  0.5249,  0.3587,  ..., -1.0153, -0.8408,  0.8813])\n",
      "distrusting\n",
      "Saved the embedding for distrusting.\n",
      "['disturbed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4196, -0.4250, -0.4985,  ..., -0.6092, -0.7734,  0.8460])\n",
      "disturbed\n",
      "Saved the embedding for disturbed.\n",
      "['diverted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6536, -0.2633, -0.7385,  ..., -0.6934, -0.1758,  0.8533])\n",
      "diverted\n",
      "Saved the embedding for diverted.\n",
      "['dod', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0746,  0.5066, -0.0869,  ..., -0.6552,  0.0829,  0.4098])\n",
      "dodgy\n",
      "Saved the embedding for dodgy.\n",
      "['do', '##le', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1825, -0.4865,  0.1501,  ..., -1.0661, -0.2837,  0.3626])\n",
      "doleful\n",
      "Saved the embedding for doleful.\n",
      "['do', '##lt', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9848, -0.1730,  0.5946,  ..., -0.4389,  0.2339,  1.0579])\n",
      "doltish\n",
      "Saved the embedding for doltish.\n",
      "['dominant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6521, -0.4861, -1.3007,  ...,  0.8046, -0.1525,  0.4891])\n",
      "dominant\n",
      "Saved the embedding for dominant.\n",
      "['dominating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5851, -0.0901, -0.6170,  ..., -0.1325, -0.8275,  1.0366])\n",
      "dominating\n",
      "Saved the embedding for dominating.\n",
      "['dom', '##ine', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1964,  0.1203, -0.0234,  ..., -0.6459, -0.9864,  0.1896])\n",
      "domineering\n",
      "Saved the embedding for domineering.\n",
      "['done'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2995,  0.5509, -0.2028,  ..., -1.0767, -0.0285,  0.5017])\n",
      "done\n",
      "Saved the embedding for done.\n",
      "['doomed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3462, -0.5580, -0.0304,  ..., -0.7775,  0.1658, -0.1252])\n",
      "doomed\n",
      "Saved the embedding for doomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1216,  0.0201,  0.4791,  ..., -0.7771, -0.5114,  0.5879])\n",
      "dopey\n",
      "Saved the embedding for dopey.\n",
      "['dot', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5013,  0.3559,  0.1688,  ..., -0.7846, -0.4168,  0.4394])\n",
      "doting\n",
      "Saved the embedding for doting.\n",
      "['doubt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6620,  0.0766, -0.4501,  ..., -0.5562, -0.5247,  0.9385])\n",
      "doubt\n",
      "Saved the embedding for doubt.\n",
      "['doubt', '##er'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9739,  0.1895,  0.3065,  ..., -1.7678, -0.7102,  0.3351])\n",
      "doubter\n",
      "Saved the embedding for doubter.\n",
      "['doubtful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7239,  0.2190,  0.3856,  ...,  0.6220,  0.0622,  0.5666])\n",
      "doubtful\n",
      "Saved the embedding for doubtful.\n",
      "['doubtful', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0786,  0.6632,  0.4061,  ...,  0.1668, -0.1414,  0.2973])\n",
      "doubtfully\n",
      "Saved the embedding for doubtfully.\n",
      "['doubtful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3594, -0.1380,  0.4330,  ..., -0.4699, -0.0161,  0.8133])\n",
      "doubtfulness\n",
      "Saved the embedding for doubtfulness.\n",
      "['doubt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3708,  0.6437, -0.7970,  ..., -1.0527, -0.6885,  0.7364])\n",
      "doubting\n",
      "Saved the embedding for doubting.\n",
      "['do', '##ur'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0456,  0.1018,  0.2393,  ..., -0.7068,  0.0253,  0.4817])\n",
      "dour\n",
      "Saved the embedding for dour.\n",
      "['down'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3213, -0.4374,  0.3947,  ..., -0.6580, -0.1363,  0.4308])\n",
      "down\n",
      "Saved the embedding for down.\n",
      "['down', '##cast'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0967, -0.2561,  0.2242,  ..., -0.4362, -0.8259,  0.7332])\n",
      "downcast\n",
      "Saved the embedding for downcast.\n",
      "['down', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3881, -0.5447, -0.2576,  ..., -1.8485, -0.7167, -0.8741])\n",
      "downhearted\n",
      "Saved the embedding for downhearted.\n",
      "['down', '##hearted', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0378, -0.0193, -0.1713,  ..., -0.7081,  0.2214,  0.5170])\n",
      "downheartedness\n",
      "Saved the embedding for downheartedness.\n",
      "['down', '##tro', '##dden'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0793,  0.0249, -0.2488,  ..., -1.7643, -0.4036,  0.3355])\n",
      "downtrodden\n",
      "Saved the embedding for downtrodden.\n",
      "['do', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0038,  0.0609,  0.6472,  ..., -0.5038, -0.4130,  1.1028])\n",
      "dozing\n",
      "Saved the embedding for dozing.\n",
      "['drained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8198,  0.0885, -0.4816,  ...,  0.6517, -0.0594,  0.4966])\n",
      "drained\n",
      "Saved the embedding for drained.\n",
      "['dramatic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1332,  0.2731, -0.1189,  ..., -1.1884,  0.0062,  0.1544])\n",
      "dramatic\n",
      "Saved the embedding for dramatic.\n",
      "['drawn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3556,  0.2102,  0.1285,  ..., -0.0328, -0.0691,  0.4282])\n",
      "drawn\n",
      "Saved the embedding for drawn.\n",
      "['dread'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1965,  0.4117, -0.5095,  ..., -0.9015, -0.3781,  0.3524])\n",
      "dread\n",
      "Saved the embedding for dread.\n",
      "['dreadful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6398,  0.8494,  0.0043,  ..., -0.8638, -0.0878,  0.4577])\n",
      "dreadful\n",
      "Saved the embedding for dreadful.\n",
      "['dread', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5661,  0.2980,  0.5514,  ..., -1.0233, -0.8863,  0.4879])\n",
      "dreading\n",
      "Saved the embedding for dreading.\n",
      "['dreaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9300,  0.3751, -0.2392,  ..., -0.4999, -0.5035,  1.1347])\n",
      "dreaming\n",
      "Saved the embedding for dreaming.\n",
      "['dream', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1545, -0.0567,  0.5305,  ..., -0.1795, -0.7515,  0.3156])\n",
      "dreamy\n",
      "Saved the embedding for dreamy.\n",
      "['dr', '##ear', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6066,  0.2674, -0.0458,  ..., -0.8972, -0.1429,  0.7281])\n",
      "dreary\n",
      "Saved the embedding for dreary.\n",
      "['driven'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1546, -0.4505, -0.8535,  ..., -0.7925,  0.4218,  0.1441])\n",
      "driven\n",
      "Saved the embedding for driven.\n",
      "['dr', '##ows', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2702,  0.4576, -0.2086,  ..., -0.8140, -0.4339,  0.5269])\n",
      "drowsy\n",
      "Saved the embedding for drowsy.\n",
      "['drugged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1363,  0.4697, -0.5866,  ..., -0.1171, -0.0850,  0.6661])\n",
      "drugged\n",
      "Saved the embedding for drugged.\n",
      "['drunk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3680,  0.4363, -0.1897,  ..., -0.9592, -0.2283,  1.1407])\n",
      "drunk\n",
      "Saved the embedding for drunk.\n",
      "['drunken', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1246,  0.7595, -0.0748,  ..., -0.1755, -0.1826,  0.9413])\n",
      "drunkenness\n",
      "Saved the embedding for drunkenness.\n",
      "['dub', '##ie', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4453,  0.0252,  0.4255,  ..., -0.6593, -0.3002,  0.1365])\n",
      "dubiety\n",
      "Saved the embedding for dubiety.\n",
      "['dubious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2539,  0.4253,  0.3635,  ..., -0.0423, -0.4634,  0.3758])\n",
      "dubious\n",
      "Saved the embedding for dubious.\n",
      "['dubious', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0269,  0.2582,  0.1979,  ..., -0.3447, -0.2124,  0.5359])\n",
      "dubiously\n",
      "Saved the embedding for dubiously.\n",
      "['dull'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2779, -0.1579, -0.1578,  ..., -0.3621, -0.7530,  0.5758])\n",
      "dull\n",
      "Saved the embedding for dull.\n",
      "['dumb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4758,  0.1436, -0.2647,  ..., -0.9526, -0.9624,  0.9842])\n",
      "dumb\n",
      "Saved the embedding for dumb.\n",
      "['dumb', '##fo', '##und'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0206, -0.0116,  0.2873,  ..., -0.1548, -0.4928,  0.3519])\n",
      "dumbfound\n",
      "Saved the embedding for dumbfound.\n",
      "['dumb', '##founded'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1448,  0.1854,  0.3257,  ..., -0.8251, -0.1250,  0.0881])\n",
      "dumbfounded\n",
      "Saved the embedding for dumbfounded.\n",
      "['dumb', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2891, -0.0584,  0.2942,  ..., -0.5982, -0.2334,  0.3057])\n",
      "dumbstruck\n",
      "Saved the embedding for dumbstruck.\n",
      "['du', '##m', '##founded'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1280,  0.1025,  0.0337,  ..., -0.9731, -0.1590, -0.2345])\n",
      "dumfounded\n",
      "Saved the embedding for dumfounded.\n",
      "['du', '##pe'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4865, -0.5616,  0.4501,  ...,  0.3339,  0.1409,  0.3124])\n",
      "dupe\n",
      "Saved the embedding for dupe.\n",
      "['du', '##pl', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.1288, -0.2850,  0.3856,  ..., -0.1190,  0.1139,  0.6572])\n",
      "duplicitous\n",
      "Saved the embedding for duplicitous.\n",
      "['d', '##ys', '##ph', '##oric'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0204,  0.5101, -0.0527,  ..., -1.3884, -0.4692,  0.1284])\n",
      "dysphoric\n",
      "Saved the embedding for dysphoric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eager'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7447,  0.3635, -0.0973,  ..., -0.2444, -0.6533,  0.6821])\n",
      "eager\n",
      "Saved the embedding for eager.\n",
      "['eager', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2682, -0.1884,  0.3436,  ..., -1.3241, -1.0432,  0.5539])\n",
      "eagerness\n",
      "Saved the embedding for eagerness.\n",
      "['earnest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1067,  0.8266, -0.1909,  ..., -0.3778, -0.2373,  0.6131])\n",
      "earnest\n",
      "Saved the embedding for earnest.\n",
      "['easy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0998, -0.1373,  0.0540,  ..., -0.4992, -0.2945,  1.0946])\n",
      "easy\n",
      "Saved the embedding for easy.\n",
      "['e', '##bu', '##llie', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1434, -0.4436,  0.3145,  ..., -0.8885, -0.0690,  0.4227])\n",
      "ebullient\n",
      "Saved the embedding for ebullient.\n",
      "['ecstasy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1307,  0.2900,  0.4290,  ..., -0.5788,  0.3060,  0.3955])\n",
      "ecstasy\n",
      "Saved the embedding for ecstasy.\n",
      "['ec', '##static'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0580,  0.2255,  0.1832,  ..., -1.4031, -0.7553,  0.0174])\n",
      "ecstatic\n",
      "Saved the embedding for ecstatic.\n",
      "['ec', '##static', '##ally'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4090,  0.0279,  0.3168,  ..., -2.1499, -0.0811, -0.1069])\n",
      "ecstatically\n",
      "Saved the embedding for ecstatically.\n",
      "['ed', '##gy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0392,  0.2159,  0.5790,  ..., -0.6053, -0.0163,  0.2870])\n",
      "edgy\n",
      "Saved the embedding for edgy.\n",
      "['eerie'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1004,  0.1056, -0.4603,  ..., -0.7181, -0.7205,  0.3714])\n",
      "eerie\n",
      "Saved the embedding for eerie.\n",
      "['e', '##ff', '##ul', '##gent'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4983, -0.1141,  0.3261,  ..., -1.1790, -0.8905,  0.7450])\n",
      "effulgent\n",
      "Saved the embedding for effulgent.\n",
      "['ego', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3668, -0.0922, -0.1636,  ..., -0.5125, -0.2120,  0.3308])\n",
      "egoistic\n",
      "Saved the embedding for egoistic.\n",
      "['ego', '##tist', '##ical'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3748,  0.3995, -0.2564,  ...,  0.4220, -0.5011,  1.0172])\n",
      "egotistical\n",
      "Saved the embedding for egotistical.\n",
      "['e', '##gre', '##gio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0579,  0.1875,  0.3014,  ..., -0.1049, -0.3656,  0.6252])\n",
      "egregious\n",
      "Saved the embedding for egregious.\n",
      "['el', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0596,  0.2082, -0.3376,  ..., -0.8579, -0.8077,  0.2795])\n",
      "elated\n",
      "Saved the embedding for elated.\n",
      "['el', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2166,  0.6596,  0.0355,  ..., -1.3804, -0.9235,  0.7250])\n",
      "elation\n",
      "Saved the embedding for elation.\n",
      "['electrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3066, -0.4300, -0.3081,  ...,  0.2768, -0.2921,  1.1721])\n",
      "electrified\n",
      "Saved the embedding for electrified.\n",
      "['elusive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1582, -0.2548,  0.3803,  ..., -0.7097,  0.0078,  0.2158])\n",
      "elusive\n",
      "Saved the embedding for elusive.\n",
      "['embarrassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1254,  0.2643, -0.2703,  ..., -0.4463, -0.5719, -0.3038])\n",
      "embarrassed\n",
      "Saved the embedding for embarrassed.\n",
      "['embarrassment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1229,  1.3338,  0.1890,  ..., -0.1376, -0.2552,  0.4902])\n",
      "embarrassment\n",
      "Saved the embedding for embarrassment.\n",
      "['em', '##bit', '##tered'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4339, -0.0999,  0.3955,  ..., -1.3054, -0.3529, -0.0690])\n",
      "embittered\n",
      "Saved the embedding for embittered.\n",
      "['em', '##body'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8770,  0.3597,  0.1326,  ..., -0.2535, -0.8342,  0.4491])\n",
      "embody\n",
      "Saved the embedding for embody.\n",
      "['emotional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6205,  0.4409,  0.1024,  ..., -0.1378, -0.3125, -0.0441])\n",
      "emotional\n",
      "Saved the embedding for emotional.\n",
      "['emotion', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3064,  0.5124, -0.2632,  ..., -0.5701, -0.7165,  0.3741])\n",
      "emotionless\n",
      "Saved the embedding for emotionless.\n",
      "['em', '##path', '##etic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.9211,  0.4833,  0.1182,  ..., -0.8290, -0.3553,  0.4051])\n",
      "empathetic\n",
      "Saved the embedding for empathetic.\n",
      "['em', '##pathic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0160,  0.3136,  0.1822,  ..., -0.7835, -0.3999,  0.0221])\n",
      "empathic\n",
      "Saved the embedding for empathic.\n",
      "['empathy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6513,  0.3118, -0.0119,  ...,  0.3449, -0.4415,  0.1390])\n",
      "empathy\n",
      "Saved the embedding for empathy.\n",
      "['emptiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2792,  0.3948,  0.4052,  ...,  0.3179, -0.8072,  1.5343])\n",
      "emptiness\n",
      "Saved the embedding for emptiness.\n",
      "['empty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1818,  0.4183,  0.2998,  ...,  0.1719, -0.4369,  1.5105])\n",
      "empty\n",
      "Saved the embedding for empty.\n",
      "['en', '##amo', '##red'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6793,  0.0939,  0.3521,  ..., -0.1797, -0.0915,  0.2300])\n",
      "enamored\n",
      "Saved the embedding for enamored.\n",
      "['enchanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1764,  0.4128,  0.2488,  ..., -0.7518, -0.4122,  0.6860])\n",
      "enchanted\n",
      "Saved the embedding for enchanted.\n",
      "['encouraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0998,  0.3160, -0.2326,  ..., -1.5135, -0.6443,  0.5408])\n",
      "encouraged\n",
      "Saved the embedding for encouraged.\n",
      "['encouragement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9152,  0.3029,  0.0214,  ..., -1.2576, -0.9554,  0.5664])\n",
      "encouragement\n",
      "Saved the embedding for encouragement.\n",
      "['encouraging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1152,  0.0343,  0.1828,  ..., -1.0159, -0.5533,  0.8862])\n",
      "encouraging\n",
      "Saved the embedding for encouraging.\n",
      "['end', '##ear', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5239,  0.1472, -0.0576,  ..., -1.1089, -0.6517, -0.0862])\n",
      "endeared\n",
      "Saved the embedding for endeared.\n",
      "['end', '##earing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0159,  0.1523,  0.2005,  ..., -1.7175, -0.5063, -0.0281])\n",
      "endearing\n",
      "Saved the embedding for endearing.\n",
      "['enduring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6761, -0.0311, -1.2183,  ..., -1.0132, -0.3573, -0.4013])\n",
      "enduring\n",
      "Saved the embedding for enduring.\n",
      "['energetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1740,  0.6516, -0.7611,  ...,  0.0933,  0.6117,  0.8010])\n",
      "energetic\n",
      "Saved the embedding for energetic.\n",
      "['en', '##er', '##gi', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1367, -0.3734,  0.2197,  ..., -0.3157, -0.2597,  0.5847])\n",
      "energized\n",
      "Saved the embedding for energized.\n",
      "['engaged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4611,  0.5690,  0.4381,  ..., -0.6288, -0.2568,  0.4460])\n",
      "engaged\n",
      "Saved the embedding for engaged.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', '##ross', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0447,  0.0895,  0.3867,  ..., -0.6730, -0.5970,  0.6993])\n",
      "engrossed\n",
      "Saved the embedding for engrossed.\n",
      "['eng', '##ross', '##ment'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1742,  0.0809,  0.6218,  ..., -0.3994, -0.1664,  0.5180])\n",
      "engrossment\n",
      "Saved the embedding for engrossment.\n",
      "['enigma', '##tic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7408,  0.3173,  0.3340,  ..., -0.4366,  0.0684,  1.0859])\n",
      "enigmatic\n",
      "Saved the embedding for enigmatic.\n",
      "['enjoy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5025, -0.4330, -0.7282,  ..., -1.2163, -0.6111, -0.1100])\n",
      "enjoy\n",
      "Saved the embedding for enjoy.\n",
      "['enjoying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0929, -0.1049, -0.2362,  ..., -0.3176,  0.0529,  0.2173])\n",
      "enjoying\n",
      "Saved the embedding for enjoying.\n",
      "['enjoyment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1764, -0.0433, -0.4415,  ..., -0.9085, -0.1696,  0.0826])\n",
      "enjoyment\n",
      "Saved the embedding for enjoyment.\n",
      "['en', '##light', '##ened'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5461,  0.1293,  0.2414,  ..., -0.2789,  0.2860,  0.5975])\n",
      "enlightened\n",
      "Saved the embedding for enlightened.\n",
      "['en', '##mity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4450,  0.0286,  0.5719,  ..., -0.5105,  0.3178,  0.6473])\n",
      "enmity\n",
      "Saved the embedding for enmity.\n",
      "['en', '##nu', '##i'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5595, -0.0056,  0.1776,  ..., -0.5239, -0.2772,  0.0431])\n",
      "ennui\n",
      "Saved the embedding for ennui.\n",
      "['enraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5007,  0.5531,  0.4816,  ..., -0.2374, -0.6098,  0.5394])\n",
      "enraged\n",
      "Saved the embedding for enraged.\n",
      "['en', '##rag', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2338, -0.3118,  0.0676,  ..., -0.6681,  0.1045,  0.6241])\n",
      "enraging\n",
      "Saved the embedding for enraging.\n",
      "['en', '##ra', '##pt', '##ured'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3965, -0.1609,  0.4759,  ..., -0.2910, -0.2824,  0.7924])\n",
      "enraptured\n",
      "Saved the embedding for enraptured.\n",
      "['entertained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3776,  0.9553, -0.2857,  ..., -0.8316, -0.4962, -0.0838])\n",
      "entertained\n",
      "Saved the embedding for entertained.\n",
      "['en', '##th', '##ral', '##led'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6320,  0.2906,  0.4177,  ..., -1.1289, -0.4951,  0.4470])\n",
      "enthralled\n",
      "Saved the embedding for enthralled.\n",
      "['en', '##thus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5975, -0.1069,  0.3611,  ..., -0.8282, -0.4548,  0.2089])\n",
      "enthused\n",
      "Saved the embedding for enthused.\n",
      "['enthusiasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3232,  0.1584, -0.0971,  ..., -1.4838, -0.7930,  0.4856])\n",
      "enthusiasm\n",
      "Saved the embedding for enthusiasm.\n",
      "['enthusiastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3791,  0.5896,  0.4801,  ..., -0.5746, -0.5654,  0.6531])\n",
      "enthusiastic\n",
      "Saved the embedding for enthusiastic.\n",
      "['en', '##tic', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4814, -0.1151,  0.3665,  ..., -0.3855,  0.0755,  0.5653])\n",
      "enticed\n",
      "Saved the embedding for enticed.\n",
      "['entrance', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2225,  0.3940,  0.4114,  ..., -0.2377, -0.8183, -0.1678])\n",
      "entranced\n",
      "Saved the embedding for entranced.\n",
      "['en', '##vious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4143, -0.0706,  0.4277,  ..., -0.5701,  0.2358,  0.4439])\n",
      "envious\n",
      "Saved the embedding for envious.\n",
      "['envy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0291, 0.5335, 0.0530,  ..., 0.8747, 0.4785, 0.6738])\n",
      "envy\n",
      "Saved the embedding for envy.\n",
      "['erotic', '##ally'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1182,  0.4159, -1.0653,  ..., -1.7102,  0.4539,  0.4669])\n",
      "erotically\n",
      "Saved the embedding for erotically.\n",
      "['estranged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2067,  0.0174, -0.2681,  ..., -0.7527,  1.1353,  0.6012])\n",
      "estranged\n",
      "Saved the embedding for estranged.\n",
      "['etched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5646,  0.6524, -0.6299,  ..., -0.1259, -0.4935,  0.6263])\n",
      "etched\n",
      "Saved the embedding for etched.\n",
      "['eu', '##ph', '##oric'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0216,  0.1475,  0.1529,  ..., -0.6408, -0.1648,  0.6291])\n",
      "euphoric\n",
      "Saved the embedding for euphoric.\n",
      "['evaluating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9558,  0.1224, -0.4866,  ..., -0.5191, -0.6316,  1.1219])\n",
      "evaluating\n",
      "Saved the embedding for evaluating.\n",
      "['eva', '##sive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-8.8710e-02, -2.1376e-01,  3.4284e-01,  ..., -8.7731e-01,\n",
      "         2.9862e-05,  9.5360e-01])\n",
      "evasive\n",
      "Saved the embedding for evasive.\n",
      "['evil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0674,  0.1627,  0.3725,  ..., -0.0921, -0.1845,  0.2835])\n",
      "evil\n",
      "Saved the embedding for evil.\n",
      "['ev', '##oke'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1726, -0.0384,  0.7238,  ..., -0.5994,  0.0500, -0.2629])\n",
      "evoke\n",
      "Saved the embedding for evoke.\n",
      "['ex', '##ace', '##rba', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3239,  0.5535,  0.6836,  ..., -0.8483, -0.3517,  0.6253])\n",
      "exacerbated\n",
      "Saved the embedding for exacerbated.\n",
      "['ex', '##al', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2899,  0.2330,  0.8604,  ..., -0.3168, -0.0569,  0.5467])\n",
      "exalted\n",
      "Saved the embedding for exalted.\n",
      "['examining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2084,  0.1607,  0.4591,  ..., -0.9728, -0.3395,  0.8308])\n",
      "examining\n",
      "Saved the embedding for examining.\n",
      "['ex', '##as', '##per', '##ate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4195,  0.3325,  0.9266,  ..., -0.3485, -0.0763,  0.6288])\n",
      "exasperate\n",
      "Saved the embedding for exasperate.\n",
      "['exasperated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2255, -0.0609, -0.0851,  ..., -0.0806, -0.2748,  0.7272])\n",
      "exasperated\n",
      "Saved the embedding for exasperated.\n",
      "['ex', '##as', '##peration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2957,  0.5492,  0.4373,  ..., -0.6804, -0.4072,  0.5004])\n",
      "exasperation\n",
      "Saved the embedding for exasperation.\n",
      "['excited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3416,  0.5537, -0.0806,  ...,  0.2781,  0.4752,  0.8926])\n",
      "excited\n",
      "Saved the embedding for excited.\n",
      "['excitedly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7070,  0.3961, -0.2551,  ..., -0.4212, -0.1684,  0.0832])\n",
      "excitedly\n",
      "Saved the embedding for excitedly.\n",
      "['excitement'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1670, -0.1405,  0.5455,  ..., -0.1059, -1.1755,  0.3069])\n",
      "excitement\n",
      "Saved the embedding for excitement.\n",
      "['ex', '##cl', '##ama', '##tion'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0399, -0.0734,  0.8860,  ..., -0.0608,  0.0855,  0.8380])\n",
      "exclamation\n",
      "Saved the embedding for exclamation.\n",
      "['ex', '##cl', '##ama', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2638,  0.0182,  1.1662,  ..., -0.1542,  0.3732,  0.8182])\n",
      "exclamatory\n",
      "Saved the embedding for exclamatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exhausted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7753, -0.1664,  0.0757,  ..., -0.1676, -0.2345,  0.2690])\n",
      "exhausted\n",
      "Saved the embedding for exhausted.\n",
      "['exhaustion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0899, -0.1988,  0.4548,  ..., -0.2376, -0.3880,  0.4954])\n",
      "exhaustion\n",
      "Saved the embedding for exhaustion.\n",
      "['exhaust', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2403,  0.3467, -0.8611,  ..., -1.0334, -0.1391, -0.1851])\n",
      "exhaustive\n",
      "Saved the embedding for exhaustive.\n",
      "['ex', '##hila', '##rated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3065, -0.0822,  0.6645,  ..., -0.7838, -0.4048,  1.0198])\n",
      "exhilarated\n",
      "Saved the embedding for exhilarated.\n",
      "['ex', '##hila', '##ration'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1358,  0.2968,  0.8404,  ..., -0.5665, -0.0335,  0.8506])\n",
      "exhilaration\n",
      "Saved the embedding for exhilaration.\n",
      "['exited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2091, -0.1023,  0.4934,  ...,  0.1955, -0.3962,  0.5506])\n",
      "exited\n",
      "Saved the embedding for exited.\n",
      "['expect', '##ant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3708,  0.3354, -0.5725,  ..., -1.0715, -0.5666,  1.1131])\n",
      "expectant\n",
      "Saved the embedding for expectant.\n",
      "['expectation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1941,  0.4146, -0.2378,  ...,  0.2262,  0.1033,  0.9059])\n",
      "expectation\n",
      "Saved the embedding for expectation.\n",
      "['expecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5108,  0.1906, -0.4402,  ...,  0.1879,  0.2931,  0.4090])\n",
      "expecting\n",
      "Saved the embedding for expecting.\n",
      "['explain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9503,  0.1573,  0.3185,  ..., -0.9094, -0.6300,  0.7140])\n",
      "explain\n",
      "Saved the embedding for explain.\n",
      "['explaining'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1669,  0.1511,  0.2464,  ..., -0.2634, -0.4588,  0.7023])\n",
      "explaining\n",
      "Saved the embedding for explaining.\n",
      "['exploit', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3198,  0.6496, -0.7487,  ..., -0.1707, -0.0856, -0.0038])\n",
      "exploitive\n",
      "Saved the embedding for exploitive.\n",
      "['explosive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1921,  0.7769,  0.0395,  ..., -0.6886, -0.4907, -0.2750])\n",
      "explosive\n",
      "Saved the embedding for explosive.\n",
      "['exposure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1877,  0.6471, -0.7717,  ..., -0.3429,  0.4313,  0.7772])\n",
      "exposure\n",
      "Saved the embedding for exposure.\n",
      "['expressive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2175,  0.7184, -0.5424,  ..., -0.2631, -0.4673, -0.0892])\n",
      "expressive\n",
      "Saved the embedding for expressive.\n",
      "['ex', '##uber', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1726,  0.1228,  0.4830,  ..., -0.6484,  0.3872,  0.9123])\n",
      "exuberant\n",
      "Saved the embedding for exuberant.\n",
      "['ex', '##ult', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0313,  0.3827,  0.7224,  ..., -0.0652,  0.1286,  1.0194])\n",
      "exultant\n",
      "Saved the embedding for exultant.\n",
      "['ex', '##ult', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2014,  0.6274,  0.9350,  ..., -1.0124,  0.0256,  0.7101])\n",
      "exulted\n",
      "Saved the embedding for exulted.\n",
      "['eye'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2893, -0.2106,  0.2751,  ..., -0.1296, -0.4672,  0.6224])\n",
      "eye\n",
      "Saved the embedding for eye.\n",
      "['eyed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0320, -0.0837, -0.2738,  ..., -0.8802, -0.4566, -0.0102])\n",
      "eyed\n",
      "Saved the embedding for eyed.\n",
      "['faced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1179, -0.1371,  0.0197,  ...,  0.3559, -0.7284,  0.0162])\n",
      "faced\n",
      "Saved the embedding for faced.\n",
      "['face', '##tious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1953,  0.1488,  0.0280,  ..., -0.7072, -0.7462,  0.3103])\n",
      "facetious\n",
      "Saved the embedding for facetious.\n",
      "['failure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5168, -0.4198, -0.0372,  ..., -0.8577, -0.5179,  0.8626])\n",
      "failure\n",
      "Saved the embedding for failure.\n",
      "['faint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1650,  0.2659, -1.2975,  ..., -0.6132,  0.0317,  0.1127])\n",
      "faint\n",
      "Saved the embedding for faint.\n",
      "['fair'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2084,  0.6643, -0.6782,  ..., -0.5420, -0.9571,  0.7159])\n",
      "fair\n",
      "Saved the embedding for fair.\n",
      "['fake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0342, -0.0721,  0.4681,  ..., -0.1777, -0.2872,  0.7603])\n",
      "fake\n",
      "Saved the embedding for fake.\n",
      "['fa', '##king'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1755,  0.0944,  0.2958,  ...,  0.0904, -0.1644,  0.4643])\n",
      "faking\n",
      "Saved the embedding for faking.\n",
      "['fa', '##lter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4082,  0.2679, -0.4793,  ..., -0.8714, -0.8893,  0.8528])\n",
      "falter\n",
      "Saved the embedding for falter.\n",
      "['fa', '##mis', '##hed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8879,  0.2090, -0.6413,  ..., -0.8217, -0.3080, -0.4954])\n",
      "famished\n",
      "Saved the embedding for famished.\n",
      "['fan', '##atic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0211,  0.3326,  0.3989,  ..., -0.8101, -0.1281,  0.4962])\n",
      "fanatic\n",
      "Saved the embedding for fanatic.\n",
      "['fan', '##ciful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2913,  0.3418,  0.8446,  ..., -1.6027,  0.1752,  0.6558])\n",
      "fanciful\n",
      "Saved the embedding for fanciful.\n",
      "['far', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0561,  0.1309,  0.6374,  ..., -1.1441, -0.1267,  0.5108])\n",
      "fart\n",
      "Saved the embedding for fart.\n",
      "['fascinated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3955, -0.6438, -0.5359,  ..., -0.3189, -0.7314,  0.4059])\n",
      "fascinated\n",
      "Saved the embedding for fascinated.\n",
      "['fast', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5872, -0.1483, -0.9701,  ..., -1.5120, -0.0123, -0.1520])\n",
      "fastidious\n",
      "Saved the embedding for fastidious.\n",
      "['fatigue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2363, -0.0458, -0.4650,  ..., -0.3560, -0.4091,  0.8429])\n",
      "fatigue\n",
      "Saved the embedding for fatigue.\n",
      "['fatigue', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1138, -0.3140, -0.0294,  ..., -0.9698, -0.4170,  0.5131])\n",
      "fatigued\n",
      "Saved the embedding for fatigued.\n",
      "['fault', '##fin', '##ding'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1012, -0.1572, -0.2680,  ..., -1.2260, -0.2628,  0.2904])\n",
      "faultfinding\n",
      "Saved the embedding for faultfinding.\n",
      "['favorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4232, -0.3648,  0.7419,  ...,  0.4817, -0.9280, -0.0202])\n",
      "favorable\n",
      "Saved the embedding for favorable.\n",
      "['fa', '##wn', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4726, -0.1699, -0.1032,  ..., -0.7896, -0.6504, -0.1297])\n",
      "fawning\n",
      "Saved the embedding for fawning.\n",
      "['fa', '##zed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2856, -0.0089,  0.3290,  ..., -0.5295, -0.9326,  1.0472])\n",
      "fazed\n",
      "Saved the embedding for fazed.\n",
      "['fear'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3066,  0.3922, -0.8200,  ...,  0.7107, -0.9805,  0.5034])\n",
      "fear\n",
      "Saved the embedding for fear.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2138,  0.2448,  0.1420,  ..., -0.2256, -0.4298,  0.4798])\n",
      "feared\n",
      "Saved the embedding for feared.\n",
      "['fearful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3182,  0.2606,  0.1425,  ...,  0.0569, -0.7185,  0.6242])\n",
      "fearful\n",
      "Saved the embedding for fearful.\n",
      "['fearing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7887, -0.1608,  0.2378,  ..., -0.1686, -0.8443,  0.5267])\n",
      "fearing\n",
      "Saved the embedding for fearing.\n",
      "['fearless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5275,  0.0648,  0.3288,  ..., -0.2955, -0.1152,  1.3940])\n",
      "fearless\n",
      "Saved the embedding for fearless.\n",
      "['fears', '##ome'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7531, -0.0254, -0.2800,  ..., -0.9584, -0.0227,  0.2011])\n",
      "fearsome\n",
      "Saved the embedding for fearsome.\n",
      "['fe', '##ckle', '##ss'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2625,  0.0081,  0.3471,  ..., -1.1691, -0.0183,  0.4226])\n",
      "feckless\n",
      "Saved the embedding for feckless.\n",
      "['fed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1780, -0.0512, -0.9080,  ...,  0.6321, -0.8593,  0.6407])\n",
      "fed\n",
      "Saved the embedding for fed.\n",
      "['fee', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2935, -0.0478,  0.2776,  ..., -1.1224, -0.3555,  0.1193])\n",
      "feeble\n",
      "Saved the embedding for feeble.\n",
      "['fei', '##gn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0909,  0.1661,  0.0965,  ..., -0.1266, -0.8750,  1.0880])\n",
      "feign\n",
      "Saved the embedding for feign.\n",
      "['fe', '##lic', '##ito', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2787,  0.2673,  0.6866,  ..., -1.0717,  0.0591,  0.3689])\n",
      "felicitous\n",
      "Saved the embedding for felicitous.\n",
      "['ferocious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4440,  0.0535,  0.3402,  ...,  0.0517, -0.7195, -0.1097])\n",
      "ferocious\n",
      "Saved the embedding for ferocious.\n",
      "['fe', '##rocity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0416, -0.0626,  0.4339,  ..., -1.0111, -0.7050,  1.2269])\n",
      "ferocity\n",
      "Saved the embedding for ferocity.\n",
      "['fest', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3046,  0.1351, -0.0611,  ..., -0.7361, -0.4823,  0.6726])\n",
      "festive\n",
      "Saved the embedding for festive.\n",
      "['fi', '##dget', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4279,  0.2125, -0.3481,  ..., -0.3258, -0.5026,  0.0870])\n",
      "fidgety\n",
      "Saved the embedding for fidgety.\n",
      "['fi', '##end', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2044, -0.2550,  0.1467,  ..., -1.1621, -0.2180,  0.6561])\n",
      "fiendish\n",
      "Saved the embedding for fiendish.\n",
      "['fierce'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5394, -0.1713, -0.5895,  ..., -0.3677, -0.1816,  0.1862])\n",
      "fierce\n",
      "Saved the embedding for fierce.\n",
      "['fiery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2081,  0.0231, -0.0714,  ..., -0.4010,  0.0411,  0.4826])\n",
      "fiery\n",
      "Saved the embedding for fiery.\n",
      "['fighting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1083, -0.0484, -0.6476,  ...,  0.0686, -0.3723,  0.7043])\n",
      "fighting\n",
      "Saved the embedding for fighting.\n",
      "['fine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1007, -0.3637, -0.1944,  ..., -0.6963,  0.5598,  0.0990])\n",
      "fine\n",
      "Saved the embedding for fine.\n",
      "['finished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1240,  0.2783,  0.6548,  ..., -0.6119, -0.4403,  0.1195])\n",
      "finished\n",
      "Saved the embedding for finished.\n",
      "['firm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0842,  0.5048,  0.1279,  ...,  0.8079, -0.3231,  0.8345])\n",
      "firm\n",
      "Saved the embedding for firm.\n",
      "['fish', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3752,  0.5424, -0.1134,  ..., -0.4293, -1.1796,  0.8620])\n",
      "fishy\n",
      "Saved the embedding for fishy.\n",
      "['fix', '##ated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0167,  0.0650, -0.3534,  ..., -1.0961,  0.1036,  0.9263])\n",
      "fixated\n",
      "Saved the embedding for fixated.\n",
      "['fixed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5251,  0.0158,  0.7677,  ..., -0.5809, -0.6933,  0.6749])\n",
      "fixed\n",
      "Saved the embedding for fixed.\n",
      "['fl', '##ab', '##berg', '##ast', '##ed'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.4380, -0.2612,  0.5236,  ..., -0.3927, -0.4570,  0.5011])\n",
      "flabbergasted\n",
      "Saved the embedding for flabbergasted.\n",
      "['flaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3242,  0.3880, -0.1026,  ..., -1.0684,  0.0797,  0.7201])\n",
      "flaming\n",
      "Saved the embedding for flaming.\n",
      "['flat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0693, -0.0840,  0.1989,  ..., -0.9997, -0.3279,  1.1222])\n",
      "flat\n",
      "Saved the embedding for flat.\n",
      "['fl', '##au', '##nting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1330,  0.0695,  0.2618,  ..., -1.0135, -0.4550,  0.9347])\n",
      "flaunting\n",
      "Saved the embedding for flaunting.\n",
      "['flight', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2077,  0.0433,  0.5258,  ...,  0.1113, -0.9075,  0.8285])\n",
      "flighty\n",
      "Saved the embedding for flighty.\n",
      "['flip', '##pan', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2002,  0.1000,  0.1830,  ..., -0.8983, -0.5943,  0.5425])\n",
      "flippant\n",
      "Saved the embedding for flippant.\n",
      "['flipped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2273,  0.8782, -0.5547,  ..., -0.7831,  1.0820,  0.9608])\n",
      "flipped\n",
      "Saved the embedding for flipped.\n",
      "['flirt', '##ation'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1988,  0.4723,  0.5295,  ..., -0.9668, -0.1561,  0.0014])\n",
      "flirtation\n",
      "Saved the embedding for flirtation.\n",
      "['flirt', '##ati', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0189,  0.4399, -0.1330,  ..., -0.6631, -0.5548, -0.1017])\n",
      "flirtatious\n",
      "Saved the embedding for flirtatious.\n",
      "['flirt', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2256,  0.6142, -0.0745,  ..., -0.8146, -0.0814, -0.3781])\n",
      "flirty\n",
      "Saved the embedding for flirty.\n",
      "['floor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3640,  0.2085, -0.3126,  ..., -0.3930, -0.2475, -0.2802])\n",
      "floored\n",
      "Saved the embedding for floored.\n",
      "['flu', '##mm', '##ox', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0031, -0.6787,  0.0393,  ..., -0.6595,  0.2489,  1.2437])\n",
      "flummoxed\n",
      "Saved the embedding for flummoxed.\n",
      "['flu', '##stered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7192,  0.2685, -0.0497,  ..., -0.7534,  0.5298,  0.9499])\n",
      "flustered\n",
      "Saved the embedding for flustered.\n",
      "['focus'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1817,  0.3704, -0.1558,  ...,  0.3577, -0.6453,  0.3995])\n",
      "focus\n",
      "Saved the embedding for focus.\n",
      "['focused'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2550,  0.3142, -0.3933,  ...,  0.1296, -0.3543,  0.6865])\n",
      "focused\n",
      "Saved the embedding for focused.\n",
      "['focusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3030,  0.3034,  0.1951,  ..., -0.2783, -0.6981,  0.7967])\n",
      "focusing\n",
      "Saved the embedding for focusing.\n",
      "['foil', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2426, -0.0547,  0.1269,  ..., -0.9173, -1.1502,  1.3265])\n",
      "foiled\n",
      "Saved the embedding for foiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foolish'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8697,  0.1007, -0.3405,  ..., -0.2949, -0.4155,  0.1539])\n",
      "foolish\n",
      "Saved the embedding for foolish.\n",
      "['for', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6186, -0.1353, -0.1487,  ..., -1.2539, -1.0153,  0.4311])\n",
      "forbearing\n",
      "Saved the embedding for forbearing.\n",
      "['forbid', '##ding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2774,  0.2188, -0.6364,  ..., -0.9882, -0.9320,  1.7266])\n",
      "forbidding\n",
      "Saved the embedding for forbidding.\n",
      "['forced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8268, -0.1040,  0.0793,  ..., -0.6851, -0.0321,  0.6411])\n",
      "forced\n",
      "Saved the embedding for forced.\n",
      "['forceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1685, -0.0372,  0.3909,  ..., -0.2236, -1.0045,  0.5199])\n",
      "forceful\n",
      "Saved the embedding for forceful.\n",
      "['for', '##feit', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0210, -0.4376, -0.0703,  ..., -1.1780, -0.5377,  0.3031])\n",
      "forfeited\n",
      "Saved the embedding for forfeited.\n",
      "['for', '##lor', '##n'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1767, -0.1779, -0.4573,  ..., -0.8742, -1.3671,  0.4890])\n",
      "forlorn\n",
      "Saved the embedding for forlorn.\n",
      "['fortunate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1137,  0.0903, -0.1008,  ..., -0.7838, -0.3195,  0.3299])\n",
      "fortunate\n",
      "Saved the embedding for fortunate.\n",
      "['forward'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1451,  0.2625, -0.6541,  ..., -1.0079,  1.1963, -0.4429])\n",
      "forward\n",
      "Saved the embedding for forward.\n",
      "['foul'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6383,  0.7211,  0.1024,  ..., -0.8414, -0.1947, -0.0761])\n",
      "foul\n",
      "Saved the embedding for foul.\n",
      "['fra', '##ct', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5652, -0.1231, -0.1183,  ..., -0.1779, -0.0731,  0.8105])\n",
      "fractious\n",
      "Saved the embedding for fractious.\n",
      "['fragile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3319,  0.3033, -0.4718,  ...,  0.0490, -0.8686,  0.1944])\n",
      "fragile\n",
      "Saved the embedding for fragile.\n",
      "['frantic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5173, -0.4725, -0.3234,  ..., -0.8353,  0.0520, -0.0680])\n",
      "frantic\n",
      "Saved the embedding for frantic.\n",
      "['fraudulent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0583, -0.1243,  0.5861,  ..., -1.0065, -0.2943,  0.9366])\n",
      "fraudulent\n",
      "Saved the embedding for fraudulent.\n",
      "['fra', '##ught'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5028,  0.5356,  0.3499,  ..., -1.1890,  0.1294,  0.2291])\n",
      "fraught\n",
      "Saved the embedding for fraught.\n",
      "['fra', '##zzled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5789, -0.3315,  0.7393,  ..., -0.2646, -0.6235,  0.7898])\n",
      "frazzled\n",
      "Saved the embedding for frazzled.\n",
      "['freaked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1985,  0.4014,  0.1948,  ...,  0.1744, -0.5270,  0.3253])\n",
      "freaked\n",
      "Saved the embedding for freaked.\n",
      "['fr', '##en', '##zie', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0232, -0.2972,  0.7260,  ..., -0.3098, -0.2250,  1.1141])\n",
      "frenzied\n",
      "Saved the embedding for frenzied.\n",
      "['fr', '##et', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0042,  0.0303,  0.2582,  ..., -1.4526, -1.3165,  0.6325])\n",
      "fretful\n",
      "Saved the embedding for fretful.\n",
      "['friend', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3462,  0.3322,  1.0006,  ..., -0.4615,  0.1836,  1.2001])\n",
      "friendliness\n",
      "Saved the embedding for friendliness.\n",
      "['friendly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5088,  0.5089,  0.0288,  ..., -0.5818, -0.1833,  0.5899])\n",
      "friendly\n",
      "Saved the embedding for friendly.\n",
      "['fright'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1311,  0.1030,  0.8452,  ..., -0.3325,  0.3778,  0.9293])\n",
      "fright\n",
      "Saved the embedding for fright.\n",
      "['frightened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3137,  0.2880, -0.1528,  ..., -0.3580, -0.5431,  0.5882])\n",
      "frightened\n",
      "Saved the embedding for frightened.\n",
      "['frightening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2554,  0.0171, -0.0592,  ..., -0.7600, -0.2454,  0.3036])\n",
      "frightening\n",
      "Saved the embedding for frightening.\n",
      "['fr', '##ig', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0463, -0.1059,  0.8456,  ..., -0.3147, -0.5362,  0.5851])\n",
      "frigid\n",
      "Saved the embedding for frigid.\n",
      "['fr', '##isk', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7554,  0.3118,  0.1795,  ..., -0.1457, -0.0682,  1.0442])\n",
      "frisky\n",
      "Saved the embedding for frisky.\n",
      "['fr', '##olic', '##ker'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9302,  0.2349,  0.5010,  ..., -0.4991, -0.2304,  1.3212])\n",
      "frolicker\n",
      "Saved the embedding for frolicker.\n",
      "['frown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1420,  0.1846, -0.5279,  ..., -0.1236, -0.4143,  0.8200])\n",
      "frown\n",
      "Saved the embedding for frown.\n",
      "['frowning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3269,  0.4741,  0.3636,  ...,  0.2675, -0.0160,  1.2015])\n",
      "frowning\n",
      "Saved the embedding for frowning.\n",
      "['frozen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4406,  0.4557,  0.2512,  ...,  0.3995, -0.4945,  0.7875])\n",
      "frozen\n",
      "Saved the embedding for frozen.\n",
      "['fr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0173, -0.1828,  0.6685,  ..., -0.1427, -0.5950,  0.5176])\n",
      "frumpy\n",
      "Saved the embedding for frumpy.\n",
      "['frustrated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2035, -0.5053,  0.5532,  ...,  0.0766, -0.7434,  0.6486])\n",
      "frustrated\n",
      "Saved the embedding for frustrated.\n",
      "['frustration'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 1.7927e-01, -1.5325e-01,  7.4076e-01,  ...,  3.3490e-05,\n",
      "        -9.2778e-01,  9.3338e-01])\n",
      "frustration\n",
      "Saved the embedding for frustration.\n",
      "['fulfilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0979, -0.2116, -0.9015,  ..., -1.6481, -0.5982,  0.1266])\n",
      "fulfilled\n",
      "Saved the embedding for fulfilled.\n",
      "['fu', '##med'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0068,  0.1355, -0.4349,  ..., -0.7953, -1.0089,  0.4451])\n",
      "fumed\n",
      "Saved the embedding for fumed.\n",
      "['fu', '##ming'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1227, -0.0784, -0.0917,  ..., -0.2031, -0.7334,  0.0787])\n",
      "fuming\n",
      "Saved the embedding for fuming.\n",
      "['fun'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0565,  0.3851,  0.6615,  ..., -1.4224, -0.6231,  1.6749])\n",
      "fun\n",
      "Saved the embedding for fun.\n",
      "['funny'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2288,  0.5191, -0.6100,  ..., -0.4697, -0.6839,  0.8982])\n",
      "funny\n",
      "Saved the embedding for funny.\n",
      "['furious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0410,  0.2810, -0.1809,  ...,  0.3876, -0.2805,  0.4790])\n",
      "furious\n",
      "Saved the embedding for furious.\n",
      "['furiously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4608,  0.2400,  0.4929,  ..., -0.4436, -0.5544,  0.7104])\n",
      "furiously\n",
      "Saved the embedding for furiously.\n",
      "['furious', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2802,  0.1855,  0.2455,  ..., -1.0846, -0.8624,  0.4411])\n",
      "furiousness\n",
      "Saved the embedding for furiousness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['furrowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2885, -0.1027, -0.8260,  ..., -1.1436, -0.7611,  0.4820])\n",
      "furrowed\n",
      "Saved the embedding for furrowed.\n",
      "['fur', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7148,  0.2684,  0.0219,  ..., -1.4458,  0.1558, -0.0697])\n",
      "furtive\n",
      "Saved the embedding for furtive.\n",
      "['fury'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0352,  0.5454, -0.1849,  ...,  0.1319,  0.1167,  0.8818])\n",
      "fury\n",
      "Saved the embedding for fury.\n",
      "['fuss', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2567,  0.6379,  0.4090,  ..., -1.1672, -1.0913,  0.8692])\n",
      "fussy\n",
      "Saved the embedding for fussy.\n",
      "['gall', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2030,  0.5232,  0.2319,  ..., -0.4234, -0.9317,  1.1945])\n",
      "galled\n",
      "Saved the embedding for galled.\n",
      "['gall', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3679,  0.3935, -0.0849,  ..., -0.8895, -0.9916,  0.8467])\n",
      "galling\n",
      "Saved the embedding for galling.\n",
      "['gasp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4239,  0.7320, -0.7570,  ...,  0.0388,  0.1283, -0.0439])\n",
      "gasp\n",
      "Saved the embedding for gasp.\n",
      "['gasped'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3338,  0.4781, -0.3440,  ...,  0.0913, -1.1404,  0.3056])\n",
      "gasped\n",
      "Saved the embedding for gasped.\n",
      "['gasping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4817,  0.9582,  0.1035,  ...,  0.0407, -0.6702,  0.6297])\n",
      "gasping\n",
      "Saved the embedding for gasping.\n",
      "['gay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0255,  0.5281,  0.3145,  ..., -0.5803, -0.4156,  1.0789])\n",
      "gay\n",
      "Saved the embedding for gay.\n",
      "['gazing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2772,  0.0463,  0.0378,  ...,  0.2276, -0.0489,  1.3119])\n",
      "gazing\n",
      "Saved the embedding for gazing.\n",
      "['gen', '##ial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3920, -0.1323,  0.1952,  ..., -0.2811, -0.7792,  0.4769])\n",
      "genial\n",
      "Saved the embedding for genial.\n",
      "['gentle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2953, -0.1599,  0.2597,  ...,  0.0785, -0.8070,  0.5882])\n",
      "gentle\n",
      "Saved the embedding for gentle.\n",
      "['genuine'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4228, -0.1598,  0.3145,  ..., -0.9201, -0.7197, -0.2525])\n",
      "genuine\n",
      "Saved the embedding for genuine.\n",
      "['g', '##has', '##tly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6728,  0.0518,  0.3231,  ..., -1.3683,  0.1845,  0.7389])\n",
      "ghastly\n",
      "Saved the embedding for ghastly.\n",
      "['gi', '##ddy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5930, -0.7752,  0.5460,  ..., -1.0188, -0.9591,  0.5886])\n",
      "giddy\n",
      "Saved the embedding for giddy.\n",
      "['giggle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0288, -0.4297, -0.1652,  ..., -0.7875, -0.2754,  0.1855])\n",
      "giggle\n",
      "Saved the embedding for giggle.\n",
      "['giggling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2509,  0.2890,  0.5430,  ..., -0.0898, -0.5474,  0.7887])\n",
      "giggling\n",
      "Saved the embedding for giggling.\n",
      "['glad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2254,  0.3917,  0.2389,  ...,  0.2552, -0.0567,  1.1983])\n",
      "glad\n",
      "Saved the embedding for glad.\n",
      "['glad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1374,  0.2785,  0.6881,  ..., -0.8059, -0.7116,  0.5517])\n",
      "gladdened\n",
      "Saved the embedding for gladdened.\n",
      "['glad', '##iol', '##a'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0887,  0.5036, -0.3798,  ..., -0.0703, -1.0192,  1.2330])\n",
      "gladiola\n",
      "Saved the embedding for gladiola.\n",
      "['glad', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0854,  0.0860,  0.3047,  ..., -0.6310, -0.5940,  1.4585])\n",
      "gladness\n",
      "Saved the embedding for gladness.\n",
      "['glad', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0980,  0.1181,  0.6112,  ..., -0.5020, -0.3471,  0.0990])\n",
      "gladsome\n",
      "Saved the embedding for gladsome.\n",
      "['glare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1677,  0.1119,  0.2045,  ..., -0.4417, -0.1336,  1.0588])\n",
      "glare\n",
      "Saved the embedding for glare.\n",
      "['glaring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2373,  0.1323,  0.6412,  ...,  0.4843, -0.5153, -0.2154])\n",
      "glaring\n",
      "Saved the embedding for glaring.\n",
      "['glazed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1594,  0.4445, -0.3261,  ..., -0.2229, -0.1377,  0.2764])\n",
      "glazed\n",
      "Saved the embedding for glazed.\n",
      "['glee'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5467, -0.3875, -0.1631,  ..., -0.7073, -0.2622,  0.5109])\n",
      "glee\n",
      "Saved the embedding for glee.\n",
      "['glee', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5306,  0.4485,  0.4329,  ..., -1.9530, -1.1130, -0.1354])\n",
      "gleeful\n",
      "Saved the embedding for gleeful.\n",
      "['glee', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4682,  0.5299,  0.2479,  ..., -0.6947, -0.5345, -0.1820])\n",
      "gleefully\n",
      "Saved the embedding for gleefully.\n",
      "['g', '##lib'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2545, -0.5265,  0.0689,  ..., -0.4379, -0.3049,  1.0512])\n",
      "glib\n",
      "Saved the embedding for glib.\n",
      "['g', '##lo', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0318,  0.0167, -0.1076,  ..., -0.7354, -0.6323,  0.2598])\n",
      "gloating\n",
      "Saved the embedding for gloating.\n",
      "['gloom'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2218,  0.2907,  0.0391,  ..., -0.3004, -0.2923,  0.7790])\n",
      "gloom\n",
      "Saved the embedding for gloom.\n",
      "['gloom', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3339,  0.1402,  0.4028,  ..., -0.5509, -0.9896,  0.3829])\n",
      "gloomy\n",
      "Saved the embedding for gloomy.\n",
      "['glow', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2476,  0.3663,  0.1887,  ..., -0.9558, -0.4213,  0.3036])\n",
      "glowering\n",
      "Saved the embedding for glowering.\n",
      "['glowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6408, -0.0436, -0.3356,  ..., -0.7817, -0.4071,  0.6608])\n",
      "glowing\n",
      "Saved the embedding for glowing.\n",
      "['g', '##lum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0663,  0.1346,  0.3022,  ..., -0.3764, -0.2590,  0.6716])\n",
      "glum\n",
      "Saved the embedding for glum.\n",
      "['g', '##nar', '##l'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0493,  0.3353,  0.0826,  ..., -0.2926, -0.9900,  0.4299])\n",
      "gnarl\n",
      "Saved the embedding for gnarl.\n",
      "['go', '##bs', '##mack', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2992, -0.5697,  0.2950,  ..., -0.5648, -0.2490,  0.0547])\n",
      "gobsmacked\n",
      "Saved the embedding for gobsmacked.\n",
      "['good'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7667,  0.0870, -0.2189,  ..., -0.5810, -0.6347,  0.8395])\n",
      "good\n",
      "Saved the embedding for good.\n",
      "['goofy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7346,  0.0937, -0.1047,  ..., -0.1660, -0.5534,  1.1440])\n",
      "goofy\n",
      "Saved the embedding for goofy.\n",
      "['gossip', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.0002,  0.6945,  0.4947,  ..., -0.0433, -0.7910, -0.5530])\n",
      "gossipy\n",
      "Saved the embedding for gossipy.\n",
      "['grand', '##ios', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4200,  0.1090, -0.2807,  ..., -1.0848, -0.6945, -0.0526])\n",
      "grandiose\n",
      "Saved the embedding for grandiose.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grateful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5022,  0.4182, -0.4831,  ..., -0.0115, -0.8259,  0.8416])\n",
      "grateful\n",
      "Saved the embedding for grateful.\n",
      "['gr', '##ati', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4359,  0.6724, -0.0244,  ..., -1.1149, -0.8809, -0.0747])\n",
      "gratified\n",
      "Saved the embedding for gratified.\n",
      "['grave'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6232,  0.5123, -0.0072,  ..., -0.3325, -0.3811,  1.0601])\n",
      "grave\n",
      "Saved the embedding for grave.\n",
      "['great'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4622,  0.1038,  0.4184,  ..., -0.5856, -0.4574,  0.9020])\n",
      "great\n",
      "Saved the embedding for great.\n",
      "['greedy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2199,  0.4779,  0.5174,  ...,  0.2076, -0.2171,  0.7245])\n",
      "greedy\n",
      "Saved the embedding for greedy.\n",
      "['greeting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1903,  0.5497,  0.5886,  ..., -0.1851, -1.1338,  0.3698])\n",
      "greeting\n",
      "Saved the embedding for greeting.\n",
      "['grief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0540, -0.3622, -0.9047,  ..., -0.0581, -0.4938,  1.1322])\n",
      "grief\n",
      "Saved the embedding for grief.\n",
      "['gr', '##ie', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0253,  0.5364,  0.4971,  ..., -0.1478, -0.0823,  0.4532])\n",
      "grieved\n",
      "Saved the embedding for grieved.\n",
      "['gr', '##ieving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0600, -0.0371,  0.4319,  ..., -1.1091, -0.5208,  0.3963])\n",
      "grieving\n",
      "Saved the embedding for grieving.\n",
      "['grim'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5159, -0.1648,  0.6229,  ..., -1.1889, -0.0312,  1.5259])\n",
      "grim\n",
      "Saved the embedding for grim.\n",
      "['grimace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4145, -0.0961, -0.5494,  ..., -0.6664, -0.7391,  0.2490])\n",
      "grimace\n",
      "Saved the embedding for grimace.\n",
      "['grim', '##acing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2060,  0.3013,  0.7401,  ..., -0.8947, -0.3934,  1.1880])\n",
      "grimacing\n",
      "Saved the embedding for grimacing.\n",
      "['grin'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1134,  0.4938, -0.5154,  ...,  0.2477, -1.0362, -0.0321])\n",
      "grin\n",
      "Saved the embedding for grin.\n",
      "['grinning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7782,  0.3121, -0.5580,  ...,  0.2922,  0.1022,  0.8701])\n",
      "grinning\n",
      "Saved the embedding for grinning.\n",
      "['grip', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2384,  0.1740, -0.0271,  ..., -0.8507, -0.6783,  0.2058])\n",
      "griping\n",
      "Saved the embedding for griping.\n",
      "['gross'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6034,  0.1553, -0.1500,  ..., -0.4308, -0.3441,  1.0245])\n",
      "gross\n",
      "Saved the embedding for gross.\n",
      "['grossed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2403,  0.1149,  0.1087,  ..., -0.1814, -0.0189,  0.9782])\n",
      "grossed\n",
      "Saved the embedding for grossed.\n",
      "['gr', '##ou', '##chy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4277,  1.1988,  0.2684,  ..., -0.8439, -0.0584,  0.9879])\n",
      "grouchy\n",
      "Saved the embedding for grouchy.\n",
      "['growl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1892, -0.9001, -0.6193,  ..., -0.6901,  0.4036,  0.3854])\n",
      "growl\n",
      "Saved the embedding for growl.\n",
      "['growling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2655,  0.3261,  0.1743,  ..., -0.0221, -0.1797,  0.3702])\n",
      "growling\n",
      "Saved the embedding for growling.\n",
      "['gr', '##udge'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0263, -0.4779,  0.2863,  ..., -0.7005, -0.5328,  0.4557])\n",
      "grudge\n",
      "Saved the embedding for grudge.\n",
      "['gr', '##ud', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5697, -0.4187, -0.7612,  ..., -1.0501, -1.2009, -0.0207])\n",
      "grudging\n",
      "Saved the embedding for grudging.\n",
      "['gruff'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0587,  0.0636,  1.1216,  ..., -0.9817,  0.3238,  0.9465])\n",
      "gruff\n",
      "Saved the embedding for gruff.\n",
      "['gr', '##umb', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1235, -0.0221,  0.2671,  ..., -0.9765, -0.3719, -0.0858])\n",
      "grumbling\n",
      "Saved the embedding for grumbling.\n",
      "['gr', '##ump', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1902,  0.1861, -0.1802,  ..., -0.5108, -0.6247,  0.6432])\n",
      "grumpy\n",
      "Saved the embedding for grumpy.\n",
      "['grunt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3713,  0.3803,  0.0229,  ..., -1.1758, -0.3593,  0.6842])\n",
      "grunt\n",
      "Saved the embedding for grunt.\n",
      "['grunt', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0833,  0.3315,  0.2105,  ..., -1.2729, -0.8981,  0.5622])\n",
      "grunting\n",
      "Saved the embedding for grunting.\n",
      "['guarded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5694,  0.1265,  0.3114,  ..., -0.8693, -0.8017,  0.3571])\n",
      "guarded\n",
      "Saved the embedding for guarded.\n",
      "['guilty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7003,  0.3078,  0.0482,  ..., -0.6698,  0.1833,  0.1774])\n",
      "guilty\n",
      "Saved the embedding for guilty.\n",
      "['gulp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2761,  0.5197,  0.1380,  ..., -0.3344, -0.6861,  0.3680])\n",
      "gulp\n",
      "Saved the embedding for gulp.\n",
      "['haggard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1924,  1.0027, -0.5058,  ..., -0.9755,  0.5567,  0.0130])\n",
      "haggard\n",
      "Saved the embedding for haggard.\n",
      "['half', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5405,  0.5893,  0.3242,  ..., -0.5649, -0.1150, -0.0979])\n",
      "halfhearted\n",
      "Saved the embedding for halfhearted.\n",
      "['halted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2501, -0.3083,  0.7983,  ..., -1.0629,  0.4148, -0.3153])\n",
      "halted\n",
      "Saved the embedding for halted.\n",
      "['ha', '##ples', '##s'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0405, -0.0269,  0.5758,  ..., -1.1561, -0.2042,  1.1041])\n",
      "hapless\n",
      "Saved the embedding for hapless.\n",
      "['happiness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5214,  0.3738,  0.4050,  ..., -0.0474,  0.3224,  0.5128])\n",
      "happiness\n",
      "Saved the embedding for happiness.\n",
      "['happy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0194, -0.1881,  0.2096,  ..., -0.2602, -1.3051,  0.5949])\n",
      "happy\n",
      "Saved the embedding for happy.\n",
      "['harassed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0607,  0.4688,  0.1069,  ..., -0.2881, -1.3772,  0.8416])\n",
      "harassed\n",
      "Saved the embedding for harassed.\n",
      "['hard'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1041,  0.4258, -0.6103,  ..., -0.2298, -0.5161,  1.0910])\n",
      "hard\n",
      "Saved the embedding for hard.\n",
      "['hardened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0453, -0.0936, -0.1740,  ..., -0.1742, -0.3675,  1.3366])\n",
      "hardened\n",
      "Saved the embedding for hardened.\n",
      "['harmful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5717,  0.2354, -0.1723,  ..., -0.7286, -0.2195,  0.9098])\n",
      "harmful\n",
      "Saved the embedding for harmful.\n",
      "['ha', '##rrie', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0510,  0.1433, -0.5176,  ..., -0.8270, -0.5367,  0.3459])\n",
      "harried\n",
      "Saved the embedding for harried.\n",
      "['harsh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9102,  0.7146, -0.0259,  ...,  0.0648, -0.3160,  1.2525])\n",
      "harsh\n",
      "Saved the embedding for harsh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3394,  0.4363, -0.5413,  ..., -0.2870, -0.7168,  0.7548])\n",
      "hate\n",
      "Saved the embedding for hate.\n",
      "['hate', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2053,  0.2865, -1.0713,  ..., -1.5166, -1.0215,  0.6680])\n",
      "hateful\n",
      "Saved the embedding for hateful.\n",
      "['hating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1032, -0.2039, -0.4158,  ...,  0.0612, -0.3207,  0.2676])\n",
      "hating\n",
      "Saved the embedding for hating.\n",
      "['hatred'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2230,  0.1313,  0.3002,  ..., -0.0800, -0.0774,  0.6289])\n",
      "hatred\n",
      "Saved the embedding for hatred.\n",
      "['ha', '##ught', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1082,  0.1185,  0.1647,  ..., -0.8024, -0.4548,  0.5661])\n",
      "haughty\n",
      "Saved the embedding for haughty.\n",
      "['haunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1553,  0.1267,  0.4716,  ..., -0.8108,  0.0846,  0.7519])\n",
      "haunted\n",
      "Saved the embedding for haunted.\n",
      "['hazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3941,  0.1145, -0.1756,  ..., -0.7574, -0.6428,  1.1464])\n",
      "hazy\n",
      "Saved the embedding for hazy.\n",
      "['heads', '##hak', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7049,  0.6647,  0.6667,  ..., -0.9479, -0.4313,  1.0920])\n",
      "headshake\n",
      "Saved the embedding for headshake.\n",
      "['heart', '##ache'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4750,  0.5326,  0.2541,  ..., -2.2817, -0.3841,  0.8584])\n",
      "heartache\n",
      "Saved the embedding for heartache.\n",
      "['heart', '##broken'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4673, -0.0974,  0.6095,  ..., -0.8250, -0.9948,  0.9575])\n",
      "heartbroken\n",
      "Saved the embedding for heartbroken.\n",
      "['hearted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2963, -0.0883, -0.3321,  ..., -0.6377, -0.5237,  0.4513])\n",
      "hearted\n",
      "Saved the embedding for hearted.\n",
      "['hearts', '##ick'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4702, -0.0463,  0.4345,  ..., -0.9118, -1.1182,  0.4894])\n",
      "heartsick\n",
      "Saved the embedding for heartsick.\n",
      "['heated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8456,  0.3193, -0.1570,  ...,  0.1464, -0.2651,  1.0261])\n",
      "heated\n",
      "Saved the embedding for heated.\n",
      "['heavy', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4868,  0.2475,  0.6373,  ..., -0.5685,  0.4363, -0.6552])\n",
      "heavyhearted\n",
      "Saved the embedding for heavyhearted.\n",
      "['heck', '##le'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0648,  0.3458,  0.9141,  ..., -1.3375, -0.4772,  0.8440])\n",
      "heckle\n",
      "Saved the embedding for heckle.\n",
      "['hee', '##df', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0195, -0.2061,  0.3989,  ..., -0.2965, -0.2611,  0.5181])\n",
      "heedful\n",
      "Saved the embedding for heedful.\n",
      "['he', '##ino', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6486,  0.1350,  0.5042,  ..., -0.1544,  0.2412,  0.6478])\n",
      "heinous\n",
      "Saved the embedding for heinous.\n",
      "['helpful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2870,  0.9149,  0.1498,  ..., -1.1575, -0.5340,  1.2825])\n",
      "helpful\n",
      "Saved the embedding for helpful.\n",
      "['helpless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6348, -0.0090,  0.1902,  ..., -0.3517, -0.8882,  0.7264])\n",
      "helpless\n",
      "Saved the embedding for helpless.\n",
      "['hesitant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4989, -0.1083, -0.2978,  ..., -0.2472, -0.6007,  0.4354])\n",
      "hesitant\n",
      "Saved the embedding for hesitant.\n",
      "['hesitantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2516,  0.6076,  0.9609,  ...,  0.1220, -0.7639,  0.5186])\n",
      "hesitantly\n",
      "Saved the embedding for hesitantly.\n",
      "['he', '##sit', '##ating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0597,  0.0777,  0.2830,  ..., -0.5459, -0.9654, -0.4997])\n",
      "hesitating\n",
      "Saved the embedding for hesitating.\n",
      "['hesitation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4123,  0.1129,  0.0035,  ...,  0.2624, -0.2816,  0.6965])\n",
      "hesitation\n",
      "Saved the embedding for hesitation.\n",
      "['high'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4861,  0.2206, -0.3139,  ..., -0.4390, -0.3138,  0.7366])\n",
      "high\n",
      "Saved the embedding for high.\n",
      "['ho', '##ller', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-2.4616e-01, -2.0420e-01, -7.6192e-04,  ..., -7.9355e-01,\n",
      "        -5.4044e-01,  5.0284e-01])\n",
      "hollering\n",
      "Saved the embedding for hollering.\n",
      "['ho', '##mic', '##idal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4345,  0.2740,  0.1373,  ...,  0.1765,  0.0338,  0.0180])\n",
      "homicidal\n",
      "Saved the embedding for homicidal.\n",
      "['honest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1768,  0.0141, -0.2051,  ...,  0.1165, -0.3620,  0.6022])\n",
      "honest\n",
      "Saved the embedding for honest.\n",
      "['honorable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4498,  0.2679,  0.9585,  ..., -0.1778, -0.0815,  0.8556])\n",
      "honorable\n",
      "Saved the embedding for honorable.\n",
      "['hope'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2103,  0.1150,  0.4340,  ..., -0.3779, -0.5993,  0.8372])\n",
      "hope\n",
      "Saved the embedding for hope.\n",
      "['hopeful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2032, -0.2499, -0.0223,  ..., -1.4119, -0.1886, -0.4499])\n",
      "hopeful\n",
      "Saved the embedding for hopeful.\n",
      "['hopeful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1950, -0.3180,  0.7473,  ..., -1.3505,  0.0395,  0.1922])\n",
      "hopefulness\n",
      "Saved the embedding for hopefulness.\n",
      "['hopeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1081, -0.1876,  0.9859,  ..., -0.3120, -0.5583,  0.5550])\n",
      "hopeless\n",
      "Saved the embedding for hopeless.\n",
      "['hoping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0956,  0.0567, -0.0746,  ...,  0.2049, -0.2838,  0.8442])\n",
      "hoping\n",
      "Saved the embedding for hoping.\n",
      "['horn', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7324,  0.2746,  0.3401,  ..., -0.6155, -0.5313,  0.4150])\n",
      "horny\n",
      "Saved the embedding for horny.\n",
      "['horrible'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2488, -0.3676, -0.2558,  ..., -0.7089,  0.1729,  0.2382])\n",
      "horrible\n",
      "Saved the embedding for horrible.\n",
      "['horrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1991,  0.2060, -0.0568,  ..., -1.6603, -0.2370,  0.7445])\n",
      "horrified\n",
      "Saved the embedding for horrified.\n",
      "['ho', '##rri', '##fy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3744,  0.0897,  0.4545,  ..., -0.8362, -0.7860,  0.2085])\n",
      "horrify\n",
      "Saved the embedding for horrify.\n",
      "['ho', '##rri', '##fying'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4716,  0.4723,  0.2738,  ..., -0.8098, -0.6003,  0.3067])\n",
      "horrifying\n",
      "Saved the embedding for horrifying.\n",
      "['horror'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2633,  0.2457,  0.2748,  ..., -0.3811,  0.3478,  0.6422])\n",
      "horror\n",
      "Saved the embedding for horror.\n",
      "['hostile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0644, -0.4985,  0.2752,  ...,  0.3181, -1.0045,  1.2068])\n",
      "hostile\n",
      "Saved the embedding for hostile.\n",
      "['hostility'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2183, -0.0798,  0.3719,  ..., -0.3377, -0.9615,  0.4529])\n",
      "hostility\n",
      "Saved the embedding for hostility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hot'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4349,  0.3011, -0.0699,  ..., -0.2523,  0.8104,  0.5346])\n",
      "hot\n",
      "Saved the embedding for hot.\n",
      "['hot', '##shot'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0010,  0.0103,  0.5407,  ..., -0.5853,  0.2748,  0.3654])\n",
      "hotshot\n",
      "Saved the embedding for hotshot.\n",
      "['huff', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5596,  0.1776,  0.7155,  ..., -2.0268, -0.8025,  1.1481])\n",
      "huffiness\n",
      "Saved the embedding for huffiness.\n",
      "['huff', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2355,  0.1176,  0.7510,  ..., -1.6657, -0.2155,  0.1524])\n",
      "huffy\n",
      "Saved the embedding for huffy.\n",
      "['humble'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0083,  0.5441,  0.0163,  ..., -0.4888, -0.1667,  1.1343])\n",
      "humble\n",
      "Saved the embedding for humble.\n",
      "['humble', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2452,  0.7432,  0.2777,  ..., -0.2905, -0.3814,  0.9500])\n",
      "humbled\n",
      "Saved the embedding for humbled.\n",
      "['hum', '##drum'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4079,  0.2300, -0.1014,  ..., -0.5582, -0.6252,  0.3074])\n",
      "humdrum\n",
      "Saved the embedding for humdrum.\n",
      "['humiliated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4150, -0.0261,  0.6138,  ...,  0.6944, -0.4832,  0.5318])\n",
      "humiliated\n",
      "Saved the embedding for humiliated.\n",
      "['hum', '##ility'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9643, -0.2741, -0.0237,  ..., -1.5644, -0.5068,  0.7137])\n",
      "humility\n",
      "Saved the embedding for humility.\n",
      "['humming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8367,  0.1167,  0.2142,  ..., -0.7870, -0.0201,  0.3863])\n",
      "humming\n",
      "Saved the embedding for humming.\n",
      "['humor'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3753,  0.3412,  0.4821,  ..., -1.0941, -0.6323,  1.3357])\n",
      "humor\n",
      "Saved the embedding for humor.\n",
      "['humor', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2768,  0.1816, -0.1452,  ..., -0.6839, -0.3786,  0.8014])\n",
      "humored\n",
      "Saved the embedding for humored.\n",
      "['humorous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4131, -0.6983,  0.3439,  ..., -0.3702,  0.4611, -0.2135])\n",
      "humorous\n",
      "Saved the embedding for humorous.\n",
      "['hunger'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9659, -0.0906, -0.8099,  ..., -1.0281, -0.2378,  0.7715])\n",
      "hunger\n",
      "Saved the embedding for hunger.\n",
      "['hungry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2783,  0.1907, -0.1515,  ..., -0.1594, -0.6106,  0.6692])\n",
      "hungry\n",
      "Saved the embedding for hungry.\n",
      "['hunted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4264,  0.8732, -0.6820,  ..., -0.0223, -0.5739,  0.7610])\n",
      "hunted\n",
      "Saved the embedding for hunted.\n",
      "['hurt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0710, -0.4817,  0.8768,  ..., -0.4044,  0.1728,  1.0302])\n",
      "hurt\n",
      "Saved the embedding for hurt.\n",
      "['hurt', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6752, -0.1934,  0.1322,  ..., -1.1658, -0.9526,  0.6638])\n",
      "hurtful\n",
      "Saved the embedding for hurtful.\n",
      "['hurting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1542,  0.0277,  0.6536,  ..., -0.0357, -0.6642,  0.8465])\n",
      "hurting\n",
      "Saved the embedding for hurting.\n",
      "['hush'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0925,  0.7419, -0.4215,  ..., -0.3334, -0.8307,  0.9303])\n",
      "hush\n",
      "Saved the embedding for hush.\n",
      "['hushed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0517,  0.1554, -0.1983,  ...,  0.2844, -0.1642,  0.3821])\n",
      "hushed\n",
      "Saved the embedding for hushed.\n",
      "['hyper'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2431, -0.1381, -0.5283,  ..., -0.0829, -1.2433,  0.5073])\n",
      "hyper\n",
      "Saved the embedding for hyper.\n",
      "['hyper', '##active'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4685,  0.0103, -0.7298,  ..., -0.5472, -1.0687, -0.0026])\n",
      "hyperactive\n",
      "Saved the embedding for hyperactive.\n",
      "['h', '##yp', '##not', '##ized'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8255,  0.1591, -0.9863,  ..., -1.6473, -0.1304,  0.6326])\n",
      "hypnotized\n",
      "Saved the embedding for hypnotized.\n",
      "['h', '##yp', '##oc', '##rit', '##ical'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([ 0.5057,  0.3428,  0.0721,  ..., -0.6275,  0.2539,  1.1783])\n",
      "hypocritical\n",
      "Saved the embedding for hypocritical.\n",
      "['hysteria'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3070,  0.3668,  0.3531,  ..., -0.8828, -0.7076,  0.3399])\n",
      "hysteria\n",
      "Saved the embedding for hysteria.\n",
      "['hysterical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5172, -0.0625, -0.1515,  ..., -0.4512, -0.2835,  0.1609])\n",
      "hysterical\n",
      "Saved the embedding for hysterical.\n",
      "['idiot', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1784,  0.7247, -0.0358,  ..., -0.4883, -0.6009,  1.0222])\n",
      "idiotic\n",
      "Saved the embedding for idiotic.\n",
      "['ignorant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4890,  0.5100,  0.0647,  ..., -0.7092, -0.8251,  0.8839])\n",
      "ignorant\n",
      "Saved the embedding for ignorant.\n",
      "['ignoring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2800,  0.3740, -0.4388,  ..., -0.9730, -0.3375,  0.7334])\n",
      "ignoring\n",
      "Saved the embedding for ignoring.\n",
      "['ill'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3312,  0.4904,  0.7413,  ..., -0.6024, -0.1976,  0.4953])\n",
      "ill\n",
      "Saved the embedding for ill.\n",
      "['imaginative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5608, -0.0725, -0.2150,  ..., -0.9769, -0.2472, -0.0715])\n",
      "imaginative\n",
      "Saved the embedding for imaginative.\n",
      "['immature'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9097, -0.1711, -0.6854,  ..., -0.0188, -0.2131,  0.0669])\n",
      "immature\n",
      "Saved the embedding for immature.\n",
      "['immersed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4289,  0.1006, -0.3208,  ..., -0.2454, -0.5941,  0.7781])\n",
      "immersed\n",
      "Saved the embedding for immersed.\n",
      "['impacted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8426, -0.0711,  0.3839,  ..., -1.2334,  0.1856,  0.6185])\n",
      "impacted\n",
      "Saved the embedding for impacted.\n",
      "['imp', '##art', '##ial'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0687,  0.2498,  0.1866,  ..., -0.6275, -0.3475,  0.4292])\n",
      "impartial\n",
      "Saved the embedding for impartial.\n",
      "['imp', '##ass', '##ioned'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2002,  0.1769,  0.4968,  ..., -0.4066, -0.0735,  0.3106])\n",
      "impassioned\n",
      "Saved the embedding for impassioned.\n",
      "['imp', '##ass', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3172,  0.3210, -0.1278,  ..., -0.6107, -0.5556,  0.1310])\n",
      "impassive\n",
      "Saved the embedding for impassive.\n",
      "['impatience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0935, -0.2018, -0.2109,  ...,  0.3013, -0.2295,  0.3563])\n",
      "impatience\n",
      "Saved the embedding for impatience.\n",
      "['impatient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0726, -0.3904,  0.3088,  ..., -0.2503,  0.1027, -0.1125])\n",
      "impatient\n",
      "Saved the embedding for impatient.\n",
      "['imp', '##eri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2268,  0.6410,  0.5283,  ..., -0.7869, -0.1529,  0.3791])\n",
      "imperious\n",
      "Saved the embedding for imperious.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imp', '##erson', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1958,  0.6485, -0.0615,  ..., -1.1200, -0.0885,  0.2873])\n",
      "impersonal\n",
      "Saved the embedding for impersonal.\n",
      "['imp', '##ert', '##inen', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1635,  0.4252,  0.0590,  ..., -1.1000, -0.6604,  0.4328])\n",
      "impertinent\n",
      "Saved the embedding for impertinent.\n",
      "['imp', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3715,  0.2431, -0.0500,  ..., -0.1880, -0.2258,  0.4389])\n",
      "impish\n",
      "Saved the embedding for impish.\n",
      "['implicated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4407,  1.0302,  0.0541,  ..., -0.6504,  0.4436, -0.8402])\n",
      "implicated\n",
      "Saved the embedding for implicated.\n",
      "['imp', '##lor', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3755,  0.1609,  0.0682,  ..., -0.5831, -0.4866,  0.3185])\n",
      "imploring\n",
      "Saved the embedding for imploring.\n",
      "['important'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1101, -0.2635, -0.0482,  ...,  0.1051, -0.7048,  0.3212])\n",
      "important\n",
      "Saved the embedding for important.\n",
      "['impressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2420,  1.0127, -0.1785,  ..., -0.6461, -0.2126,  1.0666])\n",
      "impressed\n",
      "Saved the embedding for impressed.\n",
      "['imp', '##ulsive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0804,  0.4559, -0.4525,  ..., -0.5265, -0.0006,  0.0450])\n",
      "impulsive\n",
      "Saved the embedding for impulsive.\n",
      "['inactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4970, -0.1063,  0.3805,  ...,  0.1876, -1.0905,  0.2201])\n",
      "inactive\n",
      "Saved the embedding for inactive.\n",
      "['inadequate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3544,  0.5091,  0.3565,  ..., -2.1384, -0.6019,  0.9441])\n",
      "inadequate\n",
      "Saved the embedding for inadequate.\n",
      "['ina', '##rti', '##cula', '##te'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6157,  0.2776, -0.1753,  ..., -1.1411,  0.1874,  0.3713])\n",
      "inarticulate\n",
      "Saved the embedding for inarticulate.\n",
      "['ina', '##tten', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3681,  0.3462, -0.3019,  ...,  0.0448,  0.0216,  0.4541])\n",
      "inattentive\n",
      "Saved the embedding for inattentive.\n",
      "['ina', '##udi', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1150,  0.4630,  0.5985,  ..., -0.0776, -0.1992,  0.5905])\n",
      "inaudible\n",
      "Saved the embedding for inaudible.\n",
      "['ina', '##uth', '##ent', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1491,  0.0994, -0.3372,  ...,  0.0284, -0.3657,  0.7328])\n",
      "inauthentic\n",
      "Saved the embedding for inauthentic.\n",
      "['incapable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5678, -0.8450,  0.3551,  ...,  0.2305, -0.9885,  0.2080])\n",
      "incapable\n",
      "Saved the embedding for incapable.\n",
      "['incense', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3049,  0.2460, -0.1505,  ..., -0.5997, -0.4519,  0.2489])\n",
      "incensed\n",
      "Saved the embedding for incensed.\n",
      "['inc', '##ert', '##ain'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0687,  0.5931,  0.4741,  ..., -0.6792,  0.2333,  1.1390])\n",
      "incertain\n",
      "Saved the embedding for incertain.\n",
      "['inc', '##ert', '##itude'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0246,  0.2137,  0.6528,  ..., -0.4794,  0.0546,  1.4783])\n",
      "incertitude\n",
      "Saved the embedding for incertitude.\n",
      "['inc', '##ited'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3261,  0.3821,  0.2038,  ..., -1.0131,  0.0535,  0.4790])\n",
      "incited\n",
      "Saved the embedding for incited.\n",
      "['inc', '##omp', '##re', '##hen', '##sible'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.1103,  0.5111,  0.6685,  ..., -0.2511,  0.1158,  1.0589])\n",
      "incomprehensible\n",
      "Saved the embedding for incomprehensible.\n",
      "['inc', '##ons', '##pic', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0741,  0.2217,  0.9129,  ..., -0.6641, -0.1070,  0.7758])\n",
      "inconspicuous\n",
      "Saved the embedding for inconspicuous.\n",
      "['inc', '##red', '##uli', '##ty'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1185,  0.6819,  0.9116,  ..., -0.7114, -0.0785,  1.0454])\n",
      "incredulity\n",
      "Saved the embedding for incredulity.\n",
      "['inc', '##red', '##ulous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1732,  0.4241,  0.7990,  ..., -0.6648, -0.1537,  0.8121])\n",
      "incredulous\n",
      "Saved the embedding for incredulous.\n",
      "['inc', '##red', '##ulously'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0973,  0.6965,  0.6912,  ..., -0.8466,  0.0086,  0.6275])\n",
      "incredulously\n",
      "Saved the embedding for incredulously.\n",
      "['inc', '##ul', '##pate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1295,  0.4015,  0.2425,  ..., -1.3057,  0.1060,  0.9078])\n",
      "inculpate\n",
      "Saved the embedding for inculpate.\n",
      "['inc', '##uri', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2187,  0.5592,  0.7823,  ..., -0.6705, -0.3821,  1.1193])\n",
      "incurious\n",
      "Saved the embedding for incurious.\n",
      "['ind', '##ec', '##ip', '##her', '##able'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.1788, -0.0678,  0.1945,  ..., -1.3272, -0.5240,  0.8489])\n",
      "indecipherable\n",
      "Saved the embedding for indecipherable.\n",
      "['ind', '##ec', '##ision'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4410,  0.0263,  0.3545,  ..., -0.5066, -0.9858,  0.6400])\n",
      "indecision\n",
      "Saved the embedding for indecision.\n",
      "['ind', '##ec', '##isi', '##ve'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0819,  0.1902,  0.1461,  ..., -0.6180, -0.7526,  0.1676])\n",
      "indecisive\n",
      "Saved the embedding for indecisive.\n",
      "['indifferent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2041,  0.1969,  0.7544,  ..., -0.1923, -0.0421,  1.4640])\n",
      "indifferent\n",
      "Saved the embedding for indifferent.\n",
      "['indifferent', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5603,  0.1044,  0.4448,  ..., -0.4814, -0.1401,  1.3592])\n",
      "indifferently\n",
      "Saved the embedding for indifferently.\n",
      "['ind', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2415,  0.2186,  0.3312,  ..., -0.3893, -0.7284, -0.0648])\n",
      "indignant\n",
      "Saved the embedding for indignant.\n",
      "['indo', '##lent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4670, -0.2819,  0.2709,  ..., -0.5975, -0.1738,  0.3314])\n",
      "indolent\n",
      "Saved the embedding for indolent.\n",
      "['in', '##eb', '##riated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0637,  0.8041,  0.1474,  ..., -1.4701, -1.0695,  0.2336])\n",
      "inebriated\n",
      "Saved the embedding for inebriated.\n",
      "['in', '##ert'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 5.3726e-04,  1.1281e-01, -1.8047e-01,  ..., -1.1358e+00,\n",
      "        -4.8088e-01,  6.9064e-01])\n",
      "inert\n",
      "Saved the embedding for inert.\n",
      "['in', '##fat', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4800,  0.1440, -0.4270,  ..., -2.1428, -1.3432, -0.5885])\n",
      "infatuating\n",
      "Saved the embedding for infatuating.\n",
      "['inferior'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4030,  0.0952, -0.8204,  ..., -0.3381, -0.7861,  0.6414])\n",
      "inferior\n",
      "Saved the embedding for inferior.\n",
      "['inferior', '##ity'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4496,  0.1871,  0.1641,  ..., -0.9169, -0.9034,  0.4789])\n",
      "inferiority\n",
      "Saved the embedding for inferiority.\n",
      "['in', '##fl', '##ame', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3324,  0.2147,  0.4223,  ..., -0.4883,  0.1545,  0.4503])\n",
      "inflamed\n",
      "Saved the embedding for inflamed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['informal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2913,  0.3932, -0.0062,  ..., -0.6487, -0.4704,  0.6802])\n",
      "informal\n",
      "Saved the embedding for informal.\n",
      "['informing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1342,  0.3050,  0.2183,  ..., -0.6380, -0.0283,  1.0431])\n",
      "informing\n",
      "Saved the embedding for informing.\n",
      "['in', '##fur', '##iated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2672,  0.0948,  0.5369,  ..., -1.6159, -0.3431, -0.4073])\n",
      "infuriated\n",
      "Saved the embedding for infuriated.\n",
      "['inhibit', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0575,  0.1748,  0.4186,  ..., -0.7092, -0.8851,  0.5557])\n",
      "inhibited\n",
      "Saved the embedding for inhibited.\n",
      "['inhibit', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1361,  0.4376, -0.2181,  ..., -0.7936, -0.9982,  0.3004])\n",
      "inhibiting\n",
      "Saved the embedding for inhibiting.\n",
      "['in', '##imi', '##cal'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6754,  1.1668, -0.5934,  ..., -1.1783, -0.6237,  0.9078])\n",
      "inimical\n",
      "Saved the embedding for inimical.\n",
      "['injured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5649,  0.3347, -0.4870,  ..., -0.5323,  0.5288, -0.4475])\n",
      "injured\n",
      "Saved the embedding for injured.\n",
      "['innocent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2157,  0.3520, -0.0387,  ..., -0.0089, -0.5074,  0.3773])\n",
      "innocent\n",
      "Saved the embedding for innocent.\n",
      "['in', '##patient'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0613, -0.2592,  0.2288,  ..., -0.5784,  0.0934, -0.0237])\n",
      "inpatient\n",
      "Saved the embedding for inpatient.\n",
      "['in', '##qui', '##ring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6601,  0.8638,  0.3494,  ..., -1.0803, -0.9980,  0.5098])\n",
      "inquiring\n",
      "Saved the embedding for inquiring.\n",
      "['in', '##qui', '##sit', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1297, -0.1913,  0.1670,  ..., -0.4003, -0.6638,  0.4734])\n",
      "inquisitive\n",
      "Saved the embedding for inquisitive.\n",
      "['insane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7716, -0.0702, -0.2991,  ..., -0.1614, -0.7856,  0.3709])\n",
      "insane\n",
      "Saved the embedding for insane.\n",
      "['ins', '##cr', '##utable'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6485,  0.0482,  1.0254,  ..., -0.2794, -0.4252,  0.1419])\n",
      "inscrutable\n",
      "Saved the embedding for inscrutable.\n",
      "['ins', '##ecure'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1120,  0.1688,  0.0865,  ..., -1.1247, -0.2447,  0.1507])\n",
      "insecure\n",
      "Saved the embedding for insecure.\n",
      "['ins', '##ec', '##urity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7622,  0.1118,  0.6882,  ..., -1.1453, -0.4170,  0.4164])\n",
      "insecurity\n",
      "Saved the embedding for insecurity.\n",
      "['ins', '##ens', '##itive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4671, -0.2563, -0.3364,  ..., -0.4227, -0.5807, -0.0352])\n",
      "insensitive\n",
      "Saved the embedding for insensitive.\n",
      "['ins', '##idi', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4337,  0.2486,  0.2226,  ..., -1.6430, -0.7044, -0.8918])\n",
      "insidious\n",
      "Saved the embedding for insidious.\n",
      "['ins', '##in', '##uating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0403,  0.4785,  0.1243,  ..., -1.1910, -0.6687, -0.6607])\n",
      "insinuating\n",
      "Saved the embedding for insinuating.\n",
      "['insistence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1195, -0.6793, -0.2266,  ..., -1.6372,  0.6056,  0.3703])\n",
      "insistence\n",
      "Saved the embedding for insistence.\n",
      "['insistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0996,  0.7388,  0.2647,  ..., -1.5294,  0.1264,  0.1068])\n",
      "insistent\n",
      "Saved the embedding for insistent.\n",
      "['insisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1009,  0.3969, -0.0743,  ...,  0.2456, -0.1014,  0.8886])\n",
      "insisting\n",
      "Saved the embedding for insisting.\n",
      "['ins', '##ole', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0102,  0.5079,  0.1037,  ..., -1.4390, -0.2646, -0.4846])\n",
      "insolent\n",
      "Saved the embedding for insolent.\n",
      "['ins', '##ou', '##cian', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5812,  0.2786, -0.0781,  ..., -1.4070, -0.3577,  0.2443])\n",
      "insouciance\n",
      "Saved the embedding for insouciance.\n",
      "['ins', '##ou', '##cian', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5299,  0.0827,  0.6446,  ..., -0.8554, -0.0035,  0.4889])\n",
      "insouciant\n",
      "Saved the embedding for insouciant.\n",
      "['inspired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6412,  0.2172, -0.0715,  ..., -0.1910,  0.2942,  0.3282])\n",
      "inspired\n",
      "Saved the embedding for inspired.\n",
      "['inspiring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0689,  0.5351,  0.0531,  ..., -0.5477,  0.2547,  0.5842])\n",
      "inspiring\n",
      "Saved the embedding for inspiring.\n",
      "['ins', '##ti', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1712,  0.4817,  0.3372,  ..., -0.9733, -0.6860, -0.3571])\n",
      "instigating\n",
      "Saved the embedding for instigating.\n",
      "['ins', '##tructing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0699,  0.6843,  0.6350,  ..., -0.8037, -0.4258,  0.6689])\n",
      "instructing\n",
      "Saved the embedding for instructing.\n",
      "['ins', '##ub', '##ord', '##inate'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0176,  0.1443,  0.6951,  ..., -0.8778, -0.0937,  0.2172])\n",
      "insubordinate\n",
      "Saved the embedding for insubordinate.\n",
      "['ins', '##ular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2037,  0.5461,  0.6820,  ..., -1.0256, -0.0024,  0.8728])\n",
      "insular\n",
      "Saved the embedding for insular.\n",
      "['insulted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1037, -0.1131,  0.4324,  ...,  0.0188, -0.6718,  0.6508])\n",
      "insulted\n",
      "Saved the embedding for insulted.\n",
      "['insulting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6296,  0.2828,  0.2749,  ..., -0.1705, -0.8764,  0.4309])\n",
      "insulting\n",
      "Saved the embedding for insulting.\n",
      "['intelligence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0438,  0.4417,  0.5286,  ...,  0.1659, -0.3035,  0.7934])\n",
      "intelligence\n",
      "Saved the embedding for intelligence.\n",
      "['intense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3644,  0.1644, -0.0133,  ...,  0.3819, -0.3179,  1.3756])\n",
      "intense\n",
      "Saved the embedding for intense.\n",
      "['intensely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7603,  0.4126, -0.1960,  ...,  0.0174, -0.8205,  0.3770])\n",
      "intensely\n",
      "Saved the embedding for intensely.\n",
      "['intensity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9158,  0.1532, -0.3913,  ..., -0.2421, -0.7219,  0.7116])\n",
      "intensity\n",
      "Saved the embedding for intensity.\n",
      "['intensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9736, -0.0082, -0.7756,  ...,  0.2048, -0.4151,  1.4297])\n",
      "intensive\n",
      "Saved the embedding for intensive.\n",
      "['intent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2623,  0.7551,  0.1203,  ..., -0.0286, -0.6087,  0.9488])\n",
      "intent\n",
      "Saved the embedding for intent.\n",
      "['intentional'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2440,  0.1678,  0.0604,  ..., -1.4961,  0.6336,  1.0427])\n",
      "intentional\n",
      "Saved the embedding for intentional.\n",
      "['interacting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7758, -0.0497, -0.3373,  ..., -0.2314,  0.3321,  0.5266])\n",
      "interacting\n",
      "Saved the embedding for interacting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2857,  0.9341,  0.0094,  ...,  1.0435, -1.4215,  0.2650])\n",
      "interest\n",
      "Saved the embedding for interest.\n",
      "['interested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0217,  0.1738, -0.0064,  ...,  0.1486, -0.8917,  0.2630])\n",
      "interested\n",
      "Saved the embedding for interested.\n",
      "['inter', '##ject', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3561,  0.6730, -0.3851,  ..., -1.0079, -0.3626,  0.4907])\n",
      "interjecting\n",
      "Saved the embedding for interjecting.\n",
      "['internal', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3777, -0.2325, -0.5848,  ..., -1.7891, -0.7915,  0.1164])\n",
      "internalizing\n",
      "Saved the embedding for internalizing.\n",
      "['inter', '##ro', '##gating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7628,  0.3130,  0.5529,  ..., -0.4936, -0.3574,  0.7238])\n",
      "interrogating\n",
      "Saved the embedding for interrogating.\n",
      "['interrupting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0777,  0.4603, -0.6966,  ..., -0.3937, -0.1838,  0.8921])\n",
      "interrupting\n",
      "Saved the embedding for interrupting.\n",
      "['intimidated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3852,  0.1747,  0.2399,  ...,  0.4231, -0.7540,  0.5560])\n",
      "intimidated\n",
      "Saved the embedding for intimidated.\n",
      "['intimidating'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1735,  0.3498,  0.3122,  ...,  0.2822, -0.7306,  0.2690])\n",
      "intimidating\n",
      "Saved the embedding for intimidating.\n",
      "['into', '##ler', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3724, -0.2260, -0.1823,  ..., -1.4122, -0.3755,  0.5727])\n",
      "intolerant\n",
      "Saved the embedding for intolerant.\n",
      "['into', '##xi', '##cated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1552,  0.5047, -0.3248,  ..., -0.7852, -0.5779,  0.2365])\n",
      "intoxicated\n",
      "Saved the embedding for intoxicated.\n",
      "['int', '##rigue'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1506,  0.4275, -0.0065,  ..., -0.8177,  0.0964, -0.3512])\n",
      "intrigue\n",
      "Saved the embedding for intrigue.\n",
      "['intrigued'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7013, -0.0629, -0.2816,  ..., -0.8941, -0.9566,  0.6375])\n",
      "intrigued\n",
      "Saved the embedding for intrigued.\n",
      "['intriguing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0507, -0.3082, -0.4710,  ..., -0.4457, -1.0025,  0.1672])\n",
      "intriguing\n",
      "Saved the embedding for intriguing.\n",
      "['intro', '##sp', '##ect', '##ive'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4786,  0.1520, -0.4358,  ..., -0.7155, -0.2092,  0.3193])\n",
      "introspective\n",
      "Saved the embedding for introspective.\n",
      "['invested'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4840, -0.0068,  0.0099,  ..., -0.2246, -0.2397,  0.3212])\n",
      "invested\n",
      "Saved the embedding for invested.\n",
      "['investigate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0828,  0.2948, -0.1422,  ..., -0.5700,  0.4578,  0.9050])\n",
      "investigate\n",
      "Saved the embedding for investigate.\n",
      "['investigative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2980,  0.4873, -0.0806,  ...,  0.1333,  0.5865,  0.1387])\n",
      "investigative\n",
      "Saved the embedding for investigative.\n",
      "['investigator', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1705,  0.3080,  0.7114,  ..., -0.1446, -0.2656,  0.2873])\n",
      "investigatory\n",
      "Saved the embedding for investigatory.\n",
      "['in', '##vi', '##gor', '##ated'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2034, -0.4602,  0.4806,  ..., -0.7788, -0.5038,  0.2342])\n",
      "invigorated\n",
      "Saved the embedding for invigorated.\n",
      "['involved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0484, -0.6792, -0.5881,  ..., -1.5018, -0.3147,  0.8156])\n",
      "involved\n",
      "Saved the embedding for involved.\n",
      "['ira', '##sc', '##ible'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1581, -0.0849,  0.3282,  ..., -0.5266, -0.8754,  0.6033])\n",
      "irascible\n",
      "Saved the embedding for irascible.\n",
      "['ira', '##te'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0363, -0.3509,  0.3127,  ..., -0.5509, -0.9136,  0.4582])\n",
      "irate\n",
      "Saved the embedding for irate.\n",
      "['ir', '##e'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5591,  0.5610, -0.0763,  ..., -0.8281, -0.6150,  0.5746])\n",
      "ire\n",
      "Saved the embedding for ire.\n",
      "['ir', '##ef', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1440,  0.1461,  0.2651,  ..., -0.9354, -0.1309, -0.3556])\n",
      "ireful\n",
      "Saved the embedding for ireful.\n",
      "['ir', '##ked'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0464,  0.2902,  0.1903,  ..., -0.6162, -0.3565,  0.4397])\n",
      "irked\n",
      "Saved the embedding for irked.\n",
      "['ironic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2664,  0.4660, -0.3915,  ..., -0.0680,  0.0216,  0.0788])\n",
      "ironic\n",
      "Saved the embedding for ironic.\n",
      "['irony'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1858, -0.3082, -0.6268,  ..., -0.8940,  0.5673, -0.2923])\n",
      "irony\n",
      "Saved the embedding for irony.\n",
      "['ir', '##res', '##ol', '##ute'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3778,  0.3999, -0.2364,  ..., -0.1382, -0.2151,  0.0891])\n",
      "irresolute\n",
      "Saved the embedding for irresolute.\n",
      "['ir', '##rita', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5200,  0.4590, -0.1438,  ..., -0.5161,  0.2333,  0.3433])\n",
      "irritable\n",
      "Saved the embedding for irritable.\n",
      "['ir', '##rita', '##bly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.9702,  0.3342, -0.3349,  ..., -0.9709,  0.0533,  0.1367])\n",
      "irritably\n",
      "Saved the embedding for irritably.\n",
      "['irritated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1281,  0.2543, -0.1342,  ..., -0.1321, -0.1003,  0.6831])\n",
      "irritated\n",
      "Saved the embedding for irritated.\n",
      "['irritation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1534,  0.2214,  0.1040,  ..., -0.6583, -0.0827,  1.0072])\n",
      "irritation\n",
      "Saved the embedding for irritation.\n",
      "['isolated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5265,  0.1299, -0.6391,  ..., -1.7112, -0.5146,  0.4599])\n",
      "isolated\n",
      "Saved the embedding for isolated.\n",
      "['ja', '##bbed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4803, -0.2935,  0.3160,  ..., -0.6779, -0.7156, -0.0925])\n",
      "jabbed\n",
      "Saved the embedding for jabbed.\n",
      "['jade', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4923,  0.0748,  0.5164,  ..., -0.2443, -0.7851,  0.6327])\n",
      "jaded\n",
      "Saved the embedding for jaded.\n",
      "['jar', '##red'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8343, -0.0371, -0.3036,  ..., -0.0426, -0.0626,  0.0145])\n",
      "jarred\n",
      "Saved the embedding for jarred.\n",
      "['jar', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.9226,  0.0347, -0.2448,  ..., -0.0273, -0.0647,  0.0165])\n",
      "jarring\n",
      "Saved the embedding for jarring.\n",
      "['ja', '##unt', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3499, -0.3747,  0.2060,  ..., -0.7619, -0.3189,  0.7287])\n",
      "jaunty\n",
      "Saved the embedding for jaunty.\n",
      "['jaw', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4768,  0.0510,  0.6833,  ..., -1.0181, -0.2266,  0.2970])\n",
      "jawed\n",
      "Saved the embedding for jawed.\n",
      "['jealous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1307,  0.3995, -0.5381,  ...,  0.1822, -0.2422,  1.1539])\n",
      "jealous\n",
      "Saved the embedding for jealous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je', '##ering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1824,  0.0605,  0.7671,  ..., -0.1669,  0.3013,  1.0647])\n",
      "jeering\n",
      "Saved the embedding for jeering.\n",
      "['je', '##sti', '##ng'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7154, -0.1673,  0.7047,  ..., -0.1661,  0.2801,  0.8534])\n",
      "jesting\n",
      "Saved the embedding for jesting.\n",
      "['ji', '##lt', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1632, -0.2642, -0.0867,  ..., -0.9411, -0.7607,  0.6287])\n",
      "jilted\n",
      "Saved the embedding for jilted.\n",
      "['ji', '##tter', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5089, -0.7494,  0.2818,  ..., -0.4690, -0.2271,  0.4066])\n",
      "jittery\n",
      "Saved the embedding for jittery.\n",
      "['jo', '##cular'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6915, -0.1640,  0.4883,  ..., -0.9272, -0.3619,  0.5252])\n",
      "jocular\n",
      "Saved the embedding for jocular.\n",
      "['joking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1276,  0.3920,  0.0557,  ..., -0.0254, -0.1019,  1.4219])\n",
      "joking\n",
      "Saved the embedding for joking.\n",
      "['jolly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0078,  0.3437,  0.2127,  ..., -0.9727, -0.0225,  0.7825])\n",
      "jolly\n",
      "Saved the embedding for jolly.\n",
      "['jolted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8040,  0.1145, -0.4327,  ..., -0.8820,  0.2473, -0.2798])\n",
      "jolted\n",
      "Saved the embedding for jolted.\n",
      "['jo', '##vial'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1208, -0.4027,  0.5918,  ..., -1.0841, -0.7304,  0.7369])\n",
      "jovial\n",
      "Saved the embedding for jovial.\n",
      "['joy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9337,  0.2009, -0.1500,  ..., -1.3222,  0.1491,  0.7074])\n",
      "joy\n",
      "Saved the embedding for joy.\n",
      "['joy', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1677,  0.3214, -0.1483,  ..., -1.5238, -0.1490,  0.5231])\n",
      "joyful\n",
      "Saved the embedding for joyful.\n",
      "['joy', '##fulness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6271,  0.0513,  0.4272,  ..., -0.8245, -0.0164,  1.0246])\n",
      "joyfulness\n",
      "Saved the embedding for joyfulness.\n",
      "['joy', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4249,  0.0359,  0.2344,  ..., -1.4641,  0.2781,  0.8560])\n",
      "joyless\n",
      "Saved the embedding for joyless.\n",
      "['joy', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2241,  0.6530,  0.3256,  ..., -1.5015, -0.0832,  0.9052])\n",
      "joyous\n",
      "Saved the embedding for joyous.\n",
      "['ju', '##bil', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5659, -0.0577, -0.3047,  ..., -0.7554, -0.5586,  0.4024])\n",
      "jubilant\n",
      "Saved the embedding for jubilant.\n",
      "['ju', '##bil', '##ation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7235,  0.1998, -0.2427,  ..., -0.7884, -0.5899,  0.4027])\n",
      "jubilation\n",
      "Saved the embedding for jubilation.\n",
      "['judgement', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4551,  0.1824,  0.0562,  ..., -1.0545, -0.3575,  1.0232])\n",
      "judgemental\n",
      "Saved the embedding for judgemental.\n",
      "['judging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2919, -0.3121, -0.0441,  ..., -0.2277, -0.0886,  0.5232])\n",
      "judging\n",
      "Saved the embedding for judging.\n",
      "['judgment', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1271,  0.2134, -0.1724,  ..., -0.4292, -0.4772,  0.9983])\n",
      "judgmental\n",
      "Saved the embedding for judgmental.\n",
      "['ju', '##dic', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0864,  0.1987,  0.2496,  ..., -0.6404, -0.3270,  0.3239])\n",
      "judicious\n",
      "Saved the embedding for judicious.\n",
      "['jump', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1642, -0.2487,  0.5576,  ..., -0.1983,  0.0868,  0.6851])\n",
      "jumpy\n",
      "Saved the embedding for jumpy.\n",
      "['justified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0630,  0.2409, -0.5581,  ..., -1.1209,  0.3721, -0.0782])\n",
      "justified\n",
      "Saved the embedding for justified.\n",
      "['keen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4700e+00,  5.4852e-01, -6.7604e-01,  ..., -5.8495e-01,\n",
      "        -5.4637e-04,  1.0269e+00])\n",
      "keen\n",
      "Saved the embedding for keen.\n",
      "['kind'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9402, -0.4222, -0.1714,  ..., -0.7674,  0.0144,  0.0827])\n",
      "kind\n",
      "Saved the embedding for kind.\n",
      "['kind', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0249,  0.5492, -0.1066,  ..., -0.5472, -0.7834, -0.2035])\n",
      "kindhearted\n",
      "Saved the embedding for kindhearted.\n",
      "['kiss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0391,  0.5347,  0.1803,  ..., -0.7865,  0.4685,  0.6842])\n",
      "kiss\n",
      "Saved the embedding for kiss.\n",
      "['knowing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2528,  0.2909, -0.0164,  ..., -0.0440, -0.5294,  0.5975])\n",
      "knowing\n",
      "Saved the embedding for knowing.\n",
      "['know', '##led', '##ga', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2297,  0.0564,  0.0658,  ..., -0.5094, -0.6149,  0.1756])\n",
      "knowledgable\n",
      "Saved the embedding for knowledgable.\n",
      "['knowledge', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2701,  0.1858,  0.4903,  ..., -1.0337, -0.2356,  0.6190])\n",
      "knowledgeable\n",
      "Saved the embedding for knowledgeable.\n",
      "['ko', '##sher'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0520,  0.0060,  0.5523,  ..., -1.4233, -0.6827,  0.8281])\n",
      "kosher\n",
      "Saved the embedding for kosher.\n",
      "['lack', '##ada', '##isi', '##cal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0603,  0.5287,  0.0205,  ..., -0.5760,  0.0124,  0.2510])\n",
      "lackadaisical\n",
      "Saved the embedding for lackadaisical.\n",
      "['lack', '##lus', '##ter'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3804, -0.4624,  0.2035,  ..., -0.5097,  0.0460,  0.4440])\n",
      "lackluster\n",
      "Saved the embedding for lackluster.\n",
      "['lac', '##onic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4008,  0.5074,  0.1837,  ..., -0.7535, -0.1583,  0.9670])\n",
      "laconic\n",
      "Saved the embedding for laconic.\n",
      "['lamb', '##ast', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5231,  0.4297, -0.5075,  ..., -0.3289, -0.9094,  0.0960])\n",
      "lambaste\n",
      "Saved the embedding for lambaste.\n",
      "['lame', '##nta', '##ble'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1387, -0.3912, -0.0190,  ..., -0.3048, -0.8653,  0.7395])\n",
      "lamentable\n",
      "Saved the embedding for lamentable.\n",
      "['lame', '##nting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3957,  0.3625, -0.2086,  ..., -1.9316, -1.1033, -0.6868])\n",
      "lamenting\n",
      "Saved the embedding for lamenting.\n",
      "['las', '##ci', '##vious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0655, -0.2632,  0.5516,  ..., -0.4386, -0.1745,  0.5798])\n",
      "lascivious\n",
      "Saved the embedding for lascivious.\n",
      "['laugh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9276,  0.1145,  0.6876,  ..., -0.8552, -0.4130,  1.6786])\n",
      "laugh\n",
      "Saved the embedding for laugh.\n",
      "['laughing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2485, -0.3124,  0.2482,  ..., -0.6384, -0.2619,  0.7657])\n",
      "laughing\n",
      "Saved the embedding for laughing.\n",
      "['laughter'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2270, -0.4163,  0.4890,  ..., -0.2866, -0.2568,  0.9377])\n",
      "laughter\n",
      "Saved the embedding for laughter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lazy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1821,  0.1966,  0.2812,  ..., -0.6098, -0.2982,  1.6816])\n",
      "lazy\n",
      "Saved the embedding for lazy.\n",
      "['leaving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1058,  0.7053,  0.9162,  ...,  0.6199, -1.1452,  0.7186])\n",
      "leaving\n",
      "Saved the embedding for leaving.\n",
      "['le', '##cher', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4690,  0.0844,  0.3000,  ..., -0.2985, -0.4230, -0.5602])\n",
      "lecherous\n",
      "Saved the embedding for lecherous.\n",
      "['le', '##cturing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8027, -0.2914,  0.2028,  ..., -0.6003,  0.1568,  0.3498])\n",
      "lecturing\n",
      "Saved the embedding for lecturing.\n",
      "['lee', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 7.3443e-01,  6.2763e-02, -5.7687e-04,  ..., -4.2647e-01,\n",
      "        -7.1802e-01,  6.7116e-01])\n",
      "leering\n",
      "Saved the embedding for leering.\n",
      "['lee', '##ry'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1688,  0.0700,  0.1478,  ..., -0.6159, -0.9316,  0.5514])\n",
      "leery\n",
      "Saved the embedding for leery.\n",
      "['let', '##down'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3006, -0.0207,  0.5028,  ..., -0.3365, -0.2995,  1.4436])\n",
      "letdown\n",
      "Saved the embedding for letdown.\n",
      "['let', '##har', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4247,  0.3824,  1.0096,  ..., -0.9348,  0.2207,  0.5993])\n",
      "lethargic\n",
      "Saved the embedding for lethargic.\n",
      "['level', '##head', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3148,  0.0290,  0.3370,  ..., -0.4025, -0.5333,  0.7881])\n",
      "levelheaded\n",
      "Saved the embedding for levelheaded.\n",
      "['lew', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.1671,  0.0938,  0.4586,  ..., -0.4702, -0.3155,  0.2971])\n",
      "lewd\n",
      "Saved the embedding for lewd.\n",
      "['li', '##bid', '##ino', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2857,  0.1429,  0.4594,  ..., -0.8707, -0.0841,  0.5083])\n",
      "libidinous\n",
      "Saved the embedding for libidinous.\n",
      "['lifeless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1290,  0.5286,  0.0397,  ...,  0.1094, -0.6692,  0.6737])\n",
      "lifeless\n",
      "Saved the embedding for lifeless.\n",
      "['light', '##hearted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6642,  0.4095,  1.0810,  ..., -0.2422, -0.5970,  0.2502])\n",
      "lighthearted\n",
      "Saved the embedding for lighthearted.\n",
      "['lip', '##ped'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2880, -0.2981, -0.5364,  ..., -0.6071,  0.1078,  0.2891])\n",
      "lipped\n",
      "Saved the embedding for lipped.\n",
      "['listening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4414,  0.0065,  0.3900,  ...,  0.5755, -0.8079,  0.2657])\n",
      "listening\n",
      "Saved the embedding for listening.\n",
      "['list', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0484,  0.1461,  0.4353,  ..., -0.3673, -0.2132,  0.8357])\n",
      "listless\n",
      "Saved the embedding for listless.\n",
      "['lively'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5179, -0.0757, -0.6679,  ..., -1.0013,  0.1713,  0.0494])\n",
      "lively\n",
      "Saved the embedding for lively.\n",
      "['liv', '##id'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3420,  0.9663,  0.0998,  ..., -0.0265, -0.3840,  1.4269])\n",
      "livid\n",
      "Saved the embedding for livid.\n",
      "['loaded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9384, -0.3043, -0.3594,  ...,  0.1518, -0.5686,  0.7577])\n",
      "loaded\n",
      "Saved the embedding for loaded.\n",
      "['lo', '##ath'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3412,  0.3535,  0.0102,  ..., -0.8416, -0.9058,  1.2588])\n",
      "loath\n",
      "Saved the embedding for loath.\n",
      "['lo', '##ath', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1460,  0.1569,  0.1427,  ..., -0.0766, -0.2936,  0.7280])\n",
      "loathe\n",
      "Saved the embedding for loathe.\n",
      "['lo', '##athing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0192, -0.3126,  0.0219,  ..., -0.7332, -0.4309,  0.9311])\n",
      "loathing\n",
      "Saved the embedding for loathing.\n",
      "['lo', '##ath', '##some'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0228,  0.0082,  0.4491,  ...,  0.1636, -0.2241,  0.6966])\n",
      "loathsome\n",
      "Saved the embedding for loathsome.\n",
      "['locked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0456,  0.4531, -0.2333,  ..., -1.4195, -0.5547,  1.1114])\n",
      "locked\n",
      "Saved the embedding for locked.\n",
      "['loneliness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5794, -0.1406,  1.4516,  ..., -0.6557,  0.1730,  1.1151])\n",
      "loneliness\n",
      "Saved the embedding for loneliness.\n",
      "['lonely'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2577,  0.2482,  0.4458,  ..., -0.1030, -0.1473,  0.9558])\n",
      "lonely\n",
      "Saved the embedding for lonely.\n",
      "['longing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0383,  0.1289, -0.1537,  ..., -0.7800, -0.1115,  0.3190])\n",
      "longing\n",
      "Saved the embedding for longing.\n",
      "['looking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6317,  0.4673,  0.3195,  ..., -1.2158, -1.1986,  0.7392])\n",
      "looking\n",
      "Saved the embedding for looking.\n",
      "['lo', '##ony'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0599,  0.1959,  0.1939,  ...,  0.1324, -0.3197,  1.0688])\n",
      "loony\n",
      "Saved the embedding for loony.\n",
      "['loss'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5523,  0.1365, -0.3145,  ..., -0.9742,  0.1216,  0.6822])\n",
      "loss\n",
      "Saved the embedding for loss.\n",
      "['lost'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3409, -0.0719,  0.2379,  ..., -0.9316, -0.1435, -0.0204])\n",
      "lost\n",
      "Saved the embedding for lost.\n",
      "['loud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3108,  0.1351, -0.1219,  ...,  0.4404,  0.5823,  0.5056])\n",
      "loud\n",
      "Saved the embedding for loud.\n",
      "['lou', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5837, -0.1361,  0.3126,  ..., -0.3926, -0.0753,  0.4044])\n",
      "lousy\n",
      "Saved the embedding for lousy.\n",
      "['love'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3038,  0.0465,  0.6556,  ..., -0.3516,  0.1401,  0.1769])\n",
      "love\n",
      "Saved the embedding for love.\n",
      "['loving'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9102,  0.2263, -0.4117,  ..., -0.2924, -0.4140,  0.4149])\n",
      "loving\n",
      "Saved the embedding for loving.\n",
      "['low', '##liness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6465, -0.0190, -0.1235,  ..., -1.1185, -0.8023,  0.7572])\n",
      "lowliness\n",
      "Saved the embedding for lowliness.\n",
      "['lu', '##rid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1386, -0.0338,  0.1736,  ..., -0.9328, -0.7762,  0.4582])\n",
      "lurid\n",
      "Saved the embedding for lurid.\n",
      "['lust', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3370,  0.6267, -0.2057,  ..., -0.4637, -0.1903,  0.6527])\n",
      "lustful\n",
      "Saved the embedding for lustful.\n",
      "['lust', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1287,  0.5082, -0.0287,  ..., -0.1996,  0.2877,  0.4090])\n",
      "lusting\n",
      "Saved the embedding for lusting.\n",
      "['lust', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2847,  0.4865, -0.1542,  ..., -0.2030, -0.2591,  0.3209])\n",
      "lusty\n",
      "Saved the embedding for lusty.\n",
      "['lying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3299, -0.1784,  0.0391,  ..., -0.0437,  0.0765,  0.1981])\n",
      "lying\n",
      "Saved the embedding for lying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0935,  0.4282,  0.0942,  ..., -0.5294, -0.4106,  0.9301])\n",
      "mad\n",
      "Saved the embedding for mad.\n",
      "['madden', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4413,  0.4643, -0.0828,  ..., -0.9875, -0.2659,  0.5810])\n",
      "maddened\n",
      "Saved the embedding for maddened.\n",
      "['madness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9105,  0.2989, -0.1886,  ..., -0.3715, -0.1946,  1.1728])\n",
      "madness\n",
      "Saved the embedding for madness.\n",
      "['mal', '##con', '##ten', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5006,  0.0948, -0.3374,  ..., -0.7847, -0.8597,  0.8710])\n",
      "malcontent\n",
      "Saved the embedding for malcontent.\n",
      "['male', '##fi', '##cent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0771,  0.5633, -0.1300,  ..., -0.4981, -0.2581, -0.1806])\n",
      "maleficent\n",
      "Saved the embedding for maleficent.\n",
      "['male', '##vo', '##lent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0084,  0.5122,  0.0976,  ..., -0.6874, -0.3817,  0.2740])\n",
      "malevolent\n",
      "Saved the embedding for malevolent.\n",
      "['malice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5271,  0.5581,  1.0270,  ...,  0.3009, -0.6903,  0.7771])\n",
      "malice\n",
      "Saved the embedding for malice.\n",
      "['malicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0645,  0.3788, -0.2841,  ...,  0.1644,  0.1528,  1.2724])\n",
      "malicious\n",
      "Saved the embedding for malicious.\n",
      "['mali', '##gnant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0910, -0.1198, -0.9757,  ..., -1.7476, -0.7466,  0.7091])\n",
      "malignant\n",
      "Saved the embedding for malignant.\n",
      "['mania', '##cal'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.7643, -0.0320,  0.3248,  ..., -0.8985, -0.2874,  0.4469])\n",
      "maniacal\n",
      "Saved the embedding for maniacal.\n",
      "['mani', '##pu', '##lative'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5699, -0.3003, -0.1796,  ..., -1.2282, -0.7603,  0.2726])\n",
      "manipulative\n",
      "Saved the embedding for manipulative.\n",
      "['marvel', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0841,  0.8849,  0.8962,  ...,  0.1589, -0.4259,  0.4366])\n",
      "marveled\n",
      "Saved the embedding for marveled.\n",
      "['master'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0896,  0.4889, -0.5858,  ..., -1.5341,  0.0251,  0.2403])\n",
      "master\n",
      "Saved the embedding for master.\n",
      "['mean'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3059, -0.3779,  0.3506,  ..., -0.3864,  0.0799,  0.9211])\n",
      "mean\n",
      "Saved the embedding for mean.\n",
      "['meaningful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3551, -0.0738, -0.3127,  ..., -0.5855, -0.8592,  0.1635])\n",
      "meaningful\n",
      "Saved the embedding for meaningful.\n",
      "['med', '##itative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.9961e-01, -3.9885e-04,  3.2776e-01,  ..., -4.3627e-01,\n",
      "         1.8644e-01,  2.4222e-01])\n",
      "meditative\n",
      "Saved the embedding for meditative.\n",
      "['meek'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8457, -0.1084,  0.0721,  ...,  0.1840, -0.3928,  1.4448])\n",
      "meek\n",
      "Saved the embedding for meek.\n",
      "['mel', '##an', '##cho', '##lic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2471,  0.2474,  0.2801,  ..., -0.7932,  0.3107,  0.3478])\n",
      "melancholic\n",
      "Saved the embedding for melancholic.\n",
      "['melancholy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2427,  0.1716,  0.0591,  ..., -0.6542, -0.3183,  0.2721])\n",
      "melancholy\n",
      "Saved the embedding for melancholy.\n",
      "['mel', '##low'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2252, -0.1142,  0.4116,  ..., -0.7307,  0.0374,  0.2406])\n",
      "mellow\n",
      "Saved the embedding for mellow.\n",
      "['menace'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4573,  0.0105,  0.0514,  ...,  0.2133, -0.7603, -0.1661])\n",
      "menace\n",
      "Saved the embedding for menace.\n",
      "['menacing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1198, -0.2537, -0.1469,  ...,  0.4321, -0.4139,  0.1564])\n",
      "menacing\n",
      "Saved the embedding for menacing.\n",
      "['mental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5078,  0.0206, -0.3206,  ..., -0.6060, -0.1312,  0.6227])\n",
      "mental\n",
      "Saved the embedding for mental.\n",
      "['mer', '##rily'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3362,  0.8616,  0.8055,  ..., -2.0216, -0.8072,  0.3616])\n",
      "merrily\n",
      "Saved the embedding for merrily.\n",
      "['merry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0441,  0.2017,  0.3562,  ..., -0.5544,  0.6565,  0.3147])\n",
      "merry\n",
      "Saved the embedding for merry.\n",
      "['me', '##sm', '##eri', '##zed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4101, -0.1343,  0.4438,  ..., -1.1954, -0.5696, -0.3380])\n",
      "mesmerized\n",
      "Saved the embedding for mesmerized.\n",
      "['mi', '##ffed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2557,  0.2960,  0.4113,  ..., -0.8432, -1.0285,  0.8961])\n",
      "miffed\n",
      "Saved the embedding for miffed.\n",
      "['mild'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0083, -0.2806,  0.7390,  ..., -0.1869, -0.1136,  0.2271])\n",
      "mild\n",
      "Saved the embedding for mild.\n",
      "['min', '##cing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3872, -0.2972,  0.2679,  ..., -1.4187, -1.7907,  0.2462])\n",
      "mincing\n",
      "Saved the embedding for mincing.\n",
      "['mind', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4754,  0.4574,  0.0476,  ..., -0.4936, -0.6664,  0.6864])\n",
      "mindful\n",
      "Saved the embedding for mindful.\n",
      "['mind', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3682,  0.2975,  0.3447,  ..., -0.1401, -0.5907,  0.8111])\n",
      "mindless\n",
      "Saved the embedding for mindless.\n",
      "['mirrored'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4281,  0.4709,  0.2107,  ...,  0.5647, -0.2647,  0.7807])\n",
      "mirrored\n",
      "Saved the embedding for mirrored.\n",
      "['mir', '##th'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3032,  0.5350,  0.4239,  ..., -1.3861, -0.0395,  0.9854])\n",
      "mirth\n",
      "Saved the embedding for mirth.\n",
      "['mir', '##th', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3460,  0.1096, -0.1648,  ..., -2.1103, -0.0994,  0.7954])\n",
      "mirthful\n",
      "Saved the embedding for mirthful.\n",
      "['mis', '##ant', '##hr', '##op', '##ic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.5597,  0.5449, -0.2217,  ..., -0.1203, -0.1661,  0.1785])\n",
      "misanthropic\n",
      "Saved the embedding for misanthropic.\n",
      "['mischief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6901,  0.1084, -0.1473,  ..., -0.2439, -0.4502,  0.5885])\n",
      "mischief\n",
      "Saved the embedding for mischief.\n",
      "['mischievous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3301,  0.3144, -0.1355,  ..., -0.2322, -0.3949,  0.6825])\n",
      "mischievous\n",
      "Saved the embedding for mischievous.\n",
      "['mischievous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1545,  0.2869,  0.4123,  ..., -1.2960, -0.5983,  1.1805])\n",
      "mischievousness\n",
      "Saved the embedding for mischievousness.\n",
      "['miserable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3868, -0.2975, -0.3503,  ..., -0.3479,  0.3384,  0.2509])\n",
      "miserable\n",
      "Saved the embedding for miserable.\n",
      "['misery'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6647,  0.1911,  0.5229,  ..., -0.2263, -0.5292,  0.8913])\n",
      "misery\n",
      "Saved the embedding for misery.\n",
      "['mis', '##giving'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0318,  0.3089, -0.0250,  ..., -0.3217,  0.3044,  0.8404])\n",
      "misgiving\n",
      "Saved the embedding for misgiving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mis', '##lea', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3478,  0.3054, -0.4359,  ..., -0.4106, -0.4373,  0.2348])\n",
      "mislead\n",
      "Saved the embedding for mislead.\n",
      "['mist', '##rus', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2375,  0.3757,  0.4033,  ..., -0.3974, -0.5730,  0.9491])\n",
      "mistrust\n",
      "Saved the embedding for mistrust.\n",
      "['mist', '##rus', '##tf', '##ul'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3653,  0.7298, -0.0356,  ..., -0.6777, -0.0251,  0.7922])\n",
      "mistrustful\n",
      "Saved the embedding for mistrustful.\n",
      "['mist', '##rus', '##ting'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0753,  0.7083, -0.0655,  ..., -0.6579, -0.6440,  0.9092])\n",
      "mistrusting\n",
      "Saved the embedding for mistrusting.\n",
      "['misunderstood'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0750, -0.7763,  0.1219,  ..., -0.5461, -0.3382,  0.9891])\n",
      "misunderstood\n",
      "Saved the embedding for misunderstood.\n",
      "['mock', '##ery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0230,  0.6504, -0.0837,  ..., -1.1558, -0.9774,  0.8114])\n",
      "mockery\n",
      "Saved the embedding for mockery.\n",
      "['mocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2868, -0.3657,  0.3225,  ..., -0.7229, -0.8829,  1.0618])\n",
      "mocking\n",
      "Saved the embedding for mocking.\n",
      "['mocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1762,  0.1893,  0.5872,  ..., -0.8406, -1.1876,  0.7093])\n",
      "mockingly\n",
      "Saved the embedding for mockingly.\n",
      "['modest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1793,  0.2778,  0.2066,  ..., -1.0746, -0.1520,  0.4129])\n",
      "modest\n",
      "Saved the embedding for modest.\n",
      "['mono', '##tone'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3241,  0.2721,  0.3313,  ..., -0.3309,  0.0311,  1.0368])\n",
      "monotone\n",
      "Saved the embedding for monotone.\n",
      "['monster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1222, -0.0785,  0.2288,  ..., -0.1031, -0.4422, -0.0448])\n",
      "monster\n",
      "Saved the embedding for monster.\n",
      "['moody'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3363,  0.4291,  0.5203,  ..., -0.6775,  0.0111, -0.1443])\n",
      "moody\n",
      "Saved the embedding for moody.\n",
      "['mo', '##pe', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0435, -0.2130,  0.9506,  ..., -0.3895, -0.6726,  0.4722])\n",
      "mopey\n",
      "Saved the embedding for mopey.\n",
      "['mor', '##ose'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0661,  0.0784,  0.2776,  ...,  0.0197, -0.2097,  1.1514])\n",
      "morose\n",
      "Saved the embedding for morose.\n",
      "['mort', '##ified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4339,  0.1278, -0.0769,  ..., -0.9043, -0.4581,  0.4346])\n",
      "mortified\n",
      "Saved the embedding for mortified.\n",
      "['motivated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0284,  0.4095, -0.6655,  ...,  0.0827, -0.3014,  0.8278])\n",
      "motivated\n",
      "Saved the embedding for motivated.\n",
      "['mo', '##urn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1706, -0.1793,  0.4735,  ..., -0.3811, -0.5905,  0.2748])\n",
      "mournful\n",
      "Saved the embedding for mournful.\n",
      "['mo', '##urn', '##fulness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4026, -0.3605,  0.5902,  ..., -0.3448, -0.2994,  0.8289])\n",
      "mournfulness\n",
      "Saved the embedding for mournfulness.\n",
      "['mourning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4689,  0.5441, -0.0243,  ...,  0.0929, -0.0090,  0.4267])\n",
      "mourning\n",
      "Saved the embedding for mourning.\n",
      "['mouthed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3487,  0.9281, -0.3418,  ..., -0.5776,  0.0798,  1.3881])\n",
      "mouthed\n",
      "Saved the embedding for mouthed.\n",
      "['moved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0175,  0.1754, -1.0888,  ..., -0.5062, -0.5570,  0.5690])\n",
      "moved\n",
      "Saved the embedding for moved.\n",
      "['mud', '##dled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3484,  0.0720,  0.0635,  ..., -1.2733, -0.7395,  0.9806])\n",
      "muddled\n",
      "Saved the embedding for muddled.\n",
      "['mum'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0368,  0.1434,  0.2488,  ..., -0.6369,  0.1599,  0.6049])\n",
      "mum\n",
      "Saved the embedding for mum.\n",
      "['murderous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6508, -0.3939, -0.5872,  ..., -0.7647, -0.3247, -0.1459])\n",
      "murderous\n",
      "Saved the embedding for murderous.\n",
      "['musical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4853, -0.2402, -0.1521,  ..., -1.4050,  0.0830,  0.5727])\n",
      "musical\n",
      "Saved the embedding for musical.\n",
      "['mu', '##sing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3248,  0.3132,  0.2998,  ..., -0.5605, -1.5009,  0.4169])\n",
      "musing\n",
      "Saved the embedding for musing.\n",
      "['muster'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1791,  0.2488,  0.6304,  ..., -0.4324, -0.8094,  0.9992])\n",
      "muster\n",
      "Saved the embedding for muster.\n",
      "['mute'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5254,  0.3931,  0.1272,  ..., -0.3070,  0.3836,  1.0448])\n",
      "mute\n",
      "Saved the embedding for mute.\n",
      "['muted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8283,  0.4465,  0.2288,  ...,  0.2066, -0.3462,  0.5063])\n",
      "muted\n",
      "Saved the embedding for muted.\n",
      "['muttering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2455,  0.1216, -0.1229,  ..., -0.3390, -0.4074,  0.3978])\n",
      "muttering\n",
      "Saved the embedding for muttering.\n",
      "['mysterious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1393,  0.4078,  0.5127,  ..., -1.1846, -0.1425,  1.1081])\n",
      "mysterious\n",
      "Saved the embedding for mysterious.\n",
      "['mystical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1726,  0.1822, -0.0670,  ..., -0.7922,  0.0549,  0.3789])\n",
      "mystical\n",
      "Saved the embedding for mystical.\n",
      "['my', '##sti', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1595,  0.4726,  0.0338,  ..., -1.2741, -0.7951,  0.1386])\n",
      "mystified\n",
      "Saved the embedding for mystified.\n",
      "['naive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7732,  0.1864, -0.6326,  ..., -0.5770,  0.1991,  0.3551])\n",
      "naive\n",
      "Saved the embedding for naive.\n",
      "['nap', '##ping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1780,  0.1845,  0.0972,  ..., -1.0353, -1.1090,  0.8742])\n",
      "napping\n",
      "Saved the embedding for napping.\n",
      "['narrow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2113, -0.2856, -0.4654,  ..., -0.3293, -0.3214,  0.3011])\n",
      "narrow\n",
      "Saved the embedding for narrow.\n",
      "['nasty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0216,  0.1776, -0.1459,  ..., -0.3142, -0.5514,  0.9292])\n",
      "nasty\n",
      "Saved the embedding for nasty.\n",
      "['natural'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8947,  0.5370,  0.4666,  ..., -0.5432, -0.2861,  1.6389])\n",
      "natural\n",
      "Saved the embedding for natural.\n",
      "['nature', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5770,  0.5538, -0.3248,  ..., -1.8660,  0.3406,  1.1328])\n",
      "natured\n",
      "Saved the embedding for natured.\n",
      "['naughty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4001,  0.1489,  0.6800,  ..., -0.6379,  0.2345,  0.2611])\n",
      "naughty\n",
      "Saved the embedding for naughty.\n",
      "['nausea'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7349,  0.3975, -0.1687,  ..., -1.0526, -1.0510,  1.1111])\n",
      "nausea\n",
      "Saved the embedding for nausea.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nausea', '##ted'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8126,  0.4214, -0.1264,  ..., -1.0022, -1.1475,  0.9848])\n",
      "nauseated\n",
      "Saved the embedding for nauseated.\n",
      "['na', '##use', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0077,  0.2344, -0.1280,  ..., -0.8803, -0.6440,  0.3850])\n",
      "nauseous\n",
      "Saved the embedding for nauseous.\n",
      "['needy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8328, -0.0691, -0.2046,  ..., -0.9413, -0.3995,  0.9043])\n",
      "needy\n",
      "Saved the embedding for needy.\n",
      "['ne', '##far', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0091,  0.1223, -0.2366,  ..., -1.4451, -0.0436, -0.0766])\n",
      "nefarious\n",
      "Saved the embedding for nefarious.\n",
      "['ne', '##gating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0636,  0.5150, -0.3440,  ..., -1.2718,  0.0495,  1.0054])\n",
      "negating\n",
      "Saved the embedding for negating.\n",
      "['negative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2002,  0.0632, -0.6762,  ..., -0.0761, -0.3616,  0.7726])\n",
      "negative\n",
      "Saved the embedding for negative.\n",
      "['ne', '##gat', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2042,  0.3330, -0.1428,  ..., -0.7256, -0.1042,  0.0361])\n",
      "negativity\n",
      "Saved the embedding for negativity.\n",
      "['neglected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1439,  0.6976,  0.0675,  ..., -0.0718, -0.0745,  1.4435])\n",
      "neglected\n",
      "Saved the embedding for neglected.\n",
      "['ne', '##rdy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0909, -0.3727, -0.1535,  ..., -0.9029, -0.6269,  0.3242])\n",
      "nerdy\n",
      "Saved the embedding for nerdy.\n",
      "['nerve', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1521,  0.0427,  0.4555,  ..., -0.9654, -1.6743,  0.8509])\n",
      "nerved\n",
      "Saved the embedding for nerved.\n",
      "['nerves'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0433, -0.2468,  0.4813,  ..., -0.1331, -0.3095,  0.1342])\n",
      "nerves\n",
      "Saved the embedding for nerves.\n",
      "['nervous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4053, -0.1059,  0.4565,  ..., -0.5031, -0.5898,  0.5491])\n",
      "nervous\n",
      "Saved the embedding for nervous.\n",
      "['nervously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0468, -0.3809, -0.4832,  ..., -0.6218,  0.7794, -0.2650])\n",
      "nervously\n",
      "Saved the embedding for nervously.\n",
      "['nervous', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0386,  0.6053, -0.1201,  ..., -0.9179, -1.4280,  0.7421])\n",
      "nervousness\n",
      "Saved the embedding for nervousness.\n",
      "['nes', '##cie', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2590, -0.7703,  0.4585,  ..., -0.8206,  0.1146,  0.3291])\n",
      "nescient\n",
      "Saved the embedding for nescient.\n",
      "['net', '##tled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0648, -0.2680,  0.0551,  ..., -0.6369,  0.0317,  1.2904])\n",
      "nettled\n",
      "Saved the embedding for nettled.\n",
      "['neutral'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1116,  0.2464, -0.3199,  ..., -0.2895, -0.5629,  0.7788])\n",
      "neutral\n",
      "Saved the embedding for neutral.\n",
      "['neutrality'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1255,  0.0756,  0.0375,  ..., -0.2815,  0.0622,  0.9073])\n",
      "neutrality\n",
      "Saved the embedding for neutrality.\n",
      "['nice'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1526, -0.0160, -1.1578,  ..., -0.0777, -0.9157,  1.5768])\n",
      "nice\n",
      "Saved the embedding for nice.\n",
      "['noisy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3076,  0.4431,  0.5149,  ..., -0.4187,  0.3564,  0.9945])\n",
      "noisy\n",
      "Saved the embedding for noisy.\n",
      "['non', '##bel', '##ie', '##f'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2684, -0.6203, -0.4164,  ..., -1.1907, -1.0917,  0.8727])\n",
      "nonbelief\n",
      "Saved the embedding for nonbelief.\n",
      "['non', '##chal', '##ance'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4053,  0.0444,  0.2093,  ..., -0.9505, -0.2446,  1.0005])\n",
      "nonchalance\n",
      "Saved the embedding for nonchalance.\n",
      "['non', '##chal', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2471, -0.0443,  0.0227,  ..., -1.5312, -0.0886,  0.7418])\n",
      "nonchalant\n",
      "Saved the embedding for nonchalant.\n",
      "['non', '##com', '##mit', '##tal'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1435,  0.4859, -0.0382,  ..., -1.0829, -0.5427,  0.1079])\n",
      "noncommittal\n",
      "Saved the embedding for noncommittal.\n",
      "['non', '##com', '##pl', '##ian', '##t'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0900, -0.2693,  0.3283,  ..., -0.5353, -0.7545,  0.9017])\n",
      "noncompliant\n",
      "Saved the embedding for noncompliant.\n",
      "['non', '##pl', '##uss', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3312, -0.7253,  0.2978,  ..., -0.6595, -0.5185,  0.8334])\n",
      "nonplussed\n",
      "Saved the embedding for nonplussed.\n",
      "['non', '##sen', '##sic', '##al'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4911,  0.4993, -0.1912,  ..., -1.0335, -0.0529,  0.3424])\n",
      "nonsensical\n",
      "Saved the embedding for nonsensical.\n",
      "['normal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1380, -0.4613, -0.7668,  ..., -0.0183, -0.2711,  0.5322])\n",
      "normal\n",
      "Saved the embedding for normal.\n",
      "['nose', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4188,  0.0675, -0.3065,  ..., -0.2411, -1.0716,  1.0210])\n",
      "nosey\n",
      "Saved the embedding for nosey.\n",
      "['nos', '##tal', '##gic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1682,  0.2544,  0.2027,  ..., -0.2087, -0.3372,  0.9377])\n",
      "nostalgic\n",
      "Saved the embedding for nostalgic.\n",
      "['nos', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5682,  0.5736, -0.0675,  ..., -0.6393, -0.9556,  0.8296])\n",
      "nosy\n",
      "Saved the embedding for nosy.\n",
      "['numb'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3799,  0.6341, -0.1591,  ..., -0.9386, -0.5304,  0.6776])\n",
      "numb\n",
      "Saved the embedding for numb.\n",
      "['obe', '##die', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2803,  1.4409, -0.0933,  ..., -0.9770, -0.4560, -0.0914])\n",
      "obedient\n",
      "Saved the embedding for obedient.\n",
      "['object', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5229,  0.3683, -0.0177,  ..., -0.7496, -0.2037,  1.1587])\n",
      "objecting\n",
      "Saved the embedding for objecting.\n",
      "['objection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8526,  0.4128,  0.1452,  ..., -0.5630, -0.2670,  1.0092])\n",
      "objection\n",
      "Saved the embedding for objection.\n",
      "['objective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5170, -0.0050, -0.3461,  ..., -0.4458, -0.3663,  0.6779])\n",
      "objective\n",
      "Saved the embedding for objective.\n",
      "['obliged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4602,  0.0103,  0.0088,  ..., -0.6090, -0.6757, -0.4091])\n",
      "obliged\n",
      "Saved the embedding for obliged.\n",
      "['ob', '##li', '##ging'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0250,  0.1486, -0.1190,  ..., -0.9270, -1.0946,  0.3672])\n",
      "obliging\n",
      "Saved the embedding for obliging.\n",
      "['oblivious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4785,  0.0187, -0.3773,  ..., -0.3501, -0.5396,  0.4994])\n",
      "oblivious\n",
      "Saved the embedding for oblivious.\n",
      "['ob', '##ser', '##vant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4309,  0.0465,  0.6827,  ..., -0.4336, -0.3794,  0.1209])\n",
      "observant\n",
      "Saved the embedding for observant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['observing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3263,  0.4065, -0.1258,  ...,  0.3603,  0.7308,  1.2928])\n",
      "observing\n",
      "Saved the embedding for observing.\n",
      "['obsessed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8598, -0.0546, -0.8522,  ..., -0.1498,  0.1870,  0.3922])\n",
      "obsessed\n",
      "Saved the embedding for obsessed.\n",
      "['ob', '##sti', '##nate'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3175,  0.2508,  0.8939,  ..., -1.1821, -0.8580,  0.4210])\n",
      "obstinate\n",
      "Saved the embedding for obstinate.\n",
      "['occupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0343,  0.5047, -0.0849,  ..., -0.4386, -0.8039,  0.7781])\n",
      "occupied\n",
      "Saved the embedding for occupied.\n",
      "['odd'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-4.3839e-01,  1.5015e-01,  8.2503e-01,  ..., -1.4842e-04,\n",
      "         2.4503e-01,  1.2160e+00])\n",
      "odd\n",
      "Saved the embedding for odd.\n",
      "['odi', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0404, -0.3734,  0.3571,  ..., -1.1893,  0.0231, -0.1618])\n",
      "odious\n",
      "Saved the embedding for odious.\n",
      "['off'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4436,  0.1391,  0.3173,  ...,  0.0054, -0.5868,  0.2134])\n",
      "off\n",
      "Saved the embedding for off.\n",
      "['offended'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5337,  0.1905,  0.3935,  ..., -0.1223, -0.7030,  1.2335])\n",
      "offended\n",
      "Saved the embedding for offended.\n",
      "['offensive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5190, -0.5083, -0.5528,  ..., -0.3905, -0.8281,  0.6002])\n",
      "offensive\n",
      "Saved the embedding for offensive.\n",
      "['og', '##ling'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1618,  0.7098,  0.3524,  ..., -0.4873, -0.6648,  0.6838])\n",
      "ogling\n",
      "Saved the embedding for ogling.\n",
      "['okay'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5301,  0.1391, -0.0426,  ..., -1.0903, -0.8185,  1.1780])\n",
      "okay\n",
      "Saved the embedding for okay.\n",
      "['on'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7490, -0.1762, -0.0100,  ...,  0.0713, -0.5369,  0.1752])\n",
      "on\n",
      "Saved the embedding for on.\n",
      "['open'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0741,  0.1489, -0.1719,  ..., -1.2322, -0.9820,  0.9162])\n",
      "open\n",
      "Saved the embedding for open.\n",
      "['open', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3434,  0.2511,  0.3518,  ..., -1.3793, -0.1974,  0.8967])\n",
      "openness\n",
      "Saved the embedding for openness.\n",
      "['opposed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1493,  0.0608, -0.3875,  ..., -0.6700,  0.0669,  0.5255])\n",
      "opposed\n",
      "Saved the embedding for opposed.\n",
      "['opposition', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2515,  0.6064,  0.4728,  ..., -0.0382, -1.2907,  0.5415])\n",
      "oppositional\n",
      "Saved the embedding for oppositional.\n",
      "['op', '##pressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3671,  0.5771,  0.5211,  ...,  0.6782,  0.5945,  0.9767])\n",
      "oppressed\n",
      "Saved the embedding for oppressed.\n",
      "['optimism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1212,  0.0731, -0.7406,  ..., -1.1585, -0.2479,  0.3583])\n",
      "optimism\n",
      "Saved the embedding for optimism.\n",
      "['optimistic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3691,  0.0242, -0.8073,  ..., -1.5385,  0.1313,  0.3865])\n",
      "optimistic\n",
      "Saved the embedding for optimistic.\n",
      "['ordering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0579, 0.2605, 0.9552,  ..., 0.0510, 0.4534, 0.6201])\n",
      "ordering\n",
      "Saved the embedding for ordering.\n",
      "['orgasm', '##ic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0264,  0.5103, -1.0991,  ..., -1.8433, -0.4497, -0.0598])\n",
      "orgasmic\n",
      "Saved the embedding for orgasmic.\n",
      "['or', '##nery'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6768,  0.7119,  0.4945,  ..., -1.3616, -0.2335,  0.1152])\n",
      "ornery\n",
      "Saved the embedding for ornery.\n",
      "['ou', '##ch'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9560,  0.1142,  0.0839,  ..., -0.1432, -0.2625,  0.9333])\n",
      "ouch\n",
      "Saved the embedding for ouch.\n",
      "['out'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0308,  0.2151,  0.5184,  ..., -0.7659,  0.0407,  0.5732])\n",
      "out\n",
      "Saved the embedding for out.\n",
      "['outburst'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7304,  0.2898,  0.7159,  ..., -0.4833, -0.5590,  0.9316])\n",
      "outburst\n",
      "Saved the embedding for outburst.\n",
      "['out', '##cr', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1112, -0.1160,  0.4360,  ..., -1.2008, -0.6224,  0.1270])\n",
      "outcry\n",
      "Saved the embedding for outcry.\n",
      "['out', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0690, -0.0988,  0.4150,  ..., -0.6193,  0.3738,  0.2270])\n",
      "outed\n",
      "Saved the embedding for outed.\n",
      "['out', '##land', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4147, -0.6162,  0.1900,  ..., -0.5324,  0.1783,  0.6340])\n",
      "outlandish\n",
      "Saved the embedding for outlandish.\n",
      "['outrage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3783,  0.1300, -0.7769,  ..., -0.4286, -0.5661,  0.2542])\n",
      "outrage\n",
      "Saved the embedding for outrage.\n",
      "['outraged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2529,  0.5498,  0.1460,  ..., -0.5423, -0.2416,  0.4369])\n",
      "outraged\n",
      "Saved the embedding for outraged.\n",
      "['outspoken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3189, -0.2027, -0.2376,  ..., -0.2820, -0.0265, -0.0766])\n",
      "outspoken\n",
      "Saved the embedding for outspoken.\n",
      "['over', '##be', '##aring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3695, -0.4641, -0.0844,  ..., -1.2321, -0.8033,  0.5754])\n",
      "overbearing\n",
      "Saved the embedding for overbearing.\n",
      "['over', '##ex', '##cite', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1742,  0.1363,  0.1263,  ..., -0.5214, -0.7269,  0.1696])\n",
      "overexcited\n",
      "Saved the embedding for overexcited.\n",
      "['over', '##joy', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1713,  0.3307, -0.3469,  ..., -0.9302,  0.0380,  0.7710])\n",
      "overjoyed\n",
      "Saved the embedding for overjoyed.\n",
      "['overshadowed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3815, -0.9963, -0.4072,  ..., -1.2918,  0.3237, -0.6528])\n",
      "overshadowed\n",
      "Saved the embedding for overshadowed.\n",
      "['overs', '##tr', '##ung'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3293, -0.8177, -0.6875,  ..., -0.9969, -0.9174, -0.6419])\n",
      "overstrung\n",
      "Saved the embedding for overstrung.\n",
      "['overwhelmed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3214, -0.1512,  0.2429,  ..., -0.6375, -0.6367,  0.1622])\n",
      "overwhelmed\n",
      "Saved the embedding for overwhelmed.\n",
      "['over', '##work', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0976,  0.1983, -0.2723,  ..., -0.8949, -0.4751,  0.1405])\n",
      "overworked\n",
      "Saved the embedding for overworked.\n",
      "['over', '##wr', '##ough', '##t'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3620, -0.2358, -0.1491,  ..., -1.1779, -0.4881,  0.5298])\n",
      "overwrought\n",
      "Saved the embedding for overwrought.\n",
      "['pain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0086,  0.3985, -0.1384,  ..., -1.4043,  0.2751, -0.2888])\n",
      "pain\n",
      "Saved the embedding for pain.\n",
      "['pained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7551,  0.3566, -0.3466,  ..., -1.1913,  0.0793,  0.1663])\n",
      "pained\n",
      "Saved the embedding for pained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['painful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4837, -0.1695, -0.0178,  ...,  0.2457, -0.1137,  0.5469])\n",
      "painful\n",
      "Saved the embedding for painful.\n",
      "['painfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4579,  0.0618, -0.9598,  ..., -0.8497,  0.2327, -0.0384])\n",
      "painfully\n",
      "Saved the embedding for painfully.\n",
      "['panic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2360,  0.3185,  0.5303,  ..., -0.6194, -0.4005,  0.9618])\n",
      "panic\n",
      "Saved the embedding for panic.\n",
      "['panicked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2622, -0.1153, -0.2336,  ..., -0.6881, -0.1797,  0.4474])\n",
      "panicked\n",
      "Saved the embedding for panicked.\n",
      "['panic', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2257, -0.0790,  0.0373,  ..., -1.1440, -0.9711,  1.1754])\n",
      "panicky\n",
      "Saved the embedding for panicky.\n",
      "['paralyzed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5489, -0.1462,  0.0589,  ..., -0.0297, -0.7166,  0.0533])\n",
      "paralyzed\n",
      "Saved the embedding for paralyzed.\n",
      "['paranoid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3998,  0.2549,  0.4647,  ..., -0.0737, -0.8191,  0.7369])\n",
      "paranoid\n",
      "Saved the embedding for paranoid.\n",
      "['passionate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4040,  0.0302, -0.1935,  ..., -0.7041, -0.6928,  1.0550])\n",
      "passionate\n",
      "Saved the embedding for passionate.\n",
      "['passive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7550, -0.4697, -0.3026,  ..., -0.6931, -0.8325,  0.5234])\n",
      "passive\n",
      "Saved the embedding for passive.\n",
      "['patience'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.6286, -0.0333,  0.4033,  ..., -0.1074, -0.7878,  0.8407])\n",
      "patience\n",
      "Saved the embedding for patience.\n",
      "['patient'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3488,  0.8841,  0.1664,  ..., -1.1122,  0.0202,  0.7231])\n",
      "patient\n",
      "Saved the embedding for patient.\n",
      "['patron', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1257,  1.1417,  0.4818,  ...,  0.5348, -0.2478,  0.6348])\n",
      "patronizing\n",
      "Saved the embedding for patronizing.\n",
      "['pause'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0364, -0.0692, -0.2157,  ..., -0.9759, -0.6326,  0.3983])\n",
      "pause\n",
      "Saved the embedding for pause.\n",
      "['pausing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1647,  0.2694,  0.6276,  ..., -0.9472, -0.6291,  0.0542])\n",
      "pausing\n",
      "Saved the embedding for pausing.\n",
      "['peaceful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6678, -0.6867,  1.0433,  ..., -0.2150, -0.8478,  1.1827])\n",
      "peaceful\n",
      "Saved the embedding for peaceful.\n",
      "['peculiar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4721, -0.2142, -0.8161,  ..., -0.5886, -0.2280,  0.8594])\n",
      "peculiar\n",
      "Saved the embedding for peculiar.\n",
      "['peering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8567, -0.4751, -0.1490,  ..., -1.2832,  0.1166,  0.4242])\n",
      "peering\n",
      "Saved the embedding for peering.\n",
      "['pee', '##ved'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5510, -0.0834, -0.7761,  ..., -0.7228, -0.0883,  0.5100])\n",
      "peeved\n",
      "Saved the embedding for peeved.\n",
      "['pee', '##vish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2879,  0.1296,  0.0272,  ..., -1.2659, -0.0204,  0.8903])\n",
      "peevish\n",
      "Saved the embedding for peevish.\n",
      "['pens', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3064,  0.1797,  0.6084,  ..., -0.0234, -0.5401,  0.9253])\n",
      "pensive\n",
      "Saved the embedding for pensive.\n",
      "['pep', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6820, -0.0989,  0.8712,  ..., -0.9653, -0.6308, -0.0352])\n",
      "peppy\n",
      "Saved the embedding for peppy.\n",
      "['per', '##ceptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0046,  0.5607, -0.0225,  ..., -0.2235, -0.8722,  0.8234])\n",
      "perceptive\n",
      "Saved the embedding for perceptive.\n",
      "['per', '##fi', '##dio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3407,  0.0265,  0.3631,  ..., -0.2650, -0.4919, -0.0248])\n",
      "perfidious\n",
      "Saved the embedding for perfidious.\n",
      "['per', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1725,  0.0007,  0.3662,  ..., -0.0487, -0.3836,  0.4878])\n",
      "perky\n",
      "Saved the embedding for perky.\n",
      "['per', '##plex', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3096,  0.3527,  0.5574,  ..., -0.3690, -0.2222,  0.8580])\n",
      "perplexed\n",
      "Saved the embedding for perplexed.\n",
      "['per', '##plex', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2388,  0.5172,  0.2558,  ..., -0.5121, -0.2569,  1.1196])\n",
      "perplexing\n",
      "Saved the embedding for perplexing.\n",
      "['persistent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4239, -0.1806,  0.0992,  ..., -0.8921, -0.6982,  0.2995])\n",
      "persistent\n",
      "Saved the embedding for persistent.\n",
      "['persona', '##ble'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0750,  0.0145,  0.5182,  ..., -0.5128, -0.6271,  0.3047])\n",
      "personable\n",
      "Saved the embedding for personable.\n",
      "['per', '##tur', '##bed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3625,  0.1223,  0.5432,  ..., -0.1879, -0.2856,  0.8720])\n",
      "perturbed\n",
      "Saved the embedding for perturbed.\n",
      "['per', '##verse'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2789,  0.0534,  0.5266,  ..., -0.9554, -0.6107,  0.6683])\n",
      "perverse\n",
      "Saved the embedding for perverse.\n",
      "['pe', '##sky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3435,  0.3660,  0.5384,  ..., -0.5259, -0.9348,  0.4414])\n",
      "pesky\n",
      "Saved the embedding for pesky.\n",
      "['pe', '##ssi', '##mism'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0784, -0.4010, -0.7909,  ..., -1.0897, -0.3749,  0.3129])\n",
      "pessimism\n",
      "Saved the embedding for pessimism.\n",
      "['pe', '##ssi', '##mist', '##ic'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.4824,  0.2174, -0.0852,  ..., -0.4930,  0.0086,  0.5754])\n",
      "pessimistic\n",
      "Saved the embedding for pessimistic.\n",
      "['pest', '##ered'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2128,  0.2737, -0.1591,  ..., -0.9936, -0.5050,  0.4982])\n",
      "pestered\n",
      "Saved the embedding for pestered.\n",
      "['petition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2012,  0.3366,  0.3879,  ..., -0.7408,  0.2942,  0.3871])\n",
      "petitioning\n",
      "Saved the embedding for petitioning.\n",
      "['pet', '##rified'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2194, -0.1492,  0.2829,  ..., -0.2123, -0.3118,  0.0262])\n",
      "petrified\n",
      "Saved the embedding for petrified.\n",
      "['petty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2342,  0.3417, -0.5033,  ..., -0.2103, -0.8836,  0.5971])\n",
      "petty\n",
      "Saved the embedding for petty.\n",
      "['pet', '##ula', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1489, -0.3485, -0.0561,  ..., -0.7455,  0.0792,  0.2613])\n",
      "petulant\n",
      "Saved the embedding for petulant.\n",
      "['picked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3081,  0.1068,  0.3683,  ...,  0.0132, -0.1807,  0.6845])\n",
      "picked\n",
      "Saved the embedding for picked.\n",
      "['piercing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0436, -0.0516, -0.3797,  ..., -0.3207, -0.8731,  0.9915])\n",
      "piercing\n",
      "Saved the embedding for piercing.\n",
      "['pinched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2379,  0.0453, -0.3503,  ...,  0.0375, -0.1100,  0.5956])\n",
      "pinched\n",
      "Saved the embedding for pinched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3112, -0.0655, -0.0640,  ..., -0.2799, -0.2690,  0.9496])\n",
      "pious\n",
      "Saved the embedding for pious.\n",
      "['pi', '##que', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1132, -0.1045,  0.6886,  ..., -0.8137, -0.4007,  1.0927])\n",
      "piqued\n",
      "Saved the embedding for piqued.\n",
      "['pissed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1945,  0.8221,  0.7383,  ..., -0.6379, -1.0105,  1.0869])\n",
      "pissed\n",
      "Saved the embedding for pissed.\n",
      "['pit', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0063, -0.0503, -0.4476,  ..., -0.9968, -0.4127,  0.0182])\n",
      "pitiable\n",
      "Saved the embedding for pitiable.\n",
      "['pit', '##iful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3846, -0.3973,  0.6675,  ..., -0.3502,  0.3726,  0.6205])\n",
      "pitiful\n",
      "Saved the embedding for pitiful.\n",
      "['pity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2051,  0.4010,  0.3652,  ...,  0.2013, -0.6426,  0.1819])\n",
      "pity\n",
      "Saved the embedding for pity.\n",
      "['pity', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2753,  0.7287,  0.4366,  ..., -0.3839, -0.9937,  0.4593])\n",
      "pitying\n",
      "Saved the embedding for pitying.\n",
      "['pl', '##aca', '##ted'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2762, -0.5344,  0.8406,  ..., -0.8670,  0.0458,  0.5592])\n",
      "placated\n",
      "Saved the embedding for placated.\n",
      "['pl', '##aca', '##tion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2008, -0.2002,  0.6526,  ..., -0.4042,  0.3105,  0.6218])\n",
      "placation\n",
      "Saved the embedding for placation.\n",
      "['pl', '##ac', '##id'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3911,  0.0387,  0.3127,  ..., -1.0620,  0.0092,  0.8855])\n",
      "placid\n",
      "Saved the embedding for placid.\n",
      "['plain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2415, -0.3506, -0.5421,  ..., -0.1217, -0.5294, -0.3117])\n",
      "plain\n",
      "Saved the embedding for plain.\n",
      "['plain', '##tive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0727, -0.1794, -0.5916,  ..., -1.4528, -1.1320, -0.4977])\n",
      "plaintive\n",
      "Saved the embedding for plaintive.\n",
      "['planning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6411, -0.0816,  0.5129,  ..., -1.2240, -0.4011,  0.3237])\n",
      "planning\n",
      "Saved the embedding for planning.\n",
      "['playful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2820, -0.0517, -0.1534,  ..., -0.5977,  0.8175,  0.2374])\n",
      "playful\n",
      "Saved the embedding for playful.\n",
      "['playfully'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4811,  0.6567,  0.2170,  ..., -1.5326, -0.1152, -0.2358])\n",
      "playfully\n",
      "Saved the embedding for playfully.\n",
      "['pleading'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1027,  0.3451,  0.4513,  ..., -0.2819,  0.0040,  0.5095])\n",
      "pleading\n",
      "Saved the embedding for pleading.\n",
      "['pleasant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6549, -0.4314, -0.1889,  ..., -0.3289, -0.1058,  0.4133])\n",
      "pleasant\n",
      "Saved the embedding for pleasant.\n",
      "['pleased'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2720,  0.3268, -0.2399,  ...,  0.2480, -0.2556,  0.9848])\n",
      "pleased\n",
      "Saved the embedding for pleased.\n",
      "['pleasing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2244,  0.6442,  0.0256,  ..., -0.6870, -0.3903,  0.7192])\n",
      "pleasing\n",
      "Saved the embedding for pleasing.\n",
      "['pleas', '##urable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3492,  0.6252,  0.3098,  ..., -1.1207,  0.8606,  0.1864])\n",
      "pleasurable\n",
      "Saved the embedding for pleasurable.\n",
      "['pleasure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0802,  0.2955,  0.0148,  ..., -0.6154,  0.6754,  0.6788])\n",
      "pleasure\n",
      "Saved the embedding for pleasure.\n",
      "['pleasure', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4678,  0.3230,  0.2779,  ..., -0.8492,  0.7079,  0.5422])\n",
      "pleasured\n",
      "Saved the embedding for pleasured.\n",
      "['pl', '##ian', '##t'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1045,  0.0351,  0.3381,  ..., -0.8888,  0.0092,  0.6059])\n",
      "pliant\n",
      "Saved the embedding for pliant.\n",
      "['plotting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4382,  0.0734, -0.9793,  ..., -0.5605,  0.4192,  0.1063])\n",
      "plotting\n",
      "Saved the embedding for plotting.\n",
      "['po', '##ignant'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0590, -0.1735,  0.2328,  ..., -1.3487, -0.8058,  0.6225])\n",
      "poignant\n",
      "Saved the embedding for poignant.\n",
      "['pointed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4892, -0.0829,  0.4364,  ..., -0.4038, -0.5119,  0.8992])\n",
      "pointed\n",
      "Saved the embedding for pointed.\n",
      "['poised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2006,  0.0466, -0.1699,  ...,  0.1357, -1.3981,  0.6173])\n",
      "poised\n",
      "Saved the embedding for poised.\n",
      "['polite'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5933,  0.6981,  0.8365,  ..., -0.6622, -0.2545,  0.6709])\n",
      "polite\n",
      "Saved the embedding for polite.\n",
      "['po', '##mp', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2575, -0.3011,  0.4189,  ..., -1.5287, -0.7684,  1.0420])\n",
      "pompous\n",
      "Saved the embedding for pompous.\n",
      "['ponder'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4346,  0.3333,  0.6005,  ..., -0.9297, -1.0110,  1.2433])\n",
      "ponder\n",
      "Saved the embedding for ponder.\n",
      "['ponder', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3509,  0.9184,  0.7150,  ..., -0.9379, -0.7963,  1.1741])\n",
      "pondering\n",
      "Saved the embedding for pondering.\n",
      "['po', '##oping'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2310, -0.7256,  0.1444,  ..., -1.3870, -1.2232,  0.2517])\n",
      "pooping\n",
      "Saved the embedding for pooping.\n",
      "['pop'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4000,  0.0687, -0.3738,  ..., -0.4982,  0.5820,  0.4656])\n",
      "pop\n",
      "Saved the embedding for pop.\n",
      "['posing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1511,  0.2154,  0.1456,  ..., -0.7369,  0.0895,  0.7035])\n",
      "posing\n",
      "Saved the embedding for posing.\n",
      "['positive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0278,  0.1046, -0.1286,  ..., -1.1171, -0.6131,  1.0291])\n",
      "positive\n",
      "Saved the embedding for positive.\n",
      "['po', '##sit', '##ivity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0031, -0.1756,  0.2449,  ..., -1.6473, -0.7216,  0.9770])\n",
      "positivity\n",
      "Saved the embedding for positivity.\n",
      "['possibly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7265, -0.0742, -0.0905,  ..., -1.3037, -0.8679,  0.4453])\n",
      "possibly\n",
      "Saved the embedding for possibly.\n",
      "['po', '##ut'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5707,  0.2480,  0.1819,  ..., -1.4470, -1.0163,  1.3350])\n",
      "pout\n",
      "Saved the embedding for pout.\n",
      "['po', '##uting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0546,  0.4042,  0.8412,  ..., -1.5572, -1.0009,  1.1581])\n",
      "pouting\n",
      "Saved the embedding for pouting.\n",
      "['po', '##ut', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4405, -0.1087,  0.6216,  ..., -1.2401, -1.3469,  0.9104])\n",
      "pouty\n",
      "Saved the embedding for pouty.\n",
      "['powerful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1169, -0.3513, -0.6562,  ..., -0.2329, -0.3687,  1.0890])\n",
      "powerful\n",
      "Saved the embedding for powerful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['powerless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3880, -0.1413,  0.3404,  ..., -0.3945, -0.9578,  0.6648])\n",
      "powerless\n",
      "Saved the embedding for powerless.\n",
      "['prank', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1221, -0.4078, -0.1814,  ..., -0.9495, -0.5797,  0.9363])\n",
      "pranking\n",
      "Saved the embedding for pranking.\n",
      "['pre', '##car', '##ious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4595,  0.1721,  0.3028,  ..., -0.8718, -1.1526,  0.5751])\n",
      "precarious\n",
      "Saved the embedding for precarious.\n",
      "['predatory'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0850,  0.3452,  0.5681,  ...,  0.3829, -0.3548,  0.6912])\n",
      "predatory\n",
      "Saved the embedding for predatory.\n",
      "['prejudice', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2074,  0.1951,  0.0572,  ..., -0.1890, -0.7716,  0.7223])\n",
      "prejudiced\n",
      "Saved the embedding for prejudiced.\n",
      "['preoccupied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1263, -0.0499,  0.0733,  ...,  0.0165, -0.0879,  0.4257])\n",
      "preoccupied\n",
      "Saved the embedding for preoccupied.\n",
      "['prepared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5351,  0.5208, -0.3008,  ..., -0.4211, -1.2306,  0.7728])\n",
      "prepared\n",
      "Saved the embedding for prepared.\n",
      "['preparing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3372,  0.3047, -0.0019,  ..., -0.0863, -0.2475,  0.6527])\n",
      "preparing\n",
      "Saved the embedding for preparing.\n",
      "['pretending'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0287, -0.3595, -0.8572,  ...,  0.6418, -0.3835,  0.8888])\n",
      "pretending\n",
      "Saved the embedding for pretending.\n",
      "['pre', '##ten', '##tious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5453,  0.0413, -0.2316,  ..., -0.8288, -0.6383,  0.1758])\n",
      "pretentious\n",
      "Saved the embedding for pretentious.\n",
      "['pride', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4597,  0.5830, -0.2044,  ..., -0.5313, -1.0784,  1.0387])\n",
      "prideful\n",
      "Saved the embedding for prideful.\n",
      "['pri', '##gg', '##ish'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3577, -0.1482,  0.3435,  ..., -0.2132,  0.0693,  1.1151])\n",
      "priggish\n",
      "Saved the embedding for priggish.\n",
      "['prime', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([4.9637e-01, 3.4926e-01, 9.6673e-01,  ..., 8.3145e-02, 7.2042e-05,\n",
      "        1.1497e+00])\n",
      "primed\n",
      "Saved the embedding for primed.\n",
      "['private'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8682, -0.2178,  0.5720,  ..., -0.2844, -0.2255,  0.9488])\n",
      "private\n",
      "Saved the embedding for private.\n",
      "['processing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2540,  0.3554,  0.2051,  ...,  0.1424,  0.2097,  1.0895])\n",
      "processing\n",
      "Saved the embedding for processing.\n",
      "['proposition', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3561,  0.3528,  0.6649,  ..., -0.3772, -0.4925,  1.2083])\n",
      "propositioning\n",
      "Saved the embedding for propositioning.\n",
      "['proud'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2924, -0.0314, -0.9771,  ..., -0.2208, -0.7429,  0.1399])\n",
      "proud\n",
      "Saved the embedding for proud.\n",
      "['provocative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3383,  0.6865, -0.8871,  ..., -0.6686, -0.3164, -0.2606])\n",
      "provocative\n",
      "Saved the embedding for provocative.\n",
      "['provoke'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1916,  0.3286, -0.8354,  ..., -0.3479, -0.4987,  0.5461])\n",
      "provoke\n",
      "Saved the embedding for provoke.\n",
      "['provoked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5164, -0.0863, -0.0056,  ..., -0.0151, -0.3294,  0.0327])\n",
      "provoked\n",
      "Saved the embedding for provoked.\n",
      "['pro', '##voking'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4226,  0.2369, -0.3020,  ..., -0.1858,  0.0732, -0.0234])\n",
      "provoking\n",
      "Saved the embedding for provoking.\n",
      "['pry', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1155,  0.2854, -0.2951,  ..., -0.9559, -0.6426,  0.4589])\n",
      "prying\n",
      "Saved the embedding for prying.\n",
      "['psycho'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0501, -0.5451,  0.6020,  ..., -0.4422, -0.0981,  0.6065])\n",
      "psycho\n",
      "Saved the embedding for psycho.\n",
      "['psychotic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0643, -0.7064,  0.1353,  ..., -1.3302,  0.1610, -1.0010])\n",
      "psychotic\n",
      "Saved the embedding for psychotic.\n",
      "['puck', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3539,  0.2869, -0.2817,  ..., -0.7927, -0.7760,  0.8876])\n",
      "puckish\n",
      "Saved the embedding for puckish.\n",
      "['pu', '##eri', '##le'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0821,  0.0692,  0.1408,  ..., -1.7397, -0.6732,  0.5632])\n",
      "puerile\n",
      "Saved the embedding for puerile.\n",
      "['pu', '##gna', '##cious'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2051, -0.0451,  0.3247,  ..., -1.5441, -0.4907,  0.6674])\n",
      "pugnacious\n",
      "Saved the embedding for pugnacious.\n",
      "['punished'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9649, -0.4331, -0.4218,  ..., -0.0078,  0.4180,  0.6268])\n",
      "punished\n",
      "Saved the embedding for punished.\n",
      "['punish', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7864, -0.0288, -0.3607,  ..., -0.9728, -0.6832,  1.1054])\n",
      "punishing\n",
      "Saved the embedding for punishing.\n",
      "['pun', '##itive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1801,  0.1531, -0.1860,  ..., -1.1838, -1.6302,  0.3515])\n",
      "punitive\n",
      "Saved the embedding for punitive.\n",
      "['punk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0181,  0.1393, -0.6276,  ...,  0.1520, -0.1133,  0.4083])\n",
      "punk\n",
      "Saved the embedding for punk.\n",
      "['puppy', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2216, -0.6831, -0.5109,  ..., -0.0174, -0.6674,  0.9750])\n",
      "puppyish\n",
      "Saved the embedding for puppyish.\n",
      "['purpose', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2221,  0.1585,  0.1723,  ...,  0.0998, -0.2296,  0.8434])\n",
      "purposeful\n",
      "Saved the embedding for purposeful.\n",
      "['pursed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5163,  0.1740,  0.6300,  ..., -1.1995, -0.4867,  0.6356])\n",
      "pursed\n",
      "Saved the embedding for pursed.\n",
      "['put'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0828,  0.1877, -0.1476,  ...,  0.0385,  0.0708,  0.9088])\n",
      "put\n",
      "Saved the embedding for put.\n",
      "['putting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0203,  0.4609,  0.2631,  ...,  0.4736, -0.5635,  0.7320])\n",
      "putting\n",
      "Saved the embedding for putting.\n",
      "['puzzled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2225,  0.3039,  0.2525,  ...,  0.3977, -0.3399,  0.9480])\n",
      "puzzled\n",
      "Saved the embedding for puzzled.\n",
      "['puzzle', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2486, -0.0472,  0.0228,  ..., -0.7094,  0.3829,  0.5434])\n",
      "puzzlement\n",
      "Saved the embedding for puzzlement.\n",
      "['qu', '##al', '##ms'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3246,  0.3761,  0.8043,  ...,  0.5264, -0.2764,  0.6151])\n",
      "qualms\n",
      "Saved the embedding for qualms.\n",
      "['quarrel', '##some'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3102,  0.3927,  0.1445,  ..., -0.3973, -0.2233,  0.3710])\n",
      "quarrelsome\n",
      "Saved the embedding for quarrelsome.\n",
      "['que', '##as', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1216,  0.2355,  0.1370,  ..., -0.4121, -0.5792,  0.5536])\n",
      "queasy\n",
      "Saved the embedding for queasy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['que', '##nched'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2592, -0.5355, -0.1215,  ..., -0.2272, -0.4280,  0.7057])\n",
      "quenched\n",
      "Saved the embedding for quenched.\n",
      "['questionable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7483,  0.7424, -0.3579,  ..., -0.8061, -0.6547,  0.3991])\n",
      "questionable\n",
      "Saved the embedding for questionable.\n",
      "['questioning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2302,  0.5811, -0.8111,  ..., -1.2668,  0.0973, -0.1375])\n",
      "questioning\n",
      "Saved the embedding for questioning.\n",
      "['questioning', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0182,  0.4103,  0.2639,  ..., -0.5783, -0.3167,  0.4856])\n",
      "questioningly\n",
      "Saved the embedding for questioningly.\n",
      "['quiet'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1685, -0.2009, -0.2039,  ..., -0.1685,  0.6079,  0.5533])\n",
      "quiet\n",
      "Saved the embedding for quiet.\n",
      "['quiet', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5707, -0.5211, -0.0935,  ..., -0.2309,  0.6962,  0.7626])\n",
      "quietness\n",
      "Saved the embedding for quietness.\n",
      "['quilt'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1295,  0.9150,  0.0685,  ..., -0.3687, -0.2652,  0.6179])\n",
      "quilt\n",
      "Saved the embedding for quilt.\n",
      "['qui', '##rky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2422, -0.6755, -0.0724,  ..., -0.9067, -0.3156,  0.8264])\n",
      "quirky\n",
      "Saved the embedding for quirky.\n",
      "['quiz', '##zic', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3320, -0.1684, -0.2562,  ..., -0.2749, -0.3515, -0.1290])\n",
      "quizzical\n",
      "Saved the embedding for quizzical.\n",
      "['ra', '##bid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8633,  0.0702, -0.0740,  ..., -0.8131, -0.9314,  0.6070])\n",
      "rabid\n",
      "Saved the embedding for rabid.\n",
      "['rack', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0324, -0.1869,  0.6778,  ..., -0.6261, -0.0602, -0.0324])\n",
      "racked\n",
      "Saved the embedding for racked.\n",
      "['radiant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5767,  0.3814,  0.3752,  ..., -0.0196, -0.0412,  1.1010])\n",
      "radiant\n",
      "Saved the embedding for radiant.\n",
      "['rage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1237,  0.2125, -0.3368,  ..., -0.5464, -0.4679,  0.9168])\n",
      "rage\n",
      "Saved the embedding for rage.\n",
      "['raged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0372, -0.1699, -0.5444,  ..., -0.8815, -0.3425,  0.5092])\n",
      "raged\n",
      "Saved the embedding for raged.\n",
      "['ragged'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2629,  0.6089, -0.8091,  ..., -0.6734, -0.5693,  0.8982])\n",
      "ragged\n",
      "Saved the embedding for ragged.\n",
      "['raging'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0293,  0.0965, -0.5648,  ..., -1.2673,  0.5351, -0.0349])\n",
      "raging\n",
      "Saved the embedding for raging.\n",
      "['ran', '##cor', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3373,  0.4476, -0.3141,  ..., -1.2982,  0.1595,  0.5796])\n",
      "rancorous\n",
      "Saved the embedding for rancorous.\n",
      "['randy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4167,  0.5756, -0.3825,  ..., -0.7746, -0.2632,  1.0633])\n",
      "randy\n",
      "Saved the embedding for randy.\n",
      "['rap', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2044,  0.5871,  0.1860,  ...,  0.1878, -0.3209,  1.1610])\n",
      "rapt\n",
      "Saved the embedding for rapt.\n",
      "['rattled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0460, -0.3095, -0.4486,  ..., -1.7464, -0.3649,  0.0461])\n",
      "rattled\n",
      "Saved the embedding for rattled.\n",
      "['ravi', '##ng'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0838, -0.3368, -0.2129,  ..., -0.2183,  0.1769,  0.7104])\n",
      "raving\n",
      "Saved the embedding for raving.\n",
      "['reactive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6942, -0.2664, -0.4362,  ..., -1.1557, -0.6219,  0.9048])\n",
      "reactive\n",
      "Saved the embedding for reactive.\n",
      "['ready'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5951,  0.3695, -0.2187,  ...,  0.0749, -0.4385,  0.9276])\n",
      "ready\n",
      "Saved the embedding for ready.\n",
      "['realization'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9328,  0.1668, -0.2427,  ..., -1.0262,  0.0445,  0.6802])\n",
      "realization\n",
      "Saved the embedding for realization.\n",
      "['reassured'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1228,  0.5811,  0.8031,  ..., -0.0044, -0.1385,  1.1638])\n",
      "reassured\n",
      "Saved the embedding for reassured.\n",
      "['rebellious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1962, -0.0130, -0.0767,  ..., -0.3023, -0.5433,  0.6316])\n",
      "rebellious\n",
      "Saved the embedding for rebellious.\n",
      "['re', '##bu', '##ke'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3320, -0.7311,  0.2116,  ..., -0.9479, -0.3774,  0.0348])\n",
      "rebuke\n",
      "Saved the embedding for rebuke.\n",
      "['recalling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5480,  0.7215,  1.0500,  ..., -0.4003, -0.4111,  0.4784])\n",
      "recalling\n",
      "Saved the embedding for recalling.\n",
      "['rec', '##eptive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1008,  0.2883,  0.1387,  ..., -0.5015,  0.0462,  0.1116])\n",
      "receptive\n",
      "Saved the embedding for receptive.\n",
      "['reckless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1099, -0.0082,  0.6751,  ..., -0.6036, -0.9385,  0.3843])\n",
      "reckless\n",
      "Saved the embedding for reckless.\n",
      "['recoil'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0167,  0.6383, -0.5423,  ..., -0.1794, -0.2464,  0.6758])\n",
      "recoil\n",
      "Saved the embedding for recoil.\n",
      "['recoil', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7591,  1.1783, -0.1656,  ..., -1.3679, -0.2345, -0.5565])\n",
      "recoiling\n",
      "Saved the embedding for recoiling.\n",
      "['reflecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1929,  0.0600,  0.1370,  ..., -0.5200, -0.0044,  1.0651])\n",
      "reflecting\n",
      "Saved the embedding for reflecting.\n",
      "['reflection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4263, -0.3768,  0.1141,  ..., -0.9730,  0.1761,  0.8396])\n",
      "reflection\n",
      "Saved the embedding for reflection.\n",
      "['reflective'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6469, -0.4550, -0.6735,  ..., -0.3185, -0.4453,  0.6089])\n",
      "reflective\n",
      "Saved the embedding for reflective.\n",
      "['ref', '##ul', '##gent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4219, -0.0701,  0.3867,  ..., -1.6584, -0.6440,  0.5205])\n",
      "refulgent\n",
      "Saved the embedding for refulgent.\n",
      "['refusing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1976,  0.2947,  0.1646,  ..., -0.6131, -0.7200,  0.5778])\n",
      "refusing\n",
      "Saved the embedding for refusing.\n",
      "['regret'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1457,  0.1443, -0.1824,  ..., -0.8300,  0.2803, -0.1248])\n",
      "regret\n",
      "Saved the embedding for regret.\n",
      "['regret', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4990,  0.2141, -0.2544,  ..., -0.6310,  0.1006,  0.0991])\n",
      "regretful\n",
      "Saved the embedding for regretful.\n",
      "['rejected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1704,  0.0544,  0.3250,  ..., -1.5626, -1.2523, -0.0718])\n",
      "rejected\n",
      "Saved the embedding for rejected.\n",
      "['rejecting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5839,  0.3829,  0.2762,  ..., -0.9545, -0.8541,  0.4336])\n",
      "rejecting\n",
      "Saved the embedding for rejecting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rejection'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6658, -0.2614, -0.1085,  ...,  0.0263, -0.7778,  0.4756])\n",
      "rejection\n",
      "Saved the embedding for rejection.\n",
      "['re', '##jo', '##icing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2852, -0.4755,  0.5381,  ..., -0.8061, -0.1296,  0.4822])\n",
      "rejoicing\n",
      "Saved the embedding for rejoicing.\n",
      "['relaxation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1237,  0.0303, -0.3955,  ..., -0.2279,  0.1820,  1.2975])\n",
      "relaxation\n",
      "Saved the embedding for relaxation.\n",
      "['relaxed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3671,  0.0751,  0.8969,  ..., -0.6867,  0.2165,  0.7741])\n",
      "relaxed\n",
      "Saved the embedding for relaxed.\n",
      "['relentless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0059, -0.2149,  0.1908,  ..., -1.0624, -0.0298,  0.3763])\n",
      "relentless\n",
      "Saved the embedding for relentless.\n",
      "['relief'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0432, -0.0743, -0.0684,  ..., -0.0476, -0.6181,  0.8344])\n",
      "relief\n",
      "Saved the embedding for relief.\n",
      "['relieved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0051,  0.8868, -0.0303,  ...,  0.2482, -0.9077,  0.2082])\n",
      "relieved\n",
      "Saved the embedding for relieved.\n",
      "['re', '##li', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.5997,  0.2081,  0.3005,  ..., -0.7964,  0.0781, -0.0354])\n",
      "relived\n",
      "Saved the embedding for relived.\n",
      "['reluctant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1763, -0.0954, -0.0560,  ..., -0.5006,  0.0091,  0.2587])\n",
      "reluctant\n",
      "Saved the embedding for reluctant.\n",
      "['reluctantly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1711,  0.9731,  0.5593,  ..., -0.4560, -0.6176,  0.9872])\n",
      "reluctantly\n",
      "Saved the embedding for reluctantly.\n",
      "['remorse'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7328,  0.3064, -0.6103,  ...,  0.2445, -0.9714,  0.4117])\n",
      "remorse\n",
      "Saved the embedding for remorse.\n",
      "['remorse', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1104,  0.6748, -0.5857,  ..., -0.6039, -0.4574,  0.2911])\n",
      "remorseful\n",
      "Saved the embedding for remorseful.\n",
      "['rep', '##elled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6159, -0.0201,  0.5711,  ..., -0.8282, -0.4032, -0.1071])\n",
      "repelled\n",
      "Saved the embedding for repelled.\n",
      "['rep', '##ressed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0070, -0.2567,  0.3810,  ..., -0.5505,  0.1771,  0.4695])\n",
      "repressed\n",
      "Saved the embedding for repressed.\n",
      "['rep', '##ro', '##ach'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2066,  0.4934, -0.2404,  ..., -0.6129, -0.2538, -0.0489])\n",
      "reproach\n",
      "Saved the embedding for reproach.\n",
      "['rep', '##ro', '##ach', '##ful'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0174,  0.3480,  0.3330,  ..., -1.1542, -0.7286,  0.0071])\n",
      "reproachful\n",
      "Saved the embedding for reproachful.\n",
      "['rep', '##ug', '##nan', '##ce'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3383, -0.1198,  0.3035,  ..., -1.0258, -0.2634,  0.7078])\n",
      "repugnance\n",
      "Saved the embedding for repugnance.\n",
      "['rep', '##ug', '##nant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3506,  0.2919, -0.3392,  ..., -0.8290, -0.7748,  1.1576])\n",
      "repugnant\n",
      "Saved the embedding for repugnant.\n",
      "['repulsed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0071,  1.0229, -0.1459,  ...,  1.2115, -0.2861,  0.6868])\n",
      "repulsed\n",
      "Saved the embedding for repulsed.\n",
      "['rep', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0897,  0.0465,  0.2033,  ..., -1.5288, -0.5991,  0.3852])\n",
      "repulsion\n",
      "Saved the embedding for repulsion.\n",
      "['res', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3636,  0.7591, -0.1547,  ..., -1.1765, -0.2696,  0.9673])\n",
      "resent\n",
      "Saved the embedding for resent.\n",
      "['res', '##ent', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6183,  0.5391,  0.0406,  ..., -1.2994, -0.9546,  0.5446])\n",
      "resentful\n",
      "Saved the embedding for resentful.\n",
      "['res', '##enting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2536,  0.7241,  0.6244,  ..., -0.6120, -1.1682,  0.3365])\n",
      "resenting\n",
      "Saved the embedding for resenting.\n",
      "['resentment'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3398,  0.0695,  0.4956,  ...,  0.3499, -0.5462,  0.4447])\n",
      "resentment\n",
      "Saved the embedding for resentment.\n",
      "['reserved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0062, -0.3628, -0.5891,  ..., -0.5948, -0.3940,  0.5591])\n",
      "reserved\n",
      "Saved the embedding for reserved.\n",
      "['resignation'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3613, -0.0463,  0.0823,  ..., -0.0871, -1.0974,  0.4974])\n",
      "resignation\n",
      "Saved the embedding for resignation.\n",
      "['resigned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2276,  0.6541,  0.5594,  ...,  0.4478, -0.6720,  1.0545])\n",
      "resigned\n",
      "Saved the embedding for resigned.\n",
      "['res', '##ili', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3759,  0.3704,  0.2468,  ..., -0.8354, -0.3829,  0.6558])\n",
      "resilience\n",
      "Saved the embedding for resilience.\n",
      "['resistance'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2698, -0.1203,  0.0319,  ..., -1.3113, -0.0366,  0.2639])\n",
      "resistance\n",
      "Saved the embedding for resistance.\n",
      "['resistant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0432, -0.2860,  0.0236,  ..., -0.7922, -0.0274,  0.0759])\n",
      "resistant\n",
      "Saved the embedding for resistant.\n",
      "['resist', '##ent'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1919,  0.3370, -0.6870,  ..., -0.4940, -0.8929,  0.6490])\n",
      "resistent\n",
      "Saved the embedding for resistent.\n",
      "['resisting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4760, -0.5893, -0.0624,  ..., -0.0129, -0.3515,  0.8018])\n",
      "resisting\n",
      "Saved the embedding for resisting.\n",
      "['res', '##ol', '##ute'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([0.4543, 0.1766, 0.4300,  ..., 0.2535, 0.1935, 0.3644])\n",
      "resolute\n",
      "Saved the embedding for resolute.\n",
      "['resolved'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1117, -0.1273, -0.4926,  ..., -1.2829, -0.0417,  0.0644])\n",
      "resolved\n",
      "Saved the embedding for resolved.\n",
      "['responsive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3138,  0.5928, -0.2215,  ..., -0.3492, -0.1476,  0.4119])\n",
      "responsive\n",
      "Saved the embedding for responsive.\n",
      "['rest', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4070, -0.3451,  0.4125,  ..., -1.3761, -0.1329,  0.5074])\n",
      "restful\n",
      "Saved the embedding for restful.\n",
      "['resting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2063, -0.0634, -0.0978,  ..., -0.2503, -0.7760,  0.2848])\n",
      "resting\n",
      "Saved the embedding for resting.\n",
      "['restless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3320, -0.0211,  0.3534,  ..., -0.1890, -0.5281,  0.8108])\n",
      "restless\n",
      "Saved the embedding for restless.\n",
      "['restless', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0908,  0.2124,  0.0934,  ..., -1.1142, -1.1566,  1.1044])\n",
      "restlessness\n",
      "Saved the embedding for restlessness.\n",
      "['restrained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4576,  0.5030,  0.9229,  ...,  0.5631, -0.6521, -0.3244])\n",
      "restrained\n",
      "Saved the embedding for restrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['restraint'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2845e-01, -1.3622e-03, -3.8630e-01,  ..., -3.8296e-01,\n",
      "        -3.1033e-01,  1.5070e+00])\n",
      "restraint\n",
      "Saved the embedding for restraint.\n",
      "['re', '##tal', '##iating'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.6978,  0.4095,  0.0281,  ..., -1.0275, -0.7776, -0.1419])\n",
      "retaliating\n",
      "Saved the embedding for retaliating.\n",
      "['re', '##tal', '##ia', '##tory'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.6530, -0.0824,  0.0300,  ..., -1.1571, -0.1955,  0.3832])\n",
      "retaliatory\n",
      "Saved the embedding for retaliatory.\n",
      "['re', '##thi', '##nk', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2617, -0.1998,  0.2523,  ..., -0.7790, -0.1311,  0.1328])\n",
      "rethinking\n",
      "Saved the embedding for rethinking.\n",
      "['re', '##tic', '##ence'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 1.0281, -0.0459,  0.6877,  ..., -1.2934,  0.0774,  0.1766])\n",
      "reticence\n",
      "Saved the embedding for reticence.\n",
      "['re', '##tic', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8602,  0.3184,  0.3463,  ..., -0.9888, -0.4917,  0.3327])\n",
      "reticent\n",
      "Saved the embedding for reticent.\n",
      "['revenge', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1589,  0.3291,  0.3338,  ..., -0.9625, -0.6741,  1.1851])\n",
      "revengeful\n",
      "Saved the embedding for revengeful.\n",
      "['rev', '##ere', '##nt'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1095,  0.0868,  0.4444,  ..., -0.4061,  0.0623,  0.7095])\n",
      "reverent\n",
      "Saved the embedding for reverent.\n",
      "['revolt', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4100, -0.0304,  0.0443,  ..., -0.7701, -0.7137,  0.5148])\n",
      "revolted\n",
      "Saved the embedding for revolted.\n",
      "['rev', '##ulsion'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1425,  0.2701,  0.4939,  ..., -0.3032,  0.0565,  0.8434])\n",
      "revulsion\n",
      "Saved the embedding for revulsion.\n",
      "['righteous'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0422, -0.0581,  0.2939,  ...,  0.2181, -0.0548,  0.7786])\n",
      "righteous\n",
      "Saved the embedding for righteous.\n",
      "['rigid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3813, -0.1768, -0.5405,  ...,  0.2871, -0.7398,  1.4835])\n",
      "rigid\n",
      "Saved the embedding for rigid.\n",
      "['ri', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5730,  0.0498,  0.0615,  ..., -0.8645, -0.9995,  1.0669])\n",
      "riled\n",
      "Saved the embedding for riled.\n",
      "['riot', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3563,  0.3559,  0.1972,  ..., -1.0047, -0.3467,  0.7303])\n",
      "riotous\n",
      "Saved the embedding for riotous.\n",
      "['ri', '##vet', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6931,  0.2174, -0.8011,  ..., -0.8371, -0.7646,  0.2549])\n",
      "riveted\n",
      "Saved the embedding for riveted.\n",
      "['roar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6444, -0.5632, -0.4928,  ..., -1.4561, -0.2217,  0.4332])\n",
      "roar\n",
      "Saved the embedding for roar.\n",
      "['ro', '##gui', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0250, -0.6912, -0.0835,  ..., -1.5697, -0.3401,  0.6369])\n",
      "roguish\n",
      "Saved the embedding for roguish.\n",
      "['roi', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4123,  0.1041,  0.4251,  ..., -0.9733, -0.1162,  0.7528])\n",
      "roiled\n",
      "Saved the embedding for roiled.\n",
      "['rough'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6678, -0.1512, -0.0492,  ..., -0.3321, -0.1160,  1.0572])\n",
      "rough\n",
      "Saved the embedding for rough.\n",
      "['rouse', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0264,  0.1968,  0.5621,  ..., -1.0323,  0.1320, -0.2658])\n",
      "roused\n",
      "Saved the embedding for roused.\n",
      "['rude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5588,  0.2979, -0.2538,  ..., -0.3808, -0.7752,  1.0451])\n",
      "rude\n",
      "Saved the embedding for rude.\n",
      "['rue', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1973, -0.1290, -0.3974,  ..., -0.8228,  0.1890, -0.7914])\n",
      "rueful\n",
      "Saved the embedding for rueful.\n",
      "['ru', '##ffled'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3014, -0.0733, -0.2696,  ..., -0.9708, -0.6952,  0.0131])\n",
      "ruffled\n",
      "Saved the embedding for ruffled.\n",
      "['rum', '##inating'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1441,  0.1834,  0.3760,  ..., -0.6757, -0.5825,  0.4626])\n",
      "ruminating\n",
      "Saved the embedding for ruminating.\n",
      "['rust', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2388,  0.8251, -0.4453,  ..., -1.0301, -0.7202, -0.0492])\n",
      "rustled\n",
      "Saved the embedding for rustled.\n",
      "['ruthless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5571,  0.1863, -0.2796,  ..., -0.4353,  0.4255,  0.5436])\n",
      "ruthless\n",
      "Saved the embedding for ruthless.\n",
      "['sad'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5092,  0.1675,  0.0095,  ..., -1.4620,  0.2778,  0.5178])\n",
      "sad\n",
      "Saved the embedding for sad.\n",
      "['sad', '##den'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0541,  0.2450,  0.1688,  ..., -1.1303,  0.2984,  0.7389])\n",
      "sadden\n",
      "Saved the embedding for sadden.\n",
      "['sad', '##dened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7857,  0.3754,  0.1544,  ..., -0.4435, -0.7501,  0.3162])\n",
      "saddened\n",
      "Saved the embedding for saddened.\n",
      "['sad', '##istic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3571,  0.0332,  0.4045,  ..., -0.8697, -0.0216,  0.5633])\n",
      "sadistic\n",
      "Saved the embedding for sadistic.\n",
      "['sadness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1799, -0.0259,  0.5225,  ...,  0.4762, -0.2212,  0.0630])\n",
      "sadness\n",
      "Saved the embedding for sadness.\n",
      "['sal', '##acious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5993,  0.3305, -0.0960,  ..., -1.5336, -1.1673,  0.8713])\n",
      "salacious\n",
      "Saved the embedding for salacious.\n",
      "['saliva', '##ting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1262,  0.6674,  0.4738,  ..., -1.7896, -1.4677,  0.5253])\n",
      "salivating\n",
      "Saved the embedding for salivating.\n",
      "['san', '##ct', '##imo', '##nio', '##us'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.3166,  0.2898,  0.3611,  ...,  0.0883, -0.2366,  0.2555])\n",
      "sanctimonious\n",
      "Saved the embedding for sanctimonious.\n",
      "['sane'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6783,  0.0955, -0.1172,  ..., -0.1781, -1.0115,  0.1593])\n",
      "sane\n",
      "Saved the embedding for sane.\n",
      "['sang', '##uin', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1142,  0.5426, -0.2571,  ..., -0.2189,  0.2761,  1.0474])\n",
      "sanguine\n",
      "Saved the embedding for sanguine.\n",
      "['sap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.8129,  0.1055, -1.1929,  ..., -0.7683, -0.4954,  0.4230])\n",
      "sappy\n",
      "Saved the embedding for sappy.\n",
      "['sarcasm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0631, -0.3278,  0.3096,  ..., -0.0527, -0.9225,  0.5313])\n",
      "sarcasm\n",
      "Saved the embedding for sarcasm.\n",
      "['sarcastic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0646,  0.2385, -0.5275,  ..., -0.1070, -0.8683,  0.5467])\n",
      "sarcastic\n",
      "Saved the embedding for sarcastic.\n",
      "['sar', '##don', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6372,  0.2018,  0.5296,  ..., -0.8774, -0.4540,  0.3728])\n",
      "sardonic\n",
      "Saved the embedding for sardonic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sas', '##sy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5027,  0.0080,  0.1293,  ..., -0.5751, -0.3217,  0.3794])\n",
      "sassy\n",
      "Saved the embedding for sassy.\n",
      "['sat', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1860, -0.0608,  0.4885,  ..., -1.3793, -0.9776,  0.2635])\n",
      "sated\n",
      "Saved the embedding for sated.\n",
      "['sat', '##iated'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0477,  0.5557,  0.3092,  ..., -1.1325, -0.3338, -0.0930])\n",
      "satiated\n",
      "Saved the embedding for satiated.\n",
      "['satirical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2411, -0.8612,  0.1332,  ..., -0.8219,  0.9260, -0.5804])\n",
      "satirical\n",
      "Saved the embedding for satirical.\n",
      "['satisfaction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4113, -0.0323,  0.2604,  ..., -0.4468,  0.2512, -0.1128])\n",
      "satisfaction\n",
      "Saved the embedding for satisfaction.\n",
      "['satisfied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3674,  0.0735,  0.4529,  ..., -0.4228, -0.4939,  1.9898])\n",
      "satisfied\n",
      "Saved the embedding for satisfied.\n",
      "['satisfy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1668,  0.4793,  0.8347,  ..., -0.8832, -0.1992,  1.2820])\n",
      "satisfy\n",
      "Saved the embedding for satisfy.\n",
      "['saturn', '##ine'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7939,  0.5455,  0.4225,  ...,  0.4604,  1.3874,  0.2019])\n",
      "saturnine\n",
      "Saved the embedding for saturnine.\n",
      "['sa', '##uc', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4657, -0.3604, -0.2456,  ..., -0.9562, -0.4694,  0.5370])\n",
      "saucy\n",
      "Saved the embedding for saucy.\n",
      "['savage'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2616,  0.0909,  0.5060,  ..., -1.3503, -0.1752, -0.0290])\n",
      "savage\n",
      "Saved the embedding for savage.\n",
      "['scandal', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3431,  0.5744,  0.3039,  ..., -0.7700, -0.4299,  0.4355])\n",
      "scandalized\n",
      "Saved the embedding for scandalized.\n",
      "['scare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0543,  0.1279, -0.1981,  ..., -0.6844, -0.7952,  0.4529])\n",
      "scare\n",
      "Saved the embedding for scare.\n",
      "['scared'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1951, -0.2740, -0.1381,  ..., -0.4129, -0.6717,  1.1048])\n",
      "scared\n",
      "Saved the embedding for scared.\n",
      "['scary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2281,  0.7979,  0.9094,  ..., -0.6619,  0.2802,  0.8551])\n",
      "scary\n",
      "Saved the embedding for scary.\n",
      "['scattered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3631,  0.1509,  0.1793,  ..., -0.3446,  0.7323, -0.1302])\n",
      "scattered\n",
      "Saved the embedding for scattered.\n",
      "['sc', '##had', '##en', '##fr', '##eu', '##de'] has a token embedding of size torch.Size([6, 12, 768])\n",
      "Shape is: 6 x 3072\n",
      "tensor([ 0.1118, -0.3663,  0.0296,  ..., -0.3942, -0.3333,  0.8106])\n",
      "schadenfreude\n",
      "Saved the embedding for schadenfreude.\n",
      "['sc', '##hem', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3516, -0.0419,  0.3813,  ..., -0.2900, -0.2284,  1.1398])\n",
      "scheming\n",
      "Saved the embedding for scheming.\n",
      "['sc', '##off', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5350, -0.4931,  0.1173,  ..., -0.1000, -0.2718,  0.6591])\n",
      "scoffer\n",
      "Saved the embedding for scoffer.\n",
      "['sc', '##off', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2744, -0.3336,  0.3798,  ..., -0.5721, -0.6739,  0.7583])\n",
      "scoffing\n",
      "Saved the embedding for scoffing.\n",
      "['sc', '##orn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4895, -0.1743,  0.2320,  ..., -0.1681, -0.5276,  0.8991])\n",
      "scorn\n",
      "Saved the embedding for scorn.\n",
      "['sc', '##orne', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3842, -0.0095,  0.3247,  ..., -0.5935, -0.6584,  0.4000])\n",
      "scorned\n",
      "Saved the embedding for scorned.\n",
      "['sc', '##orn', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6215, -0.2707, -0.1259,  ..., -1.0082, -1.0861,  0.6884])\n",
      "scornful\n",
      "Saved the embedding for scornful.\n",
      "['scowl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4795,  0.5378, -0.6641,  ..., -1.0471, -0.2459, -0.0128])\n",
      "scowl\n",
      "Saved the embedding for scowl.\n",
      "['scowl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4213,  0.3614, -0.1340,  ..., -0.6341, -0.2496,  0.1285])\n",
      "scowling\n",
      "Saved the embedding for scowling.\n",
      "['scream'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2490,  0.0958,  0.4229,  ..., -0.2622,  0.0690,  0.5315])\n",
      "scream\n",
      "Saved the embedding for scream.\n",
      "['screaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4618,  0.2895, -0.6417,  ..., -0.6686, -0.4267, -0.0062])\n",
      "screaming\n",
      "Saved the embedding for screaming.\n",
      "['sc', '##rut', '##ini', '##zing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.2971, -0.2023,  0.1732,  ..., -0.9313, -0.3010,  0.7984])\n",
      "scrutinizing\n",
      "Saved the embedding for scrutinizing.\n",
      "['sealed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3785,  0.4030, -0.0697,  ..., -0.5882, -0.3053, -0.1166])\n",
      "sealed\n",
      "Saved the embedding for sealed.\n",
      "['searching'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9674,  0.3643,  0.3681,  ..., -1.3105,  0.0495,  1.6073])\n",
      "searching\n",
      "Saved the embedding for searching.\n",
      "['secretive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2381,  0.1270, -0.3428,  ..., -0.5191, -0.7737,  0.6595])\n",
      "secretive\n",
      "Saved the embedding for secretive.\n",
      "['secretive', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2655,  0.8272,  0.4247,  ..., -0.4761, -0.9990,  1.2049])\n",
      "secretively\n",
      "Saved the embedding for secretively.\n",
      "['secure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1135,  0.2659,  0.3365,  ..., -0.3016, -0.2547,  0.3813])\n",
      "secure\n",
      "Saved the embedding for secure.\n",
      "['se', '##date'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5115,  0.3514,  0.2093,  ..., -0.8136, -0.8137,  0.7335])\n",
      "sedate\n",
      "Saved the embedding for sedate.\n",
      "['seduction'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2909, -0.0134, -0.2836,  ..., -0.4388,  0.3064,  0.0615])\n",
      "seduction\n",
      "Saved the embedding for seduction.\n",
      "['seductive'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3468,  0.1666, -0.2300,  ..., -1.0294, -0.3502,  0.1422])\n",
      "seductive\n",
      "Saved the embedding for seductive.\n",
      "['see', '##thing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4125,  0.0172, -0.2551,  ..., -1.4527, -0.8762,  0.0760])\n",
      "seething\n",
      "Saved the embedding for seething.\n",
      "['self'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2953, -0.0265,  0.2527,  ..., -0.4219, -0.4358,  0.1699])\n",
      "self\n",
      "Saved the embedding for self.\n",
      "['sensual'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2204,  0.0906, -0.4942,  ..., -0.1135,  0.2202,  0.6805])\n",
      "sensual\n",
      "Saved the embedding for sensual.\n",
      "['sentimental'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5046, -0.2790, -0.0271,  ..., -0.8570, -0.7415,  0.6987])\n",
      "sentimental\n",
      "Saved the embedding for sentimental.\n",
      "['serene'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.2425,  0.0646, -0.3029,  ..., -0.7609, -0.3255,  0.5679])\n",
      "serene\n",
      "Saved the embedding for serene.\n",
      "['serious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0233,  0.0643,  0.4648,  ..., -0.5936, -0.7019,  0.9048])\n",
      "serious\n",
      "Saved the embedding for serious.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seriousness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0174,  0.4382, -0.3134,  ..., -1.3854,  0.0078,  0.9109])\n",
      "seriousness\n",
      "Saved the embedding for seriousness.\n",
      "['ser', '##vil', '##e'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2733, -0.1113,  0.3387,  ..., -0.1339,  0.3114,  0.2793])\n",
      "servile\n",
      "Saved the embedding for servile.\n",
      "['set'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5269, -0.0413,  0.1660,  ...,  0.2931, -0.0346,  0.1625])\n",
      "set\n",
      "Saved the embedding for set.\n",
      "['severe'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7693, -0.2709, -0.4075,  ..., -0.1528, -0.3123,  0.4482])\n",
      "severe\n",
      "Saved the embedding for severe.\n",
      "['sha', '##bby'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2621, -0.1788, -0.2191,  ..., -0.4177, -0.4560,  0.4112])\n",
      "shabby\n",
      "Saved the embedding for shabby.\n",
      "['shady'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1433,  0.4287, -0.0665,  ..., -0.4130,  0.4169,  0.1846])\n",
      "shady\n",
      "Saved the embedding for shady.\n",
      "['shaken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0034, -0.2051, -0.4355,  ..., -1.0068, -0.4357,  0.5211])\n",
      "shaken\n",
      "Saved the embedding for shaken.\n",
      "['shaky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4645,  0.0097,  0.0195,  ..., -0.4441, -0.8650,  0.2844])\n",
      "shaky\n",
      "Saved the embedding for shaky.\n",
      "['shame'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5874, -0.2389, -0.1692,  ..., -0.2093, -0.1315,  0.7188])\n",
      "shame\n",
      "Saved the embedding for shame.\n",
      "['shame', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6740,  0.1306,  0.3895,  ..., -0.4141, -0.4977,  0.8283])\n",
      "shamed\n",
      "Saved the embedding for shamed.\n",
      "['shame', '##face', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1347,  0.3606,  0.0885,  ..., -0.9210, -0.7441,  0.5625])\n",
      "shamefaced\n",
      "Saved the embedding for shamefaced.\n",
      "['shame', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7007,  0.4364, -0.6252,  ..., -0.4105, -0.5166,  1.0026])\n",
      "shameful\n",
      "Saved the embedding for shameful.\n",
      "['shame', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2731,  0.2129, -0.3704,  ..., -0.5118, -0.7507,  0.8750])\n",
      "shameless\n",
      "Saved the embedding for shameless.\n",
      "['sharp'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2961, -0.1658, -0.9386,  ..., -0.4515, -0.0552,  0.4491])\n",
      "sharp\n",
      "Saved the embedding for sharp.\n",
      "['sheep', '##ish'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2367,  0.1461,  0.1277,  ..., -0.4450, -0.5603,  0.5914])\n",
      "sheepish\n",
      "Saved the embedding for sheepish.\n",
      "['sheep', '##ish', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2378,  0.3093,  0.0133,  ..., -0.9836, -0.4516,  0.5977])\n",
      "sheepishness\n",
      "Saved the embedding for sheepishness.\n",
      "['shell', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0165,  0.1862, -0.0761,  ..., -0.3929, -0.6814,  0.5313])\n",
      "shelled\n",
      "Saved the embedding for shelled.\n",
      "['shift', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1030,  0.1571,  0.1495,  ..., -0.9214, -0.9312,  0.7035])\n",
      "shifty\n",
      "Saved the embedding for shifty.\n",
      "['shock'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2614, -0.6653,  0.2413,  ..., -0.4501, -0.5788,  0.8618])\n",
      "shock\n",
      "Saved the embedding for shock.\n",
      "['shocked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2141, -0.1140, -0.2831,  ..., -0.3667, -0.4316,  0.9666])\n",
      "shocked\n",
      "Saved the embedding for shocked.\n",
      "['shocking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1489, -0.0430, -0.0431,  ..., -0.6923, -0.2636,  0.3903])\n",
      "shocking\n",
      "Saved the embedding for shocking.\n",
      "['shocking', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0828,  0.8118,  0.4627,  ..., -0.7412, -0.5903,  0.7808])\n",
      "shockingly\n",
      "Saved the embedding for shockingly.\n",
      "['shook'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3158,  0.4723,  0.4386,  ..., -0.2827, -0.5609,  0.9530])\n",
      "shook\n",
      "Saved the embedding for shook.\n",
      "['shout'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1217, -0.4416, -0.3536,  ..., -1.0909, -0.3883,  0.2123])\n",
      "shout\n",
      "Saved the embedding for shout.\n",
      "['shouting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0193,  0.5489,  0.6114,  ..., -0.2498, -0.0465,  0.5198])\n",
      "shouting\n",
      "Saved the embedding for shouting.\n",
      "['sh', '##rew', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4795, -0.0887, -0.1770,  ..., -1.0926, -0.6132,  0.2842])\n",
      "shrewd\n",
      "Saved the embedding for shrewd.\n",
      "['shy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3842, -0.1599,  0.4337,  ..., -0.2318, -1.3577,  0.4236])\n",
      "shy\n",
      "Saved the embedding for shy.\n",
      "['shy', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0456,  0.2007, -0.2212,  ..., -0.9535, -0.9043,  0.9916])\n",
      "shyness\n",
      "Saved the embedding for shyness.\n",
      "['sick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1371,  0.2534, -0.0445,  ..., -1.0605,  0.5591, -0.0149])\n",
      "sick\n",
      "Saved the embedding for sick.\n",
      "['sick', '##en'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-7.3525e-04,  1.4887e-01,  2.3991e-01,  ..., -1.0716e+00,\n",
      "         2.4481e-01,  3.8579e-01])\n",
      "sicken\n",
      "Saved the embedding for sicken.\n",
      "['sick', '##ened'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1757,  0.3641,  0.5239,  ..., -0.4504,  0.0690,  0.6532])\n",
      "sickened\n",
      "Saved the embedding for sickened.\n",
      "['sigh'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0817, -0.0985,  0.4461,  ..., -0.3978,  0.1433, -0.0560])\n",
      "sigh\n",
      "Saved the embedding for sigh.\n",
      "['silenced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3412, -0.1490,  0.0946,  ..., -0.6027, -0.3653,  0.1233])\n",
      "silenced\n",
      "Saved the embedding for silenced.\n",
      "['silent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2101,  0.3927, -0.0744,  ...,  0.0776, -0.2736, -0.0008])\n",
      "silent\n",
      "Saved the embedding for silent.\n",
      "['si', '##llin', '##ess'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7681, -0.1087,  0.2003,  ..., -0.4734, -0.8424,  1.1700])\n",
      "silliness\n",
      "Saved the embedding for silliness.\n",
      "['silly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3594,  0.2932, -0.2151,  ..., -0.1244, -0.4436,  0.4246])\n",
      "silly\n",
      "Saved the embedding for silly.\n",
      "['sim', '##mering'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5780,  0.0485,  0.1127,  ..., -0.6026,  0.2515,  0.4846])\n",
      "simmering\n",
      "Saved the embedding for simmering.\n",
      "['sim', '##per'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2910,  0.4104,  0.0252,  ..., -0.3420, -0.1123,  0.5955])\n",
      "simper\n",
      "Saved the embedding for simper.\n",
      "['sim', '##per', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5744,  0.2223,  0.4761,  ..., -0.5295,  0.1485,  0.5812])\n",
      "simpering\n",
      "Saved the embedding for simpering.\n",
      "['simple'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2913,  0.4586, -1.0451,  ..., -0.6121,  0.1902,  1.1908])\n",
      "simple\n",
      "Saved the embedding for simple.\n",
      "['simplicity'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0197, -0.0849, -0.2044,  ..., -0.5945,  0.1658,  0.6271])\n",
      "simplicity\n",
      "Saved the embedding for simplicity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sincere'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1855,  0.4497,  0.1735,  ..., -0.0393, -0.1804,  0.9481])\n",
      "sincere\n",
      "Saved the embedding for sincere.\n",
      "['sin', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4119,  0.2557,  0.2197,  ..., -1.0336, -0.0423,  0.3371])\n",
      "sinful\n",
      "Saved the embedding for sinful.\n",
      "['singing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3853,  0.2555, -0.0112,  ..., -0.6633,  0.6852,  0.1082])\n",
      "singing\n",
      "Saved the embedding for singing.\n",
      "['sinister'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0748,  0.0248,  0.8027,  ..., -0.4077, -0.6662,  0.1496])\n",
      "sinister\n",
      "Saved the embedding for sinister.\n",
      "['sinister', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1589, -0.0696,  0.8148,  ..., -0.7665, -0.6535,  1.0098])\n",
      "sinisterly\n",
      "Saved the embedding for sinisterly.\n",
      "['si', '##zing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4322,  0.5928,  0.4869,  ...,  0.3752, -0.5098,  1.5878])\n",
      "sizing\n",
      "Saved the embedding for sizing.\n",
      "['sk', '##ept', '##ic'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1920,  0.0494,  0.4531,  ..., -0.0237, -0.5434,  0.5922])\n",
      "skeptic\n",
      "Saved the embedding for skeptic.\n",
      "['skeptical'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4723,  0.2138,  0.0943,  ..., -0.6068, -0.9096,  0.7465])\n",
      "skeptical\n",
      "Saved the embedding for skeptical.\n",
      "['skeptical', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2214,  0.7405, -0.4889,  ..., -0.8990, -0.7548,  0.3010])\n",
      "skeptically\n",
      "Saved the embedding for skeptically.\n",
      "['skepticism'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0055,  0.8152,  0.0377,  ..., -0.9124, -0.4059,  1.0614])\n",
      "skepticism\n",
      "Saved the embedding for skepticism.\n",
      "['sketch', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0911,  0.0423,  0.4164,  ..., -0.9243, -0.8932,  0.8340])\n",
      "sketchy\n",
      "Saved the embedding for sketchy.\n",
      "['ski', '##tti', '##sh'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0151, -0.2470,  0.2784,  ...,  0.3613, -0.1064,  0.7154])\n",
      "skittish\n",
      "Saved the embedding for skittish.\n",
      "['slack'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6415,  0.3586, -0.6421,  ..., -0.2383, -0.3371,  0.8122])\n",
      "slack\n",
      "Saved the embedding for slack.\n",
      "['sl', '##ea', '##zy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6644,  0.0352,  0.7166,  ..., -1.1549, -0.2488,  1.1631])\n",
      "sleazy\n",
      "Saved the embedding for sleazy.\n",
      "['sleepy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4940, -0.1472,  0.2007,  ..., -0.2124, -0.2033,  0.6529])\n",
      "sleepy\n",
      "Saved the embedding for sleepy.\n",
      "['slick'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2854,  0.5287, -0.0143,  ..., -0.9350, -0.0985,  1.0842])\n",
      "slick\n",
      "Saved the embedding for slick.\n",
      "['slot', '##h', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2197,  0.4402,  0.7853,  ..., -1.6030,  0.3115,  0.0636])\n",
      "slothful\n",
      "Saved the embedding for slothful.\n",
      "['slow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0295,  0.0395,  0.0604,  ..., -0.6767,  0.2060,  0.2438])\n",
      "slow\n",
      "Saved the embedding for slow.\n",
      "['slug', '##gis', '##h'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2122,  0.3301,  0.0012,  ...,  0.1759, -0.6102,  0.5979])\n",
      "sluggish\n",
      "Saved the embedding for sluggish.\n",
      "['sly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4583, -0.0507, -0.1272,  ..., -1.4103,  0.2111,  0.6380])\n",
      "sly\n",
      "Saved the embedding for sly.\n",
      "['sm', '##arm', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3409, -0.2849,  0.4478,  ..., -0.4210, -0.3474,  0.6428])\n",
      "smarmy\n",
      "Saved the embedding for smarmy.\n",
      "['smart'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2327, -0.1389,  0.6955,  ..., -0.7984, -0.6437,  1.0315])\n",
      "smart\n",
      "Saved the embedding for smart.\n",
      "['smashed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2387,  0.0091,  0.0119,  ..., -0.5789, -0.0041,  0.1564])\n",
      "smashed\n",
      "Saved the embedding for smashed.\n",
      "['smile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7568, -0.3698,  0.1835,  ..., -0.1562,  0.1903,  1.2147])\n",
      "smile\n",
      "Saved the embedding for smile.\n",
      "['smiley'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1829, -0.2550, -0.2035,  ..., -0.1093, -0.3090,  1.5497])\n",
      "smiley\n",
      "Saved the embedding for smiley.\n",
      "['smiling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0547, -0.4155, -0.0572,  ..., -0.0644, -0.2275,  0.7476])\n",
      "smiling\n",
      "Saved the embedding for smiling.\n",
      "['smirk'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3691,  0.1112, -0.3845,  ..., -0.7902, -0.4366, -0.0566])\n",
      "smirk\n",
      "Saved the embedding for smirk.\n",
      "['smirk', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3454,  0.1608,  0.1301,  ..., -0.7855,  0.0054, -0.4833])\n",
      "smirking\n",
      "Saved the embedding for smirking.\n",
      "['sm', '##old', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.7558, -0.3335, -1.0855,  ..., -1.4950, -0.7199,  0.5061])\n",
      "smoldering\n",
      "Saved the embedding for smoldering.\n",
      "['sm', '##oo', '##ching'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0642,  0.4112,  0.7364,  ..., -0.3645, -0.3166,  0.7335])\n",
      "smooching\n",
      "Saved the embedding for smooching.\n",
      "['smooth'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5044, -0.2691,  0.0809,  ..., -0.7300, -0.4300,  0.3015])\n",
      "smooth\n",
      "Saved the embedding for smooth.\n",
      "['smug'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1380,  0.1510,  0.4928,  ..., -0.2139, -0.3670,  0.8833])\n",
      "smug\n",
      "Saved the embedding for smug.\n",
      "['smug', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1092,  0.1134,  0.0721,  ..., -1.4004, -0.8632,  0.6307])\n",
      "smugness\n",
      "Saved the embedding for smugness.\n",
      "['snake'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2672,  0.8122, -1.0047,  ..., -0.0421, -0.2968,  0.6227])\n",
      "snake\n",
      "Saved the embedding for snake.\n",
      "['snap', '##py'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0357, -0.5240,  0.1270,  ..., -0.7832,  0.0346,  0.3441])\n",
      "snappy\n",
      "Saved the embedding for snappy.\n",
      "['s', '##nar', '##ky'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1958, -0.0450,  0.1621,  ..., -1.1310, -1.1690,  0.5670])\n",
      "snarky\n",
      "Saved the embedding for snarky.\n",
      "['snarl'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3442,  0.2678,  0.0165,  ..., -0.4671, -0.2829,  0.4743])\n",
      "snarl\n",
      "Saved the embedding for snarl.\n",
      "['snarled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0250,  0.2446, -0.5271,  ..., -0.7671, -0.5234,  0.3579])\n",
      "snarled\n",
      "Saved the embedding for snarled.\n",
      "['snarl', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1763, -0.0248,  0.2214,  ..., -0.7928, -0.3869,  0.0632])\n",
      "snarling\n",
      "Saved the embedding for snarling.\n",
      "['snarl', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3519,  0.2002,  0.3359,  ..., -0.4343, -0.7776, -0.1956])\n",
      "snarly\n",
      "Saved the embedding for snarly.\n",
      "['sneak', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0645, -0.4993,  0.3698,  ..., -1.1780, -0.5701,  0.3650])\n",
      "sneaky\n",
      "Saved the embedding for sneaky.\n",
      "['s', '##neer'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.7889,  0.1344,  0.0084,  ..., -1.0691, -1.2547,  1.0207])\n",
      "sneer\n",
      "Saved the embedding for sneer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', '##neer', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3907,  0.1769, -1.0123,  ..., -1.5974, -0.9630, -0.0072])\n",
      "sneering\n",
      "Saved the embedding for sneering.\n",
      "['s', '##nee', '##ze'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2045,  0.0846,  0.2003,  ..., -1.0348, -1.1238,  0.4171])\n",
      "sneeze\n",
      "Saved the embedding for sneeze.\n",
      "['s', '##nee', '##zing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4471,  0.0719, -0.3664,  ..., -1.1229, -0.8507, -0.0388])\n",
      "sneezing\n",
      "Saved the embedding for sneezing.\n",
      "['s', '##nick', '##er'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4675,  0.1444, -0.0044,  ..., -0.7076, -0.6424,  0.6758])\n",
      "snicker\n",
      "Saved the embedding for snicker.\n",
      "['s', '##nick', '##ering'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2632, -0.0064,  0.0172,  ..., -1.7584, -0.9909,  0.2495])\n",
      "snickering\n",
      "Saved the embedding for snickering.\n",
      "['s', '##ni', '##de'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.0058,  0.2646, -0.1525,  ..., -0.7500, -1.1452,  0.5226])\n",
      "snide\n",
      "Saved the embedding for snide.\n",
      "['s', '##nig', '##ger', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0808, -0.3413, -0.5672,  ..., -0.3565, -0.9561,  0.3478])\n",
      "sniggering\n",
      "Saved the embedding for sniggering.\n",
      "['s', '##ni', '##vel', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5121, -0.1351, -0.7585,  ..., -1.2729, -1.4593, -0.2047])\n",
      "sniveling\n",
      "Saved the embedding for sniveling.\n",
      "['s', '##nob', '##bis', '##h'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0081,  0.1566, -0.3176,  ..., -0.6906, -0.3725,  0.3770])\n",
      "snobbish\n",
      "Saved the embedding for snobbish.\n",
      "['s', '##nob', '##by'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1452,  0.0039,  0.1549,  ..., -0.7098, -0.6613,  0.3885])\n",
      "snobby\n",
      "Saved the embedding for snobby.\n",
      "['s', '##no', '##ot', '##y'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1308, -0.0455,  0.2519,  ..., -0.1392, -0.5885,  0.3502])\n",
      "snooty\n",
      "Saved the embedding for snooty.\n",
      "['s', '##not', '##ty'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4512,  0.1103, -0.1529,  ..., -1.0225, -0.9528,  0.6110])\n",
      "snotty\n",
      "Saved the embedding for snotty.\n",
      "['soc', '##iable'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3318,  0.6879, -0.0955,  ..., -0.2239, -0.0061,  0.3833])\n",
      "sociable\n",
      "Saved the embedding for sociable.\n",
      "['soft'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3752, -0.1230,  0.4580,  ..., -0.0667,  0.4279,  0.4827])\n",
      "soft\n",
      "Saved the embedding for soft.\n",
      "['solemn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1440,  0.4378,  0.1730,  ..., -0.4956,  0.7726,  0.9736])\n",
      "solemn\n",
      "Saved the embedding for solemn.\n",
      "['sol', '##ici', '##tou', '##s'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1388,  0.3944,  0.2727,  ..., -1.1606, -0.5417,  0.4742])\n",
      "solicitous\n",
      "Saved the embedding for solicitous.\n",
      "['solitary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4569,  0.0594,  1.1759,  ...,  0.1153, -0.1574, -0.1685])\n",
      "solitary\n",
      "Saved the embedding for solitary.\n",
      "['solitude'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6794,  0.5298, -0.1023,  ..., -2.0473, -0.3860,  0.6271])\n",
      "solitude\n",
      "Saved the embedding for solitude.\n",
      "['somber'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4806, -0.6739, -0.5387,  ..., -0.9434, -0.2029, -0.1405])\n",
      "somber\n",
      "Saved the embedding for somber.\n",
      "['somber', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0649,  0.0082,  0.6843,  ..., -0.6987, -0.0382,  0.3268])\n",
      "somberly\n",
      "Saved the embedding for somberly.\n",
      "['so', '##m', '##no', '##lent'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4992, -0.5566,  0.2339,  ..., -0.7979, -0.2787,  0.7549])\n",
      "somnolent\n",
      "Saved the embedding for somnolent.\n",
      "['soothe', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5276,  0.3935,  0.2580,  ..., -0.7322, -0.5439,  1.0198])\n",
      "soothed\n",
      "Saved the embedding for soothed.\n",
      "['sore'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2327,  0.3557, -0.1011,  ..., -0.3318, -0.4284,  0.4794])\n",
      "sore\n",
      "Saved the embedding for sore.\n",
      "['sorrow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0080,  0.3739,  0.2202,  ..., -0.0637, -0.4533,  0.3115])\n",
      "sorrow\n",
      "Saved the embedding for sorrow.\n",
      "['sorrow', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0330,  0.3544,  0.2966,  ..., -0.5799, -0.2216,  0.2424])\n",
      "sorrowful\n",
      "Saved the embedding for sorrowful.\n",
      "['sorry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3830,  0.0473,  0.1493,  ..., -0.2705, -0.7675,  1.4982])\n",
      "sorry\n",
      "Saved the embedding for sorry.\n",
      "['sour'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2144,  0.1983,  0.1002,  ..., -0.4184, -0.4802,  0.3288])\n",
      "sour\n",
      "Saved the embedding for sour.\n",
      "['spaced'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4043,  0.1747, -0.4626,  ..., -0.8996,  0.1194,  0.8951])\n",
      "spaced\n",
      "Saved the embedding for spaced.\n",
      "['spa', '##cing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2164,  0.5213,  0.5005,  ..., -0.2146, -0.4210,  0.4796])\n",
      "spacing\n",
      "Saved the embedding for spacing.\n",
      "['spa', '##stic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6628,  0.4938,  0.6623,  ...,  0.3793, -0.3816,  0.8875])\n",
      "spastic\n",
      "Saved the embedding for spastic.\n",
      "['speaking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5145,  0.4660, -0.1124,  ..., -0.6211, -0.7876,  0.3066])\n",
      "speaking\n",
      "Saved the embedding for speaking.\n",
      "['spec', '##ious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 2.7982e-01,  2.0965e-04,  8.5004e-01,  ..., -1.8607e+00,\n",
      "        -2.5473e-01,  2.0228e-01])\n",
      "specious\n",
      "Saved the embedding for specious.\n",
      "['speculative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3955,  0.1777, -0.3091,  ..., -0.5529, -0.0346, -1.0416])\n",
      "speculative\n",
      "Saved the embedding for speculative.\n",
      "['speechless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2191,  0.3595,  0.2926,  ...,  0.0482,  0.0242,  0.3706])\n",
      "speechless\n",
      "Saved the embedding for speechless.\n",
      "['spent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3199,  0.4831,  0.1098,  ...,  0.0559, -1.2265,  0.5795])\n",
      "spent\n",
      "Saved the embedding for spent.\n",
      "['spirited'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3426,  0.0496,  0.0824,  ..., -0.4144, -0.0812,  0.2876])\n",
      "spirited\n",
      "Saved the embedding for spirited.\n",
      "['spirit', '##less'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0715,  0.3347, -0.1285,  ..., -0.3449,  0.0563,  0.5835])\n",
      "spiritless\n",
      "Saved the embedding for spiritless.\n",
      "['spite'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0170,  0.1746,  0.9276,  ..., -0.6173, -0.2980,  0.8805])\n",
      "spite\n",
      "Saved the embedding for spite.\n",
      "['spite', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4611,  0.6155,  0.2114,  ..., -1.5118, -0.6834,  0.2770])\n",
      "spiteful\n",
      "Saved the embedding for spiteful.\n",
      "['spoiled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1239,  1.0199,  0.1579,  ..., -0.3412, -1.0142,  0.7420])\n",
      "spoiled\n",
      "Saved the embedding for spoiled.\n",
      "['sp', '##ook', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2596,  0.1182,  0.0060,  ..., -0.1841, -0.7842,  0.9329])\n",
      "spooked\n",
      "Saved the embedding for spooked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sq', '##ue', '##ami', '##sh'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1067, -0.0082,  0.2986,  ..., -0.5967, -0.3106,  0.8903])\n",
      "squeamish\n",
      "Saved the embedding for squeamish.\n",
      "['staggered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9806,  0.0551, -0.4051,  ...,  0.7531, -1.1780,  0.6578])\n",
      "staggered\n",
      "Saved the embedding for staggered.\n",
      "['stalker'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0074, -0.1041, -0.3790,  ..., -0.3580,  0.0116,  1.0811])\n",
      "stalker\n",
      "Saved the embedding for stalker.\n",
      "['stare'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5289,  0.0673,  0.8691,  ..., -0.6041, -0.6719,  0.4251])\n",
      "stare\n",
      "Saved the embedding for stare.\n",
      "['staring'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2930,  0.1672, -0.2115,  ..., -0.2238, -0.1107,  1.0636])\n",
      "staring\n",
      "Saved the embedding for staring.\n",
      "['stars', '##tr', '##uck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4300,  0.1354,  0.2744,  ..., -1.0369,  0.0266,  0.2459])\n",
      "starstruck\n",
      "Saved the embedding for starstruck.\n",
      "['started'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0926, -0.0940,  0.7562,  ..., -0.5845, -0.2625,  0.5022])\n",
      "started\n",
      "Saved the embedding for started.\n",
      "['startled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0874, -0.2974, -0.5747,  ..., -0.0919, -0.3525,  0.4434])\n",
      "startled\n",
      "Saved the embedding for startled.\n",
      "['state', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2885,  0.3264,  0.0669,  ..., -1.1661, -1.2655,  0.6702])\n",
      "stately\n",
      "Saved the embedding for stately.\n",
      "['ste', '##ad', '##fast'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4498,  0.0475,  0.3806,  ..., -1.4453, -0.3290,  0.6952])\n",
      "steadfast\n",
      "Saved the embedding for steadfast.\n",
      "['steady'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0506,  0.0798, -0.7199,  ..., -0.5616, -0.0021,  1.3591])\n",
      "steady\n",
      "Saved the embedding for steady.\n",
      "['stealth', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5729, -0.0178,  0.2648,  ..., -1.1261,  0.2624,  0.8491])\n",
      "stealthy\n",
      "Saved the embedding for stealthy.\n",
      "['steamed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2221,  0.4857, -0.7568,  ...,  0.1713,  0.0758,  0.8927])\n",
      "steamed\n",
      "Saved the embedding for steamed.\n",
      "['steaming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1381,  0.0711, -1.3677,  ..., -0.1588, -1.2888,  0.5117])\n",
      "steaming\n",
      "Saved the embedding for steaming.\n",
      "['steel', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1368,  0.3489, -0.3406,  ..., -0.3124, -1.0181,  0.5089])\n",
      "steeling\n",
      "Saved the embedding for steeling.\n",
      "['steel', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0979,  0.4678, -0.5491,  ..., -0.6899, -0.5501,  0.9610])\n",
      "steely\n",
      "Saved the embedding for steely.\n",
      "['stern'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1368,  0.3127, -0.2678,  ..., -0.5604,  0.2947,  0.7497])\n",
      "stern\n",
      "Saved the embedding for stern.\n",
      "['stiff'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1449,  0.2973, -0.2346,  ..., -0.0118, -0.7401,  0.2929])\n",
      "stiff\n",
      "Saved the embedding for stiff.\n",
      "['stifled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1630,  0.7199, -0.2292,  ..., -0.4966, -0.2646,  0.6440])\n",
      "stifled\n",
      "Saved the embedding for stifled.\n",
      "['st', '##if', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.3577, -0.0316,  0.4682,  ..., -0.8789, -0.4236,  0.7493])\n",
      "stifling\n",
      "Saved the embedding for stifling.\n",
      "['still'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7869,  0.1207, -0.5969,  ..., -1.6300,  0.5287,  0.6846])\n",
      "still\n",
      "Saved the embedding for still.\n",
      "['stillness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5472,  0.0764,  0.2797,  ..., -0.2551, -0.6631,  0.5030])\n",
      "stillness\n",
      "Saved the embedding for stillness.\n",
      "['stimulated'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0907,  0.4355, -1.5844,  ..., -0.1129, -0.0388,  0.9467])\n",
      "stimulated\n",
      "Saved the embedding for stimulated.\n",
      "['stink', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0264,  0.6570, -0.4881,  ..., -0.8892, -0.7461,  0.5995])\n",
      "stinky\n",
      "Saved the embedding for stinky.\n",
      "['stirred'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4683, -0.4167, -0.3869,  ..., -1.2993,  0.1714,  0.1186])\n",
      "stirred\n",
      "Saved the embedding for stirred.\n",
      "['st', '##oic'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9438, -0.4423,  0.3052,  ..., -0.7968, -0.1125,  1.3088])\n",
      "stoic\n",
      "Saved the embedding for stoic.\n",
      "['st', '##oic', '##al'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8229,  0.0599,  0.0958,  ..., -0.5233, -0.2827,  1.0180])\n",
      "stoical\n",
      "Saved the embedding for stoical.\n",
      "['st', '##oli', '##d'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7149,  0.0566,  0.7103,  ..., -0.2672,  0.0249,  0.7456])\n",
      "stolid\n",
      "Saved the embedding for stolid.\n",
      "['stone', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4060,  0.5459, -0.1949,  ..., -0.6203,  0.1846, -0.4663])\n",
      "stoned\n",
      "Saved the embedding for stoned.\n",
      "['storm', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4399,  0.1188,  0.0045,  ..., -1.7205, -1.5193,  0.8198])\n",
      "storming\n",
      "Saved the embedding for storming.\n",
      "['stormy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.4129,  0.3956, -0.7133,  ...,  0.2376, -0.5489,  1.2317])\n",
      "stormy\n",
      "Saved the embedding for stormy.\n",
      "['stout'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2667,  0.1856, -0.1244,  ..., -0.1671, -1.0298, -0.1132])\n",
      "stout\n",
      "Saved the embedding for stout.\n",
      "['straight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2525, -0.3479,  0.0555,  ..., -0.8558,  0.1303, -0.3153])\n",
      "straight\n",
      "Saved the embedding for straight.\n",
      "['strained'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0497,  0.5922, -0.1438,  ..., -0.2182, -0.5346,  0.8233])\n",
      "strained\n",
      "Saved the embedding for strained.\n",
      "['strange'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0293,  0.0172, -0.1077,  ..., -0.4501, -0.0974,  1.0176])\n",
      "strange\n",
      "Saved the embedding for strange.\n",
      "['stressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6897, -0.2636, -0.5311,  ..., -0.7943, -0.6139,  0.5246])\n",
      "stressed\n",
      "Saved the embedding for stressed.\n",
      "['stricken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5716,  0.1754, -0.7365,  ..., -0.5171, -0.3687,  0.8130])\n",
      "stricken\n",
      "Saved the embedding for stricken.\n",
      "['strict'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0144,  0.2582,  0.1082,  ...,  0.0946, -0.5370,  0.3017])\n",
      "strict\n",
      "Saved the embedding for strict.\n",
      "['strong'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1211,  0.0164, -0.2300,  ...,  0.3214, -0.6848,  0.9777])\n",
      "strong\n",
      "Saved the embedding for strong.\n",
      "['struck'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.7779e-01,  4.7300e-04, -2.7061e-01,  ..., -6.7503e-01,\n",
      "        -1.2963e-01,  5.5000e-01])\n",
      "struck\n",
      "Saved the embedding for struck.\n",
      "['stubborn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4393, -0.7052,  0.9408,  ..., -0.4777, -0.0694,  0.6695])\n",
      "stubborn\n",
      "Saved the embedding for stubborn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stubborn', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 1.1545e-04,  1.0183e-01,  6.9308e-01,  ..., -1.5619e+00,\n",
      "        -4.5262e-01,  1.8042e+00])\n",
      "stubbornness\n",
      "Saved the embedding for stubbornness.\n",
      "['studio', '##us'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3301,  0.7584,  0.3448,  ...,  0.0123, -0.5465,  0.3770])\n",
      "studious\n",
      "Saved the embedding for studious.\n",
      "['studying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1562,  0.2494,  0.0879,  ..., -0.2843, -0.3875,  0.5940])\n",
      "studying\n",
      "Saved the embedding for studying.\n",
      "['stump', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3548,  0.3448, -0.0608,  ..., -1.4218,  0.3414, -0.3655])\n",
      "stumped\n",
      "Saved the embedding for stumped.\n",
      "['stung'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0920,  0.2823,  0.1740,  ..., -0.4858,  0.0106,  0.2639])\n",
      "stung\n",
      "Saved the embedding for stung.\n",
      "['stunned'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2979,  0.0505,  0.2315,  ..., -0.1102, -0.6680,  0.7531])\n",
      "stunned\n",
      "Saved the embedding for stunned.\n",
      "['stu', '##pe', '##fa', '##ction'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.3637,  0.0930,  0.0115,  ..., -1.1028, -0.7821,  0.6743])\n",
      "stupefaction\n",
      "Saved the embedding for stupefaction.\n",
      "['stu', '##pe', '##fied'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0913, -0.2530,  0.3107,  ..., -1.0676, -0.5879,  0.5532])\n",
      "stupefied\n",
      "Saved the embedding for stupefied.\n",
      "['stu', '##pe', '##fy'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2120, -0.1862,  0.5552,  ..., -1.3134, -0.5642,  0.4589])\n",
      "stupefy\n",
      "Saved the embedding for stupefy.\n",
      "['stupid'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7880,  0.3293, -0.0344,  ..., -0.0348, -0.7369,  0.7098])\n",
      "stupid\n",
      "Saved the embedding for stupid.\n",
      "['stu', '##por', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3674,  0.2855, -0.2389,  ..., -1.4253, -0.5148,  0.9205])\n",
      "stuporous\n",
      "Saved the embedding for stuporous.\n",
      "['su', '##ave'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.0543, -0.3906,  0.1923,  ..., -0.5549, -0.8169,  0.7125])\n",
      "suave\n",
      "Saved the embedding for suave.\n",
      "['subdued'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0281,  0.2606, -0.5480,  ..., -0.4087,  0.3765,  0.0038])\n",
      "subdued\n",
      "Saved the embedding for subdued.\n",
      "['sublime'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1718,  0.3281,  0.1593,  ..., -0.4724,  0.0685,  0.6062])\n",
      "sublime\n",
      "Saved the embedding for sublime.\n",
      "['sub', '##missive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.5404,  0.4014, -0.4328,  ..., -0.8217, -1.3168,  0.0291])\n",
      "submissive\n",
      "Saved the embedding for submissive.\n",
      "['suffering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6838, -0.1250, -0.2693,  ...,  0.4441, -0.2341,  0.4616])\n",
      "suffering\n",
      "Saved the embedding for suffering.\n",
      "['suggest', '##ive'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2885, -0.0434, -0.4731,  ..., -0.7385,  0.2993,  0.0209])\n",
      "suggestive\n",
      "Saved the embedding for suggestive.\n",
      "['sul', '##king'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6167,  0.5864,  0.5419,  ..., -0.9268, -0.4542,  1.0863])\n",
      "sulking\n",
      "Saved the embedding for sulking.\n",
      "['sul', '##ky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2576,  0.7564,  0.2140,  ..., -0.7653, -0.0780,  0.9141])\n",
      "sulky\n",
      "Saved the embedding for sulky.\n",
      "['sul', '##len'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2472, -0.0025,  0.2141,  ..., -1.2070, -0.5895,  1.3098])\n",
      "sullen\n",
      "Saved the embedding for sullen.\n",
      "['sul', '##len', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1268,  0.2492,  0.0451,  ..., -1.2864, -0.5052,  1.0941])\n",
      "sullenness\n",
      "Saved the embedding for sullenness.\n",
      "['sunny'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7815,  0.3649, -0.0293,  ..., -0.0615, -0.4841,  1.3846])\n",
      "sunny\n",
      "Saved the embedding for sunny.\n",
      "['superior'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2488,  0.6255,  0.0888,  ..., -0.4091, -0.3232,  0.5816])\n",
      "superior\n",
      "Saved the embedding for superior.\n",
      "['superiority'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8062,  0.0240, -0.5449,  ..., -0.4315, -0.4317,  0.7894])\n",
      "superiority\n",
      "Saved the embedding for superiority.\n",
      "['suppressed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7353, -0.1275,  0.1765,  ...,  0.0743, -1.0046,  0.5965])\n",
      "suppressed\n",
      "Saved the embedding for suppressed.\n",
      "['suppress', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1809,  0.2264, -0.3721,  ..., -1.3878, -1.3003,  0.3541])\n",
      "suppressing\n",
      "Saved the embedding for suppressing.\n",
      "['suppression'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.8231,  0.2118, -0.3675,  ..., -0.6664, -0.2503,  0.0301])\n",
      "suppression\n",
      "Saved the embedding for suppression.\n",
      "['sure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6784, -0.1299, -0.2719,  ..., -0.7294, -0.4394,  0.9878])\n",
      "sure\n",
      "Saved the embedding for sure.\n",
      "['sur', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0933,  0.4972, -0.0906,  ...,  0.0528, -0.6320,  0.4349])\n",
      "surly\n",
      "Saved the embedding for surly.\n",
      "['surprise'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2311, -0.1904,  0.1872,  ..., -0.7793, -0.4809, -0.1061])\n",
      "surprise\n",
      "Saved the embedding for surprise.\n",
      "['surprised'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3081,  0.2486,  0.2855,  ..., -0.2044, -0.0715,  0.9458])\n",
      "surprised\n",
      "Saved the embedding for surprised.\n",
      "['surprising'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1234,  0.1154, -0.3381,  ...,  0.0706, -0.1133,  0.4418])\n",
      "surprising\n",
      "Saved the embedding for surprising.\n",
      "['surprisingly'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5495,  0.1029, -0.2184,  ..., -0.5422, -0.1289,  0.1106])\n",
      "surprisingly\n",
      "Saved the embedding for surprisingly.\n",
      "['sur', '##re', '##pt', '##iti', '##ous'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.1415,  0.0751, -0.3549,  ..., -0.1302, -0.6520,  0.7992])\n",
      "surreptitious\n",
      "Saved the embedding for surreptitious.\n",
      "['suspect'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0898, -0.0344, -0.2521,  ..., -0.7328, -0.2976,  1.1849])\n",
      "suspect\n",
      "Saved the embedding for suspect.\n",
      "['suspect', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2556,  0.2614,  0.2055,  ..., -0.7837, -0.2566,  0.7274])\n",
      "suspecting\n",
      "Saved the embedding for suspecting.\n",
      "['suspense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1542,  0.8899,  0.4131,  ..., -0.7258,  0.5461, -0.0839])\n",
      "suspense\n",
      "Saved the embedding for suspense.\n",
      "['suspicion'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.7114,  0.0749, -0.0798,  ..., -0.3383, -0.8133,  0.5714])\n",
      "suspicion\n",
      "Saved the embedding for suspicion.\n",
      "['suspicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0911,  0.3693,  0.0525,  ..., -0.9985, -0.3914,  0.7970])\n",
      "suspicious\n",
      "Saved the embedding for suspicious.\n",
      "['suspiciously'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0855, -0.1631,  0.0853,  ..., -0.1922, -0.2085,  0.7381])\n",
      "suspiciously\n",
      "Saved the embedding for suspiciously.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suspicious', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1917, -0.0264, -0.2658,  ..., -0.6181, -0.4556,  0.9894])\n",
      "suspiciousness\n",
      "Saved the embedding for suspiciousness.\n",
      "['sw', '##agger', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1718,  0.1579,  0.0109,  ..., -0.5895, -0.4809,  0.3978])\n",
      "swaggering\n",
      "Saved the embedding for swaggering.\n",
      "['swearing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1839,  0.0138, -0.1400,  ...,  0.3850,  0.0816,  0.9346])\n",
      "swearing\n",
      "Saved the embedding for swearing.\n",
      "['sympathetic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4848,  0.0181, -0.3224,  ..., -0.4505,  0.8966, -0.2290])\n",
      "sympathetic\n",
      "Saved the embedding for sympathetic.\n",
      "['sy', '##mp', '##athi', '##zing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.5158, -0.0890,  0.5287,  ..., -0.2694,  0.1552,  0.6130])\n",
      "sympathizing\n",
      "Saved the embedding for sympathizing.\n",
      "['sympathy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5740,  0.4109,  0.6083,  ..., -0.7101, -0.7962,  1.1912])\n",
      "sympathy\n",
      "Saved the embedding for sympathy.\n",
      "['ta', '##cit', '##urn'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2713,  0.1026,  0.3825,  ..., -1.1309, -0.4812, -0.2322])\n",
      "taciturn\n",
      "Saved the embedding for taciturn.\n",
      "['talk', '##ative'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3810,  0.0308, -0.0036,  ..., -0.4028,  0.4692,  0.1211])\n",
      "talkative\n",
      "Saved the embedding for talkative.\n",
      "['talking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0631, -0.1483,  0.1845,  ..., -0.7563, -0.5047,  1.0530])\n",
      "talking\n",
      "Saved the embedding for talking.\n",
      "['tan', '##tal', '##ized'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3508,  0.1149,  0.4523,  ..., -0.3849, -0.8770,  0.2199])\n",
      "tantalized\n",
      "Saved the embedding for tantalized.\n",
      "['tar', '##t'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0317, -0.1080,  0.3897,  ..., -1.0306, -0.8855,  1.3448])\n",
      "tart\n",
      "Saved the embedding for tart.\n",
      "['taste', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1973,  0.5079,  0.0834,  ..., -0.3364, -0.8830,  0.1327])\n",
      "tasteful\n",
      "Saved the embedding for tasteful.\n",
      "['ta', '##tt', '##ling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3657,  0.2696,  0.1302,  ..., -0.6184, -0.8313,  0.3460])\n",
      "tattling\n",
      "Saved the embedding for tattling.\n",
      "['tau', '##nt'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3237,  0.1989, -0.3432,  ..., -1.1006, -0.5001,  0.4682])\n",
      "taunt\n",
      "Saved the embedding for taunt.\n",
      "['taunting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0027,  0.0471,  0.3632,  ..., -0.2411, -0.0306, -0.3293])\n",
      "taunting\n",
      "Saved the embedding for taunting.\n",
      "['taut'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3667,  0.0427,  0.2332,  ..., -0.8387, -0.8821,  0.0343])\n",
      "taut\n",
      "Saved the embedding for taut.\n",
      "['tear', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1223, -0.1569,  0.5027,  ..., -1.2807, -0.3273,  0.4991])\n",
      "tearful\n",
      "Saved the embedding for tearful.\n",
      "['tear', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4856,  0.0818,  0.5739,  ..., -1.1021, -0.3593,  0.5753])\n",
      "teary\n",
      "Saved the embedding for teary.\n",
      "['tease'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2918,  0.5271,  0.0234,  ..., -0.3841,  0.1924,  0.3869])\n",
      "tease\n",
      "Saved the embedding for tease.\n",
      "['teasing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4823,  1.1016, -0.1473,  ..., -0.6916, -0.0889,  0.5114])\n",
      "teasing\n",
      "Saved the embedding for teasing.\n",
      "['tempered'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1771,  0.1866,  0.4385,  ..., -0.2866,  0.5120,  1.0488])\n",
      "tempered\n",
      "Saved the embedding for tempered.\n",
      "['tempest'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1064,  0.4185,  0.0968,  ...,  0.1255, -0.1843,  0.1895])\n",
      "tempest\n",
      "Saved the embedding for tempest.\n",
      "['tempest', '##uous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1459,  0.5770,  0.7174,  ..., -0.0282,  0.1241,  0.8924])\n",
      "tempestuous\n",
      "Saved the embedding for tempestuous.\n",
      "['tempted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4960,  0.0694, -0.1264,  ..., -0.1517, -0.5237,  0.2812])\n",
      "tempted\n",
      "Saved the embedding for tempted.\n",
      "['ten', '##acious'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2228,  0.7179,  0.2665,  ..., -1.2079, -0.9197,  0.7872])\n",
      "tenacious\n",
      "Saved the embedding for tenacious.\n",
      "['tender'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2458,  0.5388,  0.2047,  ..., -0.6971,  0.2157,  0.1678])\n",
      "tender\n",
      "Saved the embedding for tender.\n",
      "['tenderness'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1938,  0.3530,  0.2752,  ...,  0.5034,  0.3375,  0.3762])\n",
      "tenderness\n",
      "Saved the embedding for tenderness.\n",
      "['tense'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2748, -0.3023,  0.1434,  ...,  0.1304, -0.3932,  0.3563])\n",
      "tense\n",
      "Saved the embedding for tense.\n",
      "['tensed'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6849,  0.1226, -0.2576,  ..., -0.2853, -0.7760,  0.8560])\n",
      "tensed\n",
      "Saved the embedding for tensed.\n",
      "['tension'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2866,  0.1332, -0.0053,  ..., -0.9946, -0.1371,  0.2285])\n",
      "tension\n",
      "Saved the embedding for tension.\n",
      "['tentative'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0314,  0.7028, -0.2351,  ...,  0.0600, -0.2498,  0.9027])\n",
      "tentative\n",
      "Saved the embedding for tentative.\n",
      "['terrified'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0363, -0.0119, -0.4862,  ..., -0.9131, -0.0666,  0.0435])\n",
      "terrified\n",
      "Saved the embedding for terrified.\n",
      "['terror'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6363, -0.6543, -0.1279,  ..., -0.3904, -0.6210,  0.9960])\n",
      "terror\n",
      "Saved the embedding for terror.\n",
      "['terror', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6547, -0.1645,  0.3312,  ..., -0.1561, -0.4659,  1.0046])\n",
      "terrorized\n",
      "Saved the embedding for terrorized.\n",
      "['terror', '##izing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2807, -0.3324, -0.0747,  ..., -0.5361, -0.8121,  0.5822])\n",
      "terrorizing\n",
      "Saved the embedding for terrorizing.\n",
      "['ter', '##se'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2759, -0.1001,  0.2545,  ..., -1.5647, -0.1411, -0.2407])\n",
      "terse\n",
      "Saved the embedding for terse.\n",
      "['test', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6907, -0.0196, -0.3235,  ...,  0.0145, -0.6524,  0.2967])\n",
      "testy\n",
      "Saved the embedding for testy.\n",
      "['te', '##tch', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2739,  0.0603,  0.3410,  ..., -0.9649, -1.1788,  0.4868])\n",
      "tetchy\n",
      "Saved the embedding for tetchy.\n",
      "['thankful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1462, -0.5245,  0.0196,  ..., -0.3545, -0.9061,  0.5214])\n",
      "thankful\n",
      "Saved the embedding for thankful.\n",
      "['thinking'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6375,  0.2330,  0.1579,  ...,  0.2578, -0.9757,  0.6725])\n",
      "thinking\n",
      "Saved the embedding for thinking.\n",
      "['thought'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1172,  0.6910,  0.0075,  ...,  0.4994, -1.0563,  0.7232])\n",
      "thought\n",
      "Saved the embedding for thought.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thoughtful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3182, -0.3995, -0.4160,  ..., -0.4334, -0.7698,  0.8394])\n",
      "thoughtful\n",
      "Saved the embedding for thoughtful.\n",
      "['thoughtful', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2649,  0.2980,  0.2432,  ..., -0.6108, -0.3470,  0.7709])\n",
      "thoughtfulness\n",
      "Saved the embedding for thoughtfulness.\n",
      "['threat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2650,  0.2609, -0.0364,  ..., -0.5473, -0.6763,  0.3133])\n",
      "threat\n",
      "Saved the embedding for threat.\n",
      "['threatened'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2250,  0.3403, -0.7477,  ..., -0.2263, -0.6743,  0.8661])\n",
      "threatened\n",
      "Saved the embedding for threatened.\n",
      "['threatening'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0337, -0.5175,  0.3720,  ..., -0.8087, -0.5153,  0.4605])\n",
      "threatening\n",
      "Saved the embedding for threatening.\n",
      "['thrilled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7453, -0.1389,  0.3939,  ..., -0.0269, -1.5906,  0.2941])\n",
      "thrilled\n",
      "Saved the embedding for thrilled.\n",
      "['thrown'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2930, -0.2328, -1.4121,  ..., -0.6137, -0.1758,  0.6308])\n",
      "thrown\n",
      "Saved the embedding for thrown.\n",
      "['thunder', '##st', '##ruck'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3808, -0.0760, -0.0804,  ..., -0.1448, -0.2278, -0.4027])\n",
      "thunderstruck\n",
      "Saved the embedding for thunderstruck.\n",
      "['thwarted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3789, -0.0637, -0.4704,  ..., -1.2610, -0.0340,  0.1638])\n",
      "thwarted\n",
      "Saved the embedding for thwarted.\n",
      "['ticked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1044, -0.6668, -0.3676,  ..., -0.1140, -0.5097, -0.2482])\n",
      "ticked\n",
      "Saved the embedding for ticked.\n",
      "['tick', '##led'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4975, -0.0206,  0.2985,  ..., -0.1446,  0.1555,  0.8929])\n",
      "tickled\n",
      "Saved the embedding for tickled.\n",
      "['tied'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([0.0688, 0.4708, 0.6557,  ..., 0.0729, 0.4198, 1.1487])\n",
      "tied\n",
      "Saved the embedding for tied.\n",
      "['tier', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.8726, -0.1833,  0.1414,  ..., -1.5560, -1.0262,  0.5584])\n",
      "tiered\n",
      "Saved the embedding for tiered.\n",
      "['tight'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0617, -0.1012,  0.0517,  ..., -0.8065, -0.2978,  0.7152])\n",
      "tight\n",
      "Saved the embedding for tight.\n",
      "['tight', '##lip', '##ped'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0964,  0.0340, -0.4487,  ..., -1.2573, -1.2969,  0.5129])\n",
      "tightlipped\n",
      "Saved the embedding for tightlipped.\n",
      "['tim', '##id'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4171,  0.3024,  0.2476,  ..., -1.0631, -0.9233,  0.9555])\n",
      "timid\n",
      "Saved the embedding for timid.\n",
      "['tim', '##id', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1723,  0.7091,  0.4552,  ..., -1.0933, -0.2373,  0.0684])\n",
      "timidly\n",
      "Saved the embedding for timidly.\n",
      "['tim', '##id', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2074,  0.3645,  0.3579,  ..., -1.2523, -0.7343,  1.1213])\n",
      "timidness\n",
      "Saved the embedding for timidness.\n",
      "['tired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0278, -0.0563,  0.3247,  ..., -0.3474, -0.5115,  0.7616])\n",
      "tired\n",
      "Saved the embedding for tired.\n",
      "['tired', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0124,  0.2278,  0.4293,  ..., -1.0440, -0.8091,  0.7682])\n",
      "tiredly\n",
      "Saved the embedding for tiredly.\n",
      "['tired', '##ness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-6.3599e-04, -2.5024e-01,  1.1030e-01,  ..., -1.2564e+00,\n",
      "        -1.0897e+00,  1.3932e+00])\n",
      "tiredness\n",
      "Saved the embedding for tiredness.\n",
      "['ti', '##till', '##ated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4168, -0.1130,  0.3756,  ..., -0.2008, -0.4750,  1.1711])\n",
      "titillated\n",
      "Saved the embedding for titillated.\n",
      "['tolerant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0012, -0.0192, -0.8316,  ..., -1.0187,  0.2621,  0.2838])\n",
      "tolerant\n",
      "Saved the embedding for tolerant.\n",
      "['tongue'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3007,  0.2778, -0.2088,  ..., -0.5510, -0.4217,  0.1772])\n",
      "tongue\n",
      "Saved the embedding for tongue.\n",
      "['tormented'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4621, -0.0426,  0.2585,  ..., -1.0612,  0.6283, -0.0827])\n",
      "tormented\n",
      "Saved the embedding for tormented.\n",
      "['touched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0568,  0.8718,  0.2083,  ..., -0.8880, -0.6964,  1.2005])\n",
      "touched\n",
      "Saved the embedding for touched.\n",
      "['tough'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5894, -0.2746,  0.3164,  ...,  0.0702, -0.2814,  0.4439])\n",
      "tough\n",
      "Saved the embedding for tough.\n",
      "['toy', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2913,  0.0274,  0.3252,  ..., -0.6052, -0.6683, -0.0990])\n",
      "toying\n",
      "Saved the embedding for toying.\n",
      "['tragic'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5415, -0.5405, -0.4811,  ..., -0.4746,  0.2273, -0.0487])\n",
      "tragic\n",
      "Saved the embedding for tragic.\n",
      "['tragic', '##al'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2609,  0.0201,  0.1621,  ..., -2.4593,  0.4937, -0.9179])\n",
      "tragical\n",
      "Saved the embedding for tragical.\n",
      "['tran', '##quil'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4170,  0.1458,  1.2056,  ..., -0.8610, -0.6868,  0.6647])\n",
      "tranquil\n",
      "Saved the embedding for tranquil.\n",
      "['tran', '##quil', '##ity'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.8075,  0.2122,  0.9500,  ..., -0.5681, -0.7002,  0.4014])\n",
      "tranquility\n",
      "Saved the embedding for tranquility.\n",
      "['trans', '##fixed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1523,  0.1795, -0.3777,  ..., -1.1053, -0.1427, -0.0397])\n",
      "transfixed\n",
      "Saved the embedding for transfixed.\n",
      "['trauma', '##tized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1658, -0.1167,  0.7625,  ..., -0.9835,  0.4862,  0.0373])\n",
      "traumatized\n",
      "Saved the embedding for traumatized.\n",
      "['trembling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7054,  0.1503,  0.1938,  ...,  0.0021, -0.4583,  0.1162])\n",
      "trembling\n",
      "Saved the embedding for trembling.\n",
      "['tre', '##pid'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0471,  0.1667,  0.5951,  ..., -0.6427, -0.8175,  1.3525])\n",
      "trepid\n",
      "Saved the embedding for trepid.\n",
      "['tre', '##pid', '##ation'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2581,  0.3415,  1.4442,  ..., -0.7982, -0.4434,  0.8458])\n",
      "trepidation\n",
      "Saved the embedding for trepidation.\n",
      "['tricks', '##ter'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2635, -0.0820, -0.4065,  ..., -0.5698, -0.3163,  0.2503])\n",
      "trickster\n",
      "Saved the embedding for trickster.\n",
      "['tricky'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7322,  0.2655,  0.0475,  ...,  0.2826, -0.1854,  1.1543])\n",
      "tricky\n",
      "Saved the embedding for tricky.\n",
      "['triumphant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7519,  0.1171,  0.5540,  ..., -1.8282, -0.1921,  0.3072])\n",
      "triumphant\n",
      "Saved the embedding for triumphant.\n",
      "['troubled'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1251,  0.1468,  0.0948,  ..., -0.4323,  0.0444,  0.6354])\n",
      "troubled\n",
      "Saved the embedding for troubled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['troubles', '##ome'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1222,  0.0161,  0.7258,  ..., -0.5508, -0.3833,  0.7535])\n",
      "troublesome\n",
      "Saved the embedding for troublesome.\n",
      "['tr', '##ou', '##bling'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0821, -0.0253,  0.5277,  ..., -0.8612, -0.2728,  0.7732])\n",
      "troubling\n",
      "Saved the embedding for troubling.\n",
      "['trusting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.1427, -0.1326, -0.5030,  ..., -0.3338, -0.7645,  1.1659])\n",
      "trusting\n",
      "Saved the embedding for trusting.\n",
      "['trust', '##worthy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1769,  0.2195,  0.5270,  ..., -0.6275, -0.2921,  0.6891])\n",
      "trustworthy\n",
      "Saved the embedding for trustworthy.\n",
      "['tu', '##mu', '##lt', '##uous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1909,  0.2077, -0.4625,  ..., -0.8751, -0.8369,  0.3585])\n",
      "tumultuous\n",
      "Saved the embedding for tumultuous.\n",
      "['turbulent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3787, -0.4617, -0.2652,  ...,  0.7613,  0.0958,  1.0571])\n",
      "turbulent\n",
      "Saved the embedding for turbulent.\n",
      "['twin', '##k', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.4544, -0.3062,  0.5574,  ..., -0.5901,  0.3762,  1.5305])\n",
      "twinkly\n",
      "Saved the embedding for twinkly.\n",
      "['um', '##bra', '##ge'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7492,  0.2787, -0.1889,  ..., -0.7826, -0.7107,  0.7455])\n",
      "umbrage\n",
      "Saved the embedding for umbrage.\n",
      "['um', '##bra', '##ge', '##ous'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.1202, -0.1282, -0.1349,  ..., -0.9817, -0.5545,  0.6871])\n",
      "umbrageous\n",
      "Saved the embedding for umbrageous.\n",
      "['unaffected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5464, -0.3371, -0.4039,  ..., -1.2990, -0.0961,  0.3392])\n",
      "unaffected\n",
      "Saved the embedding for unaffected.\n",
      "['una', '##git', '##ated'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3200, -0.1162, -0.0721,  ..., -0.0337, -0.0817,  0.2024])\n",
      "unagitated\n",
      "Saved the embedding for unagitated.\n",
      "['una', '##mus', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2176,  0.0824, -0.2019,  ..., -0.2890, -0.2534,  0.0299])\n",
      "unamused\n",
      "Saved the embedding for unamused.\n",
      "['una', '##pp', '##re', '##cia', '##tive'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.0160,  0.1372,  0.2724,  ...,  0.0018, -0.0521,  0.0081])\n",
      "unappreciative\n",
      "Saved the embedding for unappreciative.\n",
      "['una', '##pp', '##ro', '##ach', '##able'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2686, -0.1445,  0.3795,  ..., -0.5672, -0.5006,  0.3814])\n",
      "unapproachable\n",
      "Saved the embedding for unapproachable.\n",
      "['una', '##sser', '##tive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0110,  0.2232,  0.4462,  ..., -0.2800, -0.1287, -0.2189])\n",
      "unassertive\n",
      "Saved the embedding for unassertive.\n",
      "['una', '##ss', '##uming'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0738, -0.1381,  0.2556,  ..., -0.3472, -0.0015,  0.2454])\n",
      "unassuming\n",
      "Saved the embedding for unassuming.\n",
      "['unaware'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1771,  0.0351,  0.2093,  ..., -0.5587, -0.3161,  0.6391])\n",
      "unaware\n",
      "Saved the embedding for unaware.\n",
      "['un', '##bel', '##ie', '##f'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0928, -0.4364, -0.0928,  ..., -0.3247, -0.8238,  0.4431])\n",
      "unbelief\n",
      "Saved the embedding for unbelief.\n",
      "['unbelievable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1143,  0.0699,  0.6985,  ...,  0.3414, -1.3128,  0.0058])\n",
      "unbelievable\n",
      "Saved the embedding for unbelievable.\n",
      "['un', '##bel', '##ieving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0815, -0.0912, -0.5360,  ..., -1.0436, -0.8436, -0.1117])\n",
      "unbelieving\n",
      "Saved the embedding for unbelieving.\n",
      "['un', '##bot', '##hered'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0416, -0.4258,  0.3127,  ..., -0.2948, -0.0306,  0.1666])\n",
      "unbothered\n",
      "Saved the embedding for unbothered.\n",
      "['un', '##car', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1160,  0.4920, -0.3572,  ...,  0.1110, -0.4218,  0.3232])\n",
      "uncaring\n",
      "Saved the embedding for uncaring.\n",
      "['uncertain'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4984, -0.5639, -0.7869,  ..., -0.9320, -0.4221, -0.5421])\n",
      "uncertain\n",
      "Saved the embedding for uncertain.\n",
      "['uncertain', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2293,  0.5973, -0.1301,  ..., -1.1113, -0.4621,  0.1431])\n",
      "uncertainly\n",
      "Saved the embedding for uncertainly.\n",
      "['uncertainty'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3126,  0.4869, -0.1098,  ..., -0.3857,  0.0027,  0.7012])\n",
      "uncertainty\n",
      "Saved the embedding for uncertainty.\n",
      "['un', '##ci', '##vil'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1879,  0.2087,  0.4241,  ..., -0.4748, -0.0449,  0.8789])\n",
      "uncivil\n",
      "Saved the embedding for uncivil.\n",
      "['uncomfortable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2551, -0.0580, -0.5127,  ..., -0.9275,  0.2133, -0.0554])\n",
      "uncomfortable\n",
      "Saved the embedding for uncomfortable.\n",
      "['un', '##com', '##mit', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-1.3886,  0.0671, -0.3907,  ..., -0.0935,  0.2463, -0.0477])\n",
      "uncommitted\n",
      "Saved the embedding for uncommitted.\n",
      "['un', '##com', '##mun', '##icative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7909, -0.0240,  0.1257,  ..., -0.2296,  0.1925,  0.3236])\n",
      "uncommunicative\n",
      "Saved the embedding for uncommunicative.\n",
      "['un', '##com', '##pre', '##hend', '##ing'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.6044, -0.0336, -0.4816,  ..., -0.1575,  0.1615, -0.2386])\n",
      "uncomprehending\n",
      "Saved the embedding for uncomprehending.\n",
      "['un', '##com', '##promising'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2257,  0.3348, -0.4110,  ..., -0.6131,  0.4956,  0.0529])\n",
      "uncompromising\n",
      "Saved the embedding for uncompromising.\n",
      "['un', '##con', '##cer', '##ned'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8521,  0.1597,  0.3321,  ..., -0.1908,  0.1120,  0.3844])\n",
      "unconcerned\n",
      "Saved the embedding for unconcerned.\n",
      "['un', '##con', '##fide', '##nt'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.6281,  0.3804,  0.1863,  ...,  0.1307, -0.1598,  0.5977])\n",
      "unconfident\n",
      "Saved the embedding for unconfident.\n",
      "['un', '##con', '##vin', '##ced'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3479, -0.0623,  0.0287,  ..., -0.1149,  0.3596, -0.0546])\n",
      "unconvinced\n",
      "Saved the embedding for unconvinced.\n",
      "['un', '##co', '##oper', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0783,  0.0701,  0.1093,  ..., -0.0348, -0.3256,  0.6780])\n",
      "uncooperative\n",
      "Saved the embedding for uncooperative.\n",
      "['un', '##cu', '##rio', '##us'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4846, -0.4435,  0.2579,  ...,  0.0590,  0.2669,  0.5004])\n",
      "uncurious\n",
      "Saved the embedding for uncurious.\n",
      "['und', '##ec', '##ided'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2446,  0.3999,  0.4372,  ..., -0.0455, -0.6392,  0.3697])\n",
      "undecided\n",
      "Saved the embedding for undecided.\n",
      "['under', '##hand', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2235,  0.6723, -0.8035,  ...,  0.0697, -1.1759,  0.7730])\n",
      "underhanded\n",
      "Saved the embedding for underhanded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['understanding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5560,  0.2281,  0.0907,  ..., -0.2438, -0.1638,  0.5212])\n",
      "understanding\n",
      "Saved the embedding for understanding.\n",
      "['und', '##es', '##ira', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0832,  0.4374,  0.2160,  ..., -0.8055, -0.3607,  0.1629])\n",
      "undesirable\n",
      "Saved the embedding for undesirable.\n",
      "['unease'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0998, -0.2231,  0.4580,  ..., -0.2564, -0.9567,  0.0647])\n",
      "unease\n",
      "Saved the embedding for unease.\n",
      "['une', '##asi', '##ly'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3279,  0.5232, -0.3926,  ..., -0.2564,  0.2068,  0.1616])\n",
      "uneasily\n",
      "Saved the embedding for uneasily.\n",
      "['une', '##asi', '##ness'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1741,  0.1321, -0.0291,  ..., -0.2099,  0.0609,  0.5950])\n",
      "uneasiness\n",
      "Saved the embedding for uneasiness.\n",
      "['uneasy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1605, -0.0508, -0.0700,  ..., -0.4205,  0.6606, -0.1050])\n",
      "uneasy\n",
      "Saved the embedding for uneasy.\n",
      "['une', '##mot', '##ional'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.1104,  0.1670,  0.1026,  ..., -0.2344,  0.2546,  0.7213])\n",
      "unemotional\n",
      "Saved the embedding for unemotional.\n",
      "['une', '##nt', '##hus', '##ias', '##tic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.2918,  0.5070,  0.0433,  ..., -0.1621,  0.1910,  0.5425])\n",
      "unenthusiastic\n",
      "Saved the embedding for unenthusiastic.\n",
      "['une', '##x', '##cite', '##d'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8763, -0.1361, -0.4894,  ..., -0.3047, -0.0770,  0.3372])\n",
      "unexcited\n",
      "Saved the embedding for unexcited.\n",
      "['unexpected'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1048,  0.3318,  0.1364,  ..., -1.1686, -0.3609,  0.4731])\n",
      "unexpected\n",
      "Saved the embedding for unexpected.\n",
      "['unfamiliar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-6.1751e-01,  9.9253e-04, -3.6723e-01,  ...,  3.5772e-02,\n",
      "        -8.2397e-02,  1.0384e+00])\n",
      "unfamiliar\n",
      "Saved the embedding for unfamiliar.\n",
      "['un', '##fat', '##hom', '##able'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3232, -0.1830,  0.1113,  ..., -0.5575, -0.1509,  0.4692])\n",
      "unfathomable\n",
      "Saved the embedding for unfathomable.\n",
      "['un', '##fa', '##zed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5067,  0.1816,  0.2194,  ..., -0.8409, -0.0576, -0.1713])\n",
      "unfazed\n",
      "Saved the embedding for unfazed.\n",
      "['un', '##fe', '##elin', '##g'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.0669, -0.2870,  0.4126,  ..., -0.4693, -0.6434,  0.1404])\n",
      "unfeeling\n",
      "Saved the embedding for unfeeling.\n",
      "['un', '##fo', '##cus', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8818, -0.1204, -0.2936,  ...,  0.1529,  0.0743,  0.2704])\n",
      "unfocused\n",
      "Saved the embedding for unfocused.\n",
      "['un', '##for', '##ese', '##en'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2722,  0.0898, -0.2366,  ...,  0.0265, -0.1488,  0.8266])\n",
      "unforeseen\n",
      "Saved the embedding for unforeseen.\n",
      "['un', '##for', '##giving'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.4191, -0.1079,  0.2320,  ...,  0.4879,  0.0899,  0.0811])\n",
      "unforgiving\n",
      "Saved the embedding for unforgiving.\n",
      "['un', '##forth', '##coming'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.1075, -0.2655,  0.0820,  ..., -0.0309,  0.2583,  0.6042])\n",
      "unforthcoming\n",
      "Saved the embedding for unforthcoming.\n",
      "['unfortunate'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5664,  0.2705,  0.0612,  ..., -1.6272, -0.3481, -0.0848])\n",
      "unfortunate\n",
      "Saved the embedding for unfortunate.\n",
      "['un', '##fr', '##ien', '##dly'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3055,  0.1558, -0.8583,  ..., -0.8331, -0.5216, -0.7507])\n",
      "unfriendly\n",
      "Saved the embedding for unfriendly.\n",
      "['unhappy'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2119, -0.2326,  0.6782,  ..., -0.1630, -1.4143, -0.1104])\n",
      "unhappy\n",
      "Saved the embedding for unhappy.\n",
      "['un', '##hing', '##ed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0724,  0.0721, -0.0941,  ..., -0.7355, -0.5504,  0.4509])\n",
      "unhinged\n",
      "Saved the embedding for unhinged.\n",
      "['un', '##im', '##pressed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5959,  0.1399,  0.1594,  ..., -0.7134, -0.0414,  0.1409])\n",
      "unimpressed\n",
      "Saved the embedding for unimpressed.\n",
      "['un', '##in', '##formed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2537, -0.1525, -0.0996,  ...,  0.1774, -0.3608,  0.7888])\n",
      "uninformed\n",
      "Saved the embedding for uninformed.\n",
      "['un', '##ins', '##pired'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7087, -0.1922,  0.2185,  ..., -0.2414, -0.2086,  0.1171])\n",
      "uninspired\n",
      "Saved the embedding for uninspired.\n",
      "['un', '##int', '##eres', '##ted'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3361,  0.1660, -0.2468,  ..., -0.3790, -0.2098,  0.1147])\n",
      "uninterested\n",
      "Saved the embedding for uninterested.\n",
      "['un', '##in', '##vo', '##lved'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.8068, -0.2891, -0.2660,  ..., -0.7370, -0.3337, -0.0535])\n",
      "uninvolved\n",
      "Saved the embedding for uninvolved.\n",
      "['unique'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4329, -0.1662,  0.4470,  ..., -0.2696, -0.9388,  0.0149])\n",
      "unique\n",
      "Saved the embedding for unique.\n",
      "['unlike', '##able'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4542,  0.8675, -0.0183,  ..., -0.0843, -0.7546,  0.5193])\n",
      "unlikeable\n",
      "Saved the embedding for unlikeable.\n",
      "['un', '##mo', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2931,  0.0903,  0.5842,  ..., -0.3875, -0.3837,  0.1351])\n",
      "unmoved\n",
      "Saved the embedding for unmoved.\n",
      "['un', '##ner', '##ved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1017, -0.1484,  0.1760,  ..., -0.6371, -0.1783,  0.0933])\n",
      "unnerved\n",
      "Saved the embedding for unnerved.\n",
      "['unpleasant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5386,  0.1396,  0.2980,  ..., -1.0237,  0.3453,  0.7762])\n",
      "unpleasant\n",
      "Saved the embedding for unpleasant.\n",
      "['un', '##pre', '##par', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.3159, -0.1146,  0.1614,  ..., -0.2400, -0.1696,  0.2102])\n",
      "unprepared\n",
      "Saved the embedding for unprepared.\n",
      "['un', '##qui', '##et'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2998,  0.1692,  0.3090,  ..., -0.0602, -0.0638,  0.3176])\n",
      "unquiet\n",
      "Saved the embedding for unquiet.\n",
      "['un', '##rea', '##ctive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6853,  0.1812,  0.2389,  ..., -0.3450, -0.0244,  0.7403])\n",
      "unreactive\n",
      "Saved the embedding for unreactive.\n",
      "['un', '##res', '##olved'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7205,  0.2288, -0.2372,  ..., -0.1955,  0.1592,  0.5857])\n",
      "unresolved\n",
      "Saved the embedding for unresolved.\n",
      "['unrest', '##rained'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2069,  0.5242, -0.6511,  ..., -0.7687, -0.8589,  0.2057])\n",
      "unrestrained\n",
      "Saved the embedding for unrestrained.\n",
      "['un', '##ruff', '##led'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6340,  0.2551, -0.3423,  ..., -0.0089, -0.3815,  0.7066])\n",
      "unruffled\n",
      "Saved the embedding for unruffled.\n",
      "['un', '##sat', '##is', '##fied'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4634,  0.3390, -0.1070,  ..., -0.0457, -0.6636,  0.0659])\n",
      "unsatisfied\n",
      "Saved the embedding for unsatisfied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un', '##sett', '##led'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0261,  0.2647, -0.1026,  ..., -0.4464, -0.3748,  0.4496])\n",
      "unsettled\n",
      "Saved the embedding for unsettled.\n",
      "['un', '##so', '##cia', '##ble'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.4759,  0.3809, -0.0773,  ..., -0.2787, -0.0619,  0.6059])\n",
      "unsociable\n",
      "Saved the embedding for unsociable.\n",
      "['un', '##sp', '##eak', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1974,  0.2681, -0.1800,  ..., -0.3274, -0.2336,  0.0506])\n",
      "unspeaking\n",
      "Saved the embedding for unspeaking.\n",
      "['unspoken'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3609,  0.5245,  0.2508,  ..., -0.8474, -0.2840, -0.1567])\n",
      "unspoken\n",
      "Saved the embedding for unspoken.\n",
      "['un', '##st', '##run', '##g'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.1195,  0.3059,  0.5138,  ..., -0.0498, -0.3296,  1.3559])\n",
      "unstrung\n",
      "Saved the embedding for unstrung.\n",
      "['unsuccessful'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3429, -0.1612,  0.4885,  ..., -0.5261, -0.3566,  0.8092])\n",
      "unsuccessful\n",
      "Saved the embedding for unsuccessful.\n",
      "['unsure'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0737,  0.1253, -0.0892,  ..., -0.1643,  0.1211,  0.2533])\n",
      "unsure\n",
      "Saved the embedding for unsure.\n",
      "['un', '##sur', '##pr', '##ised'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-1.0636,  0.2871,  0.0253,  ..., -0.5896,  0.0755,  0.3711])\n",
      "unsurprised\n",
      "Saved the embedding for unsurprised.\n",
      "['un', '##sus', '##pe', '##cting'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5183,  0.3462, -0.1312,  ...,  0.2241, -0.0461,  0.1431])\n",
      "unsuspecting\n",
      "Saved the embedding for unsuspecting.\n",
      "['un', '##sw', '##ay', '##ed'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2274, -0.1207,  0.1379,  ..., -0.4045, -0.3187,  0.6561])\n",
      "unswayed\n",
      "Saved the embedding for unswayed.\n",
      "['un', '##sy', '##mp', '##ath', '##etic'] has a token embedding of size torch.Size([5, 12, 768])\n",
      "Shape is: 5 x 3072\n",
      "tensor([-0.6049,  0.4046,  0.5991,  ...,  0.0126, -0.1385,  0.3302])\n",
      "unsympathetic\n",
      "Saved the embedding for unsympathetic.\n",
      "['untouched'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1097,  0.3937, -0.5754,  ..., -1.0546, -0.4742,  0.5240])\n",
      "untouched\n",
      "Saved the embedding for untouched.\n",
      "['un', '##tro', '##ub', '##led'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.7406, -0.0387, -0.1195,  ..., -0.0611,  0.0510,  0.5261])\n",
      "untroubled\n",
      "Saved the embedding for untroubled.\n",
      "['un', '##trust', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2058,  0.2414, -0.1234,  ..., -0.1412, -0.4546,  0.6528])\n",
      "untrusting\n",
      "Saved the embedding for untrusting.\n",
      "['unwanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2123, -0.0389, -0.0162,  ..., -0.6009,  0.6280,  0.8254])\n",
      "unwanted\n",
      "Saved the embedding for unwanted.\n",
      "['un', '##wave', '##ring'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.2295,  0.3203,  0.1584,  ..., -0.8157, -0.8386,  0.6871])\n",
      "unwavering\n",
      "Saved the embedding for unwavering.\n",
      "['un', '##we', '##lco', '##ming'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.5723,  0.3248, -0.1948,  ..., -0.0830, -0.1892,  0.3727])\n",
      "unwelcoming\n",
      "Saved the embedding for unwelcoming.\n",
      "['un', '##well'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2394,  0.4192,  0.5356,  ..., -0.1266, -0.2084,  1.0891])\n",
      "unwell\n",
      "Saved the embedding for unwell.\n",
      "['unwilling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3245,  0.0828,  0.1733,  ...,  0.2142, -0.6176,  0.4323])\n",
      "unwilling\n",
      "Saved the embedding for unwilling.\n",
      "['un', '##yi', '##eld', '##ing'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2687,  0.3850, -0.2132,  ..., -0.1066, -0.0925,  0.3591])\n",
      "unyielding\n",
      "Saved the embedding for unyielding.\n",
      "['up'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6791,  0.0022, -0.3616,  ..., -0.0570, -0.6322,  0.5378])\n",
      "up\n",
      "Saved the embedding for up.\n",
      "['upbeat'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2609,  0.2073, -0.0234,  ..., -0.7959, -0.0320,  0.1790])\n",
      "upbeat\n",
      "Saved the embedding for upbeat.\n",
      "['up', '##lifting'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1998,  0.3249,  0.1526,  ..., -0.6654, -0.9757,  0.7571])\n",
      "uplifting\n",
      "Saved the embedding for uplifting.\n",
      "['up', '##pit', '##y'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-1.3737e-01,  1.9964e-01,  1.0481e-03,  ..., -8.5688e-01,\n",
      "        -1.0699e+00,  6.2197e-01])\n",
      "uppity\n",
      "Saved the embedding for uppity.\n",
      "['upset'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2387, -0.3671, -0.4317,  ...,  0.0100, -1.2358,  0.7784])\n",
      "upset\n",
      "Saved the embedding for upset.\n",
      "['up', '##tight'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1625,  0.2454, -0.1638,  ...,  0.0912, -0.7262,  0.3820])\n",
      "uptight\n",
      "Saved the embedding for uptight.\n",
      "['useless'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2211,  0.3255,  0.4231,  ..., -0.1062, -0.6577,  0.4149])\n",
      "useless\n",
      "Saved the embedding for useless.\n",
      "['vacant'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0361,  0.4417, -0.0959,  ..., -0.8484, -0.6007,  0.6784])\n",
      "vacant\n",
      "Saved the embedding for vacant.\n",
      "['va', '##cu', '##ous'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0031,  0.0345, -0.0842,  ..., -0.5521, -0.5153,  0.3842])\n",
      "vacuous\n",
      "Saved the embedding for vacuous.\n",
      "['van', '##qui', '##shed'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.3628,  0.1295,  0.6941,  ..., -0.4454,  0.0315,  0.8559])\n",
      "vanquished\n",
      "Saved the embedding for vanquished.\n",
      "['ve', '##hem', '##ent'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.0641, -0.0018,  0.1464,  ..., -0.2450, -0.1474,  0.7155])\n",
      "vehement\n",
      "Saved the embedding for vehement.\n",
      "['ve', '##nge', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1499,  0.5401,  0.0121,  ..., -1.4570, -0.5779,  0.2776])\n",
      "vengeful\n",
      "Saved the embedding for vengeful.\n",
      "['venom', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6614,  0.0963, -0.7741,  ..., -0.2618, -0.9882, -0.2451])\n",
      "venomous\n",
      "Saved the embedding for venomous.\n",
      "['ve', '##x'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.1166, -0.0064, -0.1210,  ..., -0.3826, -0.5592,  0.4727])\n",
      "vex\n",
      "Saved the embedding for vex.\n",
      "['ve', '##xa', '##tion'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5824, -0.0562,  0.2499,  ..., -0.2737, -0.7790,  0.5544])\n",
      "vexation\n",
      "Saved the embedding for vexation.\n",
      "['ve', '##xed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-1.1352, -0.5528,  0.1114,  ..., -0.4791, -0.6455,  0.8729])\n",
      "vexed\n",
      "Saved the embedding for vexed.\n",
      "['vicious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3555, -0.0671,  0.4973,  ...,  0.2969, -0.8468,  0.1247])\n",
      "vicious\n",
      "Saved the embedding for vicious.\n",
      "['victorious'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7639, -0.8688,  0.1165,  ..., -0.8386, -0.6933,  0.3839])\n",
      "victorious\n",
      "Saved the embedding for victorious.\n",
      "['vi', '##gil', '##ant'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.1660,  0.1330,  0.8701,  ..., -0.5568, -0.7881,  0.7456])\n",
      "vigilant\n",
      "Saved the embedding for vigilant.\n",
      "['vile'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9517,  0.3549,  0.2824,  ..., -0.5145, -0.3981,  0.3631])\n",
      "vile\n",
      "Saved the embedding for vile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['villain', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0359,  0.5067, -0.0634,  ..., -0.3968, -0.2144,  0.7419])\n",
      "villainous\n",
      "Saved the embedding for villainous.\n",
      "['vin', '##dict', '##ive'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0510, -0.1009,  0.3064,  ..., -0.6174, -0.6857,  0.8834])\n",
      "vindictive\n",
      "Saved the embedding for vindictive.\n",
      "['violence'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5859,  0.0607,  0.8000,  ..., -0.2548,  0.3317,  0.4190])\n",
      "violence\n",
      "Saved the embedding for violence.\n",
      "['violent'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.4578,  0.0196, -0.6937,  ..., -1.6682,  0.4664, -0.7200])\n",
      "violent\n",
      "Saved the embedding for violent.\n",
      "['viper', '##ous'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3890,  0.4372, -0.4146,  ..., -0.9046, -1.0771,  0.8666])\n",
      "viperous\n",
      "Saved the embedding for viperous.\n",
      "['vi', '##tu', '##per', '##ative'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([-0.2150, -0.1469,  0.2809,  ..., -0.6776, -0.4124,  0.8185])\n",
      "vituperative\n",
      "Saved the embedding for vituperative.\n",
      "['vocal'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2710,  0.3723, -0.5284,  ..., -0.3384, -0.3680,  0.3873])\n",
      "vocal\n",
      "Saved the embedding for vocal.\n",
      "['vocal', '##ized'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5566,  0.6378,  0.1558,  ..., -0.2063, -0.5583,  0.8974])\n",
      "vocalized\n",
      "Saved the embedding for vocalized.\n",
      "['vulgar'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6549,  0.6473, -0.4123,  ..., -0.5309, -0.6452,  1.0070])\n",
      "vulgar\n",
      "Saved the embedding for vulgar.\n",
      "['vulnerability'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5661,  0.3216, -0.2794,  ..., -0.6690, -0.7562,  1.0245])\n",
      "vulnerability\n",
      "Saved the embedding for vulnerability.\n",
      "['vulnerable'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.9448,  0.3551, -0.5344,  ...,  0.0293, -0.6664,  0.7309])\n",
      "vulnerable\n",
      "Saved the embedding for vulnerable.\n",
      "['wa', '##cky'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1608, -0.3462,  0.3470,  ..., -1.0701, -0.7005,  0.7129])\n",
      "wacky\n",
      "Saved the embedding for wacky.\n",
      "['waiting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3756, -0.0686,  0.5546,  ..., -0.9719, -0.1189,  0.6808])\n",
      "waiting\n",
      "Saved the embedding for waiting.\n",
      "['wanted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1982,  0.0798,  0.4552,  ..., -0.7589, -0.3584,  0.3033])\n",
      "wanted\n",
      "Saved the embedding for wanted.\n",
      "['wanting'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0181,  0.0165,  0.0671,  ..., -0.4318,  0.5908,  0.3165])\n",
      "wanting\n",
      "Saved the embedding for wanting.\n",
      "['want', '##on'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.6307, -0.0985,  0.2790,  ..., -0.2239, -0.6910,  0.5584])\n",
      "wanton\n",
      "Saved the embedding for wanton.\n",
      "['war', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2232,  0.1073,  0.4303,  ..., -0.4820, -0.6095,  0.9297])\n",
      "wariness\n",
      "Saved the embedding for wariness.\n",
      "['warm'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5451, -0.3064,  0.2748,  ..., -0.5611,  0.3619,  0.3380])\n",
      "warm\n",
      "Saved the embedding for warm.\n",
      "['wary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.3149,  0.1364, -0.6196,  ..., -0.7594, -0.8247,  0.1903])\n",
      "wary\n",
      "Saved the embedding for wary.\n",
      "['wasted'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1059,  0.2130, -0.3336,  ..., -0.5658, -0.5160,  0.4747])\n",
      "wasted\n",
      "Saved the embedding for wasted.\n",
      "['watch'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1765, -0.2653,  0.4328,  ..., -0.4839, -0.2746,  0.5437])\n",
      "watch\n",
      "Saved the embedding for watch.\n",
      "['watch', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0145, -0.1409,  0.4754,  ..., -0.6109, -0.2597,  0.2429])\n",
      "watchful\n",
      "Saved the embedding for watchful.\n",
      "['watching'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0908,  0.1389,  0.1244,  ..., -0.4057, -0.5251,  0.8778])\n",
      "watching\n",
      "Saved the embedding for watching.\n",
      "['wave', '##ring'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0488,  0.3542,  0.2790,  ..., -0.4596, -0.0873,  1.4667])\n",
      "wavering\n",
      "Saved the embedding for wavering.\n",
      "['wear', '##iness'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3942,  0.0707,  0.1539,  ..., -1.0164, -0.7355,  0.5254])\n",
      "weariness\n",
      "Saved the embedding for weariness.\n",
      "['weary'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0761,  0.3943,  0.2890,  ..., -0.6551, -0.2663,  0.3705])\n",
      "weary\n",
      "Saved the embedding for weary.\n",
      "['weeping'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2118,  0.1343, -0.7183,  ..., -1.7956, -0.6808,  0.4243])\n",
      "weeping\n",
      "Saved the embedding for weeping.\n",
      "['weird'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2051,  0.1213,  0.0279,  ..., -0.2854, -0.4728,  1.1116])\n",
      "weird\n",
      "Saved the embedding for weird.\n",
      "['welcome'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.0445, -0.2645, -0.1786,  ..., -0.0020, -1.0077,  0.5458])\n",
      "welcome\n",
      "Saved the embedding for welcome.\n",
      "['welcoming'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.5254,  0.3388, -0.2365,  ...,  0.2424, -0.9157,  0.5469])\n",
      "welcoming\n",
      "Saved the embedding for welcoming.\n",
      "['whatever'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3693,  0.8855, -0.4697,  ..., -0.8426, -0.8690,  0.7592])\n",
      "whatever\n",
      "Saved the embedding for whatever.\n",
      "['whimper', '##ing'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4342,  0.4675, -0.2124,  ..., -1.6151, -0.5235, -0.5332])\n",
      "whimpering\n",
      "Saved the embedding for whimpering.\n",
      "['w', '##him', '##sic', '##al'] has a token embedding of size torch.Size([4, 12, 768])\n",
      "Shape is: 4 x 3072\n",
      "tensor([ 0.0285, -0.0970,  0.1889,  ..., -0.1989, -0.0906,  0.5229])\n",
      "whimsical\n",
      "Saved the embedding for whimsical.\n",
      "['whisper'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0806, -0.3702, -0.0862,  ..., -1.3301, -0.2184,  0.8542])\n",
      "whisper\n",
      "Saved the embedding for whisper.\n",
      "['whistle'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.6432, -0.0919, -0.0416,  ..., -0.0473,  0.4746, -0.0505])\n",
      "whistle\n",
      "Saved the embedding for whistle.\n",
      "['white'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0627, -0.0101, -0.8500,  ..., -1.5403, -0.4634, -0.4122])\n",
      "white\n",
      "Saved the embedding for white.\n",
      "['wicked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.4391,  0.7368,  0.9433,  ..., -0.5602,  0.1271,  0.3963])\n",
      "wicked\n",
      "Saved the embedding for wicked.\n",
      "['wild'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.5474,  0.1819, -0.2885,  ..., -0.3879, -0.1124,  1.3398])\n",
      "wild\n",
      "Saved the embedding for wild.\n",
      "['will', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2350,  0.2107,  0.5959,  ..., -0.2411, -0.3198,  1.2631])\n",
      "willful\n",
      "Saved the embedding for willful.\n",
      "['willing'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-1.5832,  0.1351, -0.1726,  ..., -1.0189, -0.0357,  0.6002])\n",
      "willing\n",
      "Saved the embedding for willing.\n",
      "['wil', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.3064,  0.3867,  0.8070,  ..., -0.7661, -0.2361,  1.1622])\n",
      "wily\n",
      "Saved the embedding for wily.\n",
      "['wink'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1764, -0.0570,  0.2634,  ..., -1.4464, -0.6990,  1.0464])\n",
      "wink\n",
      "Saved the embedding for wink.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wired'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.2667, -0.1433, -0.4547,  ..., -0.4209, -0.0263,  1.1327])\n",
      "wired\n",
      "Saved the embedding for wired.\n",
      "['wish', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1382,  0.2580,  0.3462,  ..., -1.2650, -0.0182,  0.8658])\n",
      "wishful\n",
      "Saved the embedding for wishful.\n",
      "['wi', '##st', '##ful'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.6485, -0.0527,  0.0858,  ..., -1.2290, -0.8816,  0.7261])\n",
      "wistful\n",
      "Saved the embedding for wistful.\n",
      "['wi', '##st', '##fully'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.8708,  0.0314,  0.5018,  ..., -1.0104, -0.5930,  0.6682])\n",
      "wistfully\n",
      "Saved the embedding for wistfully.\n",
      "['withdraw'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1297,  0.1923,  0.0261,  ...,  0.0216, -0.3791,  0.3518])\n",
      "withdraw\n",
      "Saved the embedding for withdraw.\n",
      "['withdrawn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2714, -0.2633, -0.0853,  ..., -0.4003, -0.4832,  0.1152])\n",
      "withdrawn\n",
      "Saved the embedding for withdrawn.\n",
      "['with', '##held'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0578,  0.0420,  0.1909,  ..., -0.9608, -0.8077,  0.3401])\n",
      "withheld\n",
      "Saved the embedding for withheld.\n",
      "['with', '##holding'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.2638,  0.2086,  0.5029,  ..., -0.8086, -0.5948,  0.4194])\n",
      "withholding\n",
      "Saved the embedding for withholding.\n",
      "['wo', '##e'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.5938,  0.5032,  0.2235,  ..., -0.6302, -0.6219,  0.7179])\n",
      "woe\n",
      "Saved the embedding for woe.\n",
      "['wo', '##ef', '##ul'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([ 0.2963,  0.1002,  0.2718,  ..., -0.5348, -0.4966,  0.3086])\n",
      "woeful\n",
      "Saved the embedding for woeful.\n",
      "['wonder'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.2062, -0.0393,  0.3013,  ..., -0.4904, -0.7119,  0.7155])\n",
      "wonder\n",
      "Saved the embedding for wonder.\n",
      "['wondering'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0447,  0.2124,  0.6026,  ..., -0.0461, -0.8212,  0.9288])\n",
      "wondering\n",
      "Saved the embedding for wondering.\n",
      "['wonder', '##ment'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.4564,  0.2364,  0.3317,  ..., -0.8834, -0.4299,  0.5205])\n",
      "wonderment\n",
      "Saved the embedding for wonderment.\n",
      "['wool', '##y'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3263,  0.0370,  0.5284,  ..., -0.0872, -1.1931,  1.0602])\n",
      "wooly\n",
      "Saved the embedding for wooly.\n",
      "['woo', '##zy'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.1199,  0.5358,  0.5567,  ..., -0.7359, -0.8742,  0.8746])\n",
      "woozy\n",
      "Saved the embedding for woozy.\n",
      "['worn'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1374,  0.5614, -0.4460,  ..., -0.1688, -0.8970,  0.4358])\n",
      "worn\n",
      "Saved the embedding for worn.\n",
      "['worried'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.1515,  0.0236,  0.6317,  ..., -0.3613, -1.0342,  0.7046])\n",
      "worried\n",
      "Saved the embedding for worried.\n",
      "['wo', '##rri', '##some'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.0838,  0.3599,  0.4076,  ..., -1.5099, -1.3281,  0.6142])\n",
      "worrisome\n",
      "Saved the embedding for worrisome.\n",
      "['worry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.5354,  0.2745, -0.0383,  ..., -1.0736, -0.2600,  0.4766])\n",
      "worry\n",
      "Saved the embedding for worry.\n",
      "['worrying'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3546,  0.4551,  0.4542,  ..., -1.0131, -0.3194,  1.2030])\n",
      "worrying\n",
      "Saved the embedding for worrying.\n",
      "['worrying', '##ly'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.3902,  0.2295,  0.5191,  ..., -0.9704, -0.9466,  0.4306])\n",
      "worryingly\n",
      "Saved the embedding for worryingly.\n",
      "['wounded'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.8484,  0.5602,  0.4225,  ..., -0.5552, -0.1892,  0.3579])\n",
      "wounded\n",
      "Saved the embedding for wounded.\n",
      "['wow'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1137,  0.2709,  0.5832,  ..., -0.5028, -0.8024,  0.8203])\n",
      "wow\n",
      "Saved the embedding for wow.\n",
      "['wrath', '##ful'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4067,  0.2705, -0.2516,  ..., -1.1214, -0.2000,  1.1775])\n",
      "wrathful\n",
      "Saved the embedding for wrathful.\n",
      "['wrath', '##fully'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.0594,  0.4373,  0.1571,  ..., -0.7052,  0.2743,  0.8869])\n",
      "wrathfully\n",
      "Saved the embedding for wrathfully.\n",
      "['wrecked'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.1255,  0.4710, -0.6222,  ..., -0.8281, -0.2236,  1.3097])\n",
      "wrecked\n",
      "Saved the embedding for wrecked.\n",
      "['wr', '##etched'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.0935,  0.2535,  0.0562,  ..., -0.8781, -1.0028,  0.4025])\n",
      "wretched\n",
      "Saved the embedding for wretched.\n",
      "['wrong', '##ed'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4530,  0.4584, -0.6421,  ..., -1.4149, -1.2858,  1.2173])\n",
      "wronged\n",
      "Saved the embedding for wronged.\n",
      "['wr', '##oth'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.2544,  0.3678,  0.7130,  ..., -1.1355, -0.3554,  0.0453])\n",
      "wroth\n",
      "Saved the embedding for wroth.\n",
      "['wry'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.3485,  0.3889, -0.6632,  ..., -0.8486, -0.2068, -0.3893])\n",
      "wry\n",
      "Saved the embedding for wry.\n",
      "['ya', '##wn'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.9660, -0.1744,  0.2664,  ..., -0.4911, -1.0041,  0.3406])\n",
      "yawn\n",
      "Saved the embedding for yawn.\n",
      "['ya', '##wn', '##ing'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.5883,  0.3198, -0.3986,  ..., -1.0142, -1.4026,  0.1137])\n",
      "yawning\n",
      "Saved the embedding for yawning.\n",
      "['yearning'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.0951,  0.6085, -0.8744,  ..., -0.5039, -0.9832,  0.1922])\n",
      "yearning\n",
      "Saved the embedding for yearning.\n",
      "['yell'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.6594,  0.9001, -0.1894,  ..., -0.9336, -0.4059,  1.1078])\n",
      "yell\n",
      "Saved the embedding for yell.\n",
      "['yelling'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([ 0.3482, -0.2296,  0.6294,  ..., -0.3251,  0.5976,  0.5987])\n",
      "yelling\n",
      "Saved the embedding for yelling.\n",
      "['yielding'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.7278, -0.1782,  0.1558,  ..., -0.7999, -0.5250,  0.5495])\n",
      "yielding\n",
      "Saved the embedding for yielding.\n",
      "['yu', '##ck'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.1252, -0.2216,  0.2844,  ..., -0.0392, -0.4575,  1.1833])\n",
      "yuck\n",
      "Saved the embedding for yuck.\n",
      "['za', '##ny'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([ 0.6845,  0.3567,  0.3976,  ..., -1.0455, -0.3265,  0.7201])\n",
      "zany\n",
      "Saved the embedding for zany.\n",
      "['ze', '##alo', '##us'] has a token embedding of size torch.Size([3, 12, 768])\n",
      "Shape is: 3 x 3072\n",
      "tensor([-0.7219,  0.0134,  0.1706,  ..., -0.8432,  0.1354,  0.3045])\n",
      "zealous\n",
      "Saved the embedding for zealous.\n",
      "['zen'] has a token embedding of size torch.Size([1, 12, 768])\n",
      "Shape is: 1 x 3072\n",
      "tensor([-0.0863, -0.6942,  0.0300,  ..., -0.3105, -0.1136,  0.8786])\n",
      "zen\n",
      "Saved the embedding for zen.\n",
      "['zone', '##d'] has a token embedding of size torch.Size([2, 12, 768])\n",
      "Shape is: 2 x 3072\n",
      "tensor([-0.4793, -0.1249,  0.3823,  ..., -0.8380, -0.7752,  0.3940])\n",
      "zoned\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "# Ok, let's start putting this all together.\n",
    "############################################\n",
    "\n",
    "# Set up input and output paths.\n",
    "vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/vocabulary_embeddings/BERT.txt'\n",
    "if os.path.exists(embeddings_file):\n",
    "    os.remove(embeddings_file)\n",
    "\n",
    "# Create a list of vocabulary words we want embeddings for.\n",
    "vocab = make_vocab(vocab_file)\n",
    "\n",
    "# Tokenize the vocabulary and look up the BERT token indices.\n",
    "tokenized_text, indexed_tokens = tokenize_text(vocab)\n",
    "\n",
    "# Generate segment IDs for each token.\n",
    "segments_IDs = generate_segments_IDs(tokenized_text)\n",
    "\n",
    "# Generate and write out the contextual embeddings for the vocabulary words.\n",
    "# Embeddings are saved in a standard format that can be used for calcualting\n",
    "# the cosine distances between word vectors.\n",
    "for i in range(len(tokenized_text)):\n",
    "    # Convert indexed tokens and segments to tensors.\n",
    "    # Create a BERT model for the tokens.\n",
    "    # Get the encoded model layers and reshape them.\n",
    "    token_embeddings = generate_embeddings(indexed_tokens[i], segments_IDs[i])\n",
    "    print(f'{tokenized_text[i]} has a token embedding of size {token_embeddings.size()}')\n",
    "    \n",
    "    # Extract the contextual embedding for a token.\n",
    "    contextual_embedding = cat_last_four(token_embeddings)\n",
    "    \n",
    "    # Write the embedding to a text file, with the vocabulary word prepended.\n",
    "    vocab_word = reconstruct_tokens(tokenized_text[i])\n",
    "    # Make sure we've got the correct vocabulary word.\n",
    "    assert vocab[i] == vocab_word\n",
    "    write_embedding(embeddings_file, vocab[i], contextual_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(indexed_tokens, segments_IDs):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_IDs])\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "#         print('Type of encoded_layers: ', type(encoded_layers))\n",
    "        # Each layer in the list is a torch tensor.\n",
    "#         print('Tensor shape for each layer: ', encoded_layers[0].size())\n",
    "\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "#     print(token_embeddings.size())\n",
    "\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "#     print(token_embeddings.size())\n",
    "    \n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_last_four(token_embeddings): \n",
    "    # Concatenate the last 4 hidden layers to create contextual embeddings.\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat_last = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat_last.append(cat_vec)\n",
    "\n",
    "    print ('Shape is: %d x %d' % (len(token_vecs_cat_last), len(token_vecs_cat_last[0])))\n",
    "    print(token_vecs_cat_last[0])\n",
    "    \n",
    "    return token_vecs_cat_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_embedding(token_embeddings):\n",
    "    mean_embedding = sum(token_embeddings) / len(token_embeddings)\n",
    "    print(mean_embedding)\n",
    "    \n",
    "    return mean_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_tokens(tokenized_text):\n",
    "    vocab_word = ''\n",
    "    for i in tokenized_text:\n",
    "        vocab_word += i.strip('#')\n",
    "    print(vocab_word)\n",
    "\n",
    "    return vocab_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_embedding(embeddings_file, vocab_word, contextual_embedding):\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(vocab_word)\n",
    "            for value in contextual_embedding[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {vocab_word}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of ['absent'] and ['absent'] in token_vecs_cat is: 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# Test the similarity of a word with itself.\n",
    "# For words trained contextually, self-synonymy is less than 1.\n",
    "similarity = 1 - cosine(token_vecs_cat[0], token_vecs_cat[0])\n",
    "print(f'Similarity of {tokenized_text[8]} and {tokenized_text[8]} in token_vecs_cat is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum[4], token_vecs_sum[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_first[4], token_vecs_cat_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_first[4], token_vecs_sum_first[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_first is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle1[4], token_vecs_cat_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle1[4], token_vecs_sum_middle1[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle1 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_middle2[4], token_vecs_cat_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_middle2[4], token_vecs_sum_middle2[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_middle2 is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_cat_all[4], token_vecs_cat_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_cat_all is: {similarity}')\n",
    "# similarity = 1 - cosine(token_vecs_sum_all[4], token_vecs_sum_all[9])\n",
    "# print(f'Similarity of {tokenized_text[4]} and {tokenized_text[9]} in token_vecs_sum_all is: {similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
